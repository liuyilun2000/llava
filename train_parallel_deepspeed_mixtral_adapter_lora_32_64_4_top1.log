[2024-09-01 22:53:33,958] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-01 22:53:38,671] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2024-09-01 22:53:38,671] [INFO] [runner.py:568:main] cmd = /home/hpc/b207dd/b207dd11/miniconda3/envs/py38/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None llava/train_parallel_deepspeed_mixtral_adapter_r.py --num_stages=8 --shared_routing_adapter_num_experts=4 --shared_routing_adapter_num_experts_per_tok=1 --shared_routing_adapter_type=LoRA --lora_r=32 --lora_alpha=64 --save_model_shard=112 --skip_shard=4800 --bf16=True --lr=1e-5 --checkpoint_dir=/home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint
[2024-09-01 22:53:41,426] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-01 22:53:42,950] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]}
[2024-09-01 22:53:42,950] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=8, node_rank=0
[2024-09-01 22:53:42,950] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]})
[2024-09-01 22:53:42,950] [INFO] [launch.py:163:main] dist_world_size=8
[2024-09-01 22:53:42,950] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
[2024-09-01 22:53:42,961] [INFO] [launch.py:253:main] process 3572914 spawned with command: ['/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/bin/python', '-u', 'llava/train_parallel_deepspeed_mixtral_adapter_r.py', '--local_rank=0', '--num_stages=8', '--shared_routing_adapter_num_experts=4', '--shared_routing_adapter_num_experts_per_tok=1', '--shared_routing_adapter_type=LoRA', '--lora_r=32', '--lora_alpha=64', '--save_model_shard=112', '--skip_shard=4800', '--bf16=True', '--lr=1e-5', '--checkpoint_dir=/home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint']
[2024-09-01 22:53:42,969] [INFO] [launch.py:253:main] process 3572915 spawned with command: ['/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/bin/python', '-u', 'llava/train_parallel_deepspeed_mixtral_adapter_r.py', '--local_rank=1', '--num_stages=8', '--shared_routing_adapter_num_experts=4', '--shared_routing_adapter_num_experts_per_tok=1', '--shared_routing_adapter_type=LoRA', '--lora_r=32', '--lora_alpha=64', '--save_model_shard=112', '--skip_shard=4800', '--bf16=True', '--lr=1e-5', '--checkpoint_dir=/home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint']
[2024-09-01 22:53:42,977] [INFO] [launch.py:253:main] process 3572916 spawned with command: ['/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/bin/python', '-u', 'llava/train_parallel_deepspeed_mixtral_adapter_r.py', '--local_rank=2', '--num_stages=8', '--shared_routing_adapter_num_experts=4', '--shared_routing_adapter_num_experts_per_tok=1', '--shared_routing_adapter_type=LoRA', '--lora_r=32', '--lora_alpha=64', '--save_model_shard=112', '--skip_shard=4800', '--bf16=True', '--lr=1e-5', '--checkpoint_dir=/home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint']
[2024-09-01 22:53:42,990] [INFO] [launch.py:253:main] process 3572917 spawned with command: ['/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/bin/python', '-u', 'llava/train_parallel_deepspeed_mixtral_adapter_r.py', '--local_rank=3', '--num_stages=8', '--shared_routing_adapter_num_experts=4', '--shared_routing_adapter_num_experts_per_tok=1', '--shared_routing_adapter_type=LoRA', '--lora_r=32', '--lora_alpha=64', '--save_model_shard=112', '--skip_shard=4800', '--bf16=True', '--lr=1e-5', '--checkpoint_dir=/home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint']
[2024-09-01 22:53:43,002] [INFO] [launch.py:253:main] process 3572918 spawned with command: ['/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/bin/python', '-u', 'llava/train_parallel_deepspeed_mixtral_adapter_r.py', '--local_rank=4', '--num_stages=8', '--shared_routing_adapter_num_experts=4', '--shared_routing_adapter_num_experts_per_tok=1', '--shared_routing_adapter_type=LoRA', '--lora_r=32', '--lora_alpha=64', '--save_model_shard=112', '--skip_shard=4800', '--bf16=True', '--lr=1e-5', '--checkpoint_dir=/home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint']
[2024-09-01 22:53:43,015] [INFO] [launch.py:253:main] process 3572919 spawned with command: ['/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/bin/python', '-u', 'llava/train_parallel_deepspeed_mixtral_adapter_r.py', '--local_rank=5', '--num_stages=8', '--shared_routing_adapter_num_experts=4', '--shared_routing_adapter_num_experts_per_tok=1', '--shared_routing_adapter_type=LoRA', '--lora_r=32', '--lora_alpha=64', '--save_model_shard=112', '--skip_shard=4800', '--bf16=True', '--lr=1e-5', '--checkpoint_dir=/home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint']
[2024-09-01 22:53:43,027] [INFO] [launch.py:253:main] process 3572920 spawned with command: ['/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/bin/python', '-u', 'llava/train_parallel_deepspeed_mixtral_adapter_r.py', '--local_rank=6', '--num_stages=8', '--shared_routing_adapter_num_experts=4', '--shared_routing_adapter_num_experts_per_tok=1', '--shared_routing_adapter_type=LoRA', '--lora_r=32', '--lora_alpha=64', '--save_model_shard=112', '--skip_shard=4800', '--bf16=True', '--lr=1e-5', '--checkpoint_dir=/home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint']
[2024-09-01 22:53:43,035] [INFO] [launch.py:253:main] process 3572921 spawned with command: ['/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/bin/python', '-u', 'llava/train_parallel_deepspeed_mixtral_adapter_r.py', '--local_rank=7', '--num_stages=8', '--shared_routing_adapter_num_experts=4', '--shared_routing_adapter_num_experts_per_tok=1', '--shared_routing_adapter_type=LoRA', '--lora_r=32', '--lora_alpha=64', '--save_model_shard=112', '--skip_shard=4800', '--bf16=True', '--lr=1e-5', '--checkpoint_dir=/home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint']
[2024-09-01 22:54:00,033] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-01 22:54:00,033] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-01 22:54:01,409] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-09-01 22:54:04,580] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-01 22:54:05,050] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-09-01 22:54:11,163] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-09-01 22:54:11,949] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-01 22:54:12,392] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-09-01 22:54:12,774] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-01 22:54:13,236] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-09-01 22:54:19,177] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-01 22:54:19,231] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-01 22:54:19,375] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-01 22:54:19,652] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-09-01 22:54:19,652] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-09-01 22:54:19,675] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-09-01 22:54:19,819] [INFO] [comm.py:637:init_distributed] cdb=None
Loading checkpoint shards:   0%|          | 0/20 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/20 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/20 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/20 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/20 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/20 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/20 [00:00<?, ?it/s]Loading checkpoint shards:   5%|▌         | 1/20 [00:00<00:14,  1.30it/s]Loading checkpoint shards:  10%|█         | 2/20 [00:01<00:12,  1.49it/s]Loading checkpoint shards:   0%|          | 0/20 [00:00<?, ?it/s]Loading checkpoint shards:   5%|▌         | 1/20 [00:01<00:31,  1.67s/it]Loading checkpoint shards:   5%|▌         | 1/20 [00:01<00:29,  1.54s/it]Loading checkpoint shards:   5%|▌         | 1/20 [00:01<00:30,  1.60s/it]Loading checkpoint shards:   5%|▌         | 1/20 [00:01<00:29,  1.57s/it]Loading checkpoint shards:   5%|▌         | 1/20 [00:01<00:31,  1.64s/it]Loading checkpoint shards:  15%|█▌        | 3/20 [00:02<00:11,  1.50it/s]Loading checkpoint shards:   5%|▌         | 1/20 [00:01<00:26,  1.39s/it]Loading checkpoint shards:  10%|█         | 2/20 [00:01<00:14,  1.20it/s]Loading checkpoint shards:  20%|██        | 4/20 [00:02<00:07,  2.23it/s]Loading checkpoint shards:  10%|█         | 2/20 [00:01<00:13,  1.29it/s]Loading checkpoint shards:  10%|█         | 2/20 [00:01<00:13,  1.33it/s]Loading checkpoint shards:  10%|█         | 2/20 [00:01<00:14,  1.24it/s]Loading checkpoint shards:   5%|▌         | 1/20 [00:00<00:14,  1.34it/s]Loading checkpoint shards:  10%|█         | 2/20 [00:01<00:14,  1.24it/s]Loading checkpoint shards:  10%|█         | 2/20 [00:01<00:11,  1.50it/s]Loading checkpoint shards:  15%|█▌        | 3/20 [00:02<00:08,  1.92it/s]Loading checkpoint shards:  25%|██▌       | 5/20 [00:02<00:04,  3.07it/s]Loading checkpoint shards:  15%|█▌        | 3/20 [00:01<00:08,  2.09it/s]Loading checkpoint shards:  15%|█▌        | 3/20 [00:01<00:08,  2.00it/s]Loading checkpoint shards:  15%|█▌        | 3/20 [00:01<00:08,  2.02it/s]Loading checkpoint shards:  15%|█▌        | 3/20 [00:01<00:08,  2.02it/s]Loading checkpoint shards:  30%|███       | 6/20 [00:02<00:03,  3.98it/s]Loading checkpoint shards:  10%|█         | 2/20 [00:00<00:07,  2.46it/s]Loading checkpoint shards:  20%|██        | 4/20 [00:02<00:06,  2.66it/s]Loading checkpoint shards:  15%|█▌        | 3/20 [00:01<00:07,  2.29it/s]Loading checkpoint shards:  20%|██        | 4/20 [00:02<00:05,  2.82it/s]Loading checkpoint shards:  20%|██        | 4/20 [00:02<00:05,  2.87it/s]Loading checkpoint shards:  35%|███▌      | 7/20 [00:02<00:02,  4.93it/s]Loading checkpoint shards:  20%|██        | 4/20 [00:02<00:05,  2.75it/s]Loading checkpoint shards:  20%|██        | 4/20 [00:02<00:05,  2.89it/s]Loading checkpoint shards:  15%|█▌        | 3/20 [00:01<00:05,  3.37it/s]Loading checkpoint shards:  20%|██        | 4/20 [00:01<00:05,  3.10it/s]Loading checkpoint shards:  25%|██▌       | 5/20 [00:02<00:04,  3.38it/s]Loading checkpoint shards:  40%|████      | 8/20 [00:02<00:02,  5.86it/s]Loading checkpoint shards:  25%|██▌       | 5/20 [00:02<00:04,  3.54it/s]Loading checkpoint shards:  25%|██▌       | 5/20 [00:02<00:03,  3.78it/s]Loading checkpoint shards:  25%|██▌       | 5/20 [00:02<00:04,  3.62it/s]Loading checkpoint shards:  25%|██▌       | 5/20 [00:02<00:04,  3.41it/s]Loading checkpoint shards:  25%|██▌       | 5/20 [00:01<00:03,  3.97it/s]Loading checkpoint shards:  30%|███       | 6/20 [00:02<00:03,  4.04it/s]Loading checkpoint shards:  30%|███       | 6/20 [00:02<00:03,  4.62it/s]Loading checkpoint shards:  30%|███       | 6/20 [00:02<00:03,  4.22it/s]Loading checkpoint shards:  20%|██        | 4/20 [00:01<00:04,  3.81it/s]Loading checkpoint shards:  30%|███       | 6/20 [00:02<00:03,  4.31it/s]Loading checkpoint shards:  30%|███       | 6/20 [00:02<00:03,  4.20it/s]Loading checkpoint shards:  50%|█████     | 10/20 [00:02<00:01,  7.21it/s]Loading checkpoint shards:  30%|███       | 6/20 [00:02<00:02,  4.84it/s]Loading checkpoint shards:  35%|███▌      | 7/20 [00:02<00:02,  5.36it/s]Loading checkpoint shards:  35%|███▌      | 7/20 [00:02<00:02,  4.61it/s]Loading checkpoint shards:  35%|███▌      | 7/20 [00:02<00:02,  4.93it/s]Loading checkpoint shards:  55%|█████▌    | 11/20 [00:02<00:01,  7.68it/s]Loading checkpoint shards:  35%|███▌      | 7/20 [00:02<00:02,  4.87it/s]Loading checkpoint shards:  35%|███▌      | 7/20 [00:02<00:02,  4.95it/s]Loading checkpoint shards:  35%|███▌      | 7/20 [00:02<00:02,  5.64it/s]Loading checkpoint shards:  40%|████      | 8/20 [00:02<00:01,  6.04it/s]Loading checkpoint shards:  25%|██▌       | 5/20 [00:01<00:03,  3.97it/s]Loading checkpoint shards:  40%|████      | 8/20 [00:02<00:02,  5.59it/s]Loading checkpoint shards:  40%|████      | 8/20 [00:02<00:02,  5.12it/s]Loading checkpoint shards:  40%|████      | 8/20 [00:02<00:01,  6.37it/s]Loading checkpoint shards:  40%|████      | 8/20 [00:02<00:02,  5.40it/s]Loading checkpoint shards:  40%|████      | 8/20 [00:02<00:02,  5.39it/s]Loading checkpoint shards:  65%|██████▌   | 13/20 [00:03<00:00,  8.56it/s]Loading checkpoint shards:  45%|████▌     | 9/20 [00:02<00:01,  6.65it/s]Loading checkpoint shards:  45%|████▌     | 9/20 [00:02<00:01,  6.15it/s]Loading checkpoint shards:  45%|████▌     | 9/20 [00:02<00:01,  5.58it/s]Loading checkpoint shards:  45%|████▌     | 9/20 [00:02<00:01,  5.94it/s]Loading checkpoint shards:  70%|███████   | 14/20 [00:03<00:00,  8.85it/s]Loading checkpoint shards:  45%|████▌     | 9/20 [00:02<00:01,  6.42it/s]Loading checkpoint shards:  45%|████▌     | 9/20 [00:02<00:01,  5.94it/s]Loading checkpoint shards:  30%|███       | 6/20 [00:01<00:03,  4.17it/s]Loading checkpoint shards:  50%|█████     | 10/20 [00:02<00:01,  7.14it/s]Loading checkpoint shards:  50%|█████     | 10/20 [00:02<00:01,  6.61it/s]Loading checkpoint shards:  50%|█████     | 10/20 [00:03<00:01,  6.28it/s]Loading checkpoint shards:  75%|███████▌  | 15/20 [00:03<00:00,  9.09it/s]Loading checkpoint shards:  50%|█████     | 10/20 [00:02<00:01,  6.56it/s]Loading checkpoint shards:  50%|█████     | 10/20 [00:02<00:01,  6.41it/s]Loading checkpoint shards:  50%|█████     | 10/20 [00:02<00:01,  6.66it/s]Loading checkpoint shards:  55%|█████▌    | 11/20 [00:02<00:01,  7.47it/s]Loading checkpoint shards:  55%|█████▌    | 11/20 [00:03<00:01,  6.96it/s]Loading checkpoint shards:  55%|█████▌    | 11/20 [00:03<00:01,  6.87it/s]Loading checkpoint shards:  55%|█████▌    | 11/20 [00:03<00:01,  7.09it/s]Loading checkpoint shards:  35%|███▌      | 7/20 [00:01<00:03,  4.21it/s]Loading checkpoint shards:  60%|██████    | 12/20 [00:03<00:01,  7.77it/s]Loading checkpoint shards:  55%|█████▌    | 11/20 [00:03<00:01,  6.80it/s]Loading checkpoint shards:  55%|█████▌    | 11/20 [00:02<00:01,  6.91it/s]Loading checkpoint shards:  85%|████████▌ | 17/20 [00:03<00:00,  9.44it/s]Loading checkpoint shards:  60%|██████    | 12/20 [00:03<00:01,  7.41it/s]Loading checkpoint shards:  60%|██████    | 12/20 [00:03<00:01,  7.54it/s]Loading checkpoint shards:  60%|██████    | 12/20 [00:03<00:01,  6.84it/s]Loading checkpoint shards:  65%|██████▌   | 13/20 [00:03<00:00,  7.94it/s]Loading checkpoint shards:  90%|█████████ | 18/20 [00:03<00:00,  9.56it/s]Loading checkpoint shards:  60%|██████    | 12/20 [00:02<00:01,  7.06it/s]Loading checkpoint shards:  60%|██████    | 12/20 [00:03<00:01,  6.69it/s]Loading checkpoint shards:  65%|██████▌   | 13/20 [00:03<00:00,  7.82it/s]Loading checkpoint shards:  65%|██████▌   | 13/20 [00:03<00:00,  7.91it/s]Loading checkpoint shards:  40%|████      | 8/20 [00:02<00:02,  4.27it/s]Loading checkpoint shards:  65%|██████▌   | 13/20 [00:03<00:00,  7.03it/s]Loading checkpoint shards:  70%|███████   | 14/20 [00:03<00:00,  8.08it/s]Loading checkpoint shards:  95%|█████████▌| 19/20 [00:03<00:00,  9.66it/s]Loading checkpoint shards:  70%|███████   | 14/20 [00:03<00:00,  8.16it/s]Loading checkpoint shards:  65%|██████▌   | 13/20 [00:03<00:01,  6.93it/s]Loading checkpoint shards:  65%|██████▌   | 13/20 [00:03<00:01,  6.90it/s]Loading checkpoint shards:  70%|███████   | 14/20 [00:03<00:00,  8.22it/s]Loading checkpoint shards: 100%|██████████| 20/20 [00:03<00:00,  5.30it/s]
Some weights of LlavaForConditionalGeneration were not initialized from the model checkpoint at /home/vault/b207dd/b207dd11/llava-mixtral/llava-mixtral-pretrained-2/ and are newly initialized: ['language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter_gate.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Loading checkpoint shards:  70%|███████   | 14/20 [00:03<00:00,  7.28it/s]Convert trainable params: 34078720 || all params: 47061374976 || trainable%: 0.07
Print trainable params: 55058432 || all params: 47061374976 || trainable%: 0.12
SEED_LAYERS=False BASE_SEED=1234 SEED_FN=None
Loading checkpoint shards:  75%|███████▌  | 15/20 [00:03<00:00,  8.34it/s]Using topology: {ProcessCoord(pipe=0, data=0): 0, ProcessCoord(pipe=1, data=0): 1, ProcessCoord(pipe=2, data=0): 2, ProcessCoord(pipe=3, data=0): 3, ProcessCoord(pipe=4, data=0): 4, ProcessCoord(pipe=5, data=0): 5, ProcessCoord(pipe=6, data=0): 6, ProcessCoord(pipe=7, data=0): 7}
[2024-09-01 22:54:30,979] [INFO] [module.py:375:_partition_layers] Partitioning pipeline stages with method type:LanguageModelLayerWrapper
stage=0 layers=2
     0: LlavaMultiModalModuleWrapper
     1: LanguageModelLayerWrapper
stage=1 layers=1
     2: LanguageModelLayerWrapper
stage=2 layers=1
     3: LanguageModelLayerWrapper
stage=3 layers=1
     4: LanguageModelLayerWrapper
stage=4 layers=1
     5: LanguageModelLayerWrapper
stage=5 layers=1
     6: LanguageModelLayerWrapper
stage=6 layers=1
     7: LanguageModelLayerWrapper
stage=7 layers=2
     8: LanguageModelLayerWrapper
     9: LanguageModelFinalWrapper
  loss: loss_fn
Loading checkpoint shards:  75%|███████▌  | 15/20 [00:03<00:00,  7.21it/s]Loading checkpoint shards:  75%|███████▌  | 15/20 [00:03<00:00,  8.40it/s]Loading checkpoint shards:  70%|███████   | 14/20 [00:03<00:00,  7.15it/s]Loading checkpoint shards:  70%|███████   | 14/20 [00:03<00:00,  6.75it/s]Loading checkpoint shards:  75%|███████▌  | 15/20 [00:03<00:00,  7.46it/s]Loading checkpoint shards:  80%|████████  | 16/20 [00:03<00:00,  8.53it/s]Loading checkpoint shards:  45%|████▌     | 9/20 [00:02<00:02,  3.89it/s]Loading checkpoint shards:  80%|████████  | 16/20 [00:03<00:00,  8.54it/s]Loading checkpoint shards:  80%|████████  | 16/20 [00:03<00:00,  7.26it/s]Loading checkpoint shards:  75%|███████▌  | 15/20 [00:03<00:00,  7.33it/s]Loading checkpoint shards:  80%|████████  | 16/20 [00:03<00:00,  7.62it/s]Loading checkpoint shards:  85%|████████▌ | 17/20 [00:03<00:00,  8.66it/s]Loading checkpoint shards:  75%|███████▌  | 15/20 [00:03<00:00,  6.48it/s]Loading checkpoint shards:  85%|████████▌ | 17/20 [00:03<00:00,  8.61it/s]Loading checkpoint shards:  85%|████████▌ | 17/20 [00:03<00:00,  7.29it/s]Loading checkpoint shards:  80%|████████  | 16/20 [00:03<00:00,  7.08it/s]Loading checkpoint shards:  90%|█████████ | 18/20 [00:03<00:00,  8.72it/s]Loading checkpoint shards:  85%|████████▌ | 17/20 [00:03<00:00,  7.53it/s]Loading checkpoint shards:  80%|████████  | 16/20 [00:03<00:00,  6.78it/s]Loading checkpoint shards:  90%|█████████ | 18/20 [00:03<00:00,  8.66it/s]Loading checkpoint shards:  90%|█████████ | 18/20 [00:03<00:00,  7.36it/s]Loading checkpoint shards:  50%|█████     | 10/20 [00:02<00:02,  3.68it/s]Loading checkpoint shards:  95%|█████████▌| 19/20 [00:04<00:00,  8.74it/s]Loading checkpoint shards:  85%|████████▌ | 17/20 [00:03<00:00,  6.87it/s]Loading checkpoint shards:  95%|█████████▌| 19/20 [00:03<00:00,  8.68it/s]Loading checkpoint shards:  90%|█████████ | 18/20 [00:03<00:00,  7.35it/s]Loading checkpoint shards:  85%|████████▌ | 17/20 [00:03<00:00,  6.98it/s]Loading checkpoint shards:  95%|█████████▌| 19/20 [00:04<00:00,  7.35it/s]Loading checkpoint shards: 100%|██████████| 20/20 [00:04<00:00,  8.78it/s]Loading checkpoint shards: 100%|██████████| 20/20 [00:04<00:00,  4.75it/s]
Some weights of LlavaForConditionalGeneration were not initialized from the model checkpoint at /home/vault/b207dd/b207dd11/llava-mixtral/llava-mixtral-pretrained-2/ and are newly initialized: ['language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter_gate.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Loading checkpoint shards: 100%|██████████| 20/20 [00:04<00:00,  8.74it/s]Loading checkpoint shards: 100%|██████████| 20/20 [00:04<00:00,  4.98it/s]
Some weights of LlavaForConditionalGeneration were not initialized from the model checkpoint at /home/vault/b207dd/b207dd11/llava-mixtral/llava-mixtral-pretrained-2/ and are newly initialized: ['language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter_gate.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Convert trainable params: 34078720 || all params: 47061374976 || trainable%: 0.07
Loading checkpoint shards:  90%|█████████ | 18/20 [00:04<00:00,  7.03it/s]Print trainable params: 55058432 || all params: 47061374976 || trainable%: 0.12
Loading checkpoint shards:  95%|█████████▌| 19/20 [00:04<00:00,  7.49it/s]Convert trainable params: 34078720 || all params: 47061374976 || trainable%: 0.07
Loading checkpoint shards:  55%|█████▌    | 11/20 [00:03<00:02,  4.03it/s]Print trainable params: 55058432 || all params: 47061374976 || trainable%: 0.12
Loading checkpoint shards:  90%|█████████ | 18/20 [00:03<00:00,  6.20it/s]Loading checkpoint shards: 100%|██████████| 20/20 [00:04<00:00,  7.13it/s]Loading checkpoint shards: 100%|██████████| 20/20 [00:04<00:00,  4.80it/s]
Some weights of LlavaForConditionalGeneration were not initialized from the model checkpoint at /home/vault/b207dd/b207dd11/llava-mixtral/llava-mixtral-pretrained-2/ and are newly initialized: ['language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter_gate.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Loading checkpoint shards:  95%|█████████▌| 19/20 [00:04<00:00,  7.29it/s]Loading checkpoint shards: 100%|██████████| 20/20 [00:04<00:00,  7.86it/s]Loading checkpoint shards: 100%|██████████| 20/20 [00:04<00:00,  4.73it/s]
Some weights of LlavaForConditionalGeneration were not initialized from the model checkpoint at /home/vault/b207dd/b207dd11/llava-mixtral/llava-mixtral-pretrained-2/ and are newly initialized: ['language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter_gate.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Convert trainable params: 34078720 || all params: 47061374976 || trainable%: 0.07
Print trainable params: 55058432 || all params: 47061374976 || trainable%: 0.12
Convert trainable params: 34078720 || all params: 47061374976 || trainable%: 0.07
Print trainable params: 55058432 || all params: 47061374976 || trainable%: 0.12
Loading checkpoint shards:  60%|██████    | 12/20 [00:03<00:01,  4.30it/s]Loading checkpoint shards: 100%|██████████| 20/20 [00:04<00:00,  7.69it/s]Loading checkpoint shards: 100%|██████████| 20/20 [00:04<00:00,  4.64it/s]
Some weights of LlavaForConditionalGeneration were not initialized from the model checkpoint at /home/vault/b207dd/b207dd11/llava-mixtral/llava-mixtral-pretrained-2/ and are newly initialized: ['language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter_gate.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Loading checkpoint shards:  95%|█████████▌| 19/20 [00:04<00:00,  5.92it/s]Convert trainable params: 34078720 || all params: 47061374976 || trainable%: 0.07
Print trainable params: 55058432 || all params: 47061374976 || trainable%: 0.12
Loading checkpoint shards:  65%|██████▌   | 13/20 [00:03<00:01,  4.49it/s]Loading checkpoint shards: 100%|██████████| 20/20 [00:04<00:00,  6.09it/s]Loading checkpoint shards: 100%|██████████| 20/20 [00:04<00:00,  4.79it/s]
Some weights of LlavaForConditionalGeneration were not initialized from the model checkpoint at /home/vault/b207dd/b207dd11/llava-mixtral/llava-mixtral-pretrained-2/ and are newly initialized: ['language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter_gate.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Convert trainable params: 34078720 || all params: 47061374976 || trainable%: 0.07
Print trainable params: 55058432 || all params: 47061374976 || trainable%: 0.12
Loading checkpoint shards:  70%|███████   | 14/20 [00:03<00:01,  4.68it/s]Loading checkpoint shards:  75%|███████▌  | 15/20 [00:03<00:01,  4.69it/s]Loading checkpoint shards:  80%|████████  | 16/20 [00:04<00:00,  4.33it/s]Loading checkpoint shards:  85%|████████▌ | 17/20 [00:04<00:00,  3.52it/s]Loading checkpoint shards:  90%|█████████ | 18/20 [00:04<00:00,  3.54it/s]Rank 0 initialized with CUDA_MEM (71821950976, 85097971712)
Deepspeed engine initializing at --- RANK 0 --- ...
[2024-09-01 22:54:33,506] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown
Loading checkpoint shards:  95%|█████████▌| 19/20 [00:04<00:00,  3.99it/s]Loading checkpoint shards: 100%|██████████| 20/20 [00:05<00:00,  4.58it/s]Loading checkpoint shards: 100%|██████████| 20/20 [00:05<00:00,  3.93it/s]
Some weights of LlavaForConditionalGeneration were not initialized from the model checkpoint at /home/vault/b207dd/b207dd11/llava-mixtral/llava-mixtral-pretrained-2/ and are newly initialized: ['language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.0.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.1.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.10.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.11.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.12.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.13.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.14.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.15.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.16.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.17.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.18.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.19.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.2.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.20.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.21.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.22.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.23.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.24.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.25.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.26.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.27.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.28.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.29.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.3.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.30.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.31.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.4.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.5.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.6.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.7.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.8.block_sparse_moe.shared_routing_adapter_gate.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.0.unit.lora_A.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.0.unit.lora_B.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.1.unit.lora_A.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.1.unit.lora_B.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.2.unit.lora_A.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.2.unit.lora_B.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.3.unit.lora_A.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter.3.unit.lora_B.weight', 'language_model.model.layers.9.block_sparse_moe.shared_routing_adapter_gate.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Convert trainable params: 34078720 || all params: 47061374976 || trainable%: 0.07
Print trainable params: 55058432 || all params: 47061374976 || trainable%: 0.12
[2024-09-01 22:54:34,137] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
Rank 3 initialized with CUDA_MEM (72748892160, 85097971712)
Deepspeed engine initializing at --- RANK 3 --- ...
Rank 6 initialized with CUDA_MEM (72748892160, 85097971712)
Deepspeed engine initializing at --- RANK 6 --- ...
Rank 7 initialized with CUDA_MEM (72484651008, 85097971712)
Deepspeed engine initializing at --- RANK 7 --- ...
Using /home/hpc/b207dd/b207dd11/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Using /home/hpc/b207dd/b207dd11/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Rank 5 initialized with CUDA_MEM (72748892160, 85097971712)
Rank 2 initialized with CUDA_MEM (72748892160, 85097971712)
Deepspeed engine initializing at --- RANK 5 --- ...
Deepspeed engine initializing at --- RANK 2 --- ...
Rank 4 initialized with CUDA_MEM (72748892160, 85097971712)
Deepspeed engine initializing at --- RANK 4 --- ...
Using /home/hpc/b207dd/b207dd11/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/hpc/b207dd/b207dd11/.cache/torch_extensions/py38_cu121/fused_adam/build.ninja...
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Using /home/hpc/b207dd/b207dd11/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Rank 1 initialized with CUDA_MEM (72748892160, 85097971712)
Deepspeed engine initializing at --- RANK 1 --- ...
Using /home/hpc/b207dd/b207dd11/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Using /home/hpc/b207dd/b207dd11/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Using /home/hpc/b207dd/b207dd11/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Using /home/hpc/b207dd/b207dd11/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
ninja: no work to do.
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 1.4911565780639648 secondsTime to load fused_adam op: 0.23019719123840332 seconds

Time to load fused_adam op: 1.3160781860351562 seconds
[2024-09-01 22:54:36,771] [INFO] [logging.py:96:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adam as basic optimizer
Time to load fused_adam op: 0.7043769359588623 seconds
[2024-09-01 22:54:36,772] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
Time to load fused_adam op: 1.4920635223388672 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 1.00584077835083 seconds
[2024-09-01 22:54:36,776] [INFO] [engine.py:141:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[2024-09-01 22:54:36,777] [INFO] [engine.py:141:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[2024-09-01 22:54:36,777] [INFO] [engine.py:141:__init__] is_pipe_partitioned= False is_grad_partitioned= False
Loading extension module fused_adam...
Time to load fused_adam op: 0.704211950302124 seconds
[2024-09-01 22:54:36,783] [INFO] [engine.py:141:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[2024-09-01 22:54:36,784] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
[2024-09-01 22:54:36,784] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = adam
[2024-09-01 22:54:36,784] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = WarmupCosineLR
[2024-09-01 22:54:36,784] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupCosineLR object at 0x152109bf5100>
[2024-09-01 22:54:36,784] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[1e-05], mom=[(0.9, 0.999)]
[2024-09-01 22:54:36,785] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-09-01 22:54:36,785] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-09-01 22:54:36,785] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-09-01 22:54:36,785] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-09-01 22:54:36,785] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-09-01 22:54:36,785] [INFO] [engine.py:141:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   bfloat16_enabled ............. False
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x15210ac0fc10>
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 128
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 65536
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   loss_scale ................... 0
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-09-01 22:54:36,786] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=True, output_path='/home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint', job_name='deepspeed_monitor_logs') enabled=True
[2024-09-01 22:54:36,787] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-09-01 22:54:36,787] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-09-01 22:54:36,787] [INFO] [config.py:1000:print]   optimizer_name ............... adam
[2024-09-01 22:54:36,787] [INFO] [config.py:1000:print]   optimizer_params ............. {'lr': 1e-05}
[2024-09-01 22:54:36,787] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True, 'use_reentrant': False}
[2024-09-01 22:54:36,787] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-09-01 22:54:36,787] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-09-01 22:54:36,787] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-09-01 22:54:36,787] [INFO] [config.py:1000:print]   scheduler_name ............... WarmupCosineLR
[2024-09-01 22:54:36,787] [INFO] [config.py:1000:print]   scheduler_params ............. {'total_num_steps': 5718, 'warmup_min_ratio': 0.1, 'warmup_num_steps': 171.54}
[2024-09-01 22:54:36,787] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-09-01 22:54:36,787] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-09-01 22:54:36,787] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-09-01 22:54:36,787] [INFO] [config.py:1000:print]   steps_per_print .............. 1
[2024-09-01 22:54:36,787] [INFO] [config.py:1000:print]   train_batch_size ............. 128
[2024-09-01 22:54:36,787] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  1
[2024-09-01 22:54:36,787] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-09-01 22:54:36,787] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-09-01 22:54:36,787] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2024-09-01 22:54:36,787] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-09-01 22:54:36,787] [INFO] [config.py:1000:print]   world_size ................... 1
[2024-09-01 22:54:36,787] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  False
[2024-09-01 22:54:36,787] [INFO] [config.py:1000:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-09-01 22:54:36,787] [INFO] [config.py:1000:print]   zero_enabled ................. False
[2024-09-01 22:54:36,787] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2024-09-01 22:54:36,787] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 0
[2024-09-01 22:54:36,787] [INFO] [config.py:986:print_user_config]   json = {
    "train_batch_size": 128, 
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 128, 
    "steps_per_print": 1, 
    "optimizer": {
        "type": "Adam", 
        "params": {
            "lr": 1e-05
        }
    }, 
    "scheduler": {
        "type": "WarmupCosineLR", 
        "params": {
            "total_num_steps": 5.718000e+03, 
            "warmup_min_ratio": 0.1, 
            "warmup_num_steps": 171.54
        }
    }, 
    "pipeline": {
        "use_reentrant": false
    }, 
    "csv_monitor": {
        "enabled": true, 
        "output_path": "/home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint", 
        "job_name": "deepspeed_monitor_logs"
    }
}
[2024-09-01 22:54:36,787] [INFO] [engine.py:101:__init__] CONFIG: micro_batches=128 micro_batch_size=1
[2024-09-01 22:54:36,787] [INFO] [engine.py:141:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[2024-09-01 22:54:36,788] [INFO] [engine.py:141:__init__] is_pipe_partitioned= False is_grad_partitioned= False
Loading extension module fused_adam...
Time to load fused_adam op: 0.7039861679077148 seconds
[2024-09-01 22:54:36,831] [INFO] [engine.py:141:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[2024-09-01 22:54:39,445] [INFO] [engine.py:160:__init__] RANK=6 STAGE=6 LAYERS=1 [7, 8) STAGE_PARAMS=4259840 (4.260M) TOTAL_PARAMS=55058432 (55.058M) UNIQUE_PARAMS=55058432 (55.058M)
[2024-09-01 22:54:39,445] [INFO] [engine.py:160:__init__] RANK=3 STAGE=3 LAYERS=1 [4, 5) STAGE_PARAMS=4259840 (4.260M) TOTAL_PARAMS=55058432 (55.058M) UNIQUE_PARAMS=55058432 (55.058M)
[2024-09-01 22:54:39,445] [INFO] [engine.py:160:__init__] RANK=4 STAGE=4 LAYERS=1 [5, 6) STAGE_PARAMS=4259840 (4.260M) TOTAL_PARAMS=55058432 (55.058M) UNIQUE_PARAMS=55058432 (55.058M)
[2024-09-01 22:54:39,445] [INFO] [engine.py:160:__init__] RANK=5 STAGE=5 LAYERS=1 [6, 7) STAGE_PARAMS=4259840 (4.260M) TOTAL_PARAMS=55058432 (55.058M) UNIQUE_PARAMS=55058432 (55.058M)
[2024-09-01 22:54:39,445] [INFO] [engine.py:160:__init__] RANK=0 STAGE=0 LAYERS=2 [0, 2) STAGE_PARAMS=25239552 (25.240M) TOTAL_PARAMS=55058432 (55.058M) UNIQUE_PARAMS=55058432 (55.058M)
[2024-09-01 22:54:39,445] [INFO] [engine.py:160:__init__] RANK=1 STAGE=1 LAYERS=1 [2, 3) STAGE_PARAMS=4259840 (4.260M) TOTAL_PARAMS=55058432 (55.058M) UNIQUE_PARAMS=55058432 (55.058M)
[2024-09-01 22:54:39,445] [INFO] [engine.py:160:__init__] RANK=2 STAGE=2 LAYERS=1 [3, 4) STAGE_PARAMS=4259840 (4.260M) TOTAL_PARAMS=55058432 (55.058M) UNIQUE_PARAMS=55058432 (55.058M)
[2024-09-01 22:54:39,445] [INFO] [engine.py:160:__init__] RANK=7 STAGE=7 LAYERS=2 [8, 10) STAGE_PARAMS=4259840 (4.260M) TOTAL_PARAMS=55058432 (55.058M) UNIQUE_PARAMS=55058432 (55.058M)
Deepspeed engine successfully initialized at --- RANK 0 --- hosting 40 of 292 trainable parameters
Loading latest model checkpoint at shard 4800
[2024-09-01 22:54:40,949] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/mp_rank_00_model_states.pt...
Deepspeed engine successfully initialized at --- RANK 7 --- hosting 36 of 292 trainable parameters
[2024-09-01 22:54:41,156] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/mp_rank_00_model_states.pt...
Deepspeed engine successfully initialized at --- RANK 2 --- hosting 36 of 292 trainable parameters
Deepspeed engine successfully initialized at --- RANK 1 --- hosting 36 of 292 trainable parameters
[2024-09-01 22:54:42,183] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/mp_rank_00_model_states.pt...
[2024-09-01 22:54:42,185] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/mp_rank_00_model_states.pt...
Deepspeed engine successfully initialized at --- RANK 4 --- hosting 36 of 292 trainable parameters
Deepspeed engine successfully initialized at --- RANK 3 --- hosting 36 of 292 trainable parameters
[2024-09-01 22:54:42,275] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/mp_rank_00_model_states.pt...
[2024-09-01 22:54:42,275] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/mp_rank_00_model_states.pt...
Deepspeed engine successfully initialized at --- RANK 6 --- hosting 36 of 292 trainable parameters
Deepspeed engine successfully initialized at --- RANK 5 --- hosting 36 of 292 trainable parameters
[2024-09-01 22:54:42,336] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/mp_rank_00_model_states.pt...
[2024-09-01 22:54:42,337] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/mp_rank_00_model_states.pt...
[2024-09-01 22:54:42,402] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/mp_rank_00_model_states.pt.
[2024-09-01 22:54:42,402] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/mp_rank_00_model_states.pt.
[2024-09-01 22:54:42,402] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/mp_rank_00_model_states.pt.
[2024-09-01 22:54:42,402] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/mp_rank_00_model_states.pt.
[2024-09-01 22:54:42,402] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/mp_rank_00_model_states.pt.
[2024-09-01 22:54:42,402] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/mp_rank_00_model_states.pt.
[2024-09-01 22:54:42,402] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/mp_rank_01_model_states.pt...
[2024-09-01 22:54:42,402] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/mp_rank_00_model_states.pt.
[2024-09-01 22:54:42,402] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/mp_rank_00_model_states.pt.
[2024-09-01 22:54:42,402] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/mp_rank_05_model_states.pt...
[2024-09-01 22:54:42,403] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/mp_rank_03_model_states.pt...
[2024-09-01 22:54:42,403] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/mp_rank_06_model_states.pt...
[2024-09-01 22:54:42,403] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/mp_rank_02_model_states.pt...
[2024-09-01 22:54:42,403] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/mp_rank_04_model_states.pt...
[2024-09-01 22:54:42,403] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/mp_rank_00_model_states.pt...
[2024-09-01 22:54:42,404] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/mp_rank_07_model_states.pt...
[2024-09-01 22:54:42,428] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/mp_rank_00_model_states.pt.
[2024-09-01 22:54:42,429] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/layer_00-model_states.pt...
[2024-09-01 22:54:42,599] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/mp_rank_02_model_states.pt.
[2024-09-01 22:54:42,599] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/layer_03-model_states.pt...
[2024-09-01 22:54:42,908] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/mp_rank_07_model_states.pt.
[2024-09-01 22:54:42,910] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/layer_08-model_states.pt...
[2024-09-01 22:54:43,020] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/mp_rank_05_model_states.pt.
[2024-09-01 22:54:43,021] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/layer_06-model_states.pt...
[2024-09-01 22:54:43,115] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/mp_rank_03_model_states.pt.
[2024-09-01 22:54:43,116] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/layer_04-model_states.pt...
[2024-09-01 22:54:43,237] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/mp_rank_06_model_states.pt.
[2024-09-01 22:54:43,238] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/layer_07-model_states.pt...
[2024-09-01 22:54:43,387] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/mp_rank_04_model_states.pt.
[2024-09-01 22:54:43,388] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/layer_05-model_states.pt...
[2024-09-01 22:54:43,436] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/mp_rank_01_model_states.pt.
[2024-09-01 22:54:43,437] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/layer_02-model_states.pt...
[2024-09-01 22:54:58,146] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/layer_00-model_states.pt.
[2024-09-01 22:54:58,147] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/layer_00-model_states.pt...
[2024-09-01 22:54:58,293] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/layer_00-model_states.pt.
[2024-09-01 22:54:58,397] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/layer_01-model_states.pt...
[2024-09-01 22:57:30,978] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/layer_07-model_states.pt.
[2024-09-01 22:57:30,998] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/layer_07-model_states.pt...
[2024-09-01 22:57:32,831] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/layer_07-model_states.pt.
[2024-09-01 22:57:33,055] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/layer_06-model_states.pt.
[2024-09-01 22:57:33,087] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/layer_06-model_states.pt...
  0%|          | 0/5198 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 22:57:35,305] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/layer_06-model_states.pt.
  0%|          | 0/5198 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 22:57:36,469] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/layer_08-model_states.pt.
[2024-09-01 22:57:36,489] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/layer_08-model_states.pt...
[2024-09-01 22:57:38,330] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/layer_08-model_states.pt.
[2024-09-01 22:57:38,837] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/layer_04-model_states.pt.
[2024-09-01 22:57:38,861] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/layer_04-model_states.pt...
[2024-09-01 22:57:38,990] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/layer_09-model_states.pt...
[2024-09-01 22:57:40,725] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/layer_04-model_states.pt.
[2024-09-01 22:57:41,538] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/layer_05-model_states.pt.
[2024-09-01 22:57:41,559] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/layer_05-model_states.pt...
  0%|          | 0/5198 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 22:57:43,387] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/layer_05-model_states.pt.
  0%|          | 0/5198 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 22:57:44,855] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/layer_09-model_states.pt.
[2024-09-01 22:57:44,856] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/layer_09-model_states.pt...
[2024-09-01 22:57:44,896] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/layer_09-model_states.pt.
  0%|          | 0/5198 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 22:57:45,389] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/layer_03-model_states.pt.
[2024-09-01 22:57:45,409] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/layer_03-model_states.pt...
[2024-09-01 22:57:47,195] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/layer_03-model_states.pt.
  0%|          | 0/5198 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 22:57:55,088] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/layer_01-model_states.pt.
[2024-09-01 22:57:55,118] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/layer_01-model_states.pt...
[2024-09-01 22:57:57,044] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/layer_01-model_states.pt.
  0%|          | 0/5198 [00:00<?, ?it/s]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4500
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 22:57:59,921] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/layer_02-model_states.pt.
[2024-09-01 22:57:59,945] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/layer_02-model_states.pt...
[2024-09-01 22:58:01,760] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4799/layer_02-model_states.pt.
  0%|          | 0/5198 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 22:58:39,996] [INFO] [logging.py:96:log_dist] [Rank 0] step=4800, skipped=0, lr=[6.617586740380729e-07], mom=[(0.9, 0.999)]
steps: 4800 loss: 1.4503 iter time (s): 44.628 samples/sec: 2.868

100%|██████████| 1/1 [00:57<00:00, 57.86s/it][A100%|██████████| 1/1 [00:57<00:00, 57.86s/it]
 92%|█████████▏| 4801/5198 [00:57<00:04, 82.96it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:08<00:00, 68.82s/it][A100%|██████████| 1/1 [01:08<00:00, 68.82s/it]
 92%|█████████▏| 4801/5198 [01:09<00:05, 69.57it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:07<00:00, 67.09s/it][A100%|██████████| 1/1 [01:07<00:00, 67.09s/it]
 92%|█████████▏| 4801/5198 [01:07<00:05, 71.55it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:58<00:00, 58.91s/it][A100%|██████████| 1/1 [00:58<00:00, 58.91s/it]
 92%|█████████▏| 4801/5198 [00:58<00:04, 81.49it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:01<00:00, 61.57s/it][A100%|██████████| 1/1 [01:01<00:00, 61.57s/it]
 92%|█████████▏| 4801/5198 [01:01<00:05, 77.96it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:55<00:00, 55.26s/it][A100%|██████████| 1/1 [00:55<00:00, 55.26s/it]
 92%|█████████▏| 4801/5198 [00:55<00:04, 86.87it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:40<00:00, 40.71s/it][A100%|██████████| 1/1 [00:40<00:00, 40.71s/it]
 92%|█████████▏| 4801/5198 [00:40<00:03, 117.92it/s]
100%|██████████| 1/1 [00:45<00:00, 45.43s/it][A100%|██████████| 1/1 [00:45<00:00, 45.43s/it]
 92%|█████████▏| 4801/5198 [00:45<00:03, 105.65it/s]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4501

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A 92%|█████████▏| 4801/5198 [01:20<00:05, 69.57it/s] 92%|█████████▏| 4801/5198 [01:10<00:04, 81.49it/s] 92%|█████████▏| 4801/5198 [01:10<00:04, 82.96it/s] 92%|█████████▏| 4801/5198 [01:20<00:05, 71.55it/s] 92%|█████████▏| 4801/5198 [00:59<00:03, 105.65it/s] 92%|█████████▏| 4801/5198 [01:09<00:04, 86.87it/s] 92%|█████████▏| 4801/5198 [01:16<00:05, 77.96it/s] 92%|█████████▏| 4801/5198 [00:55<00:03, 117.92it/s]
100%|██████████| 1/1 [00:29<00:00, 29.63s/it][A100%|██████████| 1/1 [00:29<00:00, 29.63s/it]
 92%|█████████▏| 4802/5198 [01:27<00:08, 47.85it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 22:59:12,944] [INFO] [logging.py:96:log_dist] [Rank 0] step=4801, skipped=0, lr=[6.603523899509179e-07], mom=[(0.9, 0.999)]
steps: 4801 loss: 1.5074 iter time (s): 29.496 samples/sec: 4.340

100%|██████████| 1/1 [00:30<00:00, 30.20s/it][A100%|██████████| 1/1 [00:30<00:00, 30.20s/it]
 92%|█████████▏| 4802/5198 [01:39<00:09, 42.82it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.20s/it][A100%|██████████| 1/1 [00:30<00:00, 30.20s/it]
 92%|█████████▏| 4802/5198 [01:37<00:09, 43.56it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.25s/it][A100%|██████████| 1/1 [00:30<00:00, 30.25s/it]
 92%|█████████▏| 4802/5198 [01:29<00:08, 47.02it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.26s/it][A100%|██████████| 1/1 [00:30<00:00, 30.26s/it]
 92%|█████████▏| 4802/5198 [01:31<00:08, 45.81it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.23s/it][A100%|██████████| 1/1 [00:30<00:00, 30.23s/it]
 92%|█████████▏| 4802/5198 [01:25<00:08, 48.77it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.22s/it][A100%|██████████| 1/1 [00:30<00:00, 30.22s/it]
 92%|█████████▏| 4802/5198 [01:10<00:06, 57.25it/s] 
100%|██████████| 1/1 [00:30<00:00, 30.21s/it][A100%|██████████| 1/1 [00:30<00:00, 30.21s/it]
 92%|█████████▏| 4802/5198 [01:15<00:07, 54.20it/s] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4502

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.54s/it][A100%|██████████| 1/1 [00:31<00:00, 31.54s/it]
 92%|█████████▏| 4803/5198 [01:59<00:13, 29.12it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 22:59:44,610] [INFO] [logging.py:96:log_dist] [Rank 0] step=4802, skipped=0, lr=[6.58947498290853e-07], mom=[(0.9, 0.999)]
steps: 4802 loss: 1.5034 iter time (s): 30.942 samples/sec: 4.137

100%|██████████| 1/1 [00:31<00:00, 31.73s/it][A100%|██████████| 1/1 [00:31<00:00, 31.73s/it]
 92%|█████████▏| 4803/5198 [02:10<00:14, 27.15it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.71s/it][A100%|██████████| 1/1 [00:31<00:00, 31.71s/it]
 92%|█████████▏| 4803/5198 [02:09<00:14, 27.45it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.62s/it][A100%|██████████| 1/1 [00:31<00:00, 31.62s/it]
 92%|█████████▏| 4803/5198 [02:00<00:13, 28.83it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.60s/it][A100%|██████████| 1/1 [00:31<00:00, 31.60s/it]
 92%|█████████▏| 4803/5198 [02:03<00:13, 28.37it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.64s/it][A100%|██████████| 1/1 [00:31<00:00, 31.64s/it]
 92%|█████████▏| 4803/5198 [01:57<00:13, 29.46it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.62s/it][A100%|██████████| 1/1 [00:31<00:00, 31.62s/it]
 92%|█████████▏| 4803/5198 [01:42<00:12, 32.37it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.65s/it][A100%|██████████| 1/1 [00:31<00:00, 31.65s/it]
 92%|█████████▏| 4803/5198 [01:47<00:12, 31.36it/s]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4503
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.03s/it][A100%|██████████| 1/1 [00:31<00:00, 31.03s/it]
 92%|█████████▏| 4804/5198 [02:30<00:20, 18.79it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:00:15,814] [INFO] [logging.py:96:log_dist] [Rank 0] step=4803, skipped=0, lr=[6.575439995085983e-07], mom=[(0.9, 0.999)]
steps: 4803 loss: 1.4373 iter time (s): 30.487 samples/sec: 4.199

100%|██████████| 1/1 [00:31<00:00, 31.12s/it][A100%|██████████| 1/1 [00:31<00:00, 31.12s/it]
 92%|█████████▏| 4804/5198 [02:42<00:21, 17.96it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.24s/it][A100%|██████████| 1/1 [00:31<00:00, 31.24s/it]
 92%|█████████▏| 4804/5198 [02:40<00:21, 18.07it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.27s/it][A100%|██████████| 1/1 [00:31<00:00, 31.27s/it]
 92%|█████████▏| 4804/5198 [02:32<00:21, 18.64it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.19s/it][A100%|██████████| 1/1 [00:31<00:00, 31.19s/it]
 92%|█████████▏| 4804/5198 [02:34<00:21, 18.47it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.19s/it][A100%|██████████| 1/1 [00:31<00:00, 31.20s/it]
 92%|█████████▏| 4804/5198 [02:28<00:20, 18.92it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.20s/it][A100%|██████████| 1/1 [00:31<00:00, 31.20s/it]
 92%|█████████▏| 4804/5198 [02:13<00:19, 20.08it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.19s/it][A100%|██████████| 1/1 [00:31<00:00, 31.19s/it]
 92%|█████████▏| 4804/5198 [02:18<00:20, 19.69it/s]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4504
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.59s/it][A100%|██████████| 1/1 [00:31<00:00, 31.59s/it]
 92%|█████████▏| 4805/5198 [03:02<00:31, 12.40it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:00:47,519] [INFO] [logging.py:96:log_dist] [Rank 0] step=4804, skipped=0, lr=[6.561418940544341e-07], mom=[(0.9, 0.999)]
steps: 4804 loss: 1.4655 iter time (s): 30.999 samples/sec: 4.129

100%|██████████| 1/1 [00:31<00:00, 31.75s/it][A100%|██████████| 1/1 [00:31<00:00, 31.75s/it]
 92%|█████████▏| 4805/5198 [03:13<00:32, 12.03it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.71s/it][A100%|██████████| 1/1 [00:31<00:00, 31.71s/it]
 92%|█████████▏| 4805/5198 [03:12<00:32, 12.08it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.72s/it][A100%|██████████| 1/1 [00:31<00:00, 31.72s/it]
 92%|█████████▏| 4805/5198 [03:03<00:31, 12.34it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.73s/it][A100%|██████████| 1/1 [00:31<00:00, 31.73s/it]
 92%|█████████▏| 4805/5198 [03:06<00:32, 12.26it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.75s/it][A100%|██████████| 1/1 [00:31<00:00, 31.75s/it]
 92%|█████████▏| 4805/5198 [03:00<00:31, 12.46it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.74s/it][A100%|██████████| 1/1 [00:31<00:00, 31.74s/it]
 92%|█████████▏| 4805/5198 [02:45<00:30, 12.95it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.73s/it][A100%|██████████| 1/1 [00:31<00:00, 31.73s/it]
 92%|█████████▏| 4805/5198 [02:50<00:30, 12.78it/s]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4505
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.59s/it][A100%|██████████| 1/1 [00:34<00:00, 34.59s/it]
 92%|█████████▏| 4806/5198 [03:36<00:48,  8.10it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:01:22,409] [INFO] [logging.py:96:log_dist] [Rank 0] step=4805, skipped=0, lr=[6.547411823781902e-07], mom=[(0.9, 0.999)]
steps: 4805 loss: 1.4659 iter time (s): 34.150 samples/sec: 3.748

100%|██████████| 1/1 [00:34<00:00, 34.88s/it][A100%|██████████| 1/1 [00:34<00:00, 34.88s/it]
 92%|█████████▏| 4806/5198 [03:48<00:49,  7.93it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.83s/it][A100%|██████████| 1/1 [00:34<00:00, 34.83s/it]
 92%|█████████▏| 4806/5198 [03:46<00:49,  7.96it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.88s/it][A100%|██████████| 1/1 [00:34<00:00, 34.88s/it]
 92%|█████████▏| 4806/5198 [03:38<00:48,  8.06it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.87s/it][A100%|██████████| 1/1 [00:34<00:00, 34.87s/it]
 92%|█████████▏| 4806/5198 [03:41<00:48,  8.03it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.89s/it][A100%|██████████| 1/1 [00:34<00:00, 34.89s/it]
 92%|█████████▏| 4806/5198 [03:35<00:48,  8.11it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.90s/it][A100%|██████████| 1/1 [00:34<00:00, 34.90s/it]
 92%|█████████▏| 4806/5198 [03:20<00:47,  8.32it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.90s/it][A100%|██████████| 1/1 [00:34<00:00, 34.90s/it]
 92%|█████████▏| 4806/5198 [03:25<00:47,  8.25it/s]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4506
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.32s/it][A100%|██████████| 1/1 [00:31<00:00, 31.32s/it]
 92%|█████████▏| 4807/5198 [04:08<01:09,  5.60it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:01:53,711] [INFO] [logging.py:96:log_dist] [Rank 0] step=4806, skipped=0, lr=[6.533418649292485e-07], mom=[(0.9, 0.999)]
steps: 4806 loss: 1.4787 iter time (s): 30.545 samples/sec: 4.191

100%|██████████| 1/1 [00:31<00:00, 31.30s/it][A100%|██████████| 1/1 [00:31<00:00, 31.30s/it]
 92%|█████████▏| 4807/5198 [04:20<01:10,  5.52it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.32s/it][A100%|██████████| 1/1 [00:31<00:00, 31.32s/it]
 92%|█████████▏| 4807/5198 [04:18<01:10,  5.53it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.30s/it][A100%|██████████| 1/1 [00:31<00:00, 31.30s/it]
 92%|█████████▏| 4807/5198 [04:09<01:09,  5.59it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.34s/it][A100%|██████████| 1/1 [00:31<00:00, 31.34s/it]
 92%|█████████▏| 4807/5198 [04:12<01:10,  5.57it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.29s/it][A100%|██████████| 1/1 [00:31<00:00, 31.29s/it]
 92%|█████████▏| 4807/5198 [04:06<01:09,  5.61it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.30s/it][A100%|██████████| 1/1 [00:31<00:00, 31.30s/it]
 92%|█████████▏| 4807/5198 [03:51<01:08,  5.71it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.31s/it][A100%|██████████| 1/1 [00:31<00:00, 31.31s/it]
 92%|█████████▏| 4807/5198 [03:56<01:08,  5.68it/s]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4507
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.13s/it][A100%|██████████| 1/1 [00:32<00:00, 32.13s/it]
 92%|█████████▏| 4808/5198 [04:40<01:41,  3.86it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:02:25,984] [INFO] [logging.py:96:log_dist] [Rank 0] step=4807, skipped=0, lr=[6.519439421565463e-07], mom=[(0.9, 0.999)]
steps: 4807 loss: 1.4417 iter time (s): 31.502 samples/sec: 4.063

100%|██████████| 1/1 [00:32<00:00, 32.21s/it][A100%|██████████| 1/1 [00:32<00:00, 32.22s/it]
 92%|█████████▏| 4808/5198 [04:52<01:41,  3.82it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.25s/it][A100%|██████████| 1/1 [00:32<00:00, 32.25s/it]
 92%|█████████▏| 4808/5198 [04:50<01:41,  3.83it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.24s/it][A100%|██████████| 1/1 [00:32<00:00, 32.24s/it]
 92%|█████████▏| 4808/5198 [04:42<01:41,  3.85it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.29s/it][A100%|██████████| 1/1 [00:32<00:00, 32.29s/it]
 92%|█████████▏| 4808/5198 [04:44<01:41,  3.84it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.26s/it][A100%|██████████| 1/1 [00:32<00:00, 32.26s/it]
 92%|█████████▏| 4808/5198 [04:38<01:40,  3.87it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.29s/it][A100%|██████████| 1/1 [00:32<00:00, 32.29s/it]
 92%|█████████▏| 4808/5198 [04:24<01:39,  3.91it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.27s/it][A100%|██████████| 1/1 [00:32<00:00, 32.28s/it]
 92%|█████████▏| 4808/5198 [04:28<01:40,  3.89it/s]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4508
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.51s/it][A100%|██████████| 1/1 [00:30<00:00, 30.51s/it]
 93%|█████████▎| 4809/5198 [05:11<02:22,  2.72it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:02:56,533] [INFO] [logging.py:96:log_dist] [Rank 0] step=4808, skipped=0, lr=[6.505474145085708e-07], mom=[(0.9, 0.999)]
steps: 4808 loss: 1.4149 iter time (s): 29.767 samples/sec: 4.300

100%|██████████| 1/1 [00:30<00:00, 30.60s/it][A100%|██████████| 1/1 [00:30<00:00, 30.60s/it]
 93%|█████████▎| 4809/5198 [05:22<02:23,  2.70it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.51s/it][A100%|██████████| 1/1 [00:30<00:00, 30.51s/it]
 93%|█████████▎| 4809/5198 [05:20<02:23,  2.71it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.55s/it][A100%|██████████| 1/1 [00:30<00:00, 30.55s/it]
 93%|█████████▎| 4809/5198 [05:12<02:23,  2.72it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.51s/it][A100%|██████████| 1/1 [00:30<00:00, 30.51s/it]
 93%|█████████▎| 4809/5198 [05:15<02:23,  2.72it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.48s/it][A100%|██████████| 1/1 [00:30<00:00, 30.48s/it]
 93%|█████████▎| 4809/5198 [05:09<02:22,  2.73it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.47s/it][A100%|██████████| 1/1 [00:30<00:00, 30.47s/it]
 93%|█████████▎| 4809/5198 [04:54<02:21,  2.75it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.48s/it][A100%|██████████| 1/1 [00:30<00:00, 30.48s/it]
 93%|█████████▎| 4809/5198 [04:59<02:21,  2.74it/s]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4509
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.66s/it][A100%|██████████| 1/1 [00:31<00:00, 31.67s/it]
 93%|█████████▎| 4810/5198 [05:43<03:24,  1.90it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:03:28,351] [INFO] [logging.py:96:log_dist] [Rank 0] step=4809, skipped=0, lr=[6.491522824333631e-07], mom=[(0.9, 0.999)]
steps: 4809 loss: 1.4959 iter time (s): 31.102 samples/sec: 4.115

100%|██████████| 1/1 [00:31<00:00, 31.80s/it][A100%|██████████| 1/1 [00:31<00:00, 31.80s/it]
 93%|█████████▎| 4810/5198 [05:54<03:25,  1.89it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.79s/it][A100%|██████████| 1/1 [00:31<00:00, 31.79s/it]
 93%|█████████▎| 4810/5198 [05:52<03:25,  1.89it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.82s/it][A100%|██████████| 1/1 [00:31<00:00, 31.82s/it]
 93%|█████████▎| 4810/5198 [05:44<03:24,  1.90it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.76s/it][A100%|██████████| 1/1 [00:31<00:00, 31.76s/it]
 93%|█████████▎| 4810/5198 [05:47<03:24,  1.90it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.78s/it][A100%|██████████| 1/1 [00:31<00:00, 31.78s/it]
 93%|█████████▎| 4810/5198 [05:26<03:23,  1.91it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.84s/it][A100%|██████████| 1/1 [00:31<00:00, 31.84s/it]
 93%|█████████▎| 4810/5198 [05:40<03:24,  1.90it/s]
100%|██████████| 1/1 [00:31<00:00, 31.78s/it][A100%|██████████| 1/1 [00:31<00:00, 31.78s/it]
 93%|█████████▎| 4810/5198 [05:31<03:23,  1.91it/s]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4510
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.85s/it][A100%|██████████| 1/1 [00:30<00:00, 30.85s/it]
 93%|█████████▎| 4811/5198 [06:13<04:48,  1.34it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:03:59,272] [INFO] [logging.py:96:log_dist] [Rank 0] step=4810, skipped=0, lr=[6.477585463785163e-07], mom=[(0.9, 0.999)]
steps: 4810 loss: 1.4281 iter time (s): 30.238 samples/sec: 4.233

100%|██████████| 1/1 [00:30<00:00, 30.85s/it][A100%|██████████| 1/1 [00:30<00:00, 30.85s/it]
 93%|█████████▎| 4811/5198 [06:25<04:49,  1.34it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.96s/it][A100%|██████████| 1/1 [00:30<00:00, 30.96s/it]
 93%|█████████▎| 4811/5198 [06:23<04:49,  1.34it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.84s/it][A100%|██████████| 1/1 [00:30<00:00, 30.84s/it]
 93%|█████████▎| 4811/5198 [06:15<04:48,  1.34it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.88s/it][A100%|██████████| 1/1 [00:30<00:00, 30.88s/it]
 93%|█████████▎| 4811/5198 [06:18<04:48,  1.34it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.88s/it][A100%|██████████| 1/1 [00:30<00:00, 30.88s/it]
 93%|█████████▎| 4811/5198 [06:11<04:48,  1.34it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.92s/it][A100%|██████████| 1/1 [00:30<00:00, 30.92s/it]
 93%|█████████▎| 4811/5198 [05:57<04:47,  1.35it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.91s/it][A100%|██████████| 1/1 [00:30<00:00, 30.91s/it]
 93%|█████████▎| 4811/5198 [06:01<04:47,  1.35it/s]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4511
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.28s/it][A100%|██████████| 1/1 [00:35<00:00, 35.28s/it]
 93%|█████████▎| 4812/5198 [06:49<07:04,  1.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:04:34,855] [INFO] [logging.py:96:log_dist] [Rank 0] step=4811, skipped=0, lr=[6.463662067911762e-07], mom=[(0.9, 0.999)]
steps: 4811 loss: 1.4799 iter time (s): 34.902 samples/sec: 3.667

100%|██████████| 1/1 [00:35<00:00, 35.71s/it][A100%|██████████| 1/1 [00:35<00:00, 35.71s/it]
 93%|█████████▎| 4812/5198 [07:01<07:06,  1.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.61s/it][A100%|██████████| 1/1 [00:35<00:00, 35.61s/it]
 93%|█████████▎| 4812/5198 [06:59<07:05,  1.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.72s/it][A100%|██████████| 1/1 [00:35<00:00, 35.72s/it]
 93%|█████████▎| 4812/5198 [06:51<07:05,  1.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.72s/it][A100%|██████████| 1/1 [00:35<00:00, 35.73s/it]
 93%|█████████▎| 4812/5198 [06:53<07:05,  1.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.73s/it][A100%|██████████| 1/1 [00:35<00:00, 35.73s/it]
 93%|█████████▎| 4812/5198 [06:47<07:05,  1.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.72s/it][A100%|██████████| 1/1 [00:35<00:00, 35.72s/it]
 93%|█████████▎| 4812/5198 [06:32<07:04,  1.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.72s/it][A100%|██████████| 1/1 [00:35<00:00, 35.72s/it]
 93%|█████████▎| 4812/5198 [06:37<07:04,  1.10s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4512
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.19s/it][A100%|██████████| 1/1 [00:30<00:00, 30.19s/it]
 93%|█████████▎| 4813/5198 [07:19<09:44,  1.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:05:04,988] [INFO] [logging.py:96:log_dist] [Rank 0] step=4812, skipped=0, lr=[6.449752641180381e-07], mom=[(0.9, 0.999)]
steps: 4812 loss: 1.4347 iter time (s): 29.303 samples/sec: 4.368

100%|██████████| 1/1 [00:29<00:00, 30.00s/it][A100%|██████████| 1/1 [00:29<00:00, 30.00s/it]
 93%|█████████▎| 4813/5198 [07:31<09:44,  1.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 30.00s/it][A100%|██████████| 1/1 [00:29<00:00, 30.00s/it]
 93%|█████████▎| 4813/5198 [07:29<09:44,  1.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.94s/it][A100%|██████████| 1/1 [00:29<00:00, 29.94s/it]
 93%|█████████▎| 4813/5198 [07:21<09:43,  1.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.93s/it][A100%|██████████| 1/1 [00:29<00:00, 29.93s/it]
 93%|█████████▎| 4813/5198 [07:23<09:43,  1.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.92s/it][A100%|██████████| 1/1 [00:29<00:00, 29.92s/it]
 93%|█████████▎| 4813/5198 [07:02<09:42,  1.51s/it]
100%|██████████| 1/1 [00:29<00:00, 29.94s/it][A100%|██████████| 1/1 [00:29<00:00, 29.94s/it]
 93%|█████████▎| 4813/5198 [07:17<09:43,  1.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.93s/it][A100%|██████████| 1/1 [00:29<00:00, 29.93s/it]
 93%|█████████▎| 4813/5198 [07:07<09:42,  1.51s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4513
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.61s/it][A100%|██████████| 1/1 [00:28<00:00, 28.61s/it]
 93%|█████████▎| 4814/5198 [07:48<13:13,  2.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:05:33,788] [INFO] [logging.py:96:log_dist] [Rank 0] step=4813, skipped=0, lr=[6.435857188053539e-07], mom=[(0.9, 0.999)]
steps: 4813 loss: 1.4464 iter time (s): 28.170 samples/sec: 4.544

100%|██████████| 1/1 [00:28<00:00, 28.86s/it][A100%|██████████| 1/1 [00:28<00:00, 28.86s/it]
 93%|█████████▎| 4814/5198 [08:00<13:13,  2.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.84s/it][A100%|██████████| 1/1 [00:28<00:00, 28.84s/it]
 93%|█████████▎| 4814/5198 [07:58<13:13,  2.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.82s/it][A100%|██████████| 1/1 [00:28<00:00, 28.82s/it]
 93%|█████████▎| 4814/5198 [07:49<13:12,  2.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.83s/it][A100%|██████████| 1/1 [00:28<00:00, 28.83s/it]
 93%|█████████▎| 4814/5198 [07:52<13:12,  2.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.78s/it][A100%|██████████| 1/1 [00:28<00:00, 28.78s/it]
 93%|█████████▎| 4814/5198 [07:46<13:12,  2.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.83s/it][A100%|██████████| 1/1 [00:28<00:00, 28.83s/it]
 93%|█████████▎| 4814/5198 [07:31<13:11,  2.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.83s/it][A100%|██████████| 1/1 [00:28<00:00, 28.83s/it]
 93%|█████████▎| 4814/5198 [07:36<13:11,  2.06s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4514
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.81s/it][A100%|██████████| 1/1 [00:30<00:00, 30.81s/it]
 93%|█████████▎| 4815/5198 [08:19<18:19,  2.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:06:04,813] [INFO] [logging.py:96:log_dist] [Rank 0] step=4814, skipped=0, lr=[6.421975712989206e-07], mom=[(0.9, 0.999)]
steps: 4814 loss: 1.5371 iter time (s): 30.364 samples/sec: 4.216

100%|██████████| 1/1 [00:30<00:00, 30.96s/it][A100%|██████████| 1/1 [00:30<00:00, 30.96s/it]
 93%|█████████▎| 4815/5198 [08:31<18:20,  2.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.09s/it][A100%|██████████| 1/1 [00:31<00:00, 31.09s/it]
 93%|█████████▎| 4815/5198 [08:29<18:21,  2.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.11s/it][A100%|██████████| 1/1 [00:31<00:00, 31.11s/it]
 93%|█████████▎| 4815/5198 [08:21<18:20,  2.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.11s/it][A100%|██████████| 1/1 [00:31<00:00, 31.11s/it]
 93%|█████████▎| 4815/5198 [08:23<18:20,  2.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.12s/it][A100%|██████████| 1/1 [00:31<00:00, 31.12s/it]
 93%|█████████▎| 4815/5198 [08:17<18:20,  2.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.08s/it][A100%|██████████| 1/1 [00:31<00:00, 31.08s/it]
 93%|█████████▎| 4815/5198 [08:02<18:19,  2.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.09s/it][A100%|██████████| 1/1 [00:31<00:00, 31.09s/it]
 93%|█████████▎| 4815/5198 [08:07<18:19,  2.87s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_300
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:23<00:00, 23.54s/it][A100%|██████████| 1/1 [00:23<00:00, 23.54s/it]
[2024-09-01 23:06:28,508] [INFO] [logging.py:96:log_dist] [Rank 0] step=4815, skipped=0, lr=[6.408108220440927e-07], mom=[(0.9, 0.999)]
steps: 4815 loss: 2.0479 iter time (s): 22.995 samples/sec: 5.567

100%|██████████| 1/1 [00:23<00:00, 23.76s/it][A100%|██████████| 1/1 [00:23<00:00, 23.76s/it]

100%|██████████| 1/1 [00:23<00:00, 23.82s/it][A100%|██████████| 1/1 [00:23<00:00, 23.82s/it]

100%|██████████| 1/1 [00:23<00:00, 23.79s/it][A100%|██████████| 1/1 [00:23<00:00, 23.79s/it]

100%|██████████| 1/1 [00:23<00:00, 23.75s/it][A100%|██████████| 1/1 [00:23<00:00, 23.75s/it]

100%|██████████| 1/1 [00:23<00:00, 23.76s/it][A100%|██████████| 1/1 [00:23<00:00, 23.76s/it]
Checkpointing at shard 4815

100%|██████████| 1/1 [00:23<00:00, 23.79s/it][A100%|██████████| 1/1 [00:23<00:00, 23.79s/it]

100%|██████████| 1/1 [00:23<00:00, 23.78s/it][A100%|██████████| 1/1 [00:23<00:00, 23.78s/it]
[2024-09-01 23:06:31,899] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step4815 is about to be saved!
[2024-09-01 23:06:32,315] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4815/layer_00-model_states.pt...
[2024-09-01 23:06:34,198] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4815/layer_02-model_states.pt...
[2024-09-01 23:06:34,463] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4815/layer_06-model_states.pt...
[2024-09-01 23:06:34,799] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4815/layer_07-model_states.pt...
[2024-09-01 23:06:34,840] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4815/layer_08-model_states.pt...
[2024-09-01 23:06:34,840] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4815/layer_05-model_states.pt...
[2024-09-01 23:06:36,433] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4815/layer_00-model_states.pt.
[2024-09-01 23:06:38,165] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4815/layer_01-model_states.pt...
[2024-09-01 23:06:39,624] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4815/layer_04-model_states.pt...
[2024-09-01 23:06:39,658] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4815/layer_03-model_states.pt...
[2024-09-01 23:07:35,118] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4815/layer_07-model_states.pt.
[2024-09-01 23:07:35,150] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4815/mp_rank_06_model_states.pt...
[2024-09-01 23:07:35,311] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4815/mp_rank_06_model_states.pt.
[2024-09-01 23:07:35,311] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4815 is ready now!
[2024-09-01 23:07:36,804] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4815/layer_05-model_states.pt.
[2024-09-01 23:07:36,825] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4815/mp_rank_04_model_states.pt...
[2024-09-01 23:07:36,945] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4815/mp_rank_04_model_states.pt.
[2024-09-01 23:07:36,945] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4815 is ready now!
[2024-09-01 23:07:37,005] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4815/layer_08-model_states.pt.
[2024-09-01 23:07:37,062] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4815/layer_09-model_states.pt...
[2024-09-01 23:07:37,278] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4815/layer_02-model_states.pt.
[2024-09-01 23:07:37,304] [INFO] [logging.py:96:log_dist] [Rank 1] Saving model checkpoint: /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4815/mp_rank_01_model_states.pt
[2024-09-01 23:07:37,304] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4815/mp_rank_01_model_states.pt...
[2024-09-01 23:07:37,401] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4815/mp_rank_01_model_states.pt.
[2024-09-01 23:07:37,401] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4815 is ready now!
[2024-09-01 23:07:37,716] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4815/layer_06-model_states.pt.
[2024-09-01 23:07:37,738] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4815/mp_rank_05_model_states.pt...
[2024-09-01 23:07:37,842] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4815/mp_rank_05_model_states.pt.
[2024-09-01 23:07:37,842] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4815 is ready now!
[2024-09-01 23:07:37,876] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4815/layer_09-model_states.pt.
[2024-09-01 23:07:37,879] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4815/mp_rank_07_model_states.pt...
[2024-09-01 23:07:37,951] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4815/mp_rank_07_model_states.pt.
[2024-09-01 23:07:37,951] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4815 is ready now!
[2024-09-01 23:07:40,231] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4815/layer_01-model_states.pt.
[2024-09-01 23:07:40,257] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4815/mp_rank_00_model_states.pt
[2024-09-01 23:07:40,257] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4815/mp_rank_00_model_states.pt...
[2024-09-01 23:07:40,606] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4815/mp_rank_00_model_states.pt.
[2024-09-01 23:07:40,606] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4815 is ready now!
[2024-09-01 23:07:41,031] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4815/layer_04-model_states.pt.
[2024-09-01 23:07:41,034] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4815/layer_03-model_states.pt.
[2024-09-01 23:07:41,057] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4815/mp_rank_02_model_states.pt...
[2024-09-01 23:07:41,057] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4815/mp_rank_03_model_states.pt...
[2024-09-01 23:07:41,102] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4815/mp_rank_02_model_states.pt.
[2024-09-01 23:07:41,102] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4815 is ready now!
[2024-09-01 23:07:41,103] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4815/mp_rank_03_model_states.pt.
[2024-09-01 23:07:41,103] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4815 is ready now!
Checkpoint saved using --- 71.80617260932922 seconds ---
 93%|█████████▎| 4816/5198 [09:43<40:52,  6.42s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4515
 93%|█████████▎| 4816/5198 [09:59<40:55,  6.43s/it] 93%|█████████▎| 4816/5198 [09:53<40:54,  6.42s/it] 93%|█████████▎| 4816/5198 [10:05<40:58,  6.44s/it] 93%|█████████▎| 4816/5198 [09:38<40:52,  6.42s/it] 93%|█████████▎| 4816/5198 [09:56<40:56,  6.43s/it] 93%|█████████▎| 4816/5198 [10:07<41:00,  6.44s/it] 93%|█████████▎| 4816/5198 [09:56<41:09,  6.46s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A

  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:27<00:00, 27.08s/it][A100%|██████████| 1/1 [00:27<00:00, 27.08s/it]
 93%|█████████▎| 4817/5198 [10:23<47:52,  7.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:08:08,606] [INFO] [logging.py:96:log_dist] [Rank 0] step=4816, skipped=0, lr=[6.394254714857732e-07], mom=[(0.9, 0.999)]
steps: 4816 loss: 1.5120 iter time (s): 27.400 samples/sec: 4.671

100%|██████████| 1/1 [00:27<00:00, 27.70s/it][A100%|██████████| 1/1 [00:27<00:00, 27.70s/it]
 93%|█████████▎| 4817/5198 [10:34<47:55,  7.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:27<00:00, 27.79s/it][A100%|██████████| 1/1 [00:27<00:00, 27.79s/it]
 93%|█████████▎| 4817/5198 [10:33<47:55,  7.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:27<00:00, 27.87s/it][A100%|██████████| 1/1 [00:27<00:00, 27.87s/it]
 93%|█████████▎| 4817/5198 [10:24<47:55,  7.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:27<00:00, 27.94s/it][A100%|██████████| 1/1 [00:27<00:00, 27.94s/it]
 93%|█████████▎| 4817/5198 [10:27<47:56,  7.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.01s/it][A100%|██████████| 1/1 [00:28<00:00, 28.01s/it]
 93%|█████████▎| 4817/5198 [10:06<47:55,  7.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.02s/it][A100%|██████████| 1/1 [00:28<00:00, 28.02s/it]
 93%|█████████▎| 4817/5198 [10:21<47:56,  7.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.04s/it][A100%|██████████| 1/1 [00:28<00:00, 28.04s/it]
 93%|█████████▎| 4817/5198 [10:11<47:55,  7.55s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4516
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.78s/it][A100%|██████████| 1/1 [00:28<00:00, 28.78s/it]
 93%|█████████▎| 4818/5198 [10:52<57:05,  9.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:08:37,552] [INFO] [logging.py:96:log_dist] [Rank 0] step=4817, skipped=0, lr=[6.380415200684169e-07], mom=[(0.9, 0.999)]
steps: 4817 loss: 1.5120 iter time (s): 28.298 samples/sec: 4.523

100%|██████████| 1/1 [00:28<00:00, 28.91s/it][A100%|██████████| 1/1 [00:28<00:00, 28.91s/it]
 93%|█████████▎| 4818/5198 [11:03<57:08,  9.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.93s/it][A100%|██████████| 1/1 [00:28<00:00, 28.93s/it]
 93%|█████████▎| 4818/5198 [11:01<57:09,  9.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.98s/it][A100%|██████████| 1/1 [00:28<00:00, 28.98s/it]
 93%|█████████▎| 4818/5198 [10:53<57:10,  9.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.95s/it][A100%|██████████| 1/1 [00:28<00:00, 28.95s/it]
 93%|█████████▎| 4818/5198 [10:56<57:10,  9.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.90s/it][A100%|██████████| 1/1 [00:28<00:00, 28.90s/it]
 93%|█████████▎| 4818/5198 [10:50<57:08,  9.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.95s/it][A100%|██████████| 1/1 [00:28<00:00, 28.95s/it]
 93%|█████████▎| 4818/5198 [10:35<57:08,  9.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.93s/it][A100%|██████████| 1/1 [00:28<00:00, 28.93s/it]
 93%|█████████▎| 4818/5198 [10:40<57:08,  9.02s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4517
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.84s/it][A100%|██████████| 1/1 [00:31<00:00, 31.84s/it]
 93%|█████████▎| 4819/5198 [11:24<1:09:57, 11.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:09:09,560] [INFO] [logging.py:96:log_dist] [Rank 0] step=4818, skipped=0, lr=[6.366589682360307e-07], mom=[(0.9, 0.999)]
steps: 4818 loss: 1.5559 iter time (s): 31.368 samples/sec: 4.081

100%|██████████| 1/1 [00:32<00:00, 32.09s/it][A100%|██████████| 1/1 [00:32<00:00, 32.09s/it]
 93%|█████████▎| 4819/5198 [11:35<1:10:04, 11.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.11s/it][A100%|██████████| 1/1 [00:32<00:00, 32.12s/it]
 93%|█████████▎| 4819/5198 [11:34<1:10:05, 11.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.11s/it][A100%|██████████| 1/1 [00:32<00:00, 32.11s/it]
 93%|█████████▎| 4819/5198 [11:25<1:10:06, 11.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.11s/it][A100%|██████████| 1/1 [00:32<00:00, 32.11s/it]
 93%|█████████▎| 4819/5198 [11:28<1:10:06, 11.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.15s/it][A100%|██████████| 1/1 [00:32<00:00, 32.15s/it]
 93%|█████████▎| 4819/5198 [11:22<1:10:06, 11.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.16s/it][A100%|██████████| 1/1 [00:32<00:00, 32.16s/it]
 93%|█████████▎| 4819/5198 [11:07<1:10:06, 11.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.18s/it][A100%|██████████| 1/1 [00:32<00:00, 32.18s/it]
 93%|█████████▎| 4819/5198 [11:12<1:10:07, 11.10s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4518
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.66s/it][A100%|██████████| 1/1 [00:29<00:00, 29.66s/it]
 93%|█████████▎| 4820/5198 [11:54<1:23:10, 13.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:09:39,325] [INFO] [logging.py:96:log_dist] [Rank 0] step=4819, skipped=0, lr=[6.352778164321697e-07], mom=[(0.9, 0.999)]
steps: 4819 loss: 1.5116 iter time (s): 28.945 samples/sec: 4.422

100%|██████████| 1/1 [00:29<00:00, 29.64s/it][A100%|██████████| 1/1 [00:29<00:00, 29.65s/it]
 93%|█████████▎| 4820/5198 [12:05<1:23:10, 13.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.66s/it][A100%|██████████| 1/1 [00:29<00:00, 29.66s/it]
 93%|█████████▎| 4820/5198 [12:03<1:23:12, 13.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.63s/it][A100%|██████████| 1/1 [00:29<00:00, 29.63s/it]
 93%|█████████▎| 4820/5198 [11:55<1:23:11, 13.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.62s/it][A100%|██████████| 1/1 [00:29<00:00, 29.62s/it]
 93%|█████████▎| 4820/5198 [11:58<1:23:10, 13.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.62s/it][A100%|██████████| 1/1 [00:29<00:00, 29.62s/it]
 93%|█████████▎| 4820/5198 [11:51<1:23:10, 13.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.60s/it][A100%|██████████| 1/1 [00:29<00:00, 29.60s/it]
 93%|█████████▎| 4820/5198 [11:37<1:23:10, 13.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.58s/it][A100%|██████████| 1/1 [00:29<00:00, 29.58s/it]
 93%|█████████▎| 4820/5198 [11:41<1:23:10, 13.20s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4519
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.97s/it][A100%|██████████| 1/1 [00:33<00:00, 33.97s/it]
 93%|█████████▎| 4821/5198 [12:28<1:41:17, 16.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:10:13,592] [INFO] [logging.py:96:log_dist] [Rank 0] step=4820, skipped=0, lr=[6.338980650999428e-07], mom=[(0.9, 0.999)]
steps: 4820 loss: 1.4902 iter time (s): 33.623 samples/sec: 3.807

100%|██████████| 1/1 [00:34<00:00, 34.31s/it][A100%|██████████| 1/1 [00:34<00:00, 34.31s/it]
 93%|█████████▎| 4821/5198 [12:39<1:41:29, 16.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.25s/it][A100%|██████████| 1/1 [00:34<00:00, 34.25s/it]
 93%|█████████▎| 4821/5198 [12:38<1:41:27, 16.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.32s/it][A100%|██████████| 1/1 [00:34<00:00, 34.33s/it]
 93%|█████████▎| 4821/5198 [12:29<1:41:30, 16.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.33s/it][A100%|██████████| 1/1 [00:34<00:00, 34.33s/it]
 93%|█████████▎| 4821/5198 [12:32<1:41:30, 16.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.37s/it][A100%|██████████| 1/1 [00:34<00:00, 34.37s/it]
 93%|█████████▎| 4821/5198 [12:26<1:41:32, 16.16s/it]
100%|██████████| 1/1 [00:34<00:00, 34.35s/it][A100%|██████████| 1/1 [00:34<00:00, 34.35s/it]
 93%|█████████▎| 4821/5198 [12:11<1:41:30, 16.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.36s/it][A100%|██████████| 1/1 [00:34<00:00, 34.36s/it]
 93%|█████████▎| 4821/5198 [12:16<1:41:31, 16.16s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4520
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.83s/it][A100%|██████████| 1/1 [00:31<00:00, 31.83s/it]
 93%|█████████▎| 4822/5198 [13:00<1:57:32, 18.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:10:45,443] [INFO] [logging.py:96:log_dist] [Rank 0] step=4821, skipped=0, lr=[6.325197146820078e-07], mom=[(0.9, 0.999)]
steps: 4821 loss: 1.4933 iter time (s): 31.112 samples/sec: 4.114

100%|██████████| 1/1 [00:31<00:00, 31.94s/it][A100%|██████████| 1/1 [00:31<00:00, 31.94s/it]
 93%|█████████▎| 4822/5198 [13:11<1:57:40, 18.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.90s/it][A100%|██████████| 1/1 [00:31<00:00, 31.90s/it]
 93%|█████████▎| 4822/5198 [13:09<1:57:36, 18.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.88s/it][A100%|██████████| 1/1 [00:31<00:00, 31.88s/it]
 93%|█████████▎| 4822/5198 [13:01<1:57:38, 18.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.96s/it][A100%|██████████| 1/1 [00:31<00:00, 31.96s/it]
 93%|█████████▎| 4822/5198 [13:04<1:57:43, 18.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.89s/it][A100%|██████████| 1/1 [00:31<00:00, 31.89s/it]
 93%|█████████▎| 4822/5198 [12:58<1:57:40, 18.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.90s/it][A100%|██████████| 1/1 [00:31<00:00, 31.91s/it]
 93%|█████████▎| 4822/5198 [12:43<1:57:39, 18.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.90s/it][A100%|██████████| 1/1 [00:31<00:00, 31.90s/it]
 93%|█████████▎| 4822/5198 [12:48<1:57:39, 18.78s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4521
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.52s/it][A100%|██████████| 1/1 [00:31<00:00, 31.52s/it]
 93%|█████████▎| 4823/5198 [13:31<2:12:40, 21.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:11:17,107] [INFO] [logging.py:96:log_dist] [Rank 0] step=4822, skipped=0, lr=[6.311427656205746e-07], mom=[(0.9, 0.999)]
steps: 4822 loss: 1.4730 iter time (s): 30.871 samples/sec: 4.146

100%|██████████| 1/1 [00:31<00:00, 31.59s/it][A100%|██████████| 1/1 [00:31<00:00, 31.59s/it]
 93%|█████████▎| 4823/5198 [13:43<2:12:45, 21.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.68s/it][A100%|██████████| 1/1 [00:31<00:00, 31.68s/it]
 93%|█████████▎| 4823/5198 [13:41<2:12:47, 21.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.71s/it][A100%|██████████| 1/1 [00:31<00:00, 31.71s/it]
 93%|█████████▎| 4823/5198 [13:33<2:12:51, 21.26s/it]
100%|██████████| 1/1 [00:31<00:00, 31.60s/it][A100%|██████████| 1/1 [00:31<00:00, 31.60s/it]
 93%|█████████▎| 4823/5198 [13:36<2:12:47, 21.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.66s/it][A100%|██████████| 1/1 [00:31<00:00, 31.66s/it]
 93%|█████████▎| 4823/5198 [13:29<2:12:49, 21.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.70s/it][A100%|██████████| 1/1 [00:31<00:00, 31.70s/it]
 93%|█████████▎| 4823/5198 [13:15<2:12:52, 21.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.70s/it][A100%|██████████| 1/1 [00:31<00:00, 31.70s/it]
 93%|█████████▎| 4823/5198 [13:19<2:12:51, 21.26s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4522
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.01s/it][A100%|██████████| 1/1 [00:32<00:00, 32.01s/it]
 93%|█████████▎| 4824/5198 [14:03<2:26:57, 23.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:11:49,233] [INFO] [logging.py:96:log_dist] [Rank 0] step=4823, skipped=0, lr=[6.297672183574023e-07], mom=[(0.9, 0.999)]
steps: 4823 loss: 1.4449 iter time (s): 31.292 samples/sec: 4.090

100%|██████████| 1/1 [00:32<00:00, 32.06s/it][A100%|██████████| 1/1 [00:32<00:00, 32.06s/it]
 93%|█████████▎| 4824/5198 [14:15<2:26:55, 23.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.04s/it][A100%|██████████| 1/1 [00:32<00:00, 32.04s/it]
 93%|█████████▎| 4824/5198 [14:13<2:26:56, 23.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.05s/it][A100%|██████████| 1/1 [00:32<00:00, 32.05s/it]
 93%|█████████▎| 4824/5198 [14:05<2:26:59, 23.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.08s/it][A100%|██████████| 1/1 [00:32<00:00, 32.08s/it]
 93%|█████████▎| 4824/5198 [14:08<2:26:58, 23.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.07s/it][A100%|██████████| 1/1 [00:32<00:00, 32.07s/it]
 93%|█████████▎| 4824/5198 [14:01<2:26:59, 23.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.05s/it][A100%|██████████| 1/1 [00:32<00:00, 32.05s/it]
 93%|█████████▎| 4824/5198 [13:47<2:26:59, 23.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.05s/it][A100%|██████████| 1/1 [00:32<00:00, 32.05s/it]
 93%|█████████▎| 4824/5198 [13:51<2:26:59, 23.58s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4523
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.10s/it][A100%|██████████| 1/1 [00:35<00:00, 35.10s/it]
 93%|█████████▎| 4825/5198 [14:39<2:43:38, 26.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:12:24,644] [INFO] [logging.py:96:log_dist] [Rank 0] step=4824, skipped=0, lr=[6.283930733338022e-07], mom=[(0.9, 0.999)]
steps: 4824 loss: 1.4666 iter time (s): 34.644 samples/sec: 3.695

100%|██████████| 1/1 [00:35<00:00, 35.48s/it][A100%|██████████| 1/1 [00:35<00:00, 35.49s/it]
 93%|█████████▎| 4825/5198 [14:51<2:43:58, 26.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.43s/it][A100%|██████████| 1/1 [00:35<00:00, 35.43s/it]
 93%|█████████▎| 4825/5198 [14:49<2:43:53, 26.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.31s/it][A100%|██████████| 1/1 [00:35<00:00, 35.31s/it]
 93%|█████████▎| 4825/5198 [14:40<2:43:45, 26.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.38s/it][A100%|██████████| 1/1 [00:35<00:00, 35.38s/it]
 93%|█████████▎| 4825/5198 [14:43<2:43:50, 26.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.38s/it][A100%|██████████| 1/1 [00:35<00:00, 35.38s/it]
 93%|█████████▎| 4825/5198 [14:37<2:43:51, 26.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.40s/it][A100%|██████████| 1/1 [00:35<00:00, 35.40s/it]
 93%|█████████▎| 4825/5198 [14:22<2:43:52, 26.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.39s/it][A100%|██████████| 1/1 [00:35<00:00, 35.39s/it]
 93%|█████████▎| 4825/5198 [14:27<2:43:52, 26.36s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4524
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.21s/it][A100%|██████████| 1/1 [00:31<00:00, 31.21s/it]
 93%|█████████▎| 4826/5198 [15:10<2:50:59, 27.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:12:55,797] [INFO] [logging.py:96:log_dist] [Rank 0] step=4825, skipped=0, lr=[6.270203309906307e-07], mom=[(0.9, 0.999)]
steps: 4825 loss: 1.4713 iter time (s): 30.397 samples/sec: 4.211

100%|██████████| 1/1 [00:31<00:00, 31.07s/it][A100%|██████████| 1/1 [00:31<00:00, 31.07s/it]
 93%|█████████▎| 4826/5198 [15:22<2:50:51, 27.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.14s/it][A100%|██████████| 1/1 [00:31<00:00, 31.14s/it]
 93%|█████████▎| 4826/5198 [15:20<2:50:55, 27.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.19s/it][A100%|██████████| 1/1 [00:31<00:00, 31.19s/it]
 93%|█████████▎| 4826/5198 [15:12<2:50:53, 27.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.19s/it][A100%|██████████| 1/1 [00:31<00:00, 31.19s/it]
 93%|█████████▎| 4826/5198 [15:14<2:50:56, 27.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.17s/it][A100%|██████████| 1/1 [00:31<00:00, 31.17s/it]
 93%|█████████▎| 4826/5198 [15:08<2:50:56, 27.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.15s/it][A100%|██████████| 1/1 [00:31<00:00, 31.15s/it]
 93%|█████████▎| 4826/5198 [14:53<2:50:54, 27.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.16s/it][A100%|██████████| 1/1 [00:31<00:00, 31.16s/it]
 93%|█████████▎| 4826/5198 [14:58<2:50:55, 27.57s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4525
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.37s/it][A100%|██████████| 1/1 [00:32<00:00, 32.37s/it]
 93%|█████████▎| 4827/5198 [15:42<2:58:32, 28.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:13:28,341] [INFO] [logging.py:96:log_dist] [Rank 0] step=4826, skipped=0, lr=[6.256489917682997e-07], mom=[(0.9, 0.999)]
steps: 4826 loss: 1.4557 iter time (s): 31.779 samples/sec: 4.028

100%|██████████| 1/1 [00:32<00:00, 32.67s/it][A100%|██████████| 1/1 [00:32<00:00, 32.67s/it]
 93%|█████████▎| 4827/5198 [15:54<2:58:46, 28.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.64s/it][A100%|██████████| 1/1 [00:32<00:00, 32.64s/it]
 93%|█████████▎| 4827/5198 [15:52<2:58:46, 28.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.60s/it][A100%|██████████| 1/1 [00:32<00:00, 32.60s/it]
 93%|█████████▎| 4827/5198 [15:44<2:58:40, 28.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.53s/it][A100%|██████████| 1/1 [00:32<00:00, 32.53s/it]
 93%|█████████▎| 4827/5198 [15:40<2:58:35, 28.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.63s/it][A100%|██████████| 1/1 [00:32<00:00, 32.63s/it]
 93%|█████████▎| 4827/5198 [15:47<2:58:46, 28.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.57s/it][A100%|██████████| 1/1 [00:32<00:00, 32.57s/it]
 93%|█████████▎| 4827/5198 [15:26<2:58:38, 28.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.57s/it][A100%|██████████| 1/1 [00:32<00:00, 32.57s/it]
 93%|█████████▎| 4827/5198 [15:31<2:58:38, 28.89s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4526
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.52s/it][A100%|██████████| 1/1 [00:31<00:00, 31.52s/it]
 93%|█████████▎| 4828/5198 [16:14<3:02:45, 29.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:13:59,878] [INFO] [logging.py:96:log_dist] [Rank 0] step=4827, skipped=0, lr=[6.24279056106769e-07], mom=[(0.9, 0.999)]
steps: 4827 loss: 1.5547 iter time (s): 30.736 samples/sec: 4.165

100%|██████████| 1/1 [00:31<00:00, 31.36s/it][A100%|██████████| 1/1 [00:31<00:00, 31.36s/it]
 93%|█████████▎| 4828/5198 [16:26<3:02:26, 29.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.35s/it][A100%|██████████| 1/1 [00:31<00:00, 31.35s/it]
 93%|█████████▎| 4828/5198 [16:24<3:02:25, 29.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.48s/it][A100%|██████████| 1/1 [00:31<00:00, 31.48s/it]
 93%|█████████▎| 4828/5198 [16:16<3:02:35, 29.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.37s/it][A100%|██████████| 1/1 [00:31<00:00, 31.37s/it]
 93%|█████████▎| 4828/5198 [16:18<3:02:27, 29.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.46s/it][A100%|██████████| 1/1 [00:31<00:00, 31.46s/it]
 93%|█████████▎| 4828/5198 [16:12<3:02:28, 29.59s/it]
100%|██████████| 1/1 [00:31<00:00, 31.40s/it][A100%|██████████| 1/1 [00:31<00:00, 31.40s/it]
 93%|█████████▎| 4828/5198 [15:57<3:02:24, 29.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.39s/it][A100%|██████████| 1/1 [00:31<00:00, 31.39s/it]
 93%|█████████▎| 4828/5198 [16:02<3:02:24, 29.58s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4527
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.23s/it][A100%|██████████| 1/1 [00:31<00:00, 31.23s/it]
 93%|█████████▎| 4829/5198 [16:45<3:05:11, 30.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:14:31,267] [INFO] [logging.py:96:log_dist] [Rank 0] step=4828, skipped=0, lr=[6.229105244455473e-07], mom=[(0.9, 0.999)]
steps: 4828 loss: 1.4166 iter time (s): 30.728 samples/sec: 4.166

100%|██████████| 1/1 [00:31<00:00, 31.46s/it][A100%|██████████| 1/1 [00:31<00:00, 31.46s/it]
 93%|█████████▎| 4829/5198 [16:57<3:05:12, 30.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.48s/it][A100%|██████████| 1/1 [00:31<00:00, 31.48s/it]
 93%|█████████▎| 4829/5198 [16:55<3:05:13, 30.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.46s/it][A100%|██████████| 1/1 [00:31<00:00, 31.46s/it]
 93%|█████████▎| 4829/5198 [16:50<3:05:13, 30.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.50s/it][A100%|██████████| 1/1 [00:31<00:00, 31.50s/it]
 93%|█████████▎| 4829/5198 [16:47<3:05:22, 30.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.47s/it][A100%|██████████| 1/1 [00:31<00:00, 31.47s/it]
 93%|█████████▎| 4829/5198 [16:43<3:05:15, 30.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.52s/it][A100%|██████████| 1/1 [00:31<00:00, 31.52s/it]
 93%|█████████▎| 4829/5198 [16:29<3:05:17, 30.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.53s/it][A100%|██████████| 1/1 [00:31<00:00, 31.53s/it]
 93%|█████████▎| 4829/5198 [16:34<3:05:18, 30.13s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4528
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.73s/it][A100%|██████████| 1/1 [00:31<00:00, 31.73s/it]
 93%|█████████▎| 4830/5198 [17:17<3:07:44, 30.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:15:03,104] [INFO] [logging.py:96:log_dist] [Rank 0] step=4829, skipped=0, lr=[6.215433972236951e-07], mom=[(0.9, 0.999)]
steps: 4829 loss: 1.4823 iter time (s): 31.029 samples/sec: 4.125

100%|██████████| 1/1 [00:31<00:00, 31.88s/it][A100%|██████████| 1/1 [00:31<00:00, 31.88s/it]
 93%|█████████▎| 4830/5198 [17:29<3:07:49, 30.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.92s/it][A100%|██████████| 1/1 [00:31<00:00, 31.92s/it]
 93%|█████████▎| 4830/5198 [17:27<3:07:54, 30.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.76s/it][A100%|██████████| 1/1 [00:31<00:00, 31.76s/it]
 93%|█████████▎| 4830/5198 [17:19<3:07:43, 30.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.83s/it][A100%|██████████| 1/1 [00:31<00:00, 31.83s/it]
 93%|█████████▎| 4830/5198 [17:22<3:07:44, 30.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.79s/it][A100%|██████████| 1/1 [00:31<00:00, 31.79s/it]
 93%|█████████▎| 4830/5198 [17:15<3:07:42, 30.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.80s/it][A100%|██████████| 1/1 [00:31<00:00, 31.80s/it]
 93%|█████████▎| 4830/5198 [17:01<3:07:44, 30.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.78s/it][A100%|██████████| 1/1 [00:31<00:00, 31.78s/it]
 93%|█████████▎| 4830/5198 [17:05<3:07:43, 30.61s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4529
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.16s/it][A100%|██████████| 1/1 [00:34<00:00, 34.16s/it]
 93%|█████████▎| 4831/5198 [17:52<3:13:53, 31.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:15:37,577] [INFO] [logging.py:96:log_dist] [Rank 0] step=4830, skipped=0, lr=[6.201776748798181e-07], mom=[(0.9, 0.999)]
steps: 4830 loss: 1.4153 iter time (s): 33.712 samples/sec: 3.797

100%|██████████| 1/1 [00:34<00:00, 34.46s/it][A100%|██████████| 1/1 [00:34<00:00, 34.46s/it]
 93%|█████████▎| 4831/5198 [18:03<3:14:08, 31.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.41s/it][A100%|██████████| 1/1 [00:34<00:00, 34.41s/it]
 93%|█████████▎| 4831/5198 [18:02<3:14:06, 31.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.48s/it][A100%|██████████| 1/1 [00:34<00:00, 34.48s/it]
 93%|█████████▎| 4831/5198 [17:53<3:14:07, 31.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.48s/it][A100%|██████████| 1/1 [00:34<00:00, 34.48s/it]
 93%|█████████▎| 4831/5198 [17:56<3:14:08, 31.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.55s/it][A100%|██████████| 1/1 [00:34<00:00, 34.55s/it]
 93%|█████████▎| 4831/5198 [17:50<3:14:12, 31.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.51s/it][A100%|██████████| 1/1 [00:34<00:00, 34.51s/it]
 93%|█████████▎| 4831/5198 [17:35<3:14:10, 31.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.51s/it][A100%|██████████| 1/1 [00:34<00:00, 34.51s/it]
 93%|█████████▎| 4831/5198 [17:40<3:14:09, 31.74s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_301
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.75s/it][A100%|██████████| 1/1 [00:24<00:00, 24.75s/it]
 93%|█████████▎| 4832/5198 [18:16<3:01:04, 29.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:16:02,414] [INFO] [logging.py:96:log_dist] [Rank 0] step=4831, skipped=0, lr=[6.188133578520754e-07], mom=[(0.9, 0.999)]
steps: 4831 loss: 1.9538 iter time (s): 24.064 samples/sec: 5.319

100%|██████████| 1/1 [00:24<00:00, 24.93s/it][A100%|██████████| 1/1 [00:24<00:00, 24.93s/it]
 93%|█████████▎| 4832/5198 [18:28<3:01:27, 29.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.99s/it][A100%|██████████| 1/1 [00:24<00:00, 24.99s/it]
 93%|█████████▎| 4832/5198 [18:27<3:01:31, 29.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.88s/it][A100%|██████████| 1/1 [00:24<00:00, 24.88s/it]
 93%|█████████▎| 4832/5198 [18:18<3:01:19, 29.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.90s/it][A100%|██████████| 1/1 [00:24<00:00, 24.90s/it]
 93%|█████████▎| 4832/5198 [18:15<3:01:25, 29.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.99s/it][A100%|██████████| 1/1 [00:24<00:00, 24.99s/it]
 93%|█████████▎| 4832/5198 [18:21<3:01:32, 29.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.93s/it][A100%|██████████| 1/1 [00:24<00:00, 24.93s/it]
 93%|█████████▎| 4832/5198 [18:00<3:01:27, 29.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.93s/it][A100%|██████████| 1/1 [00:24<00:00, 24.93s/it]
 93%|█████████▎| 4832/5198 [18:05<3:01:27, 29.75s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4530
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.01s/it][A100%|██████████| 1/1 [00:31<00:00, 31.01s/it]
 93%|█████████▎| 4833/5198 [18:48<3:03:10, 30.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:16:33,401] [INFO] [logging.py:96:log_dist] [Rank 0] step=4832, skipped=0, lr=[6.174504465781737e-07], mom=[(0.9, 0.999)]
steps: 4832 loss: 1.4680 iter time (s): 30.085 samples/sec: 4.255

100%|██████████| 1/1 [00:30<00:00, 30.79s/it][A100%|██████████| 1/1 [00:30<00:00, 30.79s/it]
 93%|█████████▎| 4833/5198 [18:59<3:02:51, 30.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.73s/it][A100%|██████████| 1/1 [00:30<00:00, 30.73s/it]
 93%|█████████▎| 4833/5198 [18:57<3:02:47, 30.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.83s/it][A100%|██████████| 1/1 [00:30<00:00, 30.83s/it]
 93%|█████████▎| 4833/5198 [18:49<3:02:49, 30.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.74s/it][A100%|██████████| 1/1 [00:30<00:00, 30.74s/it]
 93%|█████████▎| 4833/5198 [18:52<3:02:48, 30.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.79s/it][A100%|██████████| 1/1 [00:30<00:00, 30.79s/it]
 93%|█████████▎| 4833/5198 [18:45<3:02:50, 30.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.76s/it][A100%|██████████| 1/1 [00:30<00:00, 30.76s/it]
 93%|█████████▎| 4833/5198 [18:31<3:02:47, 30.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.76s/it][A100%|██████████| 1/1 [00:30<00:00, 30.76s/it]
 93%|█████████▎| 4833/5198 [18:36<3:02:47, 30.05s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4531
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.83s/it][A100%|██████████| 1/1 [00:31<00:00, 31.83s/it]
 93%|█████████▎| 4834/5198 [19:20<3:05:57, 30.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:17:05,346] [INFO] [logging.py:96:log_dist] [Rank 0] step=4833, skipped=0, lr=[6.160889414953686e-07], mom=[(0.9, 0.999)]
steps: 4833 loss: 1.4980 iter time (s): 31.257 samples/sec: 4.095

100%|██████████| 1/1 [00:31<00:00, 31.88s/it][A100%|██████████| 1/1 [00:31<00:00, 31.88s/it]
 93%|█████████▎| 4834/5198 [19:31<3:05:39, 30.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.99s/it][A100%|██████████| 1/1 [00:31<00:00, 31.99s/it]
 93%|█████████▎| 4834/5198 [19:29<3:05:47, 30.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.91s/it][A100%|██████████| 1/1 [00:31<00:00, 31.91s/it]
 93%|█████████▎| 4834/5198 [19:21<3:05:41, 30.61s/it]
100%|██████████| 1/1 [00:31<00:00, 31.85s/it][A100%|██████████| 1/1 [00:31<00:00, 31.85s/it]
 93%|█████████▎| 4834/5198 [19:24<3:05:33, 30.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.92s/it][A100%|██████████| 1/1 [00:31<00:00, 31.92s/it]
 93%|█████████▎| 4834/5198 [19:17<3:05:41, 30.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.95s/it][A100%|██████████| 1/1 [00:31<00:00, 31.95s/it]
 93%|█████████▎| 4834/5198 [19:03<3:05:43, 30.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.94s/it][A100%|██████████| 1/1 [00:31<00:00, 31.94s/it]
 93%|█████████▎| 4834/5198 [19:08<3:05:42, 30.61s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4532
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.68s/it][A100%|██████████| 1/1 [00:30<00:00, 30.68s/it]
 93%|█████████▎| 4835/5198 [19:50<3:05:42, 30.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:17:36,146] [INFO] [logging.py:96:log_dist] [Rank 0] step=4834, skipped=0, lr=[6.14728843040465e-07], mom=[(0.9, 0.999)]
steps: 4834 loss: 1.4844 iter time (s): 30.116 samples/sec: 4.250

100%|██████████| 1/1 [00:30<00:00, 30.84s/it][A100%|██████████| 1/1 [00:30<00:00, 30.84s/it]
 93%|█████████▎| 4835/5198 [20:02<3:05:35, 30.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.73s/it][A100%|██████████| 1/1 [00:30<00:00, 30.73s/it]
 93%|█████████▎| 4835/5198 [20:00<3:05:29, 30.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.86s/it][A100%|██████████| 1/1 [00:30<00:00, 30.86s/it]
 93%|█████████▎| 4835/5198 [19:52<3:05:38, 30.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.88s/it][A100%|██████████| 1/1 [00:30<00:00, 30.88s/it]
 93%|█████████▎| 4835/5198 [19:55<3:05:35, 30.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.78s/it][A100%|██████████| 1/1 [00:30<00:00, 30.78s/it]
 93%|█████████▎| 4835/5198 [19:34<3:05:30, 30.66s/it]
100%|██████████| 1/1 [00:30<00:00, 30.82s/it][A100%|██████████| 1/1 [00:30<00:00, 30.82s/it]
 93%|█████████▎| 4835/5198 [19:48<3:05:34, 30.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.80s/it][A100%|██████████| 1/1 [00:30<00:00, 30.80s/it]
 93%|█████████▎| 4835/5198 [19:38<3:05:32, 30.67s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4533
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.66s/it][A100%|██████████| 1/1 [00:30<00:00, 30.66s/it]
 93%|█████████▎| 4836/5198 [20:21<3:05:24, 30.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:18:06,927] [INFO] [logging.py:96:log_dist] [Rank 0] step=4835, skipped=0, lr=[6.133701516498162e-07], mom=[(0.9, 0.999)]
steps: 4835 loss: 1.4878 iter time (s): 30.091 samples/sec: 4.254

100%|██████████| 1/1 [00:30<00:00, 30.76s/it][A100%|██████████| 1/1 [00:30<00:00, 30.76s/it]
 93%|█████████▎| 4836/5198 [20:33<3:05:14, 30.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.74s/it][A100%|██████████| 1/1 [00:30<00:00, 30.74s/it]
 93%|█████████▎| 4836/5198 [20:31<3:05:08, 30.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.70s/it][A100%|██████████| 1/1 [00:30<00:00, 30.70s/it]
 93%|█████████▎| 4836/5198 [20:23<3:05:10, 30.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.77s/it][A100%|██████████| 1/1 [00:30<00:00, 30.77s/it]
 93%|█████████▎| 4836/5198 [20:19<3:05:14, 30.70s/it]
100%|██████████| 1/1 [00:30<00:00, 30.83s/it][A
100%|██████████| 1/1 [00:30<00:00, 30.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A 93%|█████████▎| 4836/5198 [20:25<3:05:21, 30.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.84s/it][A100%|██████████| 1/1 [00:30<00:00, 30.84s/it]
 93%|█████████▎| 4836/5198 [20:04<3:05:19, 30.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.81s/it][A100%|██████████| 1/1 [00:30<00:00, 30.81s/it]
 93%|█████████▎| 4836/5198 [20:09<3:05:18, 30.71s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4534
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.18s/it][A100%|██████████| 1/1 [00:32<00:00, 32.18s/it]
 93%|█████████▎| 4837/5198 [20:53<3:07:40, 31.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:18:39,195] [INFO] [logging.py:96:log_dist] [Rank 0] step=4836, skipped=0, lr=[6.120128677593239e-07], mom=[(0.9, 0.999)]
steps: 4836 loss: 1.4364 iter time (s): 31.539 samples/sec: 4.058

100%|██████████| 1/1 [00:32<00:00, 32.35s/it][A100%|██████████| 1/1 [00:32<00:00, 32.35s/it]
 93%|█████████▎| 4837/5198 [21:05<3:07:42, 31.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.36s/it][A100%|██████████| 1/1 [00:32<00:00, 32.36s/it]
 93%|█████████▎| 4837/5198 [21:03<3:07:39, 31.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.37s/it][A100%|██████████| 1/1 [00:32<00:00, 32.37s/it]
 93%|█████████▎| 4837/5198 [20:55<3:07:42, 31.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.25s/it][A100%|██████████| 1/1 [00:32<00:00, 32.25s/it]
 93%|█████████▎| 4837/5198 [20:58<3:07:36, 31.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.33s/it][A100%|██████████| 1/1 [00:32<00:00, 32.33s/it]
 93%|█████████▎| 4837/5198 [20:51<3:07:40, 31.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.29s/it][A100%|██████████| 1/1 [00:32<00:00, 32.29s/it]
 93%|█████████▎| 4837/5198 [20:37<3:07:38, 31.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.30s/it][A100%|██████████| 1/1 [00:32<00:00, 32.30s/it]
 93%|█████████▎| 4837/5198 [20:41<3:07:38, 31.19s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4535
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.80s/it][A100%|██████████| 1/1 [00:30<00:00, 30.80s/it]
 93%|█████████▎| 4838/5198 [21:24<3:06:39, 31.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:19:10,253] [INFO] [logging.py:96:log_dist] [Rank 0] step=4837, skipped=0, lr=[6.106569918044388e-07], mom=[(0.9, 0.999)]
steps: 4837 loss: 1.4571 iter time (s): 30.295 samples/sec: 4.225

100%|██████████| 1/1 [00:31<00:00, 31.00s/it][A100%|██████████| 1/1 [00:31<00:00, 31.01s/it]
 93%|█████████▎| 4838/5198 [21:36<3:06:53, 31.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.12s/it][A100%|██████████| 1/1 [00:31<00:00, 31.12s/it]
 93%|█████████▎| 4838/5198 [21:34<3:07:01, 31.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.14s/it][A100%|██████████| 1/1 [00:31<00:00, 31.14s/it]
 93%|█████████▎| 4838/5198 [21:26<3:07:05, 31.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.18s/it][A100%|██████████| 1/1 [00:31<00:00, 31.18s/it]
 93%|█████████▎| 4838/5198 [21:29<3:07:06, 31.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.14s/it][A100%|██████████| 1/1 [00:31<00:00, 31.14s/it]
 93%|█████████▎| 4838/5198 [21:22<3:07:04, 31.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.16s/it][A100%|██████████| 1/1 [00:31<00:00, 31.16s/it]
 93%|█████████▎| 4838/5198 [21:08<3:07:05, 31.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.17s/it][A100%|██████████| 1/1 [00:31<00:00, 31.17s/it]
 93%|█████████▎| 4838/5198 [21:13<3:07:06, 31.18s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4536
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.03s/it][A100%|██████████| 1/1 [00:30<00:00, 30.04s/it]
 93%|█████████▎| 4839/5198 [21:54<3:04:25, 30.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:19:40,267] [INFO] [logging.py:96:log_dist] [Rank 0] step=4838, skipped=0, lr=[6.093025242201589e-07], mom=[(0.9, 0.999)]
steps: 4838 loss: 1.4727 iter time (s): 29.132 samples/sec: 4.394

100%|██████████| 1/1 [00:29<00:00, 29.95s/it][A100%|██████████| 1/1 [00:29<00:00, 29.95s/it]
 93%|█████████▎| 4839/5198 [22:06<3:04:14, 30.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.90s/it][A100%|██████████| 1/1 [00:29<00:00, 29.91s/it]
 93%|█████████▎| 4839/5198 [22:04<3:04:15, 30.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.82s/it][A100%|██████████| 1/1 [00:29<00:00, 29.82s/it]
 93%|█████████▎| 4839/5198 [21:56<3:04:09, 30.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.82s/it][A100%|██████████| 1/1 [00:29<00:00, 29.82s/it]
 93%|█████████▎| 4839/5198 [21:59<3:04:08, 30.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.83s/it][A100%|██████████| 1/1 [00:29<00:00, 29.83s/it]
 93%|█████████▎| 4839/5198 [21:52<3:04:08, 30.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.82s/it][A100%|██████████| 1/1 [00:29<00:00, 29.82s/it]
 93%|█████████▎| 4839/5198 [21:38<3:04:08, 30.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.81s/it][A100%|██████████| 1/1 [00:29<00:00, 29.81s/it]
 93%|█████████▎| 4839/5198 [21:42<3:04:08, 30.77s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4537
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.30s/it][A100%|██████████| 1/1 [00:34<00:00, 34.30s/it]
 93%|█████████▎| 4840/5198 [22:29<3:10:23, 31.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:20:14,888] [INFO] [logging.py:96:log_dist] [Rank 0] step=4839, skipped=0, lr=[6.07949465441032e-07], mom=[(0.9, 0.999)]
steps: 4839 loss: 1.4640 iter time (s): 33.938 samples/sec: 3.772

100%|██████████| 1/1 [00:34<00:00, 34.68s/it][A100%|██████████| 1/1 [00:34<00:00, 34.68s/it]
 93%|█████████▎| 4840/5198 [22:41<3:10:41, 31.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.71s/it][A100%|██████████| 1/1 [00:34<00:00, 34.71s/it]
 93%|█████████▎| 4840/5198 [22:39<3:10:45, 31.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.67s/it][A100%|██████████| 1/1 [00:34<00:00, 34.67s/it]
 93%|█████████▎| 4840/5198 [22:33<3:10:36, 31.95s/it]
100%|██████████| 1/1 [00:34<00:00, 34.73s/it][A100%|██████████| 1/1 [00:34<00:00, 34.73s/it]
 93%|█████████▎| 4840/5198 [22:31<3:10:43, 31.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.73s/it][A100%|██████████| 1/1 [00:34<00:00, 34.73s/it]
 93%|█████████▎| 4840/5198 [22:27<3:10:43, 31.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.72s/it][A100%|██████████| 1/1 [00:34<00:00, 34.72s/it]

 93%|█████████▎| 4840/5198 [22:17<3:10:41, 31.96s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4538
100%|██████████| 1/1 [00:34<00:00, 34.74s/it][A100%|██████████| 1/1 [00:34<00:00, 34.74s/it]
 93%|█████████▎| 4840/5198 [22:12<3:10:43, 31.97s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.99s/it][A100%|██████████| 1/1 [00:30<00:00, 30.99s/it]
 93%|█████████▎| 4841/5198 [23:00<3:08:27, 31.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:20:45,863] [INFO] [logging.py:96:log_dist] [Rank 0] step=4840, skipped=0, lr=[6.06597815901153e-07], mom=[(0.9, 0.999)]
steps: 4840 loss: 1.3860 iter time (s): 30.182 samples/sec: 4.241

100%|██████████| 1/1 [00:30<00:00, 30.88s/it][A100%|██████████| 1/1 [00:30<00:00, 30.88s/it]
 93%|█████████▎| 4841/5198 [23:12<3:08:15, 31.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.92s/it][A100%|██████████| 1/1 [00:30<00:00, 30.92s/it]
 93%|█████████▎| 4841/5198 [23:10<3:08:22, 31.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.88s/it][A100%|██████████| 1/1 [00:30<00:00, 30.88s/it]
 93%|█████████▎| 4841/5198 [23:02<3:08:16, 31.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.95s/it][A100%|██████████| 1/1 [00:30<00:00, 30.95s/it]
 93%|█████████▎| 4841/5198 [23:04<3:08:19, 31.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.91s/it][A100%|██████████| 1/1 [00:30<00:00, 30.91s/it]
 93%|█████████▎| 4841/5198 [22:58<3:08:18, 31.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.90s/it][A100%|██████████| 1/1 [00:30<00:00, 30.90s/it]
 93%|█████████▎| 4841/5198 [22:48<3:08:17, 31.64s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4539
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.91s/it][A100%|██████████| 1/1 [00:30<00:00, 30.91s/it]
 93%|█████████▎| 4841/5198 [22:43<3:08:19, 31.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.46s/it][A100%|██████████| 1/1 [00:33<00:00, 33.46s/it]
 93%|█████████▎| 4842/5198 [23:34<3:11:19, 32.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:21:19,590] [INFO] [logging.py:96:log_dist] [Rank 0] step=4841, skipped=0, lr=[6.052475760341633e-07], mom=[(0.9, 0.999)]
steps: 4841 loss: 1.5430 iter time (s): 33.002 samples/sec: 3.879

100%|██████████| 1/1 [00:33<00:00, 33.67s/it][A100%|██████████| 1/1 [00:33<00:00, 33.67s/it]
 93%|█████████▎| 4842/5198 [23:45<3:11:21, 32.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.66s/it][A100%|██████████| 1/1 [00:33<00:00, 33.66s/it]
 93%|█████████▎| 4842/5198 [23:44<3:11:25, 32.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.73s/it][A100%|██████████| 1/1 [00:33<00:00, 33.73s/it]
 93%|█████████▎| 4842/5198 [23:35<3:11:28, 32.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.71s/it][A100%|██████████| 1/1 [00:33<00:00, 33.71s/it]
 93%|█████████▎| 4842/5198 [23:38<3:11:28, 32.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.71s/it][A100%|██████████| 1/1 [00:33<00:00, 33.71s/it]
 93%|█████████▎| 4842/5198 [23:32<3:11:28, 32.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.72s/it][A100%|██████████| 1/1 [00:33<00:00, 33.72s/it]
 93%|█████████▎| 4842/5198 [23:17<3:11:29, 32.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.74s/it][A100%|██████████| 1/1 [00:33<00:00, 33.74s/it]
 93%|█████████▎| 4842/5198 [23:22<3:11:29, 32.27s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4540
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.94s/it][A100%|██████████| 1/1 [00:31<00:00, 31.94s/it]
 93%|█████████▎| 4843/5198 [24:06<3:10:28, 32.19s/it][2024-09-01 23:21:51,179] [INFO] [logging.py:96:log_dist] [Rank 0] step=4842, skipped=0, lr=[6.03898746273254e-07], mom=[(0.9, 0.999)]
steps: 4842 loss: 1.4109 iter time (s): 30.846 samples/sec: 4.150

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.68s/it][A100%|██████████| 1/1 [00:31<00:00, 31.68s/it]
 93%|█████████▎| 4843/5198 [24:17<3:09:49, 32.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.57s/it][A100%|██████████| 1/1 [00:31<00:00, 31.57s/it]
 93%|█████████▎| 4843/5198 [24:15<3:09:40, 32.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.61s/it][A100%|██████████| 1/1 [00:31<00:00, 31.61s/it]
 93%|█████████▎| 4843/5198 [24:07<3:09:46, 32.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.75s/it][A100%|██████████| 1/1 [00:31<00:00, 31.75s/it]
 93%|█████████▎| 4843/5198 [24:10<3:10:01, 32.12s/it]
100%|██████████| 1/1 [00:31<00:00, 31.72s/it][A100%|██████████| 1/1 [00:31<00:00, 31.73s/it]
 93%|█████████▎| 4843/5198 [24:03<3:09:58, 32.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.72s/it][A100%|██████████| 1/1 [00:31<00:00, 31.72s/it]
 93%|█████████▎| 4843/5198 [23:49<3:09:58, 32.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.19s/it][A100%|██████████| 1/1 [00:32<00:00, 32.19s/it]
 93%|█████████▎| 4843/5198 [23:54<3:10:48, 32.25s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4541
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.93s/it][A100%|██████████| 1/1 [00:32<00:00, 32.93s/it]
 93%|█████████▎| 4844/5198 [24:39<3:11:28, 32.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:22:24,653] [INFO] [logging.py:96:log_dist] [Rank 0] step=4843, skipped=0, lr=[6.025513270511635e-07], mom=[(0.9, 0.999)]
steps: 4843 loss: 1.5509 iter time (s): 32.129 samples/sec: 3.984

100%|██████████| 1/1 [00:33<00:00, 33.47s/it][A100%|██████████| 1/1 [00:33<00:00, 33.47s/it]
 93%|█████████▎| 4844/5198 [24:51<3:11:49, 32.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.52s/it][A100%|██████████| 1/1 [00:33<00:00, 33.52s/it]
 93%|█████████▎| 4844/5198 [24:49<3:11:44, 32.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.53s/it][A100%|██████████| 1/1 [00:33<00:00, 33.53s/it]
 93%|█████████▎| 4844/5198 [24:41<3:11:50, 32.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.45s/it][A100%|██████████| 1/1 [00:33<00:00, 33.45s/it]
 93%|█████████▎| 4844/5198 [24:43<3:11:55, 32.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.49s/it][A100%|██████████| 1/1 [00:33<00:00, 33.49s/it]
 93%|█████████▎| 4844/5198 [24:37<3:11:54, 32.53s/it]
100%|██████████| 1/1 [00:33<00:00, 33.45s/it][A100%|██████████| 1/1 [00:33<00:00, 33.45s/it]
 93%|█████████▎| 4844/5198 [24:22<3:11:50, 32.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.99s/it][A100%|██████████| 1/1 [00:32<00:00, 32.99s/it]
 93%|█████████▎| 4844/5198 [24:27<3:11:35, 32.47s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4542
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.82s/it][A100%|██████████| 1/1 [00:33<00:00, 33.82s/it]
 93%|█████████▎| 4845/5198 [25:13<3:13:35, 32.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:22:58,695] [INFO] [logging.py:96:log_dist] [Rank 0] step=4844, skipped=0, lr=[6.012053188001768e-07], mom=[(0.9, 0.999)]
steps: 4844 loss: 1.4812 iter time (s): 33.176 samples/sec: 3.858

100%|██████████| 1/1 [00:33<00:00, 33.90s/it][A100%|██████████| 1/1 [00:33<00:00, 33.90s/it]
 93%|█████████▎| 4845/5198 [25:24<3:13:45, 32.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.98s/it][A100%|██████████| 1/1 [00:33<00:00, 33.98s/it]
 93%|█████████▎| 4845/5198 [25:23<3:13:50, 32.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.96s/it][A100%|██████████| 1/1 [00:33<00:00, 33.96s/it]
 93%|█████████▎| 4845/5198 [25:14<3:13:52, 32.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.85s/it][A100%|██████████| 1/1 [00:33<00:00, 33.86s/it]
 93%|█████████▎| 4845/5198 [25:17<3:13:43, 32.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.87s/it][A100%|██████████| 1/1 [00:33<00:00, 33.87s/it]
 93%|█████████▎| 4845/5198 [25:11<3:13:44, 32.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.91s/it][A100%|██████████| 1/1 [00:33<00:00, 33.91s/it]
 93%|█████████▎| 4845/5198 [24:56<3:13:46, 32.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.91s/it][A100%|██████████| 1/1 [00:33<00:00, 33.91s/it]
 93%|█████████▎| 4845/5198 [25:01<3:13:35, 32.91s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4543
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.79s/it][A100%|██████████| 1/1 [00:29<00:00, 29.79s/it]
 93%|█████████▎| 4846/5198 [25:43<3:07:44, 32.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:23:28,426] [INFO] [logging.py:96:log_dist] [Rank 0] step=4845, skipped=0, lr=[5.998607219521271e-07], mom=[(0.9, 0.999)]
steps: 4845 loss: 1.4643 iter time (s): 28.991 samples/sec: 4.415

100%|██████████| 1/1 [00:29<00:00, 29.83s/it][A100%|██████████| 1/1 [00:29<00:00, 29.83s/it]
 93%|█████████▎| 4846/5198 [25:54<3:07:46, 32.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.70s/it][A100%|██████████| 1/1 [00:29<00:00, 29.70s/it]
 93%|█████████▎| 4846/5198 [25:52<3:07:35, 31.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.64s/it][A100%|██████████| 1/1 [00:29<00:00, 29.64s/it]
 93%|█████████▎| 4846/5198 [25:44<3:07:29, 31.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.70s/it][A100%|██████████| 1/1 [00:29<00:00, 29.70s/it]
 93%|█████████▎| 4846/5198 [25:47<3:07:31, 31.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.67s/it][A100%|██████████| 1/1 [00:29<00:00, 29.67s/it]
 93%|█████████▎| 4846/5198 [25:26<3:07:28, 31.96s/it]
100%|██████████| 1/1 [00:29<00:00, 29.71s/it][A100%|██████████| 1/1 [00:29<00:00, 29.71s/it]
 93%|█████████▎| 4846/5198 [25:40<3:07:32, 31.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.69s/it][A100%|██████████| 1/1 [00:29<00:00, 29.69s/it]
 93%|█████████▎| 4846/5198 [25:31<3:07:24, 31.94s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4544
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.16s/it][A100%|██████████| 1/1 [00:30<00:00, 30.16s/it]
 93%|█████████▎| 4847/5198 [26:13<3:04:13, 31.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:23:58,743] [INFO] [logging.py:96:log_dist] [Rank 0] step=4846, skipped=0, lr=[5.985175369383959e-07], mom=[(0.9, 0.999)]
steps: 4846 loss: 1.4945 iter time (s): 29.611 samples/sec: 4.323

100%|██████████| 1/1 [00:30<00:00, 30.24s/it][A100%|██████████| 1/1 [00:30<00:00, 30.24s/it]
 93%|█████████▎| 4847/5198 [26:25<3:04:09, 31.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.30s/it][A100%|██████████| 1/1 [00:30<00:00, 30.30s/it]
 93%|█████████▎| 4847/5198 [26:23<3:04:07, 31.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.44s/it][A100%|██████████| 1/1 [00:30<00:00, 30.44s/it]
 93%|█████████▎| 4847/5198 [26:15<3:04:18, 31.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.38s/it][A100%|██████████| 1/1 [00:30<00:00, 30.38s/it]
 93%|█████████▎| 4847/5198 [26:17<3:04:12, 31.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.36s/it][A100%|██████████| 1/1 [00:30<00:00, 30.36s/it]
 93%|█████████▎| 4847/5198 [26:11<3:04:12, 31.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.40s/it][A100%|██████████| 1/1 [00:30<00:00, 30.40s/it]
 93%|█████████▎| 4847/5198 [25:56<3:04:13, 31.49s/it]
100%|██████████| 1/1 [00:30<00:00, 30.37s/it][A100%|██████████| 1/1 [00:30<00:00, 30.37s/it]
 93%|█████████▎| 4847/5198 [26:01<3:04:06, 31.47s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_302
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:23<00:00, 23.48s/it][A100%|██████████| 1/1 [00:23<00:00, 23.48s/it]
 93%|█████████▎| 4848/5198 [26:36<2:49:50, 29.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:24:22,405] [INFO] [logging.py:96:log_dist] [Rank 0] step=4847, skipped=0, lr=[5.971757641899075e-07], mom=[(0.9, 0.999)]
steps: 4847 loss: 1.8758 iter time (s): 22.930 samples/sec: 5.582

100%|██████████| 1/1 [00:23<00:00, 23.81s/it][A100%|██████████| 1/1 [00:23<00:00, 23.81s/it]
 93%|█████████▎| 4848/5198 [26:48<2:50:14, 29.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:23<00:00, 23.91s/it][A100%|██████████| 1/1 [00:23<00:00, 23.92s/it]
 93%|█████████▎| 4848/5198 [26:47<2:50:23, 29.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:23<00:00, 23.74s/it][A100%|██████████| 1/1 [00:23<00:00, 23.74s/it]
 93%|█████████▎| 4848/5198 [26:38<2:50:12, 29.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:23<00:00, 23.74s/it][A100%|██████████| 1/1 [00:23<00:00, 23.74s/it]
 93%|█████████▎| 4848/5198 [26:41<2:50:08, 29.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:23<00:00, 23.77s/it][A100%|██████████| 1/1 [00:23<00:00, 23.77s/it]
 93%|█████████▎| 4848/5198 [26:35<2:50:10, 29.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:23<00:00, 23.79s/it][A100%|██████████| 1/1 [00:23<00:00, 23.79s/it]
 93%|█████████▎| 4848/5198 [26:20<2:50:14, 29.18s/it]
100%|██████████| 1/1 [00:23<00:00, 23.79s/it][A100%|██████████| 1/1 [00:23<00:00, 23.79s/it]
 93%|█████████▎| 4848/5198 [26:25<2:50:09, 29.17s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4545

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.99s/it][A100%|██████████| 1/1 [00:29<00:00, 29.99s/it]
 93%|█████████▎| 4849/5198 [27:07<2:51:09, 29.42s/it][2024-09-01 23:24:52,191] [INFO] [logging.py:96:log_dist] [Rank 0] step=4848, skipped=0, lr=[5.958354041371371e-07], mom=[(0.9, 0.999)]
steps: 4848 loss: 1.4251 iter time (s): 28.894 samples/sec: 4.430

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.61s/it][A100%|██████████| 1/1 [00:29<00:00, 29.61s/it]
 93%|█████████▎| 4849/5198 [27:18<2:50:30, 29.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.57s/it][A100%|██████████| 1/1 [00:29<00:00, 29.57s/it]
 93%|█████████▎| 4849/5198 [27:16<2:50:33, 29.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.54s/it][A100%|██████████| 1/1 [00:29<00:00, 29.54s/it]
 93%|█████████▎| 4849/5198 [27:08<2:50:22, 29.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.58s/it][A100%|██████████| 1/1 [00:29<00:00, 29.58s/it]
 93%|█████████▎| 4849/5198 [27:11<2:50:24, 29.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.61s/it][A100%|██████████| 1/1 [00:29<00:00, 29.61s/it]
 93%|█████████▎| 4849/5198 [27:04<2:50:28, 29.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.59s/it][A100%|██████████| 1/1 [00:29<00:00, 29.59s/it]
 93%|█████████▎| 4849/5198 [26:50<2:50:27, 29.31s/it]
100%|██████████| 1/1 [00:29<00:00, 29.59s/it][A100%|██████████| 1/1 [00:29<00:00, 29.59s/it]
 93%|█████████▎| 4849/5198 [26:54<2:50:24, 29.30s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4546

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.12s/it][A100%|██████████| 1/1 [00:33<00:00, 33.12s/it]
 93%|█████████▎| 4850/5198 [27:40<2:57:20, 30.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:25:25,846] [INFO] [logging.py:96:log_dist] [Rank 0] step=4849, skipped=0, lr=[5.944964572101058e-07], mom=[(0.9, 0.999)]
steps: 4849 loss: 1.5503 iter time (s): 32.950 samples/sec: 3.885

100%|██████████| 1/1 [00:33<00:00, 33.71s/it][A100%|██████████| 1/1 [00:33<00:00, 33.71s/it]
 93%|█████████▎| 4850/5198 [27:52<2:57:40, 30.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.60s/it][A100%|██████████| 1/1 [00:33<00:00, 33.60s/it]
 93%|█████████▎| 4850/5198 [27:50<2:57:32, 30.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.73s/it][A100%|██████████| 1/1 [00:33<00:00, 33.73s/it]
 93%|█████████▎| 4850/5198 [27:42<2:57:37, 30.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.72s/it][A100%|██████████| 1/1 [00:33<00:00, 33.72s/it]
 93%|█████████▎| 4850/5198 [27:44<2:57:38, 30.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.67s/it][A100%|██████████| 1/1 [00:33<00:00, 33.67s/it]
 93%|█████████▎| 4850/5198 [27:38<2:57:35, 30.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.72s/it][A100%|██████████| 1/1 [00:33<00:00, 33.72s/it]
 93%|█████████▎| 4850/5198 [27:23<2:57:39, 30.63s/it]
100%|██████████| 1/1 [00:33<00:00, 33.71s/it][A100%|██████████| 1/1 [00:33<00:00, 33.71s/it]
 93%|█████████▎| 4850/5198 [27:28<2:57:37, 30.62s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4547
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.95s/it][A100%|██████████| 1/1 [00:30<00:00, 30.95s/it]
 93%|█████████▎| 4851/5198 [28:11<2:57:42, 30.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:25:56,808] [INFO] [logging.py:96:log_dist] [Rank 0] step=4850, skipped=0, lr=[5.931589238383806e-07], mom=[(0.9, 0.999)]
steps: 4850 loss: 1.5038 iter time (s): 30.192 samples/sec: 4.239

100%|██████████| 1/1 [00:30<00:00, 30.83s/it][A100%|██████████| 1/1 [00:30<00:00, 30.83s/it]
 93%|█████████▎| 4851/5198 [28:23<2:57:31, 30.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.93s/it][A100%|██████████| 1/1 [00:30<00:00, 30.93s/it]
 93%|█████████▎| 4851/5198 [28:21<2:57:36, 30.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.94s/it][A100%|██████████| 1/1 [00:30<00:00, 30.94s/it]
 93%|█████████▎| 4851/5198 [28:13<2:57:40, 30.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.92s/it][A100%|██████████| 1/1 [00:30<00:00, 30.92s/it]
 93%|█████████▎| 4851/5198 [28:15<2:57:38, 30.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.91s/it][A100%|██████████| 1/1 [00:30<00:00, 30.91s/it]
 93%|█████████▎| 4851/5198 [28:09<2:57:36, 30.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.89s/it][A100%|██████████| 1/1 [00:30<00:00, 30.89s/it]
 93%|█████████▎| 4851/5198 [27:54<2:57:36, 30.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.90s/it][A100%|██████████| 1/1 [00:30<00:00, 30.90s/it]
 93%|█████████▎| 4851/5198 [27:59<2:57:35, 30.71s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4548
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.09s/it][A100%|██████████| 1/1 [00:33<00:00, 33.09s/it]
 93%|█████████▎| 4852/5198 [28:44<3:01:29, 31.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:26:30,013] [INFO] [logging.py:96:log_dist] [Rank 0] step=4851, skipped=0, lr=[5.918228044510769e-07], mom=[(0.9, 0.999)]
steps: 4851 loss: 1.4737 iter time (s): 32.491 samples/sec: 3.940

100%|██████████| 1/1 [00:33<00:00, 33.25s/it][A100%|██████████| 1/1 [00:33<00:00, 33.25s/it]
 93%|█████████▎| 4852/5198 [28:56<3:01:27, 31.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.33s/it][A100%|██████████| 1/1 [00:33<00:00, 33.33s/it]
 93%|█████████▎| 4852/5198 [28:54<3:01:38, 31.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.26s/it][A100%|██████████| 1/1 [00:33<00:00, 33.26s/it]
 93%|█████████▎| 4852/5198 [28:46<3:01:34, 31.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.28s/it][A100%|██████████| 1/1 [00:33<00:00, 33.28s/it]
 93%|█████████▎| 4852/5198 [28:48<3:01:34, 31.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.29s/it][A100%|██████████| 1/1 [00:33<00:00, 33.29s/it]
 93%|█████████▎| 4852/5198 [28:42<3:01:33, 31.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.26s/it][A100%|██████████| 1/1 [00:33<00:00, 33.26s/it]
 93%|█████████▎| 4852/5198 [28:28<3:01:30, 31.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.26s/it][A100%|██████████| 1/1 [00:33<00:00, 33.26s/it]
 93%|█████████▎| 4852/5198 [28:32<3:01:30, 31.48s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4549
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.75s/it][A100%|██████████| 1/1 [00:31<00:00, 31.75s/it]
 93%|█████████▎| 4853/5198 [29:16<3:01:40, 31.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:27:01,924] [INFO] [logging.py:96:log_dist] [Rank 0] step=4852, skipped=0, lr=[5.904880994768525e-07], mom=[(0.9, 0.999)]
steps: 4852 loss: 1.4365 iter time (s): 31.137 samples/sec: 4.111

100%|██████████| 1/1 [00:31<00:00, 31.89s/it][A100%|██████████| 1/1 [00:31<00:00, 31.89s/it]
 93%|█████████▎| 4853/5198 [29:28<3:01:40, 31.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.83s/it][A100%|██████████| 1/1 [00:31<00:00, 31.83s/it]
 93%|█████████▎| 4853/5198 [29:26<3:01:42, 31.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.81s/it][A100%|██████████| 1/1 [00:31<00:00, 31.81s/it]
 93%|█████████▎| 4853/5198 [29:18<3:01:36, 31.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.83s/it][A100%|██████████| 1/1 [00:31<00:00, 31.83s/it]
 93%|█████████▎| 4853/5198 [29:20<3:01:39, 31.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.84s/it][A100%|██████████| 1/1 [00:31<00:00, 31.84s/it]
 93%|█████████▎| 4853/5198 [29:14<3:01:39, 31.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.87s/it][A100%|██████████| 1/1 [00:31<00:00, 31.87s/it]
 93%|█████████▎| 4853/5198 [28:59<3:01:40, 31.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.86s/it][A100%|██████████| 1/1 [00:31<00:00, 31.86s/it]
 93%|█████████▎| 4853/5198 [29:04<3:01:39, 31.59s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4550
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.11s/it][A100%|██████████| 1/1 [00:30<00:00, 30.11s/it]
 93%|█████████▎| 4854/5198 [29:46<2:58:45, 31.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:27:32,080] [INFO] [logging.py:96:log_dist] [Rank 0] step=4853, skipped=0, lr=[5.891548093439152e-07], mom=[(0.9, 0.999)]
steps: 4853 loss: 1.4284 iter time (s): 29.422 samples/sec: 4.350

100%|██████████| 1/1 [00:30<00:00, 30.20s/it][A100%|██████████| 1/1 [00:30<00:00, 30.20s/it]
 93%|█████████▎| 4854/5198 [29:58<2:58:47, 31.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.13s/it][A100%|██████████| 1/1 [00:30<00:00, 30.13s/it]
 93%|█████████▎| 4854/5198 [29:56<2:58:40, 31.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.17s/it][A100%|██████████| 1/1 [00:30<00:00, 30.17s/it]
 93%|█████████▎| 4854/5198 [29:48<2:58:40, 31.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.15s/it][A100%|██████████| 1/1 [00:30<00:00, 30.15s/it]
 93%|█████████▎| 4854/5198 [29:50<2:58:39, 31.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.12s/it][A100%|██████████| 1/1 [00:30<00:00, 30.12s/it]
 93%|█████████▎| 4854/5198 [29:44<2:58:36, 31.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.13s/it][A100%|██████████| 1/1 [00:30<00:00, 30.13s/it]
 93%|█████████▎| 4854/5198 [29:30<2:58:38, 31.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.13s/it][A100%|██████████| 1/1 [00:30<00:00, 30.13s/it]
 93%|█████████▎| 4854/5198 [29:34<2:58:38, 31.16s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4551
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.73s/it][A100%|██████████| 1/1 [00:30<00:00, 30.73s/it]
 93%|█████████▎| 4855/5198 [30:17<2:57:40, 31.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:28:02,946] [INFO] [logging.py:96:log_dist] [Rank 0] step=4854, skipped=0, lr=[5.878229344800172e-07], mom=[(0.9, 0.999)]
steps: 4854 loss: 1.4518 iter time (s): 30.151 samples/sec: 4.245

100%|██████████| 1/1 [00:30<00:00, 30.82s/it][A100%|██████████| 1/1 [00:30<00:00, 30.82s/it]
 93%|█████████▎| 4855/5198 [30:29<2:57:39, 31.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.93s/it][A100%|██████████| 1/1 [00:30<00:00, 30.93s/it]
 93%|█████████▎| 4855/5198 [30:27<2:57:45, 31.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.88s/it][A100%|██████████| 1/1 [00:30<00:00, 30.88s/it]
 93%|█████████▎| 4855/5198 [30:19<2:57:40, 31.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.93s/it][A100%|██████████| 1/1 [00:30<00:00, 30.93s/it]
 93%|█████████▎| 4855/5198 [30:21<2:57:45, 31.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.93s/it][A100%|██████████| 1/1 [00:30<00:00, 30.93s/it]
 93%|█████████▎| 4855/5198 [30:15<2:57:42, 31.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.92s/it][A100%|██████████| 1/1 [00:30<00:00, 30.92s/it]
 93%|█████████▎| 4855/5198 [30:00<2:57:43, 31.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.93s/it][A100%|██████████| 1/1 [00:30<00:00, 30.93s/it]
 93%|█████████▎| 4855/5198 [30:05<2:57:44, 31.09s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4552
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.55s/it][A100%|██████████| 1/1 [00:33<00:00, 33.55s/it]
 93%|█████████▎| 4856/5198 [30:51<3:01:34, 31.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:28:36,744] [INFO] [logging.py:96:log_dist] [Rank 0] step=4855, skipped=0, lr=[5.864924753124573e-07], mom=[(0.9, 0.999)]
steps: 4855 loss: 1.4231 iter time (s): 33.011 samples/sec: 3.877

100%|██████████| 1/1 [00:33<00:00, 33.78s/it][A100%|██████████| 1/1 [00:33<00:00, 33.78s/it]
 93%|█████████▎| 4856/5198 [31:03<3:01:47, 31.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.68s/it][A100%|██████████| 1/1 [00:33<00:00, 33.68s/it]
 93%|█████████▎| 4856/5198 [31:01<3:01:40, 31.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.79s/it][A100%|██████████| 1/1 [00:33<00:00, 33.79s/it]
 93%|█████████▎| 4856/5198 [30:53<3:01:48, 31.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.79s/it][A100%|██████████| 1/1 [00:33<00:00, 33.79s/it]
 93%|█████████▎| 4856/5198 [30:55<3:01:52, 31.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.79s/it][A100%|██████████| 1/1 [00:33<00:00, 33.79s/it]
 93%|█████████▎| 4856/5198 [30:49<3:01:49, 31.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.80s/it][A100%|██████████| 1/1 [00:33<00:00, 33.80s/it]
 93%|█████████▎| 4856/5198 [30:34<3:01:51, 31.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.80s/it][A100%|██████████| 1/1 [00:33<00:00, 33.80s/it]
 93%|█████████▎| 4856/5198 [30:39<3:01:51, 31.90s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4553
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.25s/it][A100%|██████████| 1/1 [00:33<00:00, 33.25s/it]
 93%|█████████▎| 4857/5198 [31:24<3:03:37, 32.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:29:10,093] [INFO] [logging.py:96:log_dist] [Rank 0] step=4856, skipped=0, lr=[5.851634322680803e-07], mom=[(0.9, 0.999)]
steps: 4856 loss: 1.5175 iter time (s): 32.559 samples/sec: 3.931

100%|██████████| 1/1 [00:33<00:00, 33.27s/it][A100%|██████████| 1/1 [00:33<00:00, 33.27s/it]
 93%|█████████▎| 4857/5198 [31:36<3:03:36, 32.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.27s/it][A100%|██████████| 1/1 [00:33<00:00, 33.27s/it]
 93%|█████████▎| 4857/5198 [31:34<3:03:33, 32.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.30s/it][A100%|██████████| 1/1 [00:33<00:00, 33.30s/it]
 93%|█████████▎| 4857/5198 [31:26<3:03:41, 32.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.28s/it][A100%|██████████| 1/1 [00:33<00:00, 33.28s/it]
 93%|█████████▎| 4857/5198 [31:28<3:03:41, 32.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.34s/it][A100%|██████████| 1/1 [00:33<00:00, 33.34s/it]
 93%|█████████▎| 4857/5198 [31:22<3:03:45, 32.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.34s/it][A100%|██████████| 1/1 [00:33<00:00, 33.34s/it]
 93%|█████████▎| 4857/5198 [31:08<3:03:47, 32.34s/it]
100%|██████████| 1/1 [00:33<00:00, 33.33s/it][A100%|██████████| 1/1 [00:33<00:00, 33.33s/it]
 93%|█████████▎| 4857/5198 [31:12<3:03:45, 32.33s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4554

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.69s/it][A100%|██████████| 1/1 [00:30<00:00, 30.69s/it]
 93%|█████████▎| 4858/5198 [31:55<3:00:33, 31.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:29:40,836] [INFO] [logging.py:96:log_dist] [Rank 0] step=4857, skipped=0, lr=[5.83835805773275e-07], mom=[(0.9, 0.999)]
steps: 4857 loss: 1.4163 iter time (s): 29.961 samples/sec: 4.272

100%|██████████| 1/1 [00:30<00:00, 30.80s/it][A100%|██████████| 1/1 [00:30<00:00, 30.80s/it]
 93%|█████████▎| 4858/5198 [32:07<3:00:31, 31.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.77s/it][A100%|██████████| 1/1 [00:30<00:00, 30.77s/it]
 93%|█████████▎| 4858/5198 [32:05<3:00:26, 31.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.74s/it][A100%|██████████| 1/1 [00:30<00:00, 30.74s/it]
 93%|█████████▎| 4858/5198 [31:57<3:00:28, 31.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.68s/it][A100%|██████████| 1/1 [00:30<00:00, 30.68s/it]
 93%|█████████▎| 4858/5198 [31:59<3:00:22, 31.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.67s/it][A100%|██████████| 1/1 [00:30<00:00, 30.67s/it]
 93%|█████████▎| 4858/5198 [31:38<3:00:25, 31.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.75s/it][A100%|██████████| 1/1 [00:30<00:00, 30.75s/it]
 93%|█████████▎| 4858/5198 [31:53<3:00:33, 31.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.70s/it][A100%|██████████| 1/1 [00:30<00:00, 30.70s/it]
 93%|█████████▎| 4858/5198 [31:43<3:00:27, 31.84s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4555
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.08s/it][A100%|██████████| 1/1 [00:32<00:00, 32.08s/it]
 93%|█████████▎| 4859/5198 [32:27<3:00:37, 31.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:30:13,094] [INFO] [logging.py:96:log_dist] [Rank 0] step=4858, skipped=0, lr=[5.825095962539778e-07], mom=[(0.9, 0.999)]
steps: 4858 loss: 1.4749 iter time (s): 31.516 samples/sec: 4.061

100%|██████████| 1/1 [00:32<00:00, 32.21s/it][A100%|██████████| 1/1 [00:32<00:00, 32.21s/it]
 93%|█████████▎| 4859/5198 [32:39<3:00:36, 31.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.27s/it][A100%|██████████| 1/1 [00:32<00:00, 32.27s/it]
 93%|█████████▎| 4859/5198 [32:37<3:00:39, 31.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.26s/it][A100%|██████████| 1/1 [00:32<00:00, 32.26s/it]
 93%|█████████▎| 4859/5198 [32:29<3:00:39, 31.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.32s/it][A100%|██████████| 1/1 [00:32<00:00, 32.32s/it]
 93%|█████████▎| 4859/5198 [32:32<3:00:41, 31.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.23s/it][A100%|██████████| 1/1 [00:32<00:00, 32.23s/it]
 93%|█████████▎| 4859/5198 [32:25<3:00:38, 31.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.25s/it][A100%|██████████| 1/1 [00:32<00:00, 32.26s/it]
 93%|█████████▎| 4859/5198 [32:11<3:00:36, 31.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.26s/it][A100%|██████████| 1/1 [00:32<00:00, 32.26s/it]
 93%|█████████▎| 4859/5198 [32:15<3:00:38, 31.97s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4556
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.29s/it][A100%|██████████| 1/1 [00:29<00:00, 29.29s/it]
 93%|█████████▎| 4860/5198 [32:57<2:55:43, 31.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:30:42,362] [INFO] [logging.py:96:log_dist] [Rank 0] step=4859, skipped=0, lr=[5.811848041356695e-07], mom=[(0.9, 0.999)]
steps: 4859 loss: 1.4467 iter time (s): 28.522 samples/sec: 4.488

100%|██████████| 1/1 [00:29<00:00, 29.26s/it][A100%|██████████| 1/1 [00:29<00:00, 29.26s/it]
 93%|█████████▎| 4860/5198 [33:08<2:55:31, 31.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.21s/it][A100%|██████████| 1/1 [00:29<00:00, 29.22s/it]
 93%|█████████▎| 4860/5198 [33:06<2:55:28, 31.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.21s/it][A100%|██████████| 1/1 [00:29<00:00, 29.21s/it]
 93%|█████████▎| 4860/5198 [32:58<2:55:27, 31.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.14s/it][A100%|██████████| 1/1 [00:29<00:00, 29.14s/it]
 93%|█████████▎| 4860/5198 [33:01<2:55:22, 31.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.18s/it][A100%|██████████| 1/1 [00:29<00:00, 29.18s/it]
 93%|█████████▎| 4860/5198 [32:40<2:55:22, 31.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][A100%|██████████| 1/1 [00:29<00:00, 29.19s/it][A100%|██████████| 1/1 [00:29<00:00, 29.19s/it]
 93%|█████████▎| 4860/5198 [32:54<2:55:25, 31.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.17s/it][A100%|██████████| 1/1 [00:29<00:00, 29.17s/it]
 93%|█████████▎| 4860/5198 [32:45<2:55:22, 31.13s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4557
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.56s/it][A100%|██████████| 1/1 [00:30<00:00, 30.57s/it]
 94%|█████████▎| 4861/5198 [33:27<2:54:22, 31.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:31:13,067] [INFO] [logging.py:96:log_dist] [Rank 0] step=4860, skipped=0, lr=[5.798614298433765e-07], mom=[(0.9, 0.999)]
steps: 4860 loss: 1.4553 iter time (s): 30.055 samples/sec: 4.259

100%|██████████| 1/1 [00:30<00:00, 30.73s/it][A100%|██████████| 1/1 [00:30<00:00, 30.73s/it]
 94%|█████████▎| 4861/5198 [33:39<2:54:17, 31.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.81s/it][A100%|██████████| 1/1 [00:30<00:00, 30.81s/it]
 94%|█████████▎| 4861/5198 [33:37<2:54:24, 31.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.73s/it][A100%|██████████| 1/1 [00:30<00:00, 30.73s/it]
 94%|█████████▎| 4861/5198 [33:29<2:54:15, 31.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.76s/it][A100%|██████████| 1/1 [00:30<00:00, 30.76s/it]
 94%|█████████▎| 4861/5198 [33:31<2:54:14, 31.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.73s/it][A100%|██████████| 1/1 [00:30<00:00, 30.73s/it]
 94%|█████████▎| 4861/5198 [33:25<2:54:13, 31.02s/it]
100%|██████████| 1/1 [00:30<00:00, 30.74s/it][A100%|██████████| 1/1 [00:30<00:00, 30.74s/it]
 94%|█████████▎| 4861/5198 [33:11<2:54:12, 31.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.76s/it][A100%|██████████| 1/1 [00:30<00:00, 30.76s/it]
 94%|█████████▎| 4861/5198 [33:15<2:54:13, 31.02s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4558
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.20s/it][A100%|██████████| 1/1 [00:35<00:00, 35.20s/it]
 94%|█████████▎| 4862/5198 [34:03<3:01:00, 32.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:31:48,609] [INFO] [logging.py:96:log_dist] [Rank 0] step=4861, skipped=0, lr=[5.785394738016694e-07], mom=[(0.9, 0.999)]
steps: 4861 loss: 1.5538 iter time (s): 34.836 samples/sec: 3.674

100%|██████████| 1/1 [00:35<00:00, 35.51s/it][A100%|██████████| 1/1 [00:35<00:00, 35.51s/it]
 94%|█████████▎| 4862/5198 [34:14<3:01:19, 32.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.43s/it][A100%|██████████| 1/1 [00:35<00:00, 35.43s/it]
 94%|█████████▎| 4862/5198 [34:13<3:01:15, 32.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.55s/it][A100%|██████████| 1/1 [00:35<00:00, 35.55s/it]
 94%|█████████▎| 4862/5198 [34:04<3:01:21, 32.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.55s/it][A100%|██████████| 1/1 [00:35<00:00, 35.55s/it]
 94%|█████████▎| 4862/5198 [34:07<3:01:20, 32.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.54s/it][A100%|██████████| 1/1 [00:35<00:00, 35.54s/it]
 94%|█████████▎| 4862/5198 [34:01<3:01:18, 32.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.57s/it][A100%|██████████| 1/1 [00:35<00:00, 35.57s/it]
 94%|█████████▎| 4862/5198 [33:46<3:01:21, 32.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.54s/it][A100%|██████████| 1/1 [00:35<00:00, 35.54s/it]
 94%|█████████▎| 4862/5198 [33:51<3:01:19, 32.38s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4559
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.08s/it][A100%|██████████| 1/1 [00:31<00:00, 31.09s/it]
 94%|█████████▎| 4863/5198 [34:34<2:58:37, 31.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:32:19,570] [INFO] [logging.py:96:log_dist] [Rank 0] step=4862, skipped=0, lr=[5.772189364346665e-07], mom=[(0.9, 0.999)]
steps: 4862 loss: 1.4017 iter time (s): 30.249 samples/sec: 4.232

100%|██████████| 1/1 [00:30<00:00, 30.92s/it][A100%|██████████| 1/1 [00:30<00:00, 30.92s/it]
 94%|█████████▎| 4863/5198 [34:45<2:58:22, 31.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.01s/it][A100%|██████████| 1/1 [00:31<00:00, 31.01s/it]
 94%|█████████▎| 4863/5198 [34:44<2:58:28, 31.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.89s/it][A100%|██████████| 1/1 [00:30<00:00, 30.89s/it]
 94%|█████████▎| 4863/5198 [34:35<2:58:19, 31.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.92s/it][A100%|██████████| 1/1 [00:30<00:00, 30.92s/it]
 94%|█████████▎| 4863/5198 [34:38<2:58:22, 31.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.91s/it][A100%|██████████| 1/1 [00:30<00:00, 30.91s/it]
 94%|█████████▎| 4863/5198 [34:32<2:58:19, 31.94s/it]
100%|██████████| 1/1 [00:30<00:00, 30.88s/it][A100%|██████████| 1/1 [00:30<00:00, 30.88s/it]
 94%|█████████▎| 4863/5198 [34:17<2:58:17, 31.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.90s/it][A100%|██████████| 1/1 [00:30<00:00, 30.90s/it]
 94%|█████████▎| 4863/5198 [34:22<2:58:18, 31.94s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_303
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:22<00:00, 22.70s/it][A100%|██████████| 1/1 [00:22<00:00, 22.70s/it]
 94%|█████████▎| 4864/5198 [34:57<2:42:44, 29.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:32:42,516] [INFO] [logging.py:96:log_dist] [Rank 0] step=4863, skipped=0, lr=[5.75899818166026e-07], mom=[(0.9, 0.999)]
steps: 4863 loss: 1.8557 iter time (s): 22.321 samples/sec: 5.734

100%|██████████| 1/1 [00:23<00:00, 23.11s/it][A100%|██████████| 1/1 [00:23<00:00, 23.11s/it]
 94%|█████████▎| 4864/5198 [35:08<2:43:05, 29.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:23<00:00, 23.18s/it][A100%|██████████| 1/1 [00:23<00:00, 23.18s/it]
 94%|█████████▎| 4864/5198 [35:07<2:43:16, 29.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:23<00:00, 23.22s/it][A100%|██████████| 1/1 [00:23<00:00, 23.22s/it]
 94%|█████████▎| 4864/5198 [34:58<2:43:15, 29.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:23<00:00, 23.18s/it][A100%|██████████| 1/1 [00:23<00:00, 23.18s/it]
 94%|█████████▎| 4864/5198 [35:01<2:43:12, 29.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:23<00:00, 23.25s/it][A100%|██████████| 1/1 [00:23<00:00, 23.25s/it]
 94%|█████████▎| 4864/5198 [34:55<2:43:17, 29.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:23<00:00, 23.25s/it][A100%|██████████| 1/1 [00:23<00:00, 23.25s/it]
 94%|█████████▎| 4864/5198 [34:40<2:43:16, 29.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:23<00:00, 23.25s/it][A100%|██████████| 1/1 [00:23<00:00, 23.25s/it]
 94%|█████████▎| 4864/5198 [34:45<2:43:16, 29.33s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4560
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.37s/it][A100%|██████████| 1/1 [00:32<00:00, 32.38s/it]
 94%|█████████▎| 4865/5198 [35:29<2:47:44, 30.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:33:15,031] [INFO] [logging.py:96:log_dist] [Rank 0] step=4864, skipped=0, lr=[5.745821194189558e-07], mom=[(0.9, 0.999)]
steps: 4864 loss: 1.4717 iter time (s): 31.562 samples/sec: 4.056

100%|██████████| 1/1 [00:32<00:00, 32.45s/it][A100%|██████████| 1/1 [00:32<00:00, 32.45s/it]
 94%|█████████▎| 4865/5198 [35:41<2:47:52, 30.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.28s/it][A100%|██████████| 1/1 [00:32<00:00, 32.28s/it]
 94%|█████████▎| 4865/5198 [35:39<2:47:43, 30.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.35s/it][A100%|██████████| 1/1 [00:32<00:00, 32.35s/it]
 94%|█████████▎| 4865/5198 [35:31<2:47:48, 30.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.34s/it][A100%|██████████| 1/1 [00:32<00:00, 32.34s/it]
 94%|█████████▎| 4865/5198 [35:33<2:47:45, 30.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.34s/it][A100%|██████████| 1/1 [00:32<00:00, 32.34s/it]
 94%|█████████▎| 4865/5198 [35:27<2:47:48, 30.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.35s/it][A100%|██████████| 1/1 [00:32<00:00, 32.35s/it]
 94%|█████████▎| 4865/5198 [35:17<2:47:49, 30.24s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4561
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.38s/it][A100%|██████████| 1/1 [00:32<00:00, 32.38s/it]
 94%|█████████▎| 4865/5198 [35:13<2:47:52, 30.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.47s/it][A100%|██████████| 1/1 [00:31<00:00, 31.47s/it]
 94%|█████████▎| 4866/5198 [36:01<2:49:32, 30.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:33:46,650] [INFO] [logging.py:96:log_dist] [Rank 0] step=4865, skipped=0, lr=[5.732658406162051e-07], mom=[(0.9, 0.999)]
steps: 4865 loss: 1.5122 iter time (s): 30.819 samples/sec: 4.153

100%|██████████| 1/1 [00:31<00:00, 31.47s/it][A100%|██████████| 1/1 [00:31<00:00, 31.47s/it]
 94%|█████████▎| 4866/5198 [36:12<2:49:24, 30.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.51s/it][A100%|██████████| 1/1 [00:31<00:00, 31.51s/it]
 94%|█████████▎| 4866/5198 [36:11<2:49:22, 30.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.53s/it][A100%|██████████| 1/1 [00:31<00:00, 31.53s/it]
 94%|█████████▎| 4866/5198 [36:02<2:49:28, 30.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.52s/it][A100%|██████████| 1/1 [00:31<00:00, 31.52s/it]
 94%|█████████▎| 4866/5198 [36:05<2:49:25, 30.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.51s/it][A100%|██████████| 1/1 [00:31<00:00, 31.51s/it]
 94%|█████████▎| 4866/5198 [35:59<2:49:26, 30.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.47s/it][A100%|██████████| 1/1 [00:31<00:00, 31.47s/it]
 94%|█████████▎| 4866/5198 [35:44<2:49:24, 30.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.50s/it][A100%|██████████| 1/1 [00:31<00:00, 31.50s/it]
 94%|█████████▎| 4866/5198 [35:49<2:49:25, 30.62s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4562
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.03s/it][A100%|██████████| 1/1 [00:34<00:00, 34.03s/it]
 94%|█████████▎| 4867/5198 [36:35<2:54:47, 31.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:34:20,778] [INFO] [logging.py:96:log_dist] [Rank 0] step=4866, skipped=0, lr=[5.719509821800703e-07], mom=[(0.9, 0.999)]
steps: 4866 loss: 1.4320 iter time (s): 33.439 samples/sec: 3.828

100%|██████████| 1/1 [00:34<00:00, 34.18s/it][A100%|██████████| 1/1 [00:34<00:00, 34.18s/it]
 94%|█████████▎| 4867/5198 [36:47<2:54:48, 31.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.15s/it][A100%|██████████| 1/1 [00:34<00:00, 34.15s/it]
 94%|█████████▎| 4867/5198 [36:45<2:54:43, 31.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.17s/it][A100%|██████████| 1/1 [00:34<00:00, 34.17s/it]
 94%|█████████▎| 4867/5198 [36:37<2:54:50, 31.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.17s/it][A100%|██████████| 1/1 [00:34<00:00, 34.17s/it]
 94%|█████████▎| 4867/5198 [36:39<2:54:48, 31.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.17s/it][A100%|██████████| 1/1 [00:34<00:00, 34.17s/it]
 94%|█████████▎| 4867/5198 [36:33<2:54:48, 31.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.20s/it][A100%|██████████| 1/1 [00:34<00:00, 34.20s/it]
 94%|█████████▎| 4867/5198 [36:18<2:54:50, 31.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.19s/it][A100%|██████████| 1/1 [00:34<00:00, 34.19s/it]
 94%|█████████▎| 4867/5198 [36:23<2:54:50, 31.69s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4563
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.83s/it][A100%|██████████| 1/1 [00:31<00:00, 31.83s/it]
 94%|█████████▎| 4868/5198 [37:07<2:54:44, 31.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:34:52,500] [INFO] [logging.py:96:log_dist] [Rank 0] step=4867, skipped=0, lr=[5.706375445323889e-07], mom=[(0.9, 0.999)]
steps: 4867 loss: 1.4677 iter time (s): 30.963 samples/sec: 4.134

100%|██████████| 1/1 [00:31<00:00, 31.75s/it][A100%|██████████| 1/1 [00:31<00:00, 31.75s/it]
 94%|█████████▎| 4868/5198 [37:18<2:54:23, 31.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.87s/it][A100%|██████████| 1/1 [00:31<00:00, 31.87s/it]
 94%|█████████▎| 4868/5198 [37:17<2:54:32, 31.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.75s/it][A100%|██████████| 1/1 [00:31<00:00, 31.75s/it]
 94%|█████████▎| 4868/5198 [37:08<2:54:24, 31.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.78s/it][A100%|██████████| 1/1 [00:31<00:00, 31.78s/it]
 94%|█████████▎| 4868/5198 [37:11<2:54:26, 31.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.76s/it][A100%|██████████| 1/1 [00:31<00:00, 31.76s/it]
 94%|█████████▎| 4868/5198 [37:05<2:54:24, 31.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.78s/it][A100%|██████████| 1/1 [00:31<00:00, 31.78s/it]
 94%|█████████▎| 4868/5198 [36:50<2:54:28, 31.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.79s/it][A100%|██████████| 1/1 [00:31<00:00, 31.80s/it]
 94%|█████████▎| 4868/5198 [36:55<2:54:29, 31.73s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4564
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.96s/it][A100%|██████████| 1/1 [00:28<00:00, 28.96s/it]
 94%|█████████▎| 4869/5198 [37:36<2:49:48, 30.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:35:21,750] [INFO] [logging.py:96:log_dist] [Rank 0] step=4868, skipped=0, lr=[5.693255280945468e-07], mom=[(0.9, 0.999)]
steps: 4868 loss: 1.4907 iter time (s): 28.412 samples/sec: 4.505

100%|██████████| 1/1 [00:29<00:00, 29.17s/it][A100%|██████████| 1/1 [00:29<00:00, 29.17s/it]
 94%|█████████▎| 4869/5198 [37:48<2:49:43, 30.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.12s/it][A100%|██████████| 1/1 [00:29<00:00, 29.12s/it]
 94%|█████████▎| 4869/5198 [37:46<2:49:44, 30.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.13s/it][A100%|██████████| 1/1 [00:29<00:00, 29.13s/it]
 94%|█████████▎| 4869/5198 [37:37<2:49:39, 30.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.11s/it][A100%|██████████| 1/1 [00:29<00:00, 29.11s/it]
 94%|█████████▎| 4869/5198 [37:40<2:49:38, 30.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.15s/it][A100%|██████████| 1/1 [00:29<00:00, 29.15s/it]
 94%|█████████▎| 4869/5198 [37:34<2:49:41, 30.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.10s/it][A100%|██████████| 1/1 [00:29<00:00, 29.10s/it]
 94%|█████████▎| 4869/5198 [37:19<2:49:38, 30.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.09s/it][A100%|██████████| 1/1 [00:29<00:00, 29.09s/it]
 94%|█████████▎| 4869/5198 [37:24<2:49:37, 30.94s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4565
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.25s/it][A100%|██████████| 1/1 [00:31<00:00, 31.25s/it]
 94%|█████████▎| 4870/5198 [38:07<2:49:57, 31.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:35:52,973] [INFO] [logging.py:96:log_dist] [Rank 0] step=4869, skipped=0, lr=[5.680149332874691e-07], mom=[(0.9, 0.999)]
steps: 4869 loss: 1.4929 iter time (s): 30.541 samples/sec: 4.191

100%|██████████| 1/1 [00:31<00:00, 31.25s/it][A100%|██████████| 1/1 [00:31<00:00, 31.25s/it]
 94%|█████████▎| 4870/5198 [38:19<2:49:42, 31.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.23s/it][A100%|██████████| 1/1 [00:31<00:00, 31.24s/it]
 94%|█████████▎| 4870/5198 [38:17<2:49:41, 31.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.20s/it][A100%|██████████| 1/1 [00:31<00:00, 31.20s/it]
 94%|█████████▎| 4870/5198 [38:09<2:49:35, 31.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.28s/it][A100%|██████████| 1/1 [00:31<00:00, 31.28s/it]
 94%|█████████▎| 4870/5198 [38:11<2:49:41, 31.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.20s/it][A100%|██████████| 1/1 [00:31<00:00, 31.20s/it]
 94%|█████████▎| 4870/5198 [38:05<2:49:35, 31.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.23s/it][A100%|██████████| 1/1 [00:31<00:00, 31.23s/it]
 94%|█████████▎| 4870/5198 [37:50<2:49:37, 31.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.24s/it][A100%|██████████| 1/1 [00:31<00:00, 31.24s/it]
 94%|█████████▎| 4870/5198 [37:55<2:49:37, 31.03s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4566
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.70s/it][A100%|██████████| 1/1 [00:30<00:00, 30.70s/it]
 94%|█████████▎| 4871/5198 [38:38<2:49:02, 31.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:36:23,984] [INFO] [logging.py:96:log_dist] [Rank 0] step=4870, skipped=0, lr=[5.667057605316277e-07], mom=[(0.9, 0.999)]
steps: 4870 loss: 1.3801 iter time (s): 30.309 samples/sec: 4.223

100%|██████████| 1/1 [00:30<00:00, 30.93s/it][A100%|██████████| 1/1 [00:30<00:00, 30.93s/it]
 94%|█████████▎| 4871/5198 [38:50<2:49:01, 31.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.90s/it][A100%|██████████| 1/1 [00:30<00:00, 30.90s/it]
 94%|█████████▎| 4871/5198 [38:48<2:48:57, 31.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.04s/it][A100%|██████████| 1/1 [00:31<00:00, 31.04s/it]
 94%|█████████▎| 4871/5198 [38:40<2:49:06, 31.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.00s/it][A100%|██████████| 1/1 [00:31<00:00, 31.00s/it]
 94%|█████████▎| 4871/5198 [38:42<2:49:07, 31.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.04s/it][A100%|██████████| 1/1 [00:31<00:00, 31.04s/it]
 94%|█████████▎| 4871/5198 [38:36<2:49:06, 31.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A

100%|██████████| 1/1 [00:31<00:00, 31.02s/it][A100%|██████████| 1/1 [00:31<00:00, 31.02s/it]
 94%|█████████▎| 4871/5198 [38:26<2:49:06, 31.03s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4567
100%|██████████| 1/1 [00:31<00:00, 31.04s/it][A100%|██████████| 1/1 [00:31<00:00, 31.04s/it]
 94%|█████████▎| 4871/5198 [38:21<2:49:07, 31.03s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.52s/it][A100%|██████████| 1/1 [00:30<00:00, 30.52s/it]
 94%|█████████▎| 4872/5198 [39:09<2:47:55, 30.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:36:54,631] [INFO] [logging.py:96:log_dist] [Rank 0] step=4871, skipped=0, lr=[5.653980102470381e-07], mom=[(0.9, 0.999)]
steps: 4871 loss: 1.4896 iter time (s): 29.925 samples/sec: 4.277

100%|██████████| 1/1 [00:30<00:00, 30.69s/it][A100%|██████████| 1/1 [00:30<00:00, 30.69s/it]
 94%|█████████▎| 4872/5198 [39:20<2:47:59, 30.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.76s/it][A100%|██████████| 1/1 [00:30<00:00, 30.76s/it]
 94%|█████████▎| 4872/5198 [39:19<2:48:04, 30.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.68s/it][A100%|██████████| 1/1 [00:30<00:00, 30.68s/it]
 94%|█████████▎| 4872/5198 [39:10<2:48:02, 30.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.68s/it][A100%|██████████| 1/1 [00:30<00:00, 30.68s/it]
 94%|█████████▎| 4872/5198 [39:13<2:48:02, 30.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.66s/it][A100%|██████████| 1/1 [00:30<00:00, 30.66s/it]
 94%|█████████▎| 4872/5198 [38:52<2:48:00, 30.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.72s/it][A100%|██████████| 1/1 [00:30<00:00, 30.72s/it]
 94%|█████████▎| 4872/5198 [39:07<2:48:06, 30.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.70s/it][A100%|██████████| 1/1 [00:30<00:00, 30.70s/it]
 94%|█████████▎| 4872/5198 [38:57<2:48:04, 30.93s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4568
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.49s/it][A100%|██████████| 1/1 [00:29<00:00, 29.49s/it]
 94%|█████████▎| 4873/5198 [39:38<2:45:16, 30.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:37:24,192] [INFO] [logging.py:96:log_dist] [Rank 0] step=4872, skipped=0, lr=[5.640916828532588e-07], mom=[(0.9, 0.999)]
steps: 4872 loss: 1.4673 iter time (s): 28.778 samples/sec: 4.448

100%|██████████| 1/1 [00:29<00:00, 29.51s/it][A100%|██████████| 1/1 [00:29<00:00, 29.51s/it]
 94%|█████████▎| 4873/5198 [39:50<2:45:12, 30.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.45s/it][A100%|██████████| 1/1 [00:29<00:00, 29.45s/it]
 94%|█████████▎| 4873/5198 [39:48<2:45:09, 30.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.45s/it][A100%|██████████| 1/1 [00:29<00:00, 29.45s/it]
 94%|█████████▎| 4873/5198 [39:40<2:45:07, 30.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.45s/it][A100%|██████████| 1/1 [00:29<00:00, 29.45s/it]
 94%|█████████▎| 4873/5198 [39:43<2:45:08, 30.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.42s/it][A100%|██████████| 1/1 [00:29<00:00, 29.42s/it]
 94%|█████████▎| 4873/5198 [39:36<2:45:08, 30.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A

100%|██████████| 1/1 [00:29<00:00, 29.49s/it][A100%|██████████| 1/1 [00:29<00:00, 29.45s/it][A100%|██████████| 1/1 [00:29<00:00, 29.49s/it]
100%|██████████| 1/1 [00:29<00:00, 29.45s/it]
 94%|█████████▎| 4873/5198 [39:22<2:45:11, 30.50s/it] 94%|█████████▎| 4873/5198 [39:26<2:45:09, 30.49s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4569
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.36s/it][A100%|██████████| 1/1 [00:29<00:00, 29.36s/it]
 94%|█████████▍| 4874/5198 [40:08<2:43:06, 30.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:37:53,687] [INFO] [logging.py:96:log_dist] [Rank 0] step=4873, skipped=0, lr=[5.627867787693931e-07], mom=[(0.9, 0.999)]
steps: 4873 loss: 1.4381 iter time (s): 28.814 samples/sec: 4.442

100%|██████████| 1/1 [00:29<00:00, 29.49s/it][A100%|██████████| 1/1 [00:29<00:00, 29.49s/it]
 94%|█████████▍| 4874/5198 [40:19<2:43:04, 30.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.51s/it][A100%|██████████| 1/1 [00:29<00:00, 29.51s/it]
 94%|█████████▍| 4874/5198 [40:18<2:43:05, 30.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.57s/it][A100%|██████████| 1/1 [00:29<00:00, 29.57s/it]
 94%|█████████▍| 4874/5198 [40:09<2:43:09, 30.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.52s/it][A100%|██████████| 1/1 [00:29<00:00, 29.52s/it]
 94%|█████████▍| 4874/5198 [40:12<2:43:05, 30.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.51s/it][A100%|██████████| 1/1 [00:29<00:00, 29.51s/it]
 94%|█████████▍| 4874/5198 [40:06<2:43:03, 30.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.50s/it][A100%|██████████| 1/1 [00:29<00:00, 29.50s/it]
 94%|█████████▍| 4874/5198 [39:51<2:43:04, 30.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.52s/it][A100%|██████████| 1/1 [00:29<00:00, 29.52s/it]
 94%|█████████▍| 4874/5198 [39:56<2:43:04, 30.20s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4570
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.64s/it][A100%|██████████| 1/1 [00:30<00:00, 30.64s/it]
 94%|█████████▍| 4875/5198 [40:39<2:43:30, 30.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:38:24,488] [INFO] [logging.py:96:log_dist] [Rank 0] step=4874, skipped=0, lr=[5.614832984140843e-07], mom=[(0.9, 0.999)]
steps: 4874 loss: 1.4905 iter time (s): 30.095 samples/sec: 4.253

100%|██████████| 1/1 [00:30<00:00, 30.84s/it][A100%|██████████| 1/1 [00:30<00:00, 30.84s/it]
 94%|█████████▍| 4875/5198 [40:50<2:43:37, 30.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.82s/it][A100%|██████████| 1/1 [00:30<00:00, 30.82s/it]
 94%|█████████▍| 4875/5198 [40:48<2:43:36, 30.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.74s/it][A100%|██████████| 1/1 [00:30<00:00, 30.74s/it]
 94%|█████████▍| 4875/5198 [40:43<2:43:28, 30.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.78s/it][A100%|██████████| 1/1 [00:30<00:00, 30.78s/it]
 94%|█████████▍| 4875/5198 [40:40<2:43:34, 30.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.79s/it][A100%|██████████| 1/1 [00:30<00:00, 30.79s/it]
 94%|█████████▍| 4875/5198 [40:37<2:43:31, 30.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.81s/it][A100%|██████████| 1/1 [00:30<00:00, 30.81s/it]
 94%|█████████▍| 4875/5198 [40:22<2:43:33, 30.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.81s/it][A100%|██████████| 1/1 [00:30<00:00, 30.81s/it]
 94%|█████████▍| 4875/5198 [40:27<2:43:33, 30.38s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4571
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.20s/it][A100%|██████████| 1/1 [00:29<00:00, 29.20s/it]
 94%|█████████▍| 4876/5198 [41:08<2:41:19, 30.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:38:53,757] [INFO] [logging.py:96:log_dist] [Rank 0] step=4875, skipped=0, lr=[5.60181242205523e-07], mom=[(0.9, 0.999)]
steps: 4875 loss: 1.4777 iter time (s): 28.552 samples/sec: 4.483

100%|██████████| 1/1 [00:29<00:00, 29.19s/it][A100%|██████████| 1/1 [00:29<00:00, 29.19s/it]
 94%|█████████▍| 4876/5198 [41:20<2:41:11, 30.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.22s/it][A100%|██████████| 1/1 [00:29<00:00, 29.22s/it]
 94%|█████████▍| 4876/5198 [41:18<2:41:14, 30.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.23s/it][A100%|██████████| 1/1 [00:29<00:00, 29.23s/it]
 94%|█████████▍| 4876/5198 [41:09<2:41:14, 30.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.29s/it][A100%|██████████| 1/1 [00:29<00:00, 29.29s/it]
 94%|█████████▍| 4876/5198 [41:12<2:41:14, 30.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.27s/it][A100%|██████████| 1/1 [00:29<00:00, 29.27s/it]
 94%|█████████▍| 4876/5198 [41:06<2:41:14, 30.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.24s/it][A100%|██████████| 1/1 [00:29<00:00, 29.24s/it]
 94%|█████████▍| 4876/5198 [40:51<2:41:13, 30.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.24s/it][A100%|██████████| 1/1 [00:29<00:00, 29.24s/it]
 94%|█████████▍| 4876/5198 [40:56<2:41:13, 30.04s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4572
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.63s/it][A100%|██████████| 1/1 [00:29<00:00, 29.63s/it]
 94%|█████████▍| 4877/5198 [41:38<2:40:20, 29.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:39:23,535] [INFO] [logging.py:96:log_dist] [Rank 0] step=4876, skipped=0, lr=[5.588806105614408e-07], mom=[(0.9, 0.999)]
steps: 4876 loss: 1.4409 iter time (s): 29.086 samples/sec: 4.401

100%|██████████| 1/1 [00:29<00:00, 29.80s/it][A100%|██████████| 1/1 [00:29<00:00, 29.80s/it]
 94%|█████████▍| 4877/5198 [41:49<2:40:19, 29.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.73s/it][A100%|██████████| 1/1 [00:29<00:00, 29.73s/it]
 94%|█████████▍| 4877/5198 [41:47<2:40:15, 29.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.77s/it][A100%|██████████| 1/1 [00:29<00:00, 29.77s/it]
 94%|█████████▍| 4877/5198 [41:39<2:40:18, 29.96s/it]
100%|██████████| 1/1 [00:29<00:00, 29.74s/it][A100%|██████████| 1/1 [00:29<00:00, 29.74s/it]
 94%|█████████▍| 4877/5198 [41:42<2:40:15, 29.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.74s/it][A100%|██████████| 1/1 [00:29<00:00, 29.74s/it]
 94%|█████████▍| 4877/5198 [41:36<2:40:16, 29.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.73s/it][A100%|██████████| 1/1 [00:29<00:00, 29.73s/it]
 94%|█████████▍| 4877/5198 [41:21<2:40:14, 29.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.74s/it][A100%|██████████| 1/1 [00:29<00:00, 29.74s/it]
 94%|█████████▍| 4877/5198 [41:26<2:40:15, 29.95s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4573
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.23s/it][A100%|██████████| 1/1 [00:32<00:00, 32.23s/it]
 94%|█████████▍| 4878/5198 [42:10<2:43:39, 30.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:39:56,007] [INFO] [logging.py:96:log_dist] [Rank 0] step=4877, skipped=0, lr=[5.57581403899113e-07], mom=[(0.9, 0.999)]
steps: 4877 loss: 1.4646 iter time (s): 31.808 samples/sec: 4.024

100%|██████████| 1/1 [00:32<00:00, 32.42s/it][A100%|██████████| 1/1 [00:32<00:00, 32.42s/it]
 94%|█████████▍| 4878/5198 [42:22<2:43:45, 30.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.55s/it][A100%|██████████| 1/1 [00:32<00:00, 32.55s/it]
 94%|█████████▍| 4878/5198 [42:20<2:43:56, 30.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.51s/it][A100%|██████████| 1/1 [00:32<00:00, 32.51s/it]
 94%|█████████▍| 4878/5198 [42:12<2:43:53, 30.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.57s/it][A100%|██████████| 1/1 [00:32<00:00, 32.57s/it]
 94%|█████████▍| 4878/5198 [42:14<2:43:57, 30.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.49s/it][A100%|██████████| 1/1 [00:32<00:00, 32.49s/it]
 94%|█████████▍| 4878/5198 [42:08<2:43:50, 30.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.54s/it][A100%|██████████| 1/1 [00:32<00:00, 32.54s/it]
 94%|█████████▍| 4878/5198 [41:53<2:43:53, 30.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.53s/it][A100%|██████████| 1/1 [00:32<00:00, 32.53s/it]
 94%|█████████▍| 4878/5198 [41:58<2:43:53, 30.73s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4574
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.74s/it][A100%|██████████| 1/1 [00:28<00:00, 28.74s/it]
 94%|█████████▍| 4879/5198 [42:39<2:40:12, 30.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:40:24,719] [INFO] [logging.py:96:log_dist] [Rank 0] step=4878, skipped=0, lr=[5.562836226353563e-07], mom=[(0.9, 0.999)]
steps: 4878 loss: 1.4496 iter time (s): 27.984 samples/sec: 4.574

100%|██████████| 1/1 [00:28<00:00, 28.74s/it][A100%|██████████| 1/1 [00:28<00:00, 28.74s/it]
 94%|█████████▍| 4879/5198 [42:50<2:40:07, 30.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.63s/it][A100%|██████████| 1/1 [00:28<00:00, 28.63s/it]
 94%|█████████▍| 4879/5198 [42:49<2:40:04, 30.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.62s/it][A100%|██████████| 1/1 [00:28<00:00, 28.62s/it]
 94%|█████████▍| 4879/5198 [42:40<2:40:01, 30.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.61s/it][A100%|██████████| 1/1 [00:28<00:00, 28.61s/it]
 94%|█████████▍| 4879/5198 [42:43<2:40:03, 30.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.65s/it][A100%|██████████| 1/1 [00:28<00:00, 28.65s/it]
 94%|█████████▍| 4879/5198 [42:37<2:40:02, 30.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.63s/it][A100%|██████████| 1/1 [00:28<00:00, 28.63s/it]
 94%|█████████▍| 4879/5198 [42:22<2:40:02, 30.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.62s/it][A100%|██████████| 1/1 [00:28<00:00, 28.62s/it]
 94%|█████████▍| 4879/5198 [42:27<2:40:01, 30.10s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_304
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:22<00:00, 22.32s/it][A100%|██████████| 1/1 [00:22<00:00, 22.32s/it]
 94%|█████████▍| 4880/5198 [43:01<2:27:27, 27.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:40:47,266] [INFO] [logging.py:96:log_dist] [Rank 0] step=4879, skipped=0, lr=[5.54987267186532e-07], mom=[(0.9, 0.999)]
steps: 4879 loss: 1.8652 iter time (s): 21.934 samples/sec: 5.836

100%|██████████| 1/1 [00:22<00:00, 22.79s/it][A100%|██████████| 1/1 [00:22<00:00, 22.79s/it]
 94%|█████████▍| 4880/5198 [43:13<2:27:59, 27.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:22<00:00, 22.79s/it][A100%|██████████| 1/1 [00:22<00:00, 22.79s/it]
 94%|█████████▍| 4880/5198 [43:11<2:27:57, 27.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:22<00:00, 22.72s/it][A100%|██████████| 1/1 [00:22<00:00, 22.72s/it]
 94%|█████████▍| 4880/5198 [43:03<2:27:48, 27.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:22<00:00, 22.84s/it][A100%|██████████| 1/1 [00:22<00:00, 22.84s/it]
 94%|█████████▍| 4880/5198 [43:06<2:28:00, 27.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:22<00:00, 22.88s/it][A100%|██████████| 1/1 [00:22<00:00, 22.88s/it]
 94%|█████████▍| 4880/5198 [43:00<2:28:04, 27.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:22<00:00, 22.88s/it][A100%|██████████| 1/1 [00:22<00:00, 22.88s/it]
 94%|█████████▍| 4880/5198 [42:45<2:28:03, 27.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:22<00:00, 22.88s/it][A100%|██████████| 1/1 [00:22<00:00, 22.88s/it]
 94%|█████████▍| 4880/5198 [42:50<2:28:02, 27.93s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4575
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.45s/it][A100%|██████████| 1/1 [00:31<00:00, 31.45s/it]
 94%|█████████▍| 4881/5198 [43:33<2:32:59, 28.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:41:18,821] [INFO] [logging.py:96:log_dist] [Rank 0] step=4880, skipped=0, lr=[5.53692337968543e-07], mom=[(0.9, 0.999)]
steps: 4880 loss: 1.5517 iter time (s): 30.585 samples/sec: 4.185

100%|██████████| 1/1 [00:31<00:00, 31.38s/it][A100%|██████████| 1/1 [00:31<00:00, 31.38s/it]
 94%|█████████▍| 4881/5198 [43:45<2:33:02, 28.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.34s/it][A100%|██████████| 1/1 [00:31<00:00, 31.35s/it]
 94%|█████████▍| 4881/5198 [43:43<2:32:56, 28.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.42s/it][A100%|██████████| 1/1 [00:31<00:00, 31.42s/it]
 94%|█████████▍| 4881/5198 [43:35<2:32:57, 28.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.34s/it][A100%|██████████| 1/1 [00:31<00:00, 31.34s/it]
 94%|█████████▍| 4881/5198 [43:37<2:32:57, 28.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.28s/it][A100%|██████████| 1/1 [00:31<00:00, 31.28s/it]
 94%|█████████▍| 4881/5198 [43:31<2:32:55, 28.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.30s/it][A100%|██████████| 1/1 [00:31<00:00, 31.30s/it]
 94%|█████████▍| 4881/5198 [43:16<2:32:55, 28.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.30s/it][A100%|██████████| 1/1 [00:31<00:00, 31.30s/it]
 94%|█████████▍| 4881/5198 [43:21<2:32:55, 28.95s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4576
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.56s/it][A100%|██████████| 1/1 [00:31<00:00, 31.56s/it]
 94%|█████████▍| 4882/5198 [44:05<2:36:50, 29.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:41:50,570] [INFO] [logging.py:96:log_dist] [Rank 0] step=4881, skipped=0, lr=[5.523988353968348e-07], mom=[(0.9, 0.999)]
steps: 4881 loss: 1.3940 iter time (s): 31.013 samples/sec: 4.127

100%|██████████| 1/1 [00:31<00:00, 31.75s/it][A100%|██████████| 1/1 [00:31<00:00, 31.75s/it]
 94%|█████████▍| 4882/5198 [44:16<2:36:57, 29.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.81s/it][A100%|██████████| 1/1 [00:31<00:00, 31.81s/it]
 94%|█████████▍| 4882/5198 [44:15<2:36:59, 29.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.92s/it][A100%|██████████| 1/1 [00:31<00:00, 31.92s/it]
 94%|█████████▍| 4882/5198 [44:06<2:37:10, 29.84s/it]
100%|██████████| 1/1 [00:31<00:00, 31.85s/it][A100%|██████████| 1/1 [00:31<00:00, 31.85s/it]
 94%|█████████▍| 4882/5198 [44:09<2:37:04, 29.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.95s/it][A100%|██████████| 1/1 [00:31<00:00, 31.95s/it]
 94%|█████████▍| 4882/5198 [44:03<2:37:12, 29.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.45s/it][A100%|██████████| 1/1 [00:32<00:00, 32.45s/it]
 94%|█████████▍| 4882/5198 [43:49<2:37:59, 30.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.85s/it][A100%|██████████| 1/1 [00:32<00:00, 32.85s/it]
 94%|█████████▍| 4882/5198 [43:54<2:38:37, 30.12s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4577
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.56s/it][A100%|██████████| 1/1 [00:35<00:00, 35.56s/it]
 94%|█████████▍| 4883/5198 [44:40<2:45:39, 31.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:42:26,395] [INFO] [logging.py:96:log_dist] [Rank 0] step=4882, skipped=0, lr=[5.511067598863946e-07], mom=[(0.9, 0.999)]
steps: 4882 loss: 1.4347 iter time (s): 33.977 samples/sec: 3.767

100%|██████████| 1/1 [00:35<00:00, 35.77s/it][A100%|██████████| 1/1 [00:35<00:00, 35.77s/it]
 94%|█████████▍| 4883/5198 [44:52<2:45:52, 31.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.73s/it][A100%|██████████| 1/1 [00:35<00:00, 35.73s/it]
 94%|█████████▍| 4883/5198 [44:50<2:45:50, 31.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.68s/it][A100%|██████████| 1/1 [00:35<00:00, 35.68s/it]
 94%|█████████▍| 4883/5198 [44:42<2:45:54, 31.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.76s/it][A100%|██████████| 1/1 [00:35<00:00, 35.76s/it]
 94%|█████████▍| 4883/5198 [44:45<2:45:56, 31.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.64s/it][A100%|██████████| 1/1 [00:35<00:00, 35.64s/it]
 94%|█████████▍| 4883/5198 [44:39<2:45:52, 31.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.14s/it][A100%|██████████| 1/1 [00:35<00:00, 35.14s/it]
 94%|█████████▍| 4883/5198 [44:24<2:45:36, 31.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.74s/it][A100%|██████████| 1/1 [00:34<00:00, 34.74s/it]
 94%|█████████▍| 4883/5198 [44:29<2:45:25, 31.51s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4578
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.84s/it][A100%|██████████| 1/1 [00:30<00:00, 30.84s/it]
 94%|█████████▍| 4884/5198 [45:11<2:44:14, 31.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:42:57,163] [INFO] [logging.py:96:log_dist] [Rank 0] step=4883, skipped=0, lr=[5.498161118517526e-07], mom=[(0.9, 0.999)]
steps: 4883 loss: 1.4854 iter time (s): 29.995 samples/sec: 4.267

100%|██████████| 1/1 [00:30<00:00, 30.72s/it][A100%|██████████| 1/1 [00:30<00:00, 30.72s/it]
 94%|█████████▍| 4884/5198 [45:23<2:44:00, 31.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.77s/it][A100%|██████████| 1/1 [00:30<00:00, 30.77s/it]
 94%|█████████▍| 4884/5198 [45:21<2:44:02, 31.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.72s/it][A100%|██████████| 1/1 [00:30<00:00, 30.72s/it]
 94%|█████████▍| 4884/5198 [45:13<2:44:00, 31.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.67s/it][A100%|██████████| 1/1 [00:30<00:00, 30.67s/it]
 94%|█████████▍| 4884/5198 [45:16<2:43:57, 31.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.70s/it][A100%|██████████| 1/1 [00:30<00:00, 30.70s/it]
 94%|█████████▍| 4884/5198 [45:09<2:43:56, 31.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.69s/it][A100%|██████████| 1/1 [00:30<00:00, 30.69s/it]
 94%|█████████▍| 4884/5198 [44:55<2:43:45, 31.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.69s/it][A100%|██████████| 1/1 [00:30<00:00, 30.69s/it]
 94%|█████████▍| 4884/5198 [44:59<2:43:37, 31.27s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4579
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.93s/it][A100%|██████████| 1/1 [00:31<00:00, 31.93s/it]
 94%|█████████▍| 4885/5198 [45:43<2:44:42, 31.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:43:29,272] [INFO] [logging.py:96:log_dist] [Rank 0] step=4884, skipped=0, lr=[5.485268917069822e-07], mom=[(0.9, 0.999)]
steps: 4884 loss: 1.4818 iter time (s): 31.411 samples/sec: 4.075

100%|██████████| 1/1 [00:32<00:00, 32.10s/it][A100%|██████████| 1/1 [00:32<00:00, 32.10s/it]
 94%|█████████▍| 4885/5198 [45:55<2:44:40, 31.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.06s/it][A100%|██████████| 1/1 [00:32<00:00, 32.06s/it]
 94%|█████████▍| 4885/5198 [45:53<2:44:38, 31.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.08s/it][A100%|██████████| 1/1 [00:32<00:00, 32.08s/it]
 94%|█████████▍| 4885/5198 [45:45<2:44:39, 31.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.12s/it][A100%|██████████| 1/1 [00:32<00:00, 32.12s/it]
 94%|█████████▍| 4885/5198 [45:48<2:44:40, 31.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.14s/it][A100%|██████████| 1/1 [00:32<00:00, 32.14s/it]
 94%|█████████▍| 4885/5198 [45:41<2:44:42, 31.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.15s/it][A100%|██████████| 1/1 [00:32<00:00, 32.15s/it]
 94%|█████████▍| 4885/5198 [45:27<2:44:35, 31.55s/it]
100%|██████████| 1/1 [00:32<00:00, 32.14s/it][A100%|██████████| 1/1 [00:32<00:00, 32.14s/it]
 94%|█████████▍| 4885/5198 [45:32<2:44:28, 31.53s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4580
Training on 128 of 128 sentences.


  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.40s/it][A100%|██████████| 1/1 [00:30<00:00, 30.40s/it]
 94%|█████████▍| 4886/5198 [46:14<2:42:31, 31.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:43:59,738] [INFO] [logging.py:96:log_dist] [Rank 0] step=4885, skipped=0, lr=[5.472390998656945e-07], mom=[(0.9, 0.999)]
steps: 4885 loss: 1.5088 iter time (s): 29.731 samples/sec: 4.305

100%|██████████| 1/1 [00:30<00:00, 30.43s/it][A100%|██████████| 1/1 [00:30<00:00, 30.43s/it]
 94%|█████████▍| 4886/5198 [46:26<2:42:23, 31.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.55s/it][A100%|██████████| 1/1 [00:30<00:00, 30.55s/it]
 94%|█████████▍| 4886/5198 [46:24<2:42:33, 31.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.44s/it][A100%|██████████| 1/1 [00:30<00:00, 30.44s/it]
 94%|█████████▍| 4886/5198 [46:15<2:42:23, 31.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.46s/it][A100%|██████████| 1/1 [00:30<00:00, 30.46s/it]
 94%|█████████▍| 4886/5198 [46:18<2:42:26, 31.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.41s/it][A100%|██████████| 1/1 [00:30<00:00, 30.41s/it]
 94%|█████████▍| 4886/5198 [46:12<2:42:22, 31.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.42s/it][A100%|██████████| 1/1 [00:30<00:00, 30.42s/it]
 94%|█████████▍| 4886/5198 [45:57<2:42:19, 31.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.44s/it][A100%|██████████| 1/1 [00:30<00:00, 30.44s/it]
 94%|█████████▍| 4886/5198 [46:02<2:42:16, 31.21s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4581
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.42s/it][A100%|██████████| 1/1 [00:31<00:00, 31.42s/it]
 94%|█████████▍| 4887/5198 [46:45<2:42:28, 31.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:44:31,298] [INFO] [logging.py:96:log_dist] [Rank 0] step=4886, skipped=0, lr=[5.459527367410466e-07], mom=[(0.9, 0.999)]
steps: 4886 loss: 1.3985 iter time (s): 30.844 samples/sec: 4.150

100%|██████████| 1/1 [00:31<00:00, 31.55s/it][A100%|██████████| 1/1 [00:31<00:00, 31.56s/it]
 94%|█████████▍| 4887/5198 [46:57<2:42:23, 31.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.42s/it][A100%|██████████| 1/1 [00:31<00:00, 31.42s/it]
 94%|█████████▍| 4887/5198 [46:55<2:42:17, 31.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.54s/it][A100%|██████████| 1/1 [00:31<00:00, 31.54s/it]
 94%|█████████▍| 4887/5198 [46:47<2:42:21, 31.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.51s/it][A100%|██████████| 1/1 [00:31<00:00, 31.52s/it]
 94%|█████████▍| 4887/5198 [46:50<2:42:21, 31.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.55s/it][A100%|██████████| 1/1 [00:31<00:00, 31.55s/it]
 94%|█████████▍| 4887/5198 [46:43<2:42:22, 31.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.53s/it][A100%|██████████| 1/1 [00:31<00:00, 31.53s/it]
 94%|█████████▍| 4887/5198 [46:29<2:42:18, 31.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.52s/it][A100%|██████████| 1/1 [00:31<00:00, 31.52s/it]
 94%|█████████▍| 4887/5198 [46:33<2:42:15, 31.30s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4582
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.52s/it][A100%|██████████| 1/1 [00:30<00:00, 30.52s/it]
 94%|█████████▍| 4888/5198 [47:16<2:40:52, 31.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:45:01,934] [INFO] [logging.py:96:log_dist] [Rank 0] step=4887, skipped=0, lr=[5.446678027457358e-07], mom=[(0.9, 0.999)]
steps: 4887 loss: 1.5377 iter time (s): 29.950 samples/sec: 4.274

100%|██████████| 1/1 [00:30<00:00, 30.63s/it][A100%|██████████| 1/1 [00:30<00:00, 30.63s/it]
 94%|█████████▍| 4888/5198 [47:28<2:40:48, 31.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.61s/it][A100%|██████████| 1/1 [00:30<00:00, 30.62s/it]
 94%|█████████▍| 4888/5198 [47:26<2:40:42, 31.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.59s/it][A100%|██████████| 1/1 [00:30<00:00, 30.59s/it]
 94%|█████████▍| 4888/5198 [47:20<2:40:42, 31.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.68s/it][A100%|██████████| 1/1 [00:30<00:00, 30.68s/it]
 94%|█████████▍| 4888/5198 [47:18<2:40:50, 31.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.62s/it][A100%|██████████| 1/1 [00:30<00:00, 30.62s/it]
 94%|█████████▍| 4888/5198 [47:14<2:40:46, 31.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.63s/it][A100%|██████████| 1/1 [00:30<00:00, 30.63s/it]
 94%|█████████▍| 4888/5198 [46:59<2:40:43, 31.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.64s/it][A100%|██████████| 1/1 [00:30<00:00, 30.64s/it]
 94%|█████████▍| 4888/5198 [47:04<2:40:42, 31.10s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4583
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.18s/it][A100%|██████████| 1/1 [00:31<00:00, 31.18s/it]
 94%|█████████▍| 4889/5198 [47:47<2:40:37, 31.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:45:33,261] [INFO] [logging.py:96:log_dist] [Rank 0] step=4888, skipped=0, lr=[5.433842982920002e-07], mom=[(0.9, 0.999)]
steps: 4888 loss: 1.5075 iter time (s): 30.635 samples/sec: 4.178

100%|██████████| 1/1 [00:31<00:00, 31.32s/it][A100%|██████████| 1/1 [00:31<00:00, 31.32s/it]
 94%|█████████▍| 4889/5198 [47:59<2:40:36, 31.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.43s/it][A100%|██████████| 1/1 [00:31<00:00, 31.43s/it]
 94%|█████████▍| 4889/5198 [47:57<2:40:42, 31.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.36s/it][A100%|██████████| 1/1 [00:31<00:00, 31.36s/it]
 94%|█████████▍| 4889/5198 [47:49<2:40:41, 31.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.41s/it][A100%|██████████| 1/1 [00:31<00:00, 31.41s/it]
 94%|█████████▍| 4889/5198 [47:52<2:40:41, 31.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.41s/it][A100%|██████████| 1/1 [00:31<00:00, 31.41s/it]
 94%|█████████▍| 4889/5198 [47:45<2:40:43, 31.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.41s/it][A100%|██████████| 1/1 [00:31<00:00, 31.41s/it]
 94%|█████████▍| 4889/5198 [47:31<2:40:40, 31.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.42s/it][A100%|██████████| 1/1 [00:31<00:00, 31.42s/it]
 94%|█████████▍| 4889/5198 [47:36<2:40:40, 31.20s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4584
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.77s/it][A100%|██████████| 1/1 [00:30<00:00, 30.77s/it]
 94%|█████████▍| 4890/5198 [48:18<2:39:37, 31.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:46:04,119] [INFO] [logging.py:96:log_dist] [Rank 0] step=4889, skipped=0, lr=[5.4210222379162e-07], mom=[(0.9, 0.999)]
steps: 4889 loss: 1.5232 iter time (s): 30.068 samples/sec: 4.257

100%|██████████| 1/1 [00:30<00:00, 30.83s/it][A100%|██████████| 1/1 [00:30<00:00, 30.83s/it]
 94%|█████████▍| 4890/5198 [48:30<2:39:33, 31.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.79s/it][A100%|██████████| 1/1 [00:30<00:00, 30.79s/it]
 94%|█████████▍| 4890/5198 [48:28<2:39:33, 31.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.79s/it][A100%|██████████| 1/1 [00:30<00:00, 30.79s/it]
 94%|█████████▍| 4890/5198 [48:22<2:39:32, 31.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.83s/it][A100%|██████████| 1/1 [00:30<00:00, 30.83s/it]
 94%|█████████▍| 4890/5198 [48:16<2:39:38, 31.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.99s/it][A100%|██████████| 1/1 [00:30<00:00, 30.99s/it]
 94%|█████████▍| 4890/5198 [48:20<2:39:51, 31.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.85s/it][A100%|██████████| 1/1 [00:30<00:00, 30.85s/it]
 94%|█████████▍| 4890/5198 [48:06<2:39:38, 31.10s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4585
Training on 128 of 128 sentences.

100%|██████████| 1/1 [00:30<00:00, 30.89s/it][A100%|██████████| 1/1 [00:30<00:00, 30.89s/it]

 94%|█████████▍| 4890/5198 [48:02<2:39:41, 31.11s/it]  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.88s/it][A100%|██████████| 1/1 [00:29<00:00, 29.88s/it]
 94%|█████████▍| 4891/5198 [48:48<2:37:30, 30.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:46:34,162] [INFO] [logging.py:96:log_dist] [Rank 0] step=4890, skipped=0, lr=[5.408215796559181e-07], mom=[(0.9, 0.999)]
steps: 4890 loss: 1.4954 iter time (s): 29.252 samples/sec: 4.376

100%|██████████| 1/1 [00:30<00:00, 30.02s/it][A100%|██████████| 1/1 [00:30<00:00, 30.02s/it]
 94%|█████████▍| 4891/5198 [49:00<2:37:24, 30.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.03s/it][A100%|██████████| 1/1 [00:30<00:00, 30.03s/it]
 94%|█████████▍| 4891/5198 [48:58<2:37:26, 30.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.82s/it][A100%|██████████| 1/1 [00:29<00:00, 29.82s/it]
 94%|█████████▍| 4891/5198 [48:50<2:37:19, 30.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.11s/it][A100%|██████████| 1/1 [00:30<00:00, 30.11s/it]
 94%|█████████▍| 4891/5198 [48:53<2:37:33, 30.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.96s/it][A100%|██████████| 1/1 [00:29<00:00, 29.96s/it]
 94%|█████████▍| 4891/5198 [48:32<2:37:24, 30.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.05s/it][A100%|██████████| 1/1 [00:30<00:00, 30.05s/it]
 94%|█████████▍| 4891/5198 [48:46<2:37:31, 30.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.99s/it][A100%|██████████| 1/1 [00:29<00:00, 29.99s/it]
 94%|█████████▍| 4891/5198 [48:36<2:37:25, 30.77s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4586
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.10s/it][A100%|██████████| 1/1 [00:33<00:00, 33.10s/it]
 94%|█████████▍| 4892/5198 [49:22<2:40:48, 31.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:47:07,531] [INFO] [logging.py:96:log_dist] [Rank 0] step=4891, skipped=0, lr=[5.395423662957545e-07], mom=[(0.9, 0.999)]
steps: 4891 loss: 1.4510 iter time (s): 32.621 samples/sec: 3.924

100%|██████████| 1/1 [00:33<00:00, 33.43s/it][A100%|██████████| 1/1 [00:33<00:00, 33.43s/it]
 94%|█████████▍| 4892/5198 [49:33<2:40:59, 31.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.37s/it][A100%|██████████| 1/1 [00:33<00:00, 33.38s/it]
 94%|█████████▍| 4892/5198 [49:31<2:40:56, 31.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.41s/it][A100%|██████████| 1/1 [00:33<00:00, 33.41s/it]
 94%|█████████▍| 4892/5198 [49:23<2:40:53, 31.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.34s/it][A100%|██████████| 1/1 [00:33<00:00, 33.34s/it]
 94%|█████████▍| 4892/5198 [49:26<2:40:57, 31.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.36s/it][A100%|██████████| 1/1 [00:33<00:00, 33.36s/it]
 94%|█████████▍| 4892/5198 [49:20<2:40:57, 31.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.41s/it][A100%|██████████| 1/1 [00:33<00:00, 33.41s/it]
 94%|█████████▍| 4892/5198 [49:05<2:40:57, 31.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.39s/it][A100%|██████████| 1/1 [00:33<00:00, 33.39s/it]
 94%|█████████▍| 4892/5198 [49:10<2:40:56, 31.56s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4587
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.06s/it][A100%|██████████| 1/1 [00:30<00:00, 30.06s/it]
 94%|█████████▍| 4893/5198 [49:52<2:38:18, 31.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:47:37,662] [INFO] [logging.py:96:log_dist] [Rank 0] step=4892, skipped=0, lr=[5.382645841215339e-07], mom=[(0.9, 0.999)]
steps: 4892 loss: 1.4753 iter time (s): 29.360 samples/sec: 4.360

100%|██████████| 1/1 [00:30<00:00, 30.15s/it][A100%|██████████| 1/1 [00:30<00:00, 30.15s/it]
 94%|█████████▍| 4893/5198 [50:04<2:38:19, 31.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.08s/it][A100%|██████████| 1/1 [00:30<00:00, 30.08s/it]
 94%|█████████▍| 4893/5198 [50:02<2:38:10, 31.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.06s/it][A100%|██████████| 1/1 [00:30<00:00, 30.06s/it]
 94%|█████████▍| 4893/5198 [49:53<2:38:06, 31.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.08s/it][A100%|██████████| 1/1 [00:30<00:00, 30.08s/it]
 94%|█████████▍| 4893/5198 [49:56<2:38:10, 31.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.02s/it][A100%|██████████| 1/1 [00:30<00:00, 30.02s/it]
 94%|█████████▍| 4893/5198 [49:50<2:38:06, 31.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.03s/it][A100%|██████████| 1/1 [00:30<00:00, 30.03s/it]
 94%|█████████▍| 4893/5198 [49:35<2:38:06, 31.10s/it]
100%|██████████| 1/1 [00:30<00:00, 30.03s/it][A100%|██████████| 1/1 [00:30<00:00, 30.03s/it]
 94%|█████████▍| 4893/5198 [49:40<2:38:05, 31.10s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4588

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.71s/it][A100%|██████████| 1/1 [00:30<00:00, 30.72s/it]
 94%|█████████▍| 4894/5198 [50:23<2:37:22, 31.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:48:08,501] [INFO] [logging.py:96:log_dist] [Rank 0] step=4893, skipped=0, lr=[5.369882335432001e-07], mom=[(0.9, 0.999)]
steps: 4893 loss: 1.4193 iter time (s): 30.164 samples/sec: 4.244

100%|██████████| 1/1 [00:30<00:00, 30.75s/it][A100%|██████████| 1/1 [00:30<00:00, 30.75s/it]
 94%|█████████▍| 4894/5198 [50:34<2:37:13, 31.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.84s/it][A100%|██████████| 1/1 [00:30<00:00, 30.84s/it]
 94%|█████████▍| 4894/5198 [50:32<2:37:15, 31.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.75s/it][A100%|██████████| 1/1 [00:30<00:00, 30.75s/it]
 94%|█████████▍| 4894/5198 [50:24<2:37:04, 31.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.79s/it][A100%|██████████| 1/1 [00:30<00:00, 30.79s/it]
 94%|█████████▍| 4894/5198 [50:27<2:37:10, 31.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.77s/it][A100%|██████████| 1/1 [00:30<00:00, 30.77s/it]
 94%|█████████▍| 4894/5198 [50:20<2:37:05, 31.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.81s/it][A100%|██████████| 1/1 [00:30<00:00, 30.81s/it]
 94%|█████████▍| 4894/5198 [50:06<2:37:08, 31.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.81s/it][A100%|██████████| 1/1 [00:30<00:00, 30.81s/it]
 94%|█████████▍| 4894/5198 [50:11<2:37:08, 31.01s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4589
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.73s/it][A100%|██████████| 1/1 [00:29<00:00, 29.73s/it]
 94%|█████████▍| 4895/5198 [50:53<2:35:05, 30.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:48:38,427] [INFO] [logging.py:96:log_dist] [Rank 0] step=4894, skipped=0, lr=[5.357133149702388e-07], mom=[(0.9, 0.999)]
steps: 4894 loss: 1.4612 iter time (s): 29.279 samples/sec: 4.372

100%|██████████| 1/1 [00:29<00:00, 29.90s/it][A100%|██████████| 1/1 [00:29<00:00, 29.90s/it]
 94%|█████████▍| 4895/5198 [51:04<2:35:00, 30.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.97s/it][A100%|██████████| 1/1 [00:29<00:00, 29.97s/it]
 94%|█████████▍| 4895/5198 [51:02<2:35:07, 30.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.98s/it][A100%|██████████| 1/1 [00:29<00:00, 29.98s/it]
 94%|█████████▍| 4895/5198 [50:54<2:35:01, 30.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.93s/it][A100%|██████████| 1/1 [00:29<00:00, 29.93s/it]
 94%|█████████▍| 4895/5198 [50:50<2:34:58, 30.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.97s/it][A100%|██████████| 1/1 [00:29<00:00, 29.97s/it]
 94%|█████████▍| 4895/5198 [50:57<2:35:05, 30.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.92s/it][A100%|██████████| 1/1 [00:29<00:00, 29.92s/it]
 94%|█████████▍| 4895/5198 [50:36<2:34:58, 30.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.93s/it][A100%|██████████| 1/1 [00:29<00:00, 29.93s/it]
 94%|█████████▍| 4895/5198 [50:41<2:34:59, 30.69s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_305
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.21s/it][A100%|██████████| 1/1 [00:24<00:00, 24.21s/it]
 94%|█████████▍| 4896/5198 [51:17<2:24:57, 28.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:49:02,903] [INFO] [logging.py:96:log_dist] [Rank 0] step=4895, skipped=0, lr=[5.344398288116754e-07], mom=[(0.9, 0.999)]
steps: 4895 loss: 1.7517 iter time (s): 23.848 samples/sec: 5.367

100%|██████████| 1/1 [00:24<00:00, 24.60s/it][A100%|██████████| 1/1 [00:24<00:00, 24.60s/it]
 94%|█████████▍| 4896/5198 [51:29<2:25:17, 28.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.57s/it][A100%|██████████| 1/1 [00:24<00:00, 24.57s/it]
 94%|█████████▍| 4896/5198 [51:27<2:25:20, 28.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.64s/it][A100%|██████████| 1/1 [00:24<00:00, 24.64s/it]
 94%|█████████▍| 4896/5198 [51:19<2:25:22, 28.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.55s/it][A100%|██████████| 1/1 [00:24<00:00, 24.55s/it]
 94%|█████████▍| 4896/5198 [51:21<2:25:17, 28.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.62s/it][A100%|██████████| 1/1 [00:24<00:00, 24.62s/it]
 94%|█████████▍| 4896/5198 [51:15<2:25:18, 28.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.59s/it][A100%|██████████| 1/1 [00:24<00:00, 24.59s/it]
 94%|█████████▍| 4896/5198 [51:00<2:25:15, 28.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.61s/it][A100%|██████████| 1/1 [00:24<00:00, 24.61s/it]
 94%|█████████▍| 4896/5198 [51:05<2:25:18, 28.87s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4590
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.06s/it][A100%|██████████| 1/1 [00:30<00:00, 30.06s/it]
 94%|█████████▍| 4897/5198 [51:47<2:26:34, 29.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:49:32,974] [INFO] [logging.py:96:log_dist] [Rank 0] step=4896, skipped=0, lr=[5.331677754760744e-07], mom=[(0.9, 0.999)]
steps: 4896 loss: 1.5221 iter time (s): 29.278 samples/sec: 4.372

100%|██████████| 1/1 [00:29<00:00, 29.94s/it][A100%|██████████| 1/1 [00:29<00:00, 29.95s/it]
 94%|█████████▍| 4897/5198 [51:59<2:26:27, 29.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.96s/it][A100%|██████████| 1/1 [00:29<00:00, 29.96s/it]
 94%|█████████▍| 4897/5198 [51:57<2:26:30, 29.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.95s/it][A100%|██████████| 1/1 [00:29<00:00, 29.95s/it]
 94%|█████████▍| 4897/5198 [51:49<2:26:30, 29.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.01s/it][A100%|██████████| 1/1 [00:30<00:00, 30.01s/it]
 94%|█████████▍| 4897/5198 [51:51<2:26:32, 29.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.01s/it][A100%|██████████| 1/1 [00:30<00:00, 30.01s/it]
 94%|█████████▍| 4897/5198 [51:45<2:26:33, 29.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.04s/it][A100%|██████████| 1/1 [00:30<00:00, 30.04s/it]
 94%|█████████▍| 4897/5198 [51:30<2:26:33, 29.22s/it]
100%|██████████| 1/1 [00:29<00:00, 30.00s/it][A100%|██████████| 1/1 [00:29<00:00, 30.00s/it]
 94%|█████████▍| 4897/5198 [51:35<2:26:31, 29.21s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4591

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.87s/it][A100%|██████████| 1/1 [00:30<00:00, 30.87s/it]
 94%|█████████▍| 4898/5198 [52:18<2:28:49, 29.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:50:04,043] [INFO] [logging.py:96:log_dist] [Rank 0] step=4897, skipped=0, lr=[5.318971553715434e-07], mom=[(0.9, 0.999)]
steps: 4897 loss: 1.4952 iter time (s): 30.337 samples/sec: 4.219

100%|██████████| 1/1 [00:31<00:00, 31.09s/it][A100%|██████████| 1/1 [00:31<00:00, 31.09s/it]
 94%|█████████▍| 4898/5198 [52:30<2:28:49, 29.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 31.00s/it][A100%|██████████| 1/1 [00:30<00:00, 31.00s/it]
 94%|█████████▍| 4898/5198 [52:28<2:28:43, 29.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.03s/it][A100%|██████████| 1/1 [00:31<00:00, 31.03s/it]
 94%|█████████▍| 4898/5198 [52:20<2:28:46, 29.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.00s/it][A100%|██████████| 1/1 [00:31<00:00, 31.00s/it]
 94%|█████████▍| 4898/5198 [52:22<2:28:45, 29.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.02s/it][A100%|██████████| 1/1 [00:31<00:00, 31.02s/it]
 94%|█████████▍| 4898/5198 [52:16<2:28:47, 29.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.02s/it][A100%|██████████| 1/1 [00:31<00:00, 31.02s/it]
 94%|█████████▍| 4898/5198 [52:02<2:28:47, 29.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.03s/it][A100%|██████████| 1/1 [00:31<00:00, 31.03s/it]
 94%|█████████▍| 4898/5198 [52:06<2:28:46, 29.76s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4592
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.02s/it][A100%|██████████| 1/1 [00:30<00:00, 30.02s/it]
 94%|█████████▍| 4899/5198 [52:48<2:28:56, 29.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:50:34,185] [INFO] [logging.py:96:log_dist] [Rank 0] step=4898, skipped=0, lr=[5.306279689057289e-07], mom=[(0.9, 0.999)]
steps: 4898 loss: 1.4415 iter time (s): 29.444 samples/sec: 4.347

100%|██████████| 1/1 [00:30<00:00, 30.12s/it][A100%|██████████| 1/1 [00:30<00:00, 30.12s/it]
 94%|█████████▍| 4899/5198 [53:00<2:28:52, 29.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.17s/it][A100%|██████████| 1/1 [00:30<00:00, 30.17s/it]
 94%|█████████▍| 4899/5198 [52:58<2:28:51, 29.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.19s/it][A100%|██████████| 1/1 [00:30<00:00, 30.19s/it]
 94%|█████████▍| 4899/5198 [52:50<2:28:56, 29.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.17s/it][A100%|██████████| 1/1 [00:30<00:00, 30.17s/it]
 94%|█████████▍| 4899/5198 [52:53<2:28:54, 29.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.21s/it][A100%|██████████| 1/1 [00:30<00:00, 30.21s/it]
 94%|█████████▍| 4899/5198 [52:46<2:28:58, 29.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.21s/it][A100%|██████████| 1/1 [00:30<00:00, 30.21s/it]
 94%|█████████▍| 4899/5198 [52:32<2:28:58, 29.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.20s/it][A100%|██████████| 1/1 [00:30<00:00, 30.20s/it]
 94%|█████████▍| 4899/5198 [52:36<2:28:57, 29.89s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4593
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.55s/it][A100%|██████████| 1/1 [00:32<00:00, 32.55s/it]
 94%|█████████▍| 4900/5198 [53:21<2:32:37, 30.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:51:06,951] [INFO] [logging.py:96:log_dist] [Rank 0] step=4899, skipped=0, lr=[5.293602164858167e-07], mom=[(0.9, 0.999)]
steps: 4899 loss: 1.5474 iter time (s): 32.003 samples/sec: 4.000

100%|██████████| 1/1 [00:32<00:00, 32.81s/it][A100%|██████████| 1/1 [00:32<00:00, 32.81s/it]
 94%|█████████▍| 4900/5198 [53:33<2:32:46, 30.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.83s/it][A100%|██████████| 1/1 [00:32<00:00, 32.83s/it]
 94%|█████████▍| 4900/5198 [53:31<2:32:47, 30.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.84s/it][A100%|██████████| 1/1 [00:32<00:00, 32.84s/it]
 94%|█████████▍| 4900/5198 [53:23<2:32:50, 30.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.77s/it][A100%|██████████| 1/1 [00:32<00:00, 32.77s/it]
 94%|█████████▍| 4900/5198 [53:19<2:32:46, 30.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.87s/it][A100%|██████████| 1/1 [00:32<00:00, 32.87s/it]
 94%|█████████▍| 4900/5198 [53:25<2:32:53, 30.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.78s/it][A100%|██████████| 1/1 [00:32<00:00, 32.78s/it]
 94%|█████████▍| 4900/5198 [53:04<2:32:46, 30.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.79s/it][A100%|██████████| 1/1 [00:32<00:00, 32.79s/it]
 94%|█████████▍| 4900/5198 [53:09<2:32:47, 30.76s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4594
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.21s/it][A100%|██████████| 1/1 [00:32<00:00, 32.21s/it]
 94%|█████████▍| 4901/5198 [53:53<2:34:33, 31.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:51:39,366] [INFO] [logging.py:96:log_dist] [Rank 0] step=4900, skipped=0, lr=[5.28093898518534e-07], mom=[(0.9, 0.999)]
steps: 4900 loss: 1.5100 iter time (s): 31.616 samples/sec: 4.049

100%|██████████| 1/1 [00:32<00:00, 32.38s/it][A100%|██████████| 1/1 [00:32<00:00, 32.38s/it]
 94%|█████████▍| 4901/5198 [54:05<2:34:40, 31.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.33s/it][A100%|██████████| 1/1 [00:32<00:00, 32.33s/it]
 94%|█████████▍| 4901/5198 [54:03<2:34:37, 31.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.32s/it][A100%|██████████| 1/1 [00:32<00:00, 32.32s/it]
 94%|█████████▍| 4901/5198 [53:55<2:34:38, 31.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.30s/it][A100%|██████████| 1/1 [00:32<00:00, 32.30s/it]
 94%|█████████▍| 4901/5198 [53:58<2:34:38, 31.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.34s/it][A100%|██████████| 1/1 [00:32<00:00, 32.34s/it]
 94%|█████████▍| 4901/5198 [53:51<2:34:36, 31.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.34s/it][A100%|██████████| 1/1 [00:32<00:00, 32.35s/it]
 94%|█████████▍| 4901/5198 [53:37<2:34:37, 31.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.34s/it][A100%|██████████| 1/1 [00:32<00:00, 32.34s/it]
 94%|█████████▍| 4901/5198 [53:42<2:34:37, 31.24s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4595
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.69s/it][A100%|██████████| 1/1 [00:29<00:00, 29.69s/it]
 94%|█████████▍| 4902/5198 [54:23<2:32:02, 30.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:52:09,100] [INFO] [logging.py:96:log_dist] [Rank 0] step=4901, skipped=0, lr=[5.26829015410148e-07], mom=[(0.9, 0.999)]
steps: 4901 loss: 1.5334 iter time (s): 29.008 samples/sec: 4.413

100%|██████████| 1/1 [00:29<00:00, 29.68s/it][A100%|██████████| 1/1 [00:29<00:00, 29.68s/it]
 94%|█████████▍| 4902/5198 [54:35<2:31:51, 30.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.64s/it][A100%|██████████| 1/1 [00:29<00:00, 29.64s/it]
 94%|█████████▍| 4902/5198 [54:25<2:31:46, 30.76s/it]
100%|██████████| 1/1 [00:29<00:00, 29.79s/it][A100%|██████████| 1/1 [00:29<00:00, 29.80s/it]
 94%|█████████▍| 4902/5198 [54:33<2:31:58, 30.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.65s/it][A100%|██████████| 1/1 [00:29<00:00, 29.65s/it]
 94%|█████████▍| 4902/5198 [54:27<2:31:46, 30.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.67s/it][A100%|██████████| 1/1 [00:29<00:00, 29.67s/it]
 94%|█████████▍| 4902/5198 [54:21<2:31:47, 30.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.66s/it][A100%|██████████| 1/1 [00:29<00:00, 29.66s/it]
 94%|█████████▍| 4902/5198 [54:07<2:31:46, 30.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.65s/it][A100%|██████████| 1/1 [00:29<00:00, 29.65s/it]
 94%|█████████▍| 4902/5198 [54:11<2:31:46, 30.76s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4596
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.70s/it][A100%|██████████| 1/1 [00:29<00:00, 29.70s/it]
 94%|█████████▍| 4903/5198 [54:53<2:30:06, 30.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:52:38,987] [INFO] [logging.py:96:log_dist] [Rank 0] step=4902, skipped=0, lr=[5.255655675664618e-07], mom=[(0.9, 0.999)]
steps: 4902 loss: 1.5222 iter time (s): 29.235 samples/sec: 4.378

100%|██████████| 1/1 [00:29<00:00, 29.98s/it][A100%|██████████| 1/1 [00:29<00:00, 29.98s/it]
 94%|█████████▍| 4903/5198 [55:05<2:30:09, 30.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.80s/it][A100%|██████████| 1/1 [00:29<00:00, 29.80s/it]
 94%|█████████▍| 4903/5198 [55:03<2:29:59, 30.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.91s/it][A100%|██████████| 1/1 [00:29<00:00, 29.91s/it]
 94%|█████████▍| 4903/5198 [54:55<2:30:00, 30.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.96s/it][A100%|██████████| 1/1 [00:29<00:00, 29.96s/it]
 94%|█████████▍| 4903/5198 [54:57<2:30:05, 30.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.95s/it][A100%|██████████| 1/1 [00:29<00:00, 29.95s/it]
 94%|█████████▍| 4903/5198 [54:41<2:30:03, 30.52s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4597

100%|██████████| 1/1 [00:29<00:00, 29.99s/it][A100%|██████████| 1/1 [00:29<00:00, 29.99s/it]
 94%|█████████▍| 4903/5198 [54:51<2:30:08, 30.54s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.97s/it][A100%|██████████| 1/1 [00:29<00:00, 29.97s/it]
 94%|█████████▍| 4903/5198 [54:36<2:30:05, 30.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.21s/it][A100%|██████████| 1/1 [00:30<00:00, 30.21s/it]
 94%|█████████▍| 4904/5198 [55:24<2:29:22, 30.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:53:09,400] [INFO] [logging.py:96:log_dist] [Rank 0] step=4903, skipped=0, lr=[5.243035553928226e-07], mom=[(0.9, 0.999)]
steps: 4903 loss: 1.4684 iter time (s): 29.695 samples/sec: 4.310

100%|██████████| 1/1 [00:30<00:00, 30.29s/it][A100%|██████████| 1/1 [00:30<00:00, 30.29s/it]
 94%|█████████▍| 4904/5198 [55:35<2:29:18, 30.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.43s/it][A100%|██████████| 1/1 [00:30<00:00, 30.43s/it]
 94%|█████████▍| 4904/5198 [55:33<2:29:22, 30.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.46s/it][A100%|██████████| 1/1 [00:30<00:00, 30.46s/it]
 94%|█████████▍| 4904/5198 [55:25<2:29:25, 30.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][A100%|██████████| 1/1 [00:30<00:00, 30.33s/it][A100%|██████████| 1/1 [00:30<00:00, 30.33s/it]
 94%|█████████▍| 4904/5198 [55:28<2:29:18, 30.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.33s/it][A100%|██████████| 1/1 [00:30<00:00, 30.33s/it]
 94%|█████████▍| 4904/5198 [55:21<2:29:19, 30.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.37s/it][A100%|██████████| 1/1 [00:30<00:00, 30.37s/it]
 94%|█████████▍| 4904/5198 [55:07<2:29:22, 30.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.40s/it][A100%|██████████| 1/1 [00:30<00:00, 30.40s/it]
 94%|█████████▍| 4904/5198 [55:12<2:29:22, 30.49s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4598
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.47s/it][A100%|██████████| 1/1 [00:30<00:00, 30.47s/it]
 94%|█████████▍| 4905/5198 [55:54<2:29:05, 30.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:53:40,015] [INFO] [logging.py:96:log_dist] [Rank 0] step=4904, skipped=0, lr=[5.230429792941148e-07], mom=[(0.9, 0.999)]
steps: 4904 loss: 1.4219 iter time (s): 29.908 samples/sec: 4.280

100%|██████████| 1/1 [00:30<00:00, 30.73s/it][A100%|██████████| 1/1 [00:30<00:00, 30.73s/it]
 94%|█████████▍| 4905/5198 [56:06<2:29:11, 30.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.62s/it][A100%|██████████| 1/1 [00:30<00:00, 30.62s/it]
 94%|█████████▍| 4905/5198 [56:04<2:29:04, 30.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.59s/it][A100%|██████████| 1/1 [00:30<00:00, 30.60s/it]
 94%|█████████▍| 4905/5198 [55:56<2:29:05, 30.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.66s/it][A100%|██████████| 1/1 [00:30<00:00, 30.66s/it]
 94%|█████████▍| 4905/5198 [55:58<2:29:05, 30.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.69s/it][A100%|██████████| 1/1 [00:30<00:00, 30.70s/it]
 94%|█████████▍| 4905/5198 [55:52<2:29:09, 30.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.69s/it][A100%|██████████| 1/1 [00:30<00:00, 30.69s/it]
 94%|█████████▍| 4905/5198 [55:38<2:29:09, 30.55s/it]
100%|██████████| 1/1 [00:30<00:00, 30.68s/it][A100%|██████████| 1/1 [00:30<00:00, 30.68s/it]
 94%|█████████▍| 4905/5198 [55:42<2:29:09, 30.54s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4599

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.37s/it][A100%|██████████| 1/1 [00:33<00:00, 33.37s/it]
 94%|█████████▍| 4906/5198 [56:28<2:33:00, 31.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:54:13,698] [INFO] [logging.py:96:log_dist] [Rank 0] step=4905, skipped=0, lr=[5.217838396747628e-07], mom=[(0.9, 0.999)]
steps: 4905 loss: 1.4608 iter time (s): 32.909 samples/sec: 3.890

100%|██████████| 1/1 [00:33<00:00, 33.62s/it][A100%|██████████| 1/1 [00:33<00:00, 33.62s/it]
 94%|█████████▍| 4906/5198 [56:40<2:33:10, 31.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.71s/it][A100%|██████████| 1/1 [00:33<00:00, 33.71s/it]
 94%|█████████▍| 4906/5198 [56:38<2:33:13, 31.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.69s/it][A100%|██████████| 1/1 [00:33<00:00, 33.69s/it]
 94%|█████████▍| 4906/5198 [56:29<2:33:11, 31.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.67s/it][A100%|██████████| 1/1 [00:33<00:00, 33.67s/it]
 94%|█████████▍| 4906/5198 [56:32<2:33:10, 31.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.65s/it][A100%|██████████| 1/1 [00:33<00:00, 33.66s/it]
 94%|█████████▍| 4906/5198 [56:26<2:33:11, 31.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.65s/it][A100%|██████████| 1/1 [00:33<00:00, 33.65s/it]
 94%|█████████▍| 4906/5198 [56:11<2:33:11, 31.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.67s/it][A100%|██████████| 1/1 [00:33<00:00, 33.67s/it]
 94%|█████████▍| 4906/5198 [56:16<2:33:12, 31.48s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4600
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.50s/it][A100%|██████████| 1/1 [00:33<00:00, 33.50s/it]
 94%|█████████▍| 4907/5198 [57:01<2:35:40, 32.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:54:47,325] [INFO] [logging.py:96:log_dist] [Rank 0] step=4906, skipped=0, lr=[5.205261369387301e-07], mom=[(0.9, 0.999)]
steps: 4906 loss: 1.4104 iter time (s): 32.864 samples/sec: 3.895

100%|██████████| 1/1 [00:33<00:00, 33.66s/it][A100%|██████████| 1/1 [00:33<00:00, 33.66s/it]
 94%|█████████▍| 4907/5198 [57:13<2:35:49, 32.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.53s/it][A100%|██████████| 1/1 [00:33<00:00, 33.53s/it]
 94%|█████████▍| 4907/5198 [57:11<2:35:41, 32.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.64s/it][A100%|██████████| 1/1 [00:33<00:00, 33.64s/it]
 94%|█████████▍| 4907/5198 [57:03<2:35:49, 32.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.64s/it][A100%|██████████| 1/1 [00:33<00:00, 33.64s/it]
 94%|█████████▍| 4907/5198 [57:06<2:35:49, 32.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][A100%|██████████| 1/1 [00:33<00:00, 33.57s/it][A100%|██████████| 1/1 [00:33<00:00, 33.57s/it]
 94%|█████████▍| 4907/5198 [56:59<2:35:43, 32.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.58s/it][A100%|██████████| 1/1 [00:33<00:00, 33.58s/it]
 94%|█████████▍| 4907/5198 [56:50<2:35:45, 32.11s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4601
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.61s/it][A100%|██████████| 1/1 [00:33<00:00, 33.61s/it]
 94%|█████████▍| 4907/5198 [56:45<2:35:47, 32.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.65s/it][A100%|██████████| 1/1 [00:36<00:00, 36.65s/it]
 94%|█████████▍| 4908/5198 [57:38<2:42:03, 33.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:55:24,300] [INFO] [logging.py:96:log_dist] [Rank 0] step=4907, skipped=0, lr=[5.192698714895183e-07], mom=[(0.9, 0.999)]
steps: 4907 loss: 1.4596 iter time (s): 36.250 samples/sec: 3.531

100%|██████████| 1/1 [00:36<00:00, 36.97s/it][A100%|██████████| 1/1 [00:36<00:00, 36.97s/it]
 94%|█████████▍| 4908/5198 [57:50<2:42:19, 33.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.03s/it][A100%|██████████| 1/1 [00:37<00:00, 37.03s/it]
 94%|█████████▍| 4908/5198 [57:48<2:42:19, 33.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.95s/it][A100%|██████████| 1/1 [00:36<00:00, 36.95s/it]
 94%|█████████▍| 4908/5198 [57:43<2:42:17, 33.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.04s/it][A100%|██████████| 1/1 [00:37<00:00, 37.04s/it]
 94%|█████████▍| 4908/5198 [57:40<2:42:25, 33.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.05s/it][A100%|██████████| 1/1 [00:37<00:00, 37.05s/it]
 94%|█████████▍| 4908/5198 [57:22<2:42:24, 33.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.14s/it][A100%|██████████| 1/1 [00:37<00:00, 37.14s/it]
 94%|█████████▍| 4908/5198 [57:37<2:42:30, 33.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.09s/it][A100%|██████████| 1/1 [00:37<00:00, 37.09s/it]
 94%|█████████▍| 4908/5198 [57:27<2:42:26, 33.61s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4602
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.08s/it][A100%|██████████| 1/1 [00:29<00:00, 29.08s/it]
 94%|█████████▍| 4909/5198 [58:08<2:35:19, 32.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:55:53,269] [INFO] [logging.py:96:log_dist] [Rank 0] step=4908, skipped=0, lr=[5.180150437301691e-07], mom=[(0.9, 0.999)]
steps: 4908 loss: 1.5136 iter time (s): 28.123 samples/sec: 4.551

100%|██████████| 1/1 [00:28<00:00, 28.88s/it][A100%|██████████| 1/1 [00:28<00:00, 28.88s/it]
 94%|█████████▍| 4909/5198 [58:19<2:35:00, 32.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.88s/it][A100%|██████████| 1/1 [00:28<00:00, 28.88s/it]
 94%|█████████▍| 4909/5198 [58:17<2:34:58, 32.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.80s/it][A100%|██████████| 1/1 [00:28<00:00, 28.80s/it]
 94%|█████████▍| 4909/5198 [58:09<2:34:55, 32.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.85s/it][A100%|██████████| 1/1 [00:28<00:00, 28.85s/it]
 94%|█████████▍| 4909/5198 [58:12<2:34:55, 32.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.75s/it][A100%|██████████| 1/1 [00:28<00:00, 28.75s/it]
 94%|█████████▍| 4909/5198 [58:05<2:34:54, 32.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.80s/it][A100%|██████████| 1/1 [00:28<00:00, 28.80s/it]
 94%|█████████▍| 4909/5198 [57:51<2:34:55, 32.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.78s/it][A100%|██████████| 1/1 [00:28<00:00, 28.78s/it]
 94%|█████████▍| 4909/5198 [57:55<2:34:54, 32.16s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4603
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.45s/it][A100%|██████████| 1/1 [00:30<00:00, 30.45s/it]
 94%|█████████▍| 4910/5198 [58:38<2:32:29, 31.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:56:24,014] [INFO] [logging.py:96:log_dist] [Rank 0] step=4909, skipped=0, lr=[5.167616540632619e-07], mom=[(0.9, 0.999)]
steps: 4909 loss: 1.3831 iter time (s): 30.086 samples/sec: 4.254

100%|██████████| 1/1 [00:30<00:00, 30.72s/it][A100%|██████████| 1/1 [00:30<00:00, 30.72s/it]
 94%|█████████▍| 4910/5198 [58:50<2:32:22, 31.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.77s/it][A100%|██████████| 1/1 [00:30<00:00, 30.77s/it]
 94%|█████████▍| 4910/5198 [58:48<2:32:26, 31.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.77s/it][A100%|██████████| 1/1 [00:30<00:00, 30.77s/it]
 94%|█████████▍| 4910/5198 [58:40<2:32:24, 31.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.82s/it][A100%|██████████| 1/1 [00:30<00:00, 30.82s/it]
 94%|█████████▍| 4910/5198 [58:42<2:32:28, 31.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.80s/it][A100%|██████████| 1/1 [00:30<00:00, 30.80s/it]
 94%|█████████▍| 4910/5198 [58:36<2:32:25, 31.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.82s/it][A100%|██████████| 1/1 [00:30<00:00, 30.82s/it]
 94%|█████████▍| 4910/5198 [58:22<2:32:27, 31.76s/it]
100%|██████████| 1/1 [00:30<00:00, 30.81s/it][A100%|██████████| 1/1 [00:30<00:00, 30.82s/it]
 94%|█████████▍| 4910/5198 [58:26<2:32:26, 31.76s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4604
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.47s/it][A100%|██████████| 1/1 [00:30<00:00, 30.47s/it]
 94%|█████████▍| 4911/5198 [59:09<2:30:20, 31.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:56:54,571] [INFO] [logging.py:96:log_dist] [Rank 0] step=4910, skipped=0, lr=[5.155097028909155e-07], mom=[(0.9, 0.999)]
steps: 4910 loss: 1.4602 iter time (s): 29.821 samples/sec: 4.292

100%|██████████| 1/1 [00:30<00:00, 30.62s/it][A100%|██████████| 1/1 [00:30<00:00, 30.62s/it]
 94%|█████████▍| 4911/5198 [59:20<2:30:14, 31.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.60s/it][A100%|██████████| 1/1 [00:30<00:00, 30.60s/it]
 94%|█████████▍| 4911/5198 [59:19<2:30:15, 31.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.55s/it][A100%|██████████| 1/1 [00:30<00:00, 30.55s/it]
 94%|█████████▍| 4911/5198 [59:10<2:30:09, 31.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.50s/it][A100%|██████████| 1/1 [00:30<00:00, 30.50s/it]
 94%|█████████▍| 4911/5198 [59:13<2:30:08, 31.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.52s/it][A100%|██████████| 1/1 [00:30<00:00, 30.52s/it]
 94%|█████████▍| 4911/5198 [59:07<2:30:07, 31.39s/it]
100%|██████████| 1/1 [00:30<00:00, 30.47s/it][A100%|██████████| 1/1 [00:30<00:00, 30.47s/it]
 94%|█████████▍| 4911/5198 [58:52<2:30:04, 31.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.50s/it][A100%|██████████| 1/1 [00:30<00:00, 30.50s/it]
 94%|█████████▍| 4911/5198 [58:57<2:30:06, 31.38s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_306
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.37s/it][A100%|██████████| 1/1 [00:24<00:00, 24.37s/it]
 94%|█████████▍| 4912/5198 [59:33<2:19:55, 29.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:57:19,267] [INFO] [logging.py:96:log_dist] [Rank 0] step=4911, skipped=0, lr=[5.142591906147871e-07], mom=[(0.9, 0.999)]
steps: 4911 loss: 1.8293 iter time (s): 24.045 samples/sec: 5.323

100%|██████████| 1/1 [00:24<00:00, 24.71s/it][A100%|██████████| 1/1 [00:24<00:00, 24.71s/it]
 94%|█████████▍| 4912/5198 [59:45<2:20:09, 29.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.67s/it][A100%|██████████| 1/1 [00:24<00:00, 24.67s/it]
 94%|█████████▍| 4912/5198 [59:43<2:20:06, 29.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.71s/it][A100%|██████████| 1/1 [00:24<00:00, 24.71s/it]
 94%|█████████▍| 4912/5198 [59:35<2:20:05, 29.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.78s/it][A100%|██████████| 1/1 [00:24<00:00, 24.78s/it]
 94%|█████████▍| 4912/5198 [59:38<2:20:11, 29.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.80s/it][A100%|██████████| 1/1 [00:24<00:00, 24.80s/it]
 94%|█████████▍| 4912/5198 [59:31<2:20:11, 29.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.83s/it][A100%|██████████| 1/1 [00:24<00:00, 24.83s/it]
 94%|█████████▍| 4912/5198 [59:17<2:20:12, 29.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.81s/it][A100%|██████████| 1/1 [00:24<00:00, 24.81s/it]
 94%|█████████▍| 4912/5198 [59:22<2:20:11, 29.41s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4605
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.52s/it][A100%|██████████| 1/1 [00:29<00:00, 29.52s/it]
 95%|█████████▍| 4913/5198 [1:00:03<2:19:53, 29.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:57:48,793] [INFO] [logging.py:96:log_dist] [Rank 0] step=4912, skipped=0, lr=[5.130101176360723e-07], mom=[(0.9, 0.999)]
steps: 4912 loss: 1.4611 iter time (s): 28.731 samples/sec: 4.455

100%|██████████| 1/1 [00:29<00:00, 29.45s/it][A100%|██████████| 1/1 [00:29<00:00, 29.45s/it]
 95%|█████████▍| 4913/5198 [1:00:15<2:19:44, 29.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.40s/it][A100%|██████████| 1/1 [00:29<00:00, 29.40s/it]
 95%|█████████▍| 4913/5198 [1:00:13<2:19:38, 29.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.49s/it][A100%|██████████| 1/1 [00:29<00:00, 29.49s/it]
 95%|█████████▍| 4913/5198 [1:00:05<2:19:44, 29.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.39s/it][A100%|██████████| 1/1 [00:29<00:00, 29.39s/it]
 95%|█████████▍| 4913/5198 [1:00:07<2:19:40, 29.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.37s/it][A100%|██████████| 1/1 [00:29<00:00, 29.37s/it]
 95%|█████████▍| 4913/5198 [1:00:01<2:19:39, 29.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.36s/it][A100%|██████████| 1/1 [00:29<00:00, 29.36s/it]
 95%|█████████▍| 4913/5198 [59:46<2:19:38, 29.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.37s/it][A100%|██████████| 1/1 [00:29<00:00, 29.37s/it]
 95%|█████████▍| 4913/5198 [59:51<2:19:39, 29.40s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4606
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.09s/it][A100%|██████████| 1/1 [00:30<00:00, 30.09s/it]
 95%|█████████▍| 4914/5198 [1:00:33<2:20:31, 29.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:58:19,055] [INFO] [logging.py:96:log_dist] [Rank 0] step=4913, skipped=0, lr=[5.117624843555037e-07], mom=[(0.9, 0.999)]
steps: 4913 loss: 1.4126 iter time (s): 29.610 samples/sec: 4.323

100%|██████████| 1/1 [00:30<00:00, 30.21s/it][A100%|██████████| 1/1 [00:30<00:00, 30.21s/it]
 95%|█████████▍| 4914/5198 [1:00:45<2:20:23, 29.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.36s/it][A100%|██████████| 1/1 [00:30<00:00, 30.37s/it]
 95%|█████████▍| 4914/5198 [1:00:43<2:20:32, 29.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.34s/it][A100%|██████████| 1/1 [00:30<00:00, 30.34s/it]
 95%|█████████▍| 4914/5198 [1:00:35<2:20:34, 29.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.35s/it][A100%|██████████| 1/1 [00:30<00:00, 30.35s/it]
 95%|█████████▍| 4914/5198 [1:00:37<2:20:31, 29.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.32s/it][A100%|██████████| 1/1 [00:30<00:00, 30.32s/it]
 95%|█████████▍| 4914/5198 [1:00:31<2:20:28, 29.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.36s/it][A100%|██████████| 1/1 [00:30<00:00, 30.36s/it]
 95%|█████████▍| 4914/5198 [1:00:17<2:20:32, 29.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.36s/it][A100%|██████████| 1/1 [00:30<00:00, 30.36s/it]
 95%|█████████▍| 4914/5198 [1:00:21<2:20:31, 29.69s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4607
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.47s/it][A100%|██████████| 1/1 [00:29<00:00, 29.47s/it]
 95%|█████████▍| 4915/5198 [1:01:03<2:19:53, 29.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:58:48,637] [INFO] [logging.py:96:log_dist] [Rank 0] step=4914, skipped=0, lr=[5.105162911733536e-07], mom=[(0.9, 0.999)]
steps: 4914 loss: 1.5445 iter time (s): 28.829 samples/sec: 4.440

100%|██████████| 1/1 [00:29<00:00, 29.61s/it][A100%|██████████| 1/1 [00:29<00:00, 29.61s/it]
 95%|█████████▍| 4915/5198 [1:01:14<2:19:50, 29.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.56s/it][A100%|██████████| 1/1 [00:29<00:00, 29.56s/it]
 95%|█████████▍| 4915/5198 [1:01:13<2:19:52, 29.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.51s/it][A100%|██████████| 1/1 [00:29<00:00, 29.51s/it]
 95%|█████████▍| 4915/5198 [1:01:07<2:19:47, 29.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.56s/it][A100%|██████████| 1/1 [00:29<00:00, 29.56s/it]
 95%|█████████▍| 4915/5198 [1:01:04<2:19:53, 29.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.59s/it][A100%|██████████| 1/1 [00:29<00:00, 29.59s/it]
 95%|█████████▍| 4915/5198 [1:01:01<2:19:52, 29.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.54s/it][A100%|██████████| 1/1 [00:29<00:00, 29.54s/it]
 95%|█████████▍| 4915/5198 [1:00:46<2:19:50, 29.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.53s/it][A100%|██████████| 1/1 [00:29<00:00, 29.53s/it]
 95%|█████████▍| 4915/5198 [1:00:51<2:19:49, 29.64s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4608
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.79s/it][A100%|██████████| 1/1 [00:30<00:00, 30.79s/it]
 95%|█████████▍| 4916/5198 [1:01:34<2:21:09, 30.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:59:19,589] [INFO] [logging.py:96:log_dist] [Rank 0] step=4915, skipped=0, lr=[5.092715384894319e-07], mom=[(0.9, 0.999)]
steps: 4915 loss: 1.3703 iter time (s): 30.242 samples/sec: 4.232

100%|██████████| 1/1 [00:30<00:00, 30.98s/it][A100%|██████████| 1/1 [00:30<00:00, 30.98s/it]
 95%|█████████▍| 4916/5198 [1:01:45<2:21:14, 30.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.88s/it][A100%|██████████| 1/1 [00:30<00:00, 30.88s/it]
 95%|█████████▍| 4916/5198 [1:01:43<2:21:07, 30.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.90s/it][A100%|██████████| 1/1 [00:30<00:00, 30.90s/it]
 95%|█████████▍| 4916/5198 [1:01:35<2:21:10, 30.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.02s/it][A100%|██████████| 1/1 [00:31<00:00, 31.02s/it]
 95%|█████████▍| 4916/5198 [1:01:38<2:21:15, 30.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.02s/it][A100%|██████████| 1/1 [00:31<00:00, 31.02s/it]
 95%|█████████▍| 4916/5198 [1:01:32<2:21:18, 30.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.02s/it][A100%|██████████| 1/1 [00:31<00:00, 31.02s/it]
 95%|█████████▍| 4916/5198 [1:01:17<2:21:17, 30.06s/it]
100%|██████████| 1/1 [00:31<00:00, 31.02s/it][A100%|██████████| 1/1 [00:31<00:00, 31.02s/it]
 95%|█████████▍| 4916/5198 [1:01:22<2:21:16, 30.06s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4609

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.70s/it][A100%|██████████| 1/1 [00:28<00:00, 28.70s/it]
 95%|█████████▍| 4917/5198 [1:02:03<2:18:56, 29.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-01 23:59:48,326] [INFO] [logging.py:96:log_dist] [Rank 0] step=4916, skipped=0, lr=[5.080282267030853e-07], mom=[(0.9, 0.999)]
steps: 4916 loss: 1.4660 iter time (s): 27.955 samples/sec: 4.579

100%|██████████| 1/1 [00:28<00:00, 28.68s/it][A100%|██████████| 1/1 [00:28<00:00, 28.68s/it]
 95%|█████████▍| 4917/5198 [1:02:14<2:18:49, 29.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.78s/it][A100%|██████████| 1/1 [00:28<00:00, 28.78s/it]
 95%|█████████▍| 4917/5198 [1:02:12<2:18:52, 29.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.65s/it][A100%|██████████| 1/1 [00:28<00:00, 28.65s/it]
 95%|█████████▍| 4917/5198 [1:02:04<2:18:43, 29.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.66s/it][A100%|██████████| 1/1 [00:28<00:00, 28.66s/it]
 95%|█████████▍| 4917/5198 [1:02:07<2:18:48, 29.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.59s/it][A100%|██████████| 1/1 [00:28<00:00, 28.59s/it]
 95%|█████████▍| 4917/5198 [1:02:00<2:18:44, 29.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.63s/it][A100%|██████████| 1/1 [00:28<00:00, 28.63s/it]
 95%|█████████▍| 4917/5198 [1:01:46<2:18:46, 29.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.63s/it][A100%|██████████| 1/1 [00:28<00:00, 28.63s/it]
 95%|█████████▍| 4917/5198 [1:01:51<2:18:46, 29.63s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4610
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.34s/it][A100%|██████████| 1/1 [00:30<00:00, 30.34s/it]
 95%|█████████▍| 4918/5198 [1:02:33<2:19:36, 29.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:00:18,875] [INFO] [logging.py:96:log_dist] [Rank 0] step=4917, skipped=0, lr=[5.067863562132015e-07], mom=[(0.9, 0.999)]
steps: 4917 loss: 1.4611 iter time (s): 29.865 samples/sec: 4.286

100%|██████████| 1/1 [00:30<00:00, 30.62s/it][A100%|██████████| 1/1 [00:30<00:00, 30.62s/it]
 95%|█████████▍| 4918/5198 [1:02:45<2:19:43, 29.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.57s/it][A100%|██████████| 1/1 [00:30<00:00, 30.57s/it]
 95%|█████████▍| 4918/5198 [1:02:43<2:19:40, 29.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.58s/it][A100%|██████████| 1/1 [00:30<00:00, 30.58s/it]
 95%|█████████▍| 4918/5198 [1:02:35<2:19:35, 29.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.63s/it][A100%|██████████| 1/1 [00:30<00:00, 30.63s/it]
 95%|█████████▍| 4918/5198 [1:02:37<2:19:42, 29.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.58s/it][A100%|██████████| 1/1 [00:30<00:00, 30.58s/it]
 95%|█████████▍| 4918/5198 [1:02:16<2:19:37, 29.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.65s/it][A100%|██████████| 1/1 [00:30<00:00, 30.65s/it]
 95%|█████████▍| 4918/5198 [1:02:31<2:19:41, 29.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.62s/it][A100%|██████████| 1/1 [00:30<00:00, 30.62s/it]
 95%|█████████▍| 4918/5198 [1:02:21<2:19:40, 29.93s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4611
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.47s/it][A100%|██████████| 1/1 [00:33<00:00, 33.47s/it]
 95%|█████████▍| 4919/5198 [1:03:07<2:24:19, 31.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:00:52,625] [INFO] [logging.py:96:log_dist] [Rank 0] step=4918, skipped=0, lr=[5.055459274182003e-07], mom=[(0.9, 0.999)]
steps: 4918 loss: 1.4453 iter time (s): 32.992 samples/sec: 3.880

100%|██████████| 1/1 [00:33<00:00, 33.78s/it][A100%|██████████| 1/1 [00:33<00:00, 33.78s/it]
 95%|█████████▍| 4919/5198 [1:03:19<2:24:35, 31.10s/it]
100%|██████████| 1/1 [00:33<00:00, 33.71s/it][A100%|██████████| 1/1 [00:33<00:00, 33.71s/it]
 95%|█████████▍| 4919/5198 [1:03:17<2:24:28, 31.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.88s/it][A100%|██████████| 1/1 [00:33<00:00, 33.88s/it]
 95%|█████████▍| 4919/5198 [1:03:08<2:24:38, 31.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.74s/it][A100%|██████████| 1/1 [00:33<00:00, 33.74s/it]
 95%|█████████▍| 4919/5198 [1:03:11<2:24:32, 31.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.76s/it][A100%|██████████| 1/1 [00:33<00:00, 33.76s/it]
 95%|█████████▍| 4919/5198 [1:03:05<2:24:32, 31.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.79s/it][A100%|██████████| 1/1 [00:33<00:00, 33.79s/it]
 95%|█████████▍| 4919/5198 [1:02:50<2:24:32, 31.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.77s/it][A100%|██████████| 1/1 [00:33<00:00, 33.77s/it]
 95%|█████████▍| 4919/5198 [1:02:55<2:24:32, 31.08s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4612
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.28s/it][A100%|██████████| 1/1 [00:30<00:00, 30.28s/it]
 95%|█████████▍| 4920/5198 [1:03:37<2:22:57, 30.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:01:22,935] [INFO] [logging.py:96:log_dist] [Rank 0] step=4919, skipped=0, lr=[5.043069407160435e-07], mom=[(0.9, 0.999)]
steps: 4919 loss: 1.4271 iter time (s): 29.525 samples/sec: 4.335

100%|██████████| 1/1 [00:30<00:00, 30.21s/it][A100%|██████████| 1/1 [00:30<00:00, 30.21s/it]
 95%|█████████▍| 4920/5198 [1:03:49<2:22:51, 30.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.28s/it][A100%|██████████| 1/1 [00:30<00:00, 30.28s/it]
 95%|█████████▍| 4920/5198 [1:03:47<2:22:52, 30.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.20s/it][A100%|██████████| 1/1 [00:30<00:00, 30.20s/it]
 95%|█████████▍| 4920/5198 [1:03:39<2:22:52, 30.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.26s/it][A100%|██████████| 1/1 [00:30<00:00, 30.26s/it]
 95%|█████████▍| 4920/5198 [1:03:41<2:22:54, 30.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.22s/it][A100%|██████████| 1/1 [00:30<00:00, 30.22s/it]
 95%|█████████▍| 4920/5198 [1:03:20<2:22:49, 30.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.26s/it][A100%|██████████| 1/1 [00:30<00:00, 30.26s/it]
 95%|█████████▍| 4920/5198 [1:03:35<2:22:53, 30.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.24s/it][A100%|██████████| 1/1 [00:30<00:00, 30.24s/it]
 95%|█████████▍| 4920/5198 [1:03:25<2:22:51, 30.83s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4613
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.10s/it][A100%|██████████| 1/1 [00:32<00:00, 32.10s/it]
 95%|█████████▍| 4921/5198 [1:04:09<2:24:21, 31.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:01:55,244] [INFO] [logging.py:96:log_dist] [Rank 0] step=4920, skipped=0, lr=[5.030693965042283e-07], mom=[(0.9, 0.999)]
steps: 4920 loss: 1.4856 iter time (s): 31.588 samples/sec: 4.052

100%|██████████| 1/1 [00:32<00:00, 32.23s/it][A100%|██████████| 1/1 [00:32<00:00, 32.23s/it]
 95%|█████████▍| 4921/5198 [1:04:21<2:24:18, 31.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.33s/it][A100%|██████████| 1/1 [00:32<00:00, 32.33s/it]
 95%|█████████▍| 4921/5198 [1:04:19<2:24:26, 31.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.28s/it][A100%|██████████| 1/1 [00:32<00:00, 32.28s/it]
 95%|█████████▍| 4921/5198 [1:04:11<2:24:22, 31.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.29s/it][A100%|██████████| 1/1 [00:32<00:00, 32.30s/it]
 95%|█████████▍| 4921/5198 [1:04:14<2:24:24, 31.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.31s/it][A100%|██████████| 1/1 [00:32<00:00, 32.31s/it]
 95%|█████████▍| 4921/5198 [1:04:07<2:24:24, 31.28s/it]
100%|██████████| 1/1 [00:32<00:00, 32.33s/it][A100%|██████████| 1/1 [00:32<00:00, 32.33s/it]
 95%|█████████▍| 4921/5198 [1:03:53<2:24:24, 31.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.32s/it][A100%|██████████| 1/1 [00:32<00:00, 32.32s/it]
 95%|█████████▍| 4921/5198 [1:03:57<2:24:24, 31.28s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4614
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.75s/it][A100%|██████████| 1/1 [00:31<00:00, 31.75s/it]
 95%|█████████▍| 4922/5198 [1:04:41<2:24:41, 31.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:02:27,118] [INFO] [logging.py:96:log_dist] [Rank 0] step=4921, skipped=0, lr=[5.018332951797902e-07], mom=[(0.9, 0.999)]
steps: 4921 loss: 1.3978 iter time (s): 31.135 samples/sec: 4.111

100%|██████████| 1/1 [00:31<00:00, 31.93s/it][A100%|██████████| 1/1 [00:31<00:00, 31.93s/it]
 95%|█████████▍| 4922/5198 [1:04:53<2:24:43, 31.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.92s/it][A100%|██████████| 1/1 [00:31<00:00, 31.93s/it]
 95%|█████████▍| 4922/5198 [1:04:51<2:24:48, 31.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.89s/it][A100%|██████████| 1/1 [00:31<00:00, 31.89s/it]
 95%|█████████▍| 4922/5198 [1:04:43<2:24:43, 31.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.89s/it][A100%|██████████| 1/1 [00:31<00:00, 31.89s/it]
 95%|█████████▍| 4922/5198 [1:04:46<2:24:45, 31.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.87s/it][A100%|██████████| 1/1 [00:31<00:00, 31.87s/it]
 95%|█████████▍| 4922/5198 [1:04:39<2:24:42, 31.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.91s/it][A100%|██████████| 1/1 [00:31<00:00, 31.91s/it]
 95%|█████████▍| 4922/5198 [1:04:25<2:24:46, 31.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.90s/it][A100%|██████████| 1/1 [00:31<00:00, 31.90s/it]
 95%|█████████▍| 4922/5198 [1:04:29<2:24:45, 31.47s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4615
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.33s/it][A100%|██████████| 1/1 [00:33<00:00, 33.33s/it]
 95%|█████████▍| 4923/5198 [1:05:15<2:26:56, 32.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:03:00,670] [INFO] [logging.py:96:log_dist] [Rank 0] step=4922, skipped=0, lr=[5.005986371393007e-07], mom=[(0.9, 0.999)]
steps: 4922 loss: 1.4652 iter time (s): 32.779 samples/sec: 3.905

100%|██████████| 1/1 [00:33<00:00, 33.51s/it][A100%|██████████| 1/1 [00:33<00:00, 33.51s/it]
 95%|█████████▍| 4923/5198 [1:05:26<2:27:02, 32.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.46s/it][A100%|██████████| 1/1 [00:33<00:00, 33.46s/it]
 95%|█████████▍| 4923/5198 [1:05:25<2:27:01, 32.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.55s/it][A100%|██████████| 1/1 [00:33<00:00, 33.55s/it]
 95%|█████████▍| 4923/5198 [1:05:16<2:27:04, 32.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.56s/it][A100%|██████████| 1/1 [00:33<00:00, 33.56s/it]
 95%|█████████▍| 4923/5198 [1:05:19<2:27:07, 32.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.54s/it][A100%|██████████| 1/1 [00:33<00:00, 33.54s/it]
 95%|█████████▍| 4923/5198 [1:05:13<2:27:03, 32.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.54s/it][A100%|██████████| 1/1 [00:33<00:00, 33.54s/it]
 95%|█████████▍| 4923/5198 [1:04:58<2:27:06, 32.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.54s/it][A100%|██████████| 1/1 [00:33<00:00, 33.54s/it]
 95%|█████████▍| 4923/5198 [1:05:03<2:27:05, 32.09s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4616
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.52s/it][A100%|██████████| 1/1 [00:30<00:00, 30.52s/it]
 95%|█████████▍| 4924/5198 [1:05:45<2:24:30, 31.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:03:31,206] [INFO] [logging.py:96:log_dist] [Rank 0] step=4923, skipped=0, lr=[4.993654227788704e-07], mom=[(0.9, 0.999)]
steps: 4923 loss: 1.5020 iter time (s): 29.768 samples/sec: 4.300

100%|██████████| 1/1 [00:30<00:00, 30.51s/it][A100%|██████████| 1/1 [00:30<00:00, 30.51s/it]
 95%|█████████▍| 4924/5198 [1:05:57<2:24:21, 31.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.56s/it][A100%|██████████| 1/1 [00:30<00:00, 30.56s/it]
 95%|█████████▍| 4924/5198 [1:05:55<2:24:25, 31.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.43s/it][A100%|██████████| 1/1 [00:30<00:00, 30.43s/it]
 95%|█████████▍| 4924/5198 [1:05:50<2:24:18, 31.60s/it]
100%|██████████| 1/1 [00:30<00:00, 30.54s/it][A100%|██████████| 1/1 [00:30<00:00, 30.54s/it]
 95%|█████████▍| 4924/5198 [1:05:47<2:24:25, 31.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.46s/it][A100%|██████████| 1/1 [00:30<00:00, 30.46s/it]
 95%|█████████▍| 4924/5198 [1:05:29<2:24:20, 31.61s/it]
100%|██████████| 1/1 [00:30<00:00, 30.51s/it][A100%|██████████| 1/1 [00:30<00:00, 30.51s/it]
 95%|█████████▍| 4924/5198 [1:05:43<2:24:23, 31.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.47s/it][A100%|██████████| 1/1 [00:30<00:00, 30.47s/it]
 95%|█████████▍| 4924/5198 [1:05:33<2:24:20, 31.61s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4617
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.95s/it][A100%|██████████| 1/1 [00:29<00:00, 29.95s/it]
 95%|█████████▍| 4925/5198 [1:06:15<2:21:51, 31.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:04:01,200] [INFO] [logging.py:96:log_dist] [Rank 0] step=4924, skipped=0, lr=[4.981336524941427e-07], mom=[(0.9, 0.999)]
steps: 4924 loss: 1.5703 iter time (s): 29.291 samples/sec: 4.370

100%|██████████| 1/1 [00:29<00:00, 29.97s/it][A100%|██████████| 1/1 [00:29<00:00, 29.97s/it]
 95%|█████████▍| 4925/5198 [1:06:27<2:21:37, 31.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.93s/it][A100%|██████████| 1/1 [00:29<00:00, 29.93s/it]
 95%|█████████▍| 4925/5198 [1:06:25<2:21:35, 31.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.88s/it][A100%|██████████| 1/1 [00:29<00:00, 29.88s/it]
 95%|█████████▍| 4925/5198 [1:06:17<2:21:32, 31.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.96s/it][A100%|██████████| 1/1 [00:29<00:00, 29.96s/it]
 95%|█████████▍| 4925/5198 [1:06:20<2:21:32, 31.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.92s/it][A100%|██████████| 1/1 [00:29<00:00, 29.92s/it]
 95%|█████████▍| 4925/5198 [1:06:13<2:21:32, 31.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.96s/it][A100%|██████████| 1/1 [00:29<00:00, 29.96s/it]
 95%|█████████▍| 4925/5198 [1:06:03<2:21:33, 31.11s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4618
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.98s/it][A100%|██████████| 1/1 [00:29<00:00, 29.98s/it]
 95%|█████████▍| 4925/5198 [1:05:59<2:21:36, 31.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.29s/it][A100%|██████████| 1/1 [00:30<00:00, 30.29s/it]
 95%|█████████▍| 4926/5198 [1:06:46<2:20:17, 30.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:04:31,715] [INFO] [logging.py:96:log_dist] [Rank 0] step=4925, skipped=0, lr=[4.969033266803007e-07], mom=[(0.9, 0.999)]
steps: 4925 loss: 1.4519 iter time (s): 29.841 samples/sec: 4.289

100%|██████████| 1/1 [00:30<00:00, 30.53s/it][A100%|██████████| 1/1 [00:30<00:00, 30.53s/it]
 95%|█████████▍| 4926/5198 [1:06:58<2:20:18, 30.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.56s/it][A100%|██████████| 1/1 [00:30<00:00, 30.56s/it]
 95%|█████████▍| 4926/5198 [1:06:56<2:20:19, 30.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.62s/it][A100%|██████████| 1/1 [00:30<00:00, 30.62s/it]
 95%|█████████▍| 4926/5198 [1:06:47<2:20:22, 30.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.64s/it][A100%|██████████| 1/1 [00:30<00:00, 30.64s/it]
 95%|█████████▍| 4926/5198 [1:06:50<2:20:23, 30.97s/it]
100%|██████████| 1/1 [00:30<00:00, 30.57s/it][A100%|██████████| 1/1 [00:30<00:00, 30.57s/it]
 95%|█████████▍| 4926/5198 [1:06:44<2:20:18, 30.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.56s/it][A100%|██████████| 1/1 [00:30<00:00, 30.56s/it]
 95%|█████████▍| 4926/5198 [1:06:29<2:20:19, 30.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.58s/it][A100%|██████████| 1/1 [00:30<00:00, 30.58s/it]
 95%|█████████▍| 4926/5198 [1:06:34<2:20:19, 30.95s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4619
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.04s/it][A100%|██████████| 1/1 [00:32<00:00, 32.04s/it]
 95%|█████████▍| 4927/5198 [1:07:18<2:21:26, 31.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:05:03,982] [INFO] [logging.py:96:log_dist] [Rank 0] step=4926, skipped=0, lr=[4.956744457320643e-07], mom=[(0.9, 0.999)]
steps: 4926 loss: 1.5209 iter time (s): 31.527 samples/sec: 4.060

100%|██████████| 1/1 [00:32<00:00, 32.24s/it][A100%|██████████| 1/1 [00:32<00:00, 32.24s/it]
 95%|█████████▍| 4927/5198 [1:07:30<2:21:32, 31.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.26s/it][A100%|██████████| 1/1 [00:32<00:00, 32.27s/it]
 95%|█████████▍| 4927/5198 [1:07:28<2:21:35, 31.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.16s/it][A100%|██████████| 1/1 [00:32<00:00, 32.16s/it]
 95%|█████████▍| 4927/5198 [1:07:20<2:21:29, 31.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.23s/it][A100%|██████████| 1/1 [00:32<00:00, 32.23s/it]
 95%|█████████▍| 4927/5198 [1:07:22<2:21:35, 31.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.30s/it][A100%|██████████| 1/1 [00:32<00:00, 32.30s/it]
 95%|█████████▍| 4927/5198 [1:07:16<2:21:37, 31.36s/it]
100%|██████████| 1/1 [00:32<00:00, 32.25s/it][A100%|██████████| 1/1 [00:32<00:00, 32.25s/it]
 95%|█████████▍| 4927/5198 [1:07:01<2:21:34, 31.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.27s/it][A100%|██████████| 1/1 [00:32<00:00, 32.27s/it]
 95%|█████████▍| 4927/5198 [1:07:06<2:21:35, 31.35s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_307
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:23<00:00, 23.66s/it][A100%|██████████| 1/1 [00:23<00:00, 23.66s/it]
[2024-09-02 00:05:27,715] [INFO] [logging.py:96:log_dist] [Rank 0] step=4927, skipped=0, lr=[4.944470100436881e-07], mom=[(0.9, 0.999)]
steps: 4927 loss: 2.1123 iter time (s): 23.018 samples/sec: 5.561

100%|██████████| 1/1 [00:23<00:00, 23.90s/it][A100%|██████████| 1/1 [00:23<00:00, 23.90s/it]

100%|██████████| 1/1 [00:23<00:00, 23.89s/it][A100%|██████████| 1/1 [00:23<00:00, 23.89s/it]

100%|██████████| 1/1 [00:23<00:00, 23.98s/it][A100%|██████████| 1/1 [00:23<00:00, 23.98s/it]

100%|██████████| 1/1 [00:23<00:00, 23.85s/it][A100%|██████████| 1/1 [00:23<00:00, 23.85s/it]

100%|██████████| 1/1 [00:23<00:00, 23.97s/it][A100%|██████████| 1/1 [00:23<00:00, 23.97s/it]

100%|██████████| 1/1 [00:23<00:00, 23.95s/it][A100%|██████████| 1/1 [00:23<00:00, 23.95s/it]

100%|██████████| 1/1 [00:23<00:00, 23.93s/it][A100%|██████████| 1/1 [00:23<00:00, 23.93s/it]
Checkpointing at shard 4927
[2024-09-02 00:05:28,653] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step4927 is about to be saved!
[2024-09-02 00:05:29,097] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4927/layer_00-model_states.pt...
[2024-09-02 00:05:30,981] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4927/layer_02-model_states.pt...
[2024-09-02 00:05:31,201] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4927/layer_06-model_states.pt...
[2024-09-02 00:05:31,551] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4927/layer_05-model_states.pt...
[2024-09-02 00:05:31,603] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4927/layer_07-model_states.pt...
[2024-09-02 00:05:31,643] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4927/layer_08-model_states.pt...
[2024-09-02 00:05:33,252] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4927/layer_00-model_states.pt.
[2024-09-02 00:05:34,952] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4927/layer_01-model_states.pt...
[2024-09-02 00:05:36,542] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4927/layer_03-model_states.pt...
[2024-09-02 00:05:36,570] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4927/layer_04-model_states.pt...
[2024-09-02 00:06:20,346] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4927/layer_05-model_states.pt.
[2024-09-02 00:06:20,391] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4927/mp_rank_04_model_states.pt...
[2024-09-02 00:06:20,631] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4927/mp_rank_04_model_states.pt.
[2024-09-02 00:06:20,631] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4927 is ready now!
[2024-09-02 00:06:22,737] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4927/layer_02-model_states.pt.
[2024-09-02 00:06:22,760] [INFO] [logging.py:96:log_dist] [Rank 1] Saving model checkpoint: /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4927/mp_rank_01_model_states.pt
[2024-09-02 00:06:22,760] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4927/mp_rank_01_model_states.pt...
[2024-09-02 00:06:22,776] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4927/layer_07-model_states.pt.
[2024-09-02 00:06:22,801] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4927/mp_rank_06_model_states.pt...
[2024-09-02 00:06:22,822] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4927/mp_rank_01_model_states.pt.
[2024-09-02 00:06:22,822] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4927 is ready now!
[2024-09-02 00:06:22,864] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4927/mp_rank_06_model_states.pt.
[2024-09-02 00:06:22,864] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4927 is ready now!
[2024-09-02 00:06:22,938] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4927/layer_08-model_states.pt.
[2024-09-02 00:06:22,993] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4927/layer_09-model_states.pt...
[2024-09-02 00:06:23,098] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4927/layer_06-model_states.pt.
[2024-09-02 00:06:23,120] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4927/mp_rank_05_model_states.pt...
[2024-09-02 00:06:23,207] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4927/mp_rank_05_model_states.pt.
[2024-09-02 00:06:23,208] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4927 is ready now!
[2024-09-02 00:06:23,739] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4927/layer_09-model_states.pt.
[2024-09-02 00:06:23,742] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4927/mp_rank_07_model_states.pt...
[2024-09-02 00:06:23,908] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4927/mp_rank_07_model_states.pt.
[2024-09-02 00:06:23,908] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4927 is ready now!
[2024-09-02 00:06:25,757] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4927/layer_01-model_states.pt.
[2024-09-02 00:06:25,782] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4927/mp_rank_00_model_states.pt
[2024-09-02 00:06:25,782] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4927/mp_rank_00_model_states.pt...
[2024-09-02 00:06:26,118] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4927/mp_rank_00_model_states.pt.
[2024-09-02 00:06:26,118] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4927 is ready now!
[2024-09-02 00:06:26,331] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4927/layer_03-model_states.pt.
[2024-09-02 00:06:26,351] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4927/layer_04-model_states.pt.
[2024-09-02 00:06:26,353] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4927/mp_rank_02_model_states.pt...
[2024-09-02 00:06:26,374] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4927/mp_rank_03_model_states.pt...
[2024-09-02 00:06:26,381] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4927/mp_rank_02_model_states.pt.
[2024-09-02 00:06:26,381] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4927 is ready now!
[2024-09-02 00:06:26,402] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step4927/mp_rank_03_model_states.pt.
[2024-09-02 00:06:26,402] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4927 is ready now!
Checkpoint saved using --- 57.74956130981445 seconds ---
 95%|█████████▍| 4928/5198 [1:08:28<3:29:01, 46.45s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4620
 95%|█████████▍| 4928/5198 [1:08:41<3:30:32, 46.79s/it] 95%|█████████▍| 4928/5198 [1:08:52<3:29:35, 46.58s/it] 95%|█████████▍| 4928/5198 [1:08:38<3:29:05, 46.46s/it] 95%|█████████▍| 4928/5198 [1:08:50<3:29:24, 46.54s/it] 95%|█████████▍| 4928/5198 [1:08:42<3:29:17, 46.51s/it] 95%|█████████▍| 4928/5198 [1:08:44<3:29:09, 46.48s/it] 95%|█████████▍| 4928/5198 [1:08:23<3:29:03, 46.46s/it]Training on 128 of 128 sentences.


  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.64s/it][A100%|██████████| 1/1 [00:29<00:00, 29.64s/it]
 95%|█████████▍| 4929/5198 [1:09:11<3:06:59, 41.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:06:56,672] [INFO] [logging.py:96:log_dist] [Rank 0] step=4928, skipped=0, lr=[4.932210200089644e-07], mom=[(0.9, 0.999)]
steps: 4928 loss: 1.5398 iter time (s): 30.056 samples/sec: 4.259

100%|██████████| 1/1 [00:30<00:00, 30.33s/it][A100%|██████████| 1/1 [00:30<00:00, 30.33s/it]
 95%|█████████▍| 4929/5198 [1:09:22<3:07:15, 41.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.50s/it][A100%|██████████| 1/1 [00:30<00:00, 30.50s/it]
 95%|█████████▍| 4929/5198 [1:09:21<3:07:21, 41.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.56s/it][A100%|██████████| 1/1 [00:30<00:00, 30.56s/it]
 95%|█████████▍| 4929/5198 [1:09:12<3:07:20, 41.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.71s/it][A100%|██████████| 1/1 [00:30<00:00, 30.71s/it]
 95%|█████████▍| 4929/5198 [1:09:15<3:07:27, 41.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.74s/it][A100%|██████████| 1/1 [00:30<00:00, 30.74s/it]
 95%|█████████▍| 4929/5198 [1:08:54<3:07:25, 41.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.76s/it][A100%|██████████| 1/1 [00:30<00:00, 30.76s/it]
 95%|█████████▍| 4929/5198 [1:09:09<3:07:28, 41.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.78s/it][A100%|██████████| 1/1 [00:30<00:00, 30.78s/it]
 95%|█████████▍| 4929/5198 [1:08:59<3:07:28, 41.81s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4621
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.70s/it][A100%|██████████| 1/1 [00:32<00:00, 32.70s/it]
 95%|█████████▍| 4930/5198 [1:09:44<2:54:23, 39.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:07:29,537] [INFO] [logging.py:96:log_dist] [Rank 0] step=4929, skipped=0, lr=[4.919964760212217e-07], mom=[(0.9, 0.999)]
steps: 4929 loss: 1.5013 iter time (s): 32.125 samples/sec: 3.984

100%|██████████| 1/1 [00:32<00:00, 32.90s/it][A100%|██████████| 1/1 [00:32<00:00, 32.90s/it]
 95%|█████████▍| 4930/5198 [1:09:55<2:54:42, 39.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.87s/it][A100%|██████████| 1/1 [00:32<00:00, 32.87s/it]
 95%|█████████▍| 4930/5198 [1:09:54<2:54:43, 39.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 33.00s/it][A100%|██████████| 1/1 [00:32<00:00, 33.00s/it]
 95%|█████████▍| 4930/5198 [1:09:45<2:54:52, 39.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.87s/it][A100%|██████████| 1/1 [00:32<00:00, 32.87s/it]
 95%|█████████▍| 4930/5198 [1:09:48<2:54:47, 39.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.94s/it][A100%|██████████| 1/1 [00:32<00:00, 32.94s/it]
 95%|█████████▍| 4930/5198 [1:09:27<2:54:51, 39.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.93s/it][A100%|██████████| 1/1 [00:32<00:00, 32.93s/it]
 95%|█████████▍| 4930/5198 [1:09:42<2:54:53, 39.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.92s/it][A100%|██████████| 1/1 [00:32<00:00, 32.92s/it]
 95%|█████████▍| 4930/5198 [1:09:32<2:54:51, 39.15s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4622
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.98s/it][A100%|██████████| 1/1 [00:35<00:00, 35.98s/it]
 95%|█████████▍| 4931/5198 [1:10:20<2:49:54, 38.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:08:05,839] [INFO] [logging.py:96:log_dist] [Rank 0] step=4930, skipped=0, lr=[4.907733784733229e-07], mom=[(0.9, 0.999)]
steps: 4930 loss: 1.5286 iter time (s): 35.499 samples/sec: 3.606

100%|██████████| 1/1 [00:36<00:00, 36.27s/it][A100%|██████████| 1/1 [00:36<00:00, 36.27s/it]
 95%|█████████▍| 4931/5198 [1:10:32<2:50:16, 38.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.22s/it][A100%|██████████| 1/1 [00:36<00:00, 36.22s/it]
 95%|█████████▍| 4931/5198 [1:10:30<2:50:13, 38.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.17s/it][A100%|██████████| 1/1 [00:36<00:00, 36.17s/it]
 95%|█████████▍| 4931/5198 [1:10:24<2:50:12, 38.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.22s/it][A100%|██████████| 1/1 [00:36<00:00, 36.22s/it]
 95%|█████████▍| 4931/5198 [1:10:22<2:50:19, 38.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.21s/it][A100%|██████████| 1/1 [00:36<00:00, 36.21s/it]
 95%|█████████▍| 4931/5198 [1:10:18<2:50:18, 38.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.24s/it][A100%|██████████| 1/1 [00:36<00:00, 36.24s/it]
 95%|█████████▍| 4931/5198 [1:10:03<2:50:20, 38.28s/it]
100%|██████████| 1/1 [00:36<00:00, 36.22s/it][A100%|██████████| 1/1 [00:36<00:00, 36.22s/it]
 95%|█████████▍| 4931/5198 [1:10:08<2:50:18, 38.27s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4623

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.24s/it][A100%|██████████| 1/1 [00:29<00:00, 29.24s/it]
 95%|█████████▍| 4932/5198 [1:10:49<2:37:37, 35.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:08:35,039] [INFO] [logging.py:96:log_dist] [Rank 0] step=4931, skipped=0, lr=[4.895517277576697e-07], mom=[(0.9, 0.999)]
steps: 4931 loss: 1.4528 iter time (s): 28.469 samples/sec: 4.496

100%|██████████| 1/1 [00:29<00:00, 29.24s/it][A100%|██████████| 1/1 [00:29<00:00, 29.24s/it]
 95%|█████████▍| 4932/5198 [1:11:01<2:37:39, 35.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.28s/it][A100%|██████████| 1/1 [00:29<00:00, 29.28s/it]
 95%|█████████▍| 4932/5198 [1:10:59<2:37:39, 35.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.17s/it][A100%|██████████| 1/1 [00:29<00:00, 29.17s/it]
 95%|█████████▍| 4932/5198 [1:10:51<2:37:35, 35.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.25s/it][A100%|██████████| 1/1 [00:29<00:00, 29.25s/it]
 95%|█████████▍| 4932/5198 [1:10:53<2:37:37, 35.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.22s/it][A100%|██████████| 1/1 [00:29<00:00, 29.22s/it]
 95%|█████████▍| 4932/5198 [1:10:47<2:37:38, 35.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.20s/it][A100%|██████████| 1/1 [00:29<00:00, 29.20s/it]
 95%|█████████▍| 4932/5198 [1:10:33<2:37:38, 35.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.21s/it][A100%|██████████| 1/1 [00:29<00:00, 29.21s/it]
 95%|█████████▍| 4932/5198 [1:10:37<2:37:37, 35.56s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4624
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.84s/it][A100%|██████████| 1/1 [00:31<00:00, 31.84s/it]
 95%|█████████▍| 4933/5198 [1:11:21<2:32:19, 34.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:09:07,085] [INFO] [logging.py:96:log_dist] [Rank 0] step=4932, skipped=0, lr=[4.883315242661965e-07], mom=[(0.9, 0.999)]
steps: 4932 loss: 1.4602 iter time (s): 31.299 samples/sec: 4.090

100%|██████████| 1/1 [00:31<00:00, 31.97s/it][A100%|██████████| 1/1 [00:31<00:00, 31.97s/it]
 95%|█████████▍| 4933/5198 [1:11:33<2:32:19, 34.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.98s/it][A100%|██████████| 1/1 [00:31<00:00, 31.98s/it]
 95%|█████████▍| 4933/5198 [1:11:31<2:32:19, 34.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.08s/it][A100%|██████████| 1/1 [00:32<00:00, 32.08s/it]
 95%|█████████▍| 4933/5198 [1:11:23<2:32:24, 34.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.03s/it][A100%|██████████| 1/1 [00:32<00:00, 32.04s/it]
 95%|█████████▍| 4933/5198 [1:11:25<2:32:22, 34.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.00s/it][A100%|██████████| 1/1 [00:32<00:00, 32.00s/it]
 95%|█████████▍| 4933/5198 [1:11:19<2:32:20, 34.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.03s/it][A100%|██████████| 1/1 [00:32<00:00, 32.03s/it]
 95%|█████████▍| 4933/5198 [1:11:05<2:32:22, 34.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.04s/it][A100%|██████████| 1/1 [00:32<00:00, 32.04s/it]
 95%|█████████▍| 4933/5198 [1:11:09<2:32:23, 34.50s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4625
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.82s/it][A100%|██████████| 1/1 [00:28<00:00, 28.82s/it]
 95%|█████████▍| 4934/5198 [1:11:50<2:24:29, 32.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:09:36,017] [INFO] [logging.py:96:log_dist] [Rank 0] step=4933, skipped=0, lr=[4.871127683903754e-07], mom=[(0.9, 0.999)]
steps: 4933 loss: 1.4575 iter time (s): 28.184 samples/sec: 4.542

100%|██████████| 1/1 [00:28<00:00, 28.83s/it][A100%|██████████| 1/1 [00:28<00:00, 28.83s/it]
 95%|█████████▍| 4934/5198 [1:12:02<2:24:17, 32.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.76s/it][A100%|██████████| 1/1 [00:28<00:00, 28.76s/it]
 95%|█████████▍| 4934/5198 [1:12:00<2:24:12, 32.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.77s/it][A100%|██████████| 1/1 [00:28<00:00, 28.77s/it]
 95%|█████████▍| 4934/5198 [1:11:52<2:24:16, 32.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.79s/it][A100%|██████████| 1/1 [00:28<00:00, 28.79s/it]
 95%|█████████▍| 4934/5198 [1:11:54<2:24:16, 32.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.81s/it][A100%|██████████| 1/1 [00:28<00:00, 28.81s/it]
 95%|█████████▍| 4934/5198 [1:11:48<2:24:16, 32.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.82s/it][A100%|██████████| 1/1 [00:28<00:00, 28.82s/it]
 95%|█████████▍| 4934/5198 [1:11:33<2:24:18, 32.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.81s/it][A100%|██████████| 1/1 [00:28<00:00, 28.81s/it]
 95%|█████████▍| 4934/5198 [1:11:38<2:24:18, 32.80s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4626
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.26s/it][A100%|██████████| 1/1 [00:30<00:00, 30.26s/it]
 95%|█████████▍| 4935/5198 [1:12:21<2:20:44, 32.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:10:06,453] [INFO] [logging.py:96:log_dist] [Rank 0] step=4934, skipped=0, lr=[4.858954605212145e-07], mom=[(0.9, 0.999)]
steps: 4934 loss: 1.4456 iter time (s): 29.808 samples/sec: 4.294

100%|██████████| 1/1 [00:30<00:00, 30.57s/it][A100%|██████████| 1/1 [00:30<00:00, 30.57s/it]
 95%|█████████▍| 4935/5198 [1:12:32<2:20:49, 32.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.61s/it][A100%|██████████| 1/1 [00:30<00:00, 30.61s/it]
 95%|█████████▍| 4935/5198 [1:12:30<2:20:49, 32.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.51s/it][A100%|██████████| 1/1 [00:30<00:00, 30.51s/it]
 95%|█████████▍| 4935/5198 [1:12:22<2:20:44, 32.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.56s/it][A100%|██████████| 1/1 [00:30<00:00, 30.56s/it]
 95%|█████████▍| 4935/5198 [1:12:25<2:20:48, 32.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.52s/it][A100%|██████████| 1/1 [00:30<00:00, 30.52s/it]
 95%|█████████▍| 4935/5198 [1:12:19<2:20:45, 32.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.53s/it][A100%|██████████| 1/1 [00:30<00:00, 30.53s/it]
 95%|█████████▍| 4935/5198 [1:12:04<2:20:47, 32.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.53s/it][A100%|██████████| 1/1 [00:30<00:00, 30.54s/it]
 95%|█████████▍| 4935/5198 [1:12:09<2:20:47, 32.12s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4627
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.00s/it][A100%|██████████| 1/1 [00:31<00:00, 31.00s/it]
 95%|█████████▍| 4936/5198 [1:12:52<2:18:58, 31.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:10:37,615] [INFO] [logging.py:96:log_dist] [Rank 0] step=4935, skipped=0, lr=[4.846796010492541e-07], mom=[(0.9, 0.999)]
steps: 4935 loss: 1.4786 iter time (s): 30.418 samples/sec: 4.208

100%|██████████| 1/1 [00:31<00:00, 31.06s/it][A100%|██████████| 1/1 [00:31<00:00, 31.06s/it]
 95%|█████████▍| 4936/5198 [1:13:03<2:18:54, 31.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.16s/it][A100%|██████████| 1/1 [00:31<00:00, 31.16s/it]
 95%|█████████▍| 4936/5198 [1:13:02<2:19:02, 31.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.17s/it][A100%|██████████| 1/1 [00:31<00:00, 31.17s/it]
 95%|█████████▍| 4936/5198 [1:12:53<2:18:59, 31.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.11s/it][A100%|██████████| 1/1 [00:31<00:00, 31.11s/it]
 95%|█████████▍| 4936/5198 [1:12:56<2:18:57, 31.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.15s/it][A100%|██████████| 1/1 [00:31<00:00, 31.15s/it]
 95%|█████████▍| 4936/5198 [1:12:50<2:18:58, 31.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.11s/it][A100%|██████████| 1/1 [00:31<00:00, 31.11s/it]
 95%|█████████▍| 4936/5198 [1:12:35<2:18:56, 31.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.12s/it][A100%|██████████| 1/1 [00:31<00:00, 31.12s/it]
 95%|█████████▍| 4936/5198 [1:12:40<2:18:56, 31.82s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4628
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.84s/it][A100%|██████████| 1/1 [00:30<00:00, 30.84s/it]
 95%|█████████▍| 4937/5198 [1:13:23<2:17:18, 31.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:11:08,590] [INFO] [logging.py:96:log_dist] [Rank 0] step=4936, skipped=0, lr=[4.834651903645743e-07], mom=[(0.9, 0.999)]
steps: 4936 loss: 1.4757 iter time (s): 30.284 samples/sec: 4.227

100%|██████████| 1/1 [00:30<00:00, 30.99s/it][A100%|██████████| 1/1 [00:30<00:00, 30.99s/it]
 95%|█████████▍| 4937/5198 [1:13:34<2:17:19, 31.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 31.00s/it][A100%|██████████| 1/1 [00:30<00:00, 31.00s/it]
 95%|█████████▍| 4937/5198 [1:13:33<2:17:24, 31.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.02s/it][A100%|██████████| 1/1 [00:31<00:00, 31.02s/it]
 95%|█████████▍| 4937/5198 [1:13:24<2:17:24, 31.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.05s/it][A100%|██████████| 1/1 [00:31<00:00, 31.05s/it]
 95%|█████████▍| 4937/5198 [1:13:27<2:17:25, 31.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.01s/it][A100%|██████████| 1/1 [00:31<00:00, 31.01s/it]
 95%|█████████▍| 4937/5198 [1:13:21<2:17:23, 31.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.03s/it][A100%|██████████| 1/1 [00:31<00:00, 31.03s/it]
 95%|█████████▍| 4937/5198 [1:13:06<2:17:23, 31.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.04s/it][A100%|██████████| 1/1 [00:31<00:00, 31.04s/it]
 95%|█████████▍| 4937/5198 [1:13:11<2:17:24, 31.59s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4629
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.05s/it][A100%|██████████| 1/1 [00:32<00:00, 32.05s/it]
 95%|█████████▍| 4938/5198 [1:13:55<2:17:34, 31.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:11:40,786] [INFO] [logging.py:96:log_dist] [Rank 0] step=4937, skipped=0, lr=[4.82252228856787e-07], mom=[(0.9, 0.999)]
steps: 4937 loss: 1.4274 iter time (s): 31.431 samples/sec: 4.072

100%|██████████| 1/1 [00:32<00:00, 32.23s/it][A100%|██████████| 1/1 [00:32<00:00, 32.23s/it]
 95%|█████████▍| 4938/5198 [1:14:07<2:17:39, 31.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.14s/it][A100%|██████████| 1/1 [00:32<00:00, 32.14s/it]
 95%|█████████▍| 4938/5198 [1:14:05<2:17:36, 31.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.20s/it][A100%|██████████| 1/1 [00:32<00:00, 32.20s/it]
 95%|█████████▍| 4938/5198 [1:13:57<2:17:40, 31.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.22s/it][A100%|██████████| 1/1 [00:32<00:00, 32.22s/it]
 95%|█████████▍| 4938/5198 [1:13:59<2:17:43, 31.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.22s/it][A100%|██████████| 1/1 [00:32<00:00, 32.22s/it]
 95%|█████████▍| 4938/5198 [1:13:53<2:17:42, 31.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.25s/it][A100%|██████████| 1/1 [00:32<00:00, 32.25s/it]
 95%|█████████▍| 4938/5198 [1:13:38<2:17:44, 31.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.24s/it][A100%|██████████| 1/1 [00:32<00:00, 32.24s/it]
 95%|█████████▍| 4938/5198 [1:13:43<2:17:44, 31.79s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4630
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.68s/it][A100%|██████████| 1/1 [00:30<00:00, 30.68s/it]
 95%|█████████▌| 4939/5198 [1:14:26<2:15:51, 31.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:12:11,604] [INFO] [logging.py:96:log_dist] [Rank 0] step=4938, skipped=0, lr=[4.810407169150404e-07], mom=[(0.9, 0.999)]
steps: 4938 loss: 1.5214 iter time (s): 30.004 samples/sec: 4.266

100%|██████████| 1/1 [00:30<00:00, 30.90s/it][A100%|██████████| 1/1 [00:30<00:00, 30.90s/it]
 95%|█████████▌| 4939/5198 [1:14:38<2:16:01, 31.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.83s/it][A100%|██████████| 1/1 [00:30<00:00, 30.83s/it]
 95%|█████████▌| 4939/5198 [1:14:36<2:15:53, 31.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.78s/it][A100%|██████████| 1/1 [00:30<00:00, 30.78s/it]
 95%|█████████▌| 4939/5198 [1:14:27<2:15:52, 31.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.76s/it][A100%|██████████| 1/1 [00:30<00:00, 30.76s/it]
 95%|█████████▌| 4939/5198 [1:14:30<2:15:52, 31.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.79s/it][A100%|██████████| 1/1 [00:30<00:00, 30.79s/it]
 95%|█████████▌| 4939/5198 [1:14:24<2:15:54, 31.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.75s/it][A100%|██████████| 1/1 [00:30<00:00, 30.75s/it]
 95%|█████████▌| 4939/5198 [1:14:14<2:15:52, 31.48s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4631

100%|██████████| 1/1 [00:30<00:00, 30.77s/it][A100%|██████████| 1/1 [00:30<00:00, 30.77s/it]
 95%|█████████▌| 4939/5198 [1:14:09<2:15:53, 31.48s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.32s/it][A100%|██████████| 1/1 [00:31<00:00, 31.32s/it]
 95%|█████████▌| 4940/5198 [1:14:57<2:15:18, 31.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:12:43,028] [INFO] [logging.py:96:log_dist] [Rank 0] step=4939, skipped=0, lr=[4.798306549280191e-07], mom=[(0.9, 0.999)]
steps: 4939 loss: 1.4544 iter time (s): 30.670 samples/sec: 4.173

100%|██████████| 1/1 [00:31<00:00, 31.24s/it][A100%|██████████| 1/1 [00:31<00:00, 31.24s/it]
 95%|█████████▌| 4940/5198 [1:15:09<2:15:09, 31.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.39s/it][A100%|██████████| 1/1 [00:31<00:00, 31.39s/it]
 95%|█████████▌| 4940/5198 [1:15:07<2:15:16, 31.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.41s/it][A100%|██████████| 1/1 [00:31<00:00, 31.41s/it]
 95%|█████████▌| 4940/5198 [1:14:59<2:15:16, 31.46s/it]
100%|██████████| 1/1 [00:31<00:00, 31.35s/it][A100%|██████████| 1/1 [00:31<00:00, 31.35s/it]
 95%|█████████▌| 4940/5198 [1:15:01<2:15:11, 31.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.36s/it][A100%|██████████| 1/1 [00:31<00:00, 31.36s/it]
 95%|█████████▌| 4940/5198 [1:14:40<2:15:13, 31.45s/it]
100%|██████████| 1/1 [00:31<00:00, 31.40s/it][A100%|██████████| 1/1 [00:31<00:00, 31.40s/it]
 95%|█████████▌| 4940/5198 [1:14:55<2:15:16, 31.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.40s/it][A100%|██████████| 1/1 [00:31<00:00, 31.40s/it]
 95%|█████████▌| 4940/5198 [1:14:45<2:15:15, 31.46s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4632
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.15s/it][A100%|██████████| 1/1 [00:29<00:00, 29.15s/it]
 95%|█████████▌| 4941/5198 [1:15:26<2:11:58, 30.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:13:12,279] [INFO] [logging.py:96:log_dist] [Rank 0] step=4940, skipped=0, lr=[4.786220432839387e-07], mom=[(0.9, 0.999)]
steps: 4940 loss: 1.5756 iter time (s): 28.517 samples/sec: 4.489

100%|██████████| 1/1 [00:29<00:00, 29.27s/it][A100%|██████████| 1/1 [00:29<00:00, 29.27s/it]
 95%|█████████▌| 4941/5198 [1:15:38<2:11:52, 30.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.25s/it][A100%|██████████| 1/1 [00:29<00:00, 29.25s/it]
 95%|█████████▌| 4941/5198 [1:15:36<2:11:54, 30.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.20s/it][A100%|██████████| 1/1 [00:29<00:00, 29.20s/it]
 95%|█████████▌| 4941/5198 [1:15:28<2:11:52, 30.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.26s/it][A100%|██████████| 1/1 [00:29<00:00, 29.26s/it]
 95%|█████████▌| 4941/5198 [1:15:31<2:11:52, 30.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.17s/it][A100%|██████████| 1/1 [00:29<00:00, 29.17s/it]
 95%|█████████▌| 4941/5198 [1:15:24<2:11:49, 30.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.21s/it][A100%|██████████| 1/1 [00:29<00:00, 29.21s/it]
 95%|█████████▌| 4941/5198 [1:15:10<2:11:50, 30.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.19s/it][A100%|██████████| 1/1 [00:29<00:00, 29.19s/it]
 95%|█████████▌| 4941/5198 [1:15:14<2:11:49, 30.78s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4633
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.18s/it][A100%|██████████| 1/1 [00:29<00:00, 29.18s/it]
 95%|█████████▌| 4942/5198 [1:15:56<2:09:34, 30.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:13:41,596] [INFO] [logging.py:96:log_dist] [Rank 0] step=4941, skipped=0, lr=[4.77414882370553e-07], mom=[(0.9, 0.999)]
steps: 4941 loss: 1.3934 iter time (s): 28.639 samples/sec: 4.469

100%|██████████| 1/1 [00:29<00:00, 29.34s/it][A100%|██████████| 1/1 [00:29<00:00, 29.34s/it]
 95%|█████████▌| 4942/5198 [1:16:07<2:09:31, 30.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.31s/it][A100%|██████████| 1/1 [00:29<00:00, 29.31s/it]
 95%|█████████▌| 4942/5198 [1:16:06<2:09:30, 30.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.32s/it][A100%|██████████| 1/1 [00:29<00:00, 29.32s/it]
 95%|█████████▌| 4942/5198 [1:15:57<2:09:29, 30.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.37s/it][A100%|██████████| 1/1 [00:29<00:00, 29.37s/it]
 95%|█████████▌| 4942/5198 [1:16:00<2:09:33, 30.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.33s/it][A100%|██████████| 1/1 [00:29<00:00, 29.33s/it]
 95%|█████████▌| 4942/5198 [1:15:54<2:09:28, 30.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A

100%|██████████| 1/1 [00:29<00:00, 29.34s/it][A100%|██████████| 1/1 [00:29<00:00, 29.34s/it]
 95%|█████████▌| 4942/5198 [1:15:44<2:09:29, 30.35s/it]100%|██████████| 1/1 [00:29<00:00, 29.35s/it][ALoading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4634
100%|██████████| 1/1 [00:29<00:00, 29.35s/it]
 95%|█████████▌| 4942/5198 [1:15:39<2:09:30, 30.35s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s]
[A  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.73s/it][A100%|██████████| 1/1 [00:30<00:00, 30.74s/it]
 95%|█████████▌| 4943/5198 [1:16:27<2:09:43, 30.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:14:12,537] [INFO] [logging.py:96:log_dist] [Rank 0] step=4942, skipped=0, lr=[4.7620917257514963e-07], mom=[(0.9, 0.999)]
steps: 4942 loss: 1.4322 iter time (s): 30.232 samples/sec: 4.234

100%|██████████| 1/1 [00:30<00:00, 30.88s/it][A100%|██████████| 1/1 [00:30<00:00, 30.88s/it]
 95%|█████████▌| 4943/5198 [1:16:38<2:09:41, 30.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.99s/it][A100%|██████████| 1/1 [00:30<00:00, 30.99s/it]
 95%|█████████▌| 4943/5198 [1:16:37<2:09:49, 30.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.96s/it][A100%|██████████| 1/1 [00:30<00:00, 30.96s/it]
 95%|█████████▌| 4943/5198 [1:16:28<2:09:46, 30.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.92s/it][A100%|██████████| 1/1 [00:30<00:00, 30.92s/it]
 95%|█████████▌| 4943/5198 [1:16:31<2:09:45, 30.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.94s/it][A100%|██████████| 1/1 [00:30<00:00, 30.95s/it]
 95%|█████████▌| 4943/5198 [1:16:10<2:09:45, 30.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.00s/it][A100%|██████████| 1/1 [00:31<00:00, 31.00s/it]
 95%|█████████▌| 4943/5198 [1:16:25<2:09:49, 30.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.98s/it][A100%|██████████| 1/1 [00:30<00:00, 30.98s/it]
 95%|█████████▌| 4943/5198 [1:16:15<2:09:47, 30.54s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_308
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.78s/it][A100%|██████████| 1/1 [00:24<00:00, 24.78s/it]
 95%|█████████▌| 4944/5198 [1:16:52<2:02:03, 28.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:14:37,549] [INFO] [logging.py:96:log_dist] [Rank 0] step=4943, skipped=0, lr=[4.750049142845493e-07], mom=[(0.9, 0.999)]
steps: 4943 loss: 1.9567 iter time (s): 24.288 samples/sec: 5.270

100%|██████████| 1/1 [00:25<00:00, 25.30s/it][A100%|██████████| 1/1 [00:25<00:00, 25.30s/it]
 95%|█████████▌| 4944/5198 [1:17:04<2:02:34, 28.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:25<00:00, 25.16s/it][A100%|██████████| 1/1 [00:25<00:00, 25.16s/it]
 95%|█████████▌| 4944/5198 [1:17:02<2:02:29, 28.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:25<00:00, 25.19s/it][A100%|██████████| 1/1 [00:25<00:00, 25.20s/it]
 95%|█████████▌| 4944/5198 [1:16:54<2:02:29, 28.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:25<00:00, 25.17s/it][A100%|██████████| 1/1 [00:25<00:00, 25.17s/it]
 95%|█████████▌| 4944/5198 [1:16:50<2:02:29, 28.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:25<00:00, 25.27s/it][A100%|██████████| 1/1 [00:25<00:00, 25.28s/it]
 95%|█████████▌| 4944/5198 [1:16:56<2:02:35, 28.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:25<00:00, 25.25s/it][A100%|██████████| 1/1 [00:25<00:00, 25.25s/it]
 95%|█████████▌| 4944/5198 [1:16:35<2:02:33, 28.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:25<00:00, 25.23s/it][A100%|██████████| 1/1 [00:25<00:00, 25.23s/it]
 95%|█████████▌| 4944/5198 [1:16:40<2:02:33, 28.95s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4635
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.69s/it][A100%|██████████| 1/1 [00:29<00:00, 29.69s/it]
 95%|█████████▌| 4945/5198 [1:17:21<2:02:51, 29.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:15:07,215] [INFO] [logging.py:96:log_dist] [Rank 0] step=4944, skipped=0, lr=[4.7380210788510807e-07], mom=[(0.9, 0.999)]
steps: 4944 loss: 1.5120 iter time (s): 28.691 samples/sec: 4.461

100%|██████████| 1/1 [00:29<00:00, 29.38s/it][A100%|██████████| 1/1 [00:29<00:00, 29.38s/it]
 95%|█████████▌| 4945/5198 [1:17:33<2:02:38, 29.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.41s/it][A100%|██████████| 1/1 [00:29<00:00, 29.41s/it]
 95%|█████████▌| 4945/5198 [1:17:31<2:02:36, 29.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.28s/it][A100%|██████████| 1/1 [00:29<00:00, 29.28s/it]
 95%|█████████▌| 4945/5198 [1:17:26<2:02:31, 29.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.42s/it][A100%|██████████| 1/1 [00:29<00:00, 29.42s/it]
 95%|█████████▌| 4945/5198 [1:17:23<2:02:38, 29.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.37s/it][A100%|██████████| 1/1 [00:29<00:00, 29.37s/it]
 95%|█████████▌| 4945/5198 [1:17:19<2:02:33, 29.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.33s/it][A100%|██████████| 1/1 [00:29<00:00, 29.33s/it]
 95%|█████████▌| 4945/5198 [1:17:05<2:02:33, 29.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.32s/it][A100%|██████████| 1/1 [00:29<00:00, 29.32s/it]
 95%|█████████▌| 4945/5198 [1:17:09<2:02:32, 29.06s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4636
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.15s/it][A100%|██████████| 1/1 [00:31<00:00, 31.15s/it]
 95%|█████████▌| 4946/5198 [1:17:53<2:05:10, 29.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:15:38,623] [INFO] [logging.py:96:log_dist] [Rank 0] step=4945, skipped=0, lr=[4.726007537627176e-07], mom=[(0.9, 0.999)]
steps: 4945 loss: 1.4584 iter time (s): 30.764 samples/sec: 4.161

100%|██████████| 1/1 [00:31<00:00, 31.46s/it][A100%|██████████| 1/1 [00:31<00:00, 31.46s/it]
 95%|█████████▌| 4946/5198 [1:18:04<2:05:09, 29.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.47s/it][A100%|██████████| 1/1 [00:31<00:00, 31.47s/it]
 95%|█████████▌| 4946/5198 [1:18:03<2:05:08, 29.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.51s/it][A100%|██████████| 1/1 [00:31<00:00, 31.51s/it]
 95%|█████████▌| 4946/5198 [1:17:54<2:05:13, 29.82s/it]
100%|██████████| 1/1 [00:31<00:00, 31.53s/it][A100%|██████████| 1/1 [00:31<00:00, 31.53s/it]
 95%|█████████▌| 4946/5198 [1:17:57<2:05:10, 29.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.53s/it][A100%|██████████| 1/1 [00:31<00:00, 31.53s/it]
 95%|█████████▌| 4946/5198 [1:17:51<2:05:11, 29.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.52s/it][A100%|██████████| 1/1 [00:31<00:00, 31.52s/it]
 95%|█████████▌| 4946/5198 [1:17:36<2:05:10, 29.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.56s/it][A100%|██████████| 1/1 [00:31<00:00, 31.56s/it]
 95%|█████████▌| 4946/5198 [1:17:41<2:05:12, 29.81s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4637
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.33s/it][A100%|██████████| 1/1 [00:33<00:00, 33.33s/it]
 95%|█████████▌| 4947/5198 [1:18:26<2:09:17, 30.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:16:12,222] [INFO] [logging.py:96:log_dist] [Rank 0] step=4946, skipped=0, lr=[4.714008523027999e-07], mom=[(0.9, 0.999)]
steps: 4946 loss: 1.4559 iter time (s): 32.798 samples/sec: 3.903

100%|██████████| 1/1 [00:33<00:00, 33.57s/it][A100%|██████████| 1/1 [00:33<00:00, 33.57s/it]
 95%|█████████▌| 4947/5198 [1:18:38<2:09:24, 30.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.54s/it][A100%|██████████| 1/1 [00:33<00:00, 33.54s/it]
 95%|█████████▌| 4947/5198 [1:18:36<2:09:22, 30.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.53s/it][A100%|██████████| 1/1 [00:33<00:00, 33.53s/it]
 95%|█████████▌| 4947/5198 [1:18:31<2:09:21, 30.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.55s/it][A100%|██████████| 1/1 [00:33<00:00, 33.55s/it]
 95%|█████████▌| 4947/5198 [1:18:28<2:09:25, 30.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.53s/it][A100%|██████████| 1/1 [00:33<00:00, 33.53s/it]
 95%|█████████▌| 4947/5198 [1:18:24<2:09:23, 30.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.54s/it][A100%|██████████| 1/1 [00:33<00:00, 33.54s/it]
 95%|█████████▌| 4947/5198 [1:18:10<2:09:22, 30.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.50s/it][A100%|██████████| 1/1 [00:33<00:00, 33.50s/it]
 95%|█████████▌| 4947/5198 [1:18:14<2:09:21, 30.92s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4638
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:39<00:00, 39.18s/it][A100%|██████████| 1/1 [00:39<00:00, 39.18s/it]
 95%|█████████▌| 4948/5198 [1:19:06<2:19:18, 33.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:16:51,572] [INFO] [logging.py:96:log_dist] [Rank 0] step=4947, skipped=0, lr=[4.702024038903147e-07], mom=[(0.9, 0.999)]
steps: 4947 loss: 1.4157 iter time (s): 38.645 samples/sec: 3.312

100%|██████████| 1/1 [00:39<00:00, 39.40s/it][A100%|██████████| 1/1 [00:39<00:00, 39.41s/it]
 95%|█████████▌| 4948/5198 [1:19:17<2:19:29, 33.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:39<00:00, 39.53s/it][A100%|██████████| 1/1 [00:39<00:00, 39.54s/it]
 95%|█████████▌| 4948/5198 [1:19:16<2:19:37, 33.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:39<00:00, 39.48s/it][A100%|██████████| 1/1 [00:39<00:00, 39.48s/it]
 95%|█████████▌| 4948/5198 [1:19:08<2:19:36, 33.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:39<00:00, 39.62s/it][A100%|██████████| 1/1 [00:39<00:00, 39.63s/it]
 95%|█████████▌| 4948/5198 [1:19:10<2:19:43, 33.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:39<00:00, 39.59s/it][A100%|██████████| 1/1 [00:39<00:00, 39.59s/it]
 95%|█████████▌| 4948/5198 [1:19:04<2:19:42, 33.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:39<00:00, 39.62s/it][A100%|██████████| 1/1 [00:39<00:00, 39.62s/it]
 95%|█████████▌| 4948/5198 [1:18:49<2:19:44, 33.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:39<00:00, 39.63s/it][A100%|██████████| 1/1 [00:39<00:00, 39.63s/it]
 95%|█████████▌| 4948/5198 [1:18:54<2:19:43, 33.54s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4639
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.91s/it][A100%|██████████| 1/1 [00:31<00:00, 31.91s/it]
 95%|█████████▌| 4949/5198 [1:19:38<2:16:58, 33.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:17:23,481] [INFO] [logging.py:96:log_dist] [Rank 0] step=4948, skipped=0, lr=[4.6900540890975304e-07], mom=[(0.9, 0.999)]
steps: 4948 loss: 1.5031 iter time (s): 30.914 samples/sec: 4.141

100%|██████████| 1/1 [00:31<00:00, 31.80s/it][A100%|██████████| 1/1 [00:31<00:00, 31.80s/it]
 95%|█████████▌| 4949/5198 [1:19:49<2:16:51, 32.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.69s/it][A100%|██████████| 1/1 [00:31<00:00, 31.69s/it]
 95%|█████████▌| 4949/5198 [1:19:47<2:16:48, 32.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.70s/it][A100%|██████████| 1/1 [00:31<00:00, 31.70s/it]
 95%|█████████▌| 4949/5198 [1:19:39<2:16:51, 32.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.65s/it][A100%|██████████| 1/1 [00:31<00:00, 31.65s/it]
 95%|█████████▌| 4949/5198 [1:19:42<2:16:49, 32.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.69s/it][A100%|██████████| 1/1 [00:31<00:00, 31.69s/it]
 95%|█████████▌| 4949/5198 [1:19:36<2:16:52, 32.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.64s/it][A100%|██████████| 1/1 [00:31<00:00, 31.64s/it]
 95%|█████████▌| 4949/5198 [1:19:26<2:16:49, 32.97s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4640

100%|██████████| 1/1 [00:31<00:00, 31.66s/it][A100%|██████████| 1/1 [00:31<00:00, 31.66s/it]
 95%|█████████▌| 4949/5198 [1:19:21<2:16:51, 32.98s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.88s/it][A100%|██████████| 1/1 [00:30<00:00, 30.88s/it]
 95%|█████████▌| 4950/5198 [1:20:09<2:13:58, 32.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:17:54,444] [INFO] [logging.py:96:log_dist] [Rank 0] step=4949, skipped=0, lr=[4.6780986774514097e-07], mom=[(0.9, 0.999)]
steps: 4949 loss: 1.5298 iter time (s): 30.227 samples/sec: 4.235

100%|██████████| 1/1 [00:30<00:00, 30.95s/it][A100%|██████████| 1/1 [00:30<00:00, 30.95s/it]
 95%|█████████▌| 4950/5198 [1:20:20<2:13:48, 32.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.96s/it][A100%|██████████| 1/1 [00:30<00:00, 30.96s/it]
 95%|█████████▌| 4950/5198 [1:20:18<2:13:47, 32.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.87s/it][A100%|██████████| 1/1 [00:30<00:00, 30.87s/it]
 95%|█████████▌| 4950/5198 [1:20:10<2:13:42, 32.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.93s/it][A100%|██████████| 1/1 [00:30<00:00, 30.93s/it]
 95%|█████████▌| 4950/5198 [1:20:13<2:13:45, 32.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.86s/it][A100%|██████████| 1/1 [00:30<00:00, 30.87s/it]
 95%|█████████▌| 4950/5198 [1:20:06<2:13:42, 32.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.87s/it][A100%|██████████| 1/1 [00:30<00:00, 30.87s/it]
 95%|█████████▌| 4950/5198 [1:19:52<2:13:42, 32.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.89s/it][A100%|██████████| 1/1 [00:30<00:00, 30.89s/it]
 95%|█████████▌| 4950/5198 [1:19:57<2:13:42, 32.35s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4641
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:41<00:00, 41.93s/it][A100%|██████████| 1/1 [00:41<00:00, 41.93s/it]
 95%|█████████▌| 4951/5198 [1:20:51<2:25:20, 35.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:18:36,949] [INFO] [logging.py:96:log_dist] [Rank 0] step=4950, skipped=0, lr=[4.6661578078003775e-07], mom=[(0.9, 0.999)]
steps: 4950 loss: 1.4217 iter time (s): 41.836 samples/sec: 3.060

100%|██████████| 1/1 [00:42<00:00, 42.52s/it][A100%|██████████| 1/1 [00:42<00:00, 42.52s/it]
 95%|█████████▌| 4951/5198 [1:21:03<2:25:49, 35.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:42<00:00, 42.69s/it][A100%|██████████| 1/1 [00:42<00:00, 42.69s/it]
 95%|█████████▌| 4951/5198 [1:21:01<2:26:00, 35.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:42<00:00, 42.76s/it][A100%|██████████| 1/1 [00:42<00:00, 42.76s/it]
 95%|█████████▌| 4951/5198 [1:20:53<2:26:02, 35.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:42<00:00, 42.77s/it][A100%|██████████| 1/1 [00:42<00:00, 42.77s/it]
 95%|█████████▌| 4951/5198 [1:20:56<2:26:05, 35.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:42<00:00, 42.82s/it][A100%|██████████| 1/1 [00:42<00:00, 42.82s/it]
 95%|█████████▌| 4951/5198 [1:20:49<2:26:06, 35.49s/it]
100%|██████████| 1/1 [00:42<00:00, 42.78s/it][A100%|██████████| 1/1 [00:42<00:00, 42.78s/it]
 95%|█████████▌| 4951/5198 [1:20:35<2:26:03, 35.48s/it]
100%|██████████| 1/1 [00:42<00:00, 42.77s/it][A100%|██████████| 1/1 [00:42<00:00, 42.78s/it]
 95%|█████████▌| 4951/5198 [1:20:39<2:26:03, 35.48s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4642

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.85s/it][A100%|██████████| 1/1 [00:30<00:00, 30.85s/it]
 95%|█████████▌| 4952/5198 [1:21:22<2:19:26, 34.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:19:07,475] [INFO] [logging.py:96:log_dist] [Rank 0] step=4951, skipped=0, lr=[4.6542314839753647e-07], mom=[(0.9, 0.999)]
steps: 4951 loss: 1.3934 iter time (s): 29.582 samples/sec: 4.327

100%|██████████| 1/1 [00:30<00:00, 30.50s/it][A100%|██████████| 1/1 [00:30<00:00, 30.50s/it]
 95%|█████████▌| 4952/5198 [1:21:33<2:19:11, 33.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.33s/it][A100%|██████████| 1/1 [00:30<00:00, 30.33s/it]
 95%|█████████▌| 4952/5198 [1:21:31<2:19:07, 33.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.25s/it][A100%|██████████| 1/1 [00:30<00:00, 30.25s/it]
 95%|█████████▌| 4952/5198 [1:21:23<2:19:02, 33.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.28s/it][A100%|██████████| 1/1 [00:30<00:00, 30.28s/it]
 95%|█████████▌| 4952/5198 [1:21:26<2:19:06, 33.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.25s/it][A100%|██████████| 1/1 [00:30<00:00, 30.25s/it]
 95%|█████████▌| 4952/5198 [1:21:20<2:19:04, 33.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.27s/it][A100%|██████████| 1/1 [00:30<00:00, 30.27s/it]
 95%|█████████▌| 4952/5198 [1:21:05<2:19:03, 33.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.28s/it][A100%|██████████| 1/1 [00:30<00:00, 30.28s/it]
 95%|█████████▌| 4952/5198 [1:21:10<2:19:04, 33.92s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4643
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.32s/it][A100%|██████████| 1/1 [00:35<00:00, 35.32s/it]
 95%|█████████▌| 4953/5198 [1:21:57<2:20:39, 34.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:19:43,184] [INFO] [logging.py:96:log_dist] [Rank 0] step=4952, skipped=0, lr=[4.642319709802626e-07], mom=[(0.9, 0.999)]
steps: 4952 loss: 1.4943 iter time (s): 35.009 samples/sec: 3.656

100%|██████████| 1/1 [00:35<00:00, 35.73s/it][A100%|██████████| 1/1 [00:35<00:00, 35.73s/it]
 95%|█████████▌| 4953/5198 [1:22:09<2:20:48, 34.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.80s/it][A100%|██████████| 1/1 [00:35<00:00, 35.80s/it]
 95%|█████████▌| 4953/5198 [1:22:07<2:20:51, 34.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.81s/it][A100%|██████████| 1/1 [00:35<00:00, 35.81s/it]
 95%|█████████▌| 4953/5198 [1:21:59<2:20:48, 34.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.69s/it][A100%|██████████| 1/1 [00:35<00:00, 35.69s/it]
 95%|█████████▌| 4953/5198 [1:22:02<2:20:43, 34.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.75s/it][A100%|██████████| 1/1 [00:35<00:00, 35.75s/it]
 95%|█████████▌| 4953/5198 [1:21:55<2:20:45, 34.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.78s/it][A100%|██████████| 1/1 [00:35<00:00, 35.78s/it]
 95%|█████████▌| 4953/5198 [1:21:41<2:20:47, 34.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.79s/it][A100%|██████████| 1/1 [00:35<00:00, 35.79s/it]
 95%|█████████▌| 4953/5198 [1:21:45<2:20:48, 34.48s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4644
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.66s/it][A100%|██████████| 1/1 [00:30<00:00, 30.66s/it]
 95%|█████████▌| 4954/5198 [1:22:28<2:15:44, 33.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:20:13,832] [INFO] [logging.py:96:log_dist] [Rank 0] step=4953, skipped=0, lr=[4.630422489103757e-07], mom=[(0.9, 0.999)]
steps: 4953 loss: 1.4956 iter time (s): 29.863 samples/sec: 4.286

100%|██████████| 1/1 [00:30<00:00, 30.56s/it][A100%|██████████| 1/1 [00:30<00:00, 30.57s/it]
 95%|█████████▌| 4954/5198 [1:22:40<2:15:28, 33.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.51s/it][A100%|██████████| 1/1 [00:30<00:00, 30.51s/it]
 95%|█████████▌| 4954/5198 [1:22:38<2:15:25, 33.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.50s/it][A100%|██████████| 1/1 [00:30<00:00, 30.50s/it]
 95%|█████████▌| 4954/5198 [1:22:29<2:15:22, 33.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.56s/it][A100%|██████████| 1/1 [00:30<00:00, 30.56s/it]
 95%|█████████▌| 4954/5198 [1:22:32<2:15:23, 33.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.52s/it][A100%|██████████| 1/1 [00:30<00:00, 30.52s/it]
 95%|█████████▌| 4954/5198 [1:22:11<2:15:23, 33.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.59s/it][A100%|██████████| 1/1 [00:30<00:00, 30.59s/it]
 95%|█████████▌| 4954/5198 [1:22:26<2:15:27, 33.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.53s/it][A100%|██████████| 1/1 [00:30<00:00, 30.53s/it]
 95%|█████████▌| 4954/5198 [1:22:16<2:15:24, 33.30s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4645
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.68s/it][A100%|██████████| 1/1 [00:28<00:00, 28.68s/it]
 95%|█████████▌| 4955/5198 [1:22:57<2:09:40, 32.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:20:42,696] [INFO] [logging.py:96:log_dist] [Rank 0] step=4954, skipped=0, lr=[4.618539825695688e-07], mom=[(0.9, 0.999)]
steps: 4954 loss: 1.4870 iter time (s): 28.189 samples/sec: 4.541

100%|██████████| 1/1 [00:28<00:00, 28.90s/it][A100%|██████████| 1/1 [00:28<00:00, 28.90s/it]
 95%|█████████▌| 4955/5198 [1:23:09<2:09:34, 31.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.79s/it][A100%|██████████| 1/1 [00:28<00:00, 28.79s/it]
 95%|█████████▌| 4955/5198 [1:23:07<2:09:23, 31.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.91s/it][A100%|██████████| 1/1 [00:28<00:00, 28.91s/it]
 95%|█████████▌| 4955/5198 [1:22:58<2:09:30, 31.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.84s/it][A100%|██████████| 1/1 [00:28<00:00, 28.84s/it]
 95%|█████████▌| 4955/5198 [1:23:01<2:09:26, 31.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.83s/it][A100%|██████████| 1/1 [00:28<00:00, 28.83s/it]
 95%|█████████▌| 4955/5198 [1:22:55<2:09:27, 31.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.85s/it][A100%|██████████| 1/1 [00:28<00:00, 28.86s/it]
 95%|█████████▌| 4955/5198 [1:22:40<2:09:27, 31.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.85s/it][A100%|██████████| 1/1 [00:28<00:00, 28.85s/it]
 95%|█████████▌| 4955/5198 [1:22:45<2:09:27, 31.97s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4646
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.37s/it][A100%|██████████| 1/1 [00:28<00:00, 28.37s/it]
 95%|█████████▌| 4956/5198 [1:23:25<2:04:58, 30.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:21:11,216] [INFO] [logging.py:96:log_dist] [Rank 0] step=4955, skipped=0, lr=[4.6066717233906604e-07], mom=[(0.9, 0.999)]
steps: 4955 loss: 1.4826 iter time (s): 27.856 samples/sec: 4.595

100%|██████████| 1/1 [00:28<00:00, 28.47s/it][A100%|██████████| 1/1 [00:28<00:00, 28.47s/it]
 95%|█████████▌| 4956/5198 [1:23:37<2:04:46, 30.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.51s/it][A100%|██████████| 1/1 [00:28<00:00, 28.51s/it]
 95%|█████████▌| 4956/5198 [1:23:35<2:04:42, 30.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.42s/it][A100%|██████████| 1/1 [00:28<00:00, 28.42s/it]
 95%|█████████▌| 4956/5198 [1:23:27<2:04:40, 30.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.54s/it][A100%|██████████| 1/1 [00:28<00:00, 28.54s/it]
 95%|█████████▌| 4956/5198 [1:23:30<2:04:46, 30.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.49s/it][A100%|██████████| 1/1 [00:28<00:00, 28.49s/it]
 95%|█████████▌| 4956/5198 [1:23:23<2:04:43, 30.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.50s/it][A100%|██████████| 1/1 [00:28<00:00, 28.50s/it]
 95%|█████████▌| 4956/5198 [1:23:13<2:04:44, 30.93s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4647
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.52s/it][A100%|██████████| 1/1 [00:28<00:00, 28.52s/it]
 95%|█████████▌| 4956/5198 [1:23:09<2:04:46, 30.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.68s/it][A100%|██████████| 1/1 [00:29<00:00, 29.69s/it]
 95%|█████████▌| 4957/5198 [1:23:55<2:03:06, 30.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:21:41,096] [INFO] [logging.py:96:log_dist] [Rank 0] step=4956, skipped=0, lr=[4.594818185996275e-07], mom=[(0.9, 0.999)]
steps: 4956 loss: 1.4481 iter time (s): 29.232 samples/sec: 4.379

100%|██████████| 1/1 [00:29<00:00, 29.84s/it][A100%|██████████| 1/1 [00:29<00:00, 29.84s/it]
 95%|█████████▌| 4957/5198 [1:24:07<2:02:57, 30.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.91s/it][A100%|██████████| 1/1 [00:29<00:00, 29.91s/it]
 95%|█████████▌| 4957/5198 [1:24:05<2:02:59, 30.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.93s/it][A100%|██████████| 1/1 [00:29<00:00, 29.93s/it]
 95%|█████████▌| 4957/5198 [1:23:57<2:03:00, 30.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.83s/it][A100%|██████████| 1/1 [00:29<00:00, 29.83s/it]
 95%|█████████▌| 4957/5198 [1:23:59<2:02:56, 30.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.89s/it][A100%|██████████| 1/1 [00:29<00:00, 29.89s/it]
 95%|█████████▌| 4957/5198 [1:23:53<2:02:58, 30.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.89s/it][A100%|██████████| 1/1 [00:29<00:00, 29.89s/it]
 95%|█████████▌| 4957/5198 [1:23:39<2:02:59, 30.62s/it]
100%|██████████| 1/1 [00:29<00:00, 29.90s/it][A100%|██████████| 1/1 [00:29<00:00, 29.90s/it]
 95%|█████████▌| 4957/5198 [1:23:43<2:02:59, 30.62s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4648

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.61s/it][A100%|██████████| 1/1 [00:31<00:00, 31.62s/it]
 95%|█████████▌| 4958/5198 [1:24:27<2:03:57, 30.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:22:12,974] [INFO] [logging.py:96:log_dist] [Rank 0] step=4957, skipped=0, lr=[4.5829792173154207e-07], mom=[(0.9, 0.999)]
steps: 4957 loss: 1.4994 iter time (s): 31.206 samples/sec: 4.102

100%|██████████| 1/1 [00:31<00:00, 31.97s/it][A100%|██████████| 1/1 [00:31<00:00, 31.97s/it]
 95%|█████████▌| 4958/5198 [1:24:39<2:04:05, 31.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.90s/it][A100%|██████████| 1/1 [00:31<00:00, 31.90s/it]
 95%|█████████▌| 4958/5198 [1:24:37<2:04:01, 31.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.94s/it][A100%|██████████| 1/1 [00:31<00:00, 31.94s/it]
 95%|█████████▌| 4958/5198 [1:24:29<2:04:04, 31.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.93s/it][A100%|██████████| 1/1 [00:31<00:00, 31.93s/it]
 95%|█████████▌| 4958/5198 [1:24:31<2:04:01, 31.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.92s/it][A100%|██████████| 1/1 [00:31<00:00, 31.92s/it]
 95%|█████████▌| 4958/5198 [1:24:25<2:04:02, 31.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.91s/it][A100%|██████████| 1/1 [00:31<00:00, 31.91s/it]
 95%|█████████▌| 4958/5198 [1:24:15<2:04:01, 31.01s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4649

100%|██████████| 1/1 [00:31<00:00, 31.91s/it][A100%|██████████| 1/1 [00:31<00:00, 31.91s/it]
 95%|█████████▌| 4958/5198 [1:24:10<2:04:02, 31.01s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.02s/it][A100%|██████████| 1/1 [00:31<00:00, 31.02s/it]
 95%|█████████▌| 4959/5198 [1:24:58<2:03:38, 31.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:22:44,131] [INFO] [logging.py:96:log_dist] [Rank 0] step=4958, skipped=0, lr=[4.5711548211463334e-07], mom=[(0.9, 0.999)]
steps: 4958 loss: 1.4298 iter time (s): 30.448 samples/sec: 4.204

100%|██████████| 1/1 [00:31<00:00, 31.14s/it][A100%|██████████| 1/1 [00:31<00:00, 31.14s/it]
 95%|█████████▌| 4959/5198 [1:25:10<2:03:43, 31.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.18s/it][A100%|██████████| 1/1 [00:31<00:00, 31.18s/it]
 95%|█████████▌| 4959/5198 [1:25:08<2:03:43, 31.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.08s/it][A100%|██████████| 1/1 [00:31<00:00, 31.08s/it]
 95%|█████████▌| 4959/5198 [1:25:00<2:03:39, 31.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.20s/it][A100%|██████████| 1/1 [00:31<00:00, 31.20s/it]
 95%|█████████▌| 4959/5198 [1:25:03<2:03:45, 31.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.14s/it][A100%|██████████| 1/1 [00:31<00:00, 31.14s/it]
 95%|█████████▌| 4959/5198 [1:24:42<2:03:40, 31.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.19s/it][A100%|██████████| 1/1 [00:31<00:00, 31.19s/it]
 95%|█████████▌| 4959/5198 [1:24:56<2:03:44, 31.06s/it]
100%|██████████| 1/1 [00:31<00:00, 31.16s/it][A100%|██████████| 1/1 [00:31<00:00, 31.16s/it]
 95%|█████████▌| 4959/5198 [1:24:46<2:03:42, 31.05s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_309

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:23<00:00, 23.83s/it][A100%|██████████| 1/1 [00:23<00:00, 23.83s/it]
 95%|█████████▌| 4960/5198 [1:25:22<1:54:46, 28.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:23:08,222] [INFO] [logging.py:96:log_dist] [Rank 0] step=4959, skipped=0, lr=[4.5593450012825836e-07], mom=[(0.9, 0.999)]
steps: 4959 loss: 1.9293 iter time (s): 23.405 samples/sec: 5.469

100%|██████████| 1/1 [00:24<00:00, 24.28s/it][A100%|██████████| 1/1 [00:24<00:00, 24.28s/it]
 95%|█████████▌| 4960/5198 [1:25:34<1:55:08, 29.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.34s/it][A100%|██████████| 1/1 [00:24<00:00, 24.34s/it]
 95%|█████████▌| 4960/5198 [1:25:32<1:55:13, 29.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.44s/it][A100%|██████████| 1/1 [00:24<00:00, 24.44s/it]
 95%|█████████▌| 4960/5198 [1:25:24<1:55:17, 29.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.47s/it][A100%|██████████| 1/1 [00:24<00:00, 24.48s/it]
 95%|█████████▌| 4960/5198 [1:25:27<1:55:24, 29.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.53s/it][A100%|██████████| 1/1 [00:24<00:00, 24.53s/it]
 95%|█████████▌| 4960/5198 [1:25:21<1:55:27, 29.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.57s/it][A100%|██████████| 1/1 [00:24<00:00, 24.57s/it]
 95%|█████████▌| 4960/5198 [1:25:06<1:55:27, 29.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.56s/it][A100%|██████████| 1/1 [00:24<00:00, 24.56s/it]
 95%|█████████▌| 4960/5198 [1:25:11<1:55:27, 29.11s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4650
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.94s/it][A100%|██████████| 1/1 [00:30<00:00, 30.94s/it]
 95%|█████████▌| 4961/5198 [1:25:53<1:56:49, 29.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:23:39,203] [INFO] [logging.py:96:log_dist] [Rank 0] step=4960, skipped=0, lr=[4.5475497615130493e-07], mom=[(0.9, 0.999)]
steps: 4960 loss: 1.4033 iter time (s): 29.798 samples/sec: 4.296

100%|██████████| 1/1 [00:30<00:00, 30.68s/it][A100%|██████████| 1/1 [00:30<00:00, 30.68s/it]
 95%|█████████▌| 4961/5198 [1:26:05<1:56:37, 29.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.64s/it][A100%|██████████| 1/1 [00:30<00:00, 30.64s/it]
 95%|█████████▌| 4961/5198 [1:26:03<1:56:38, 29.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.67s/it][A100%|██████████| 1/1 [00:30<00:00, 30.67s/it]
 95%|█████████▌| 4961/5198 [1:25:55<1:56:43, 29.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.57s/it][A100%|██████████| 1/1 [00:30<00:00, 30.57s/it]
 95%|█████████▌| 4961/5198 [1:25:58<1:56:41, 29.54s/it]
100%|██████████| 1/1 [00:30<00:00, 30.46s/it][A100%|██████████| 1/1 [00:30<00:00, 30.46s/it]
 95%|█████████▌| 4961/5198 [1:25:51<1:56:35, 29.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.50s/it][A100%|██████████| 1/1 [00:30<00:00, 30.50s/it]
 95%|█████████▌| 4961/5198 [1:25:37<1:56:38, 29.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.50s/it][A100%|██████████| 1/1 [00:30<00:00, 30.50s/it]
 95%|█████████▌| 4961/5198 [1:25:41<1:56:38, 29.53s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4651
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.11s/it][A100%|██████████| 1/1 [00:29<00:00, 29.11s/it]
 95%|█████████▌| 4962/5198 [1:26:23<1:55:57, 29.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:24:08,445] [INFO] [logging.py:96:log_dist] [Rank 0] step=4961, skipped=0, lr=[4.535769105621948e-07], mom=[(0.9, 0.999)]
steps: 4961 loss: 1.4376 iter time (s): 28.528 samples/sec: 4.487

100%|██████████| 1/1 [00:29<00:00, 29.29s/it][A100%|██████████| 1/1 [00:29<00:00, 29.29s/it]
 95%|█████████▌| 4962/5198 [1:26:34<1:55:51, 29.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.27s/it][A100%|██████████| 1/1 [00:29<00:00, 29.27s/it]
 95%|█████████▌| 4962/5198 [1:26:32<1:55:50, 29.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.16s/it][A100%|██████████| 1/1 [00:29<00:00, 29.16s/it]
 95%|█████████▌| 4962/5198 [1:26:24<1:55:47, 29.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.16s/it][A100%|██████████| 1/1 [00:29<00:00, 29.16s/it]
 95%|█████████▌| 4962/5198 [1:26:06<1:55:42, 29.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.22s/it][A100%|██████████| 1/1 [00:29<00:00, 29.22s/it]
 95%|█████████▌| 4962/5198 [1:26:27<1:55:49, 29.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.23s/it][A100%|██████████| 1/1 [00:29<00:00, 29.23s/it]
 95%|█████████▌| 4962/5198 [1:26:20<1:55:46, 29.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.20s/it][A100%|██████████| 1/1 [00:29<00:00, 29.20s/it]
 95%|█████████▌| 4962/5198 [1:26:11<1:55:45, 29.43s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4652
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.32s/it][A100%|██████████| 1/1 [00:31<00:00, 31.32s/it]
 95%|█████████▌| 4963/5198 [1:26:54<1:57:48, 30.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:24:39,946] [INFO] [logging.py:96:log_dist] [Rank 0] step=4962, skipped=0, lr=[4.5240030373887826e-07], mom=[(0.9, 0.999)]
steps: 4962 loss: 1.3706 iter time (s): 30.825 samples/sec: 4.152

100%|██████████| 1/1 [00:31<00:00, 31.50s/it][A100%|██████████| 1/1 [00:31<00:00, 31.50s/it]
 95%|█████████▌| 4963/5198 [1:27:06<1:57:47, 30.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.47s/it][A100%|██████████| 1/1 [00:31<00:00, 31.47s/it]
 95%|█████████▌| 4963/5198 [1:27:04<1:57:43, 30.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.52s/it][A100%|██████████| 1/1 [00:31<00:00, 31.52s/it]
 95%|█████████▌| 4963/5198 [1:26:56<1:57:45, 30.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.43s/it][A100%|██████████| 1/1 [00:31<00:00, 31.43s/it]
 95%|█████████▌| 4963/5198 [1:26:58<1:57:40, 30.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.50s/it][A100%|██████████| 1/1 [00:31<00:00, 31.50s/it]
 95%|█████████▌| 4963/5198 [1:26:52<1:57:43, 30.06s/it]
100%|██████████| 1/1 [00:31<00:00, 31.52s/it][A100%|██████████| 1/1 [00:31<00:00, 31.53s/it]
 95%|█████████▌| 4963/5198 [1:26:37<1:57:42, 30.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.51s/it][A100%|██████████| 1/1 [00:31<00:00, 31.51s/it]
 95%|█████████▌| 4963/5198 [1:26:42<1:57:42, 30.05s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4653
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.25s/it][A100%|██████████| 1/1 [00:29<00:00, 29.25s/it]
 95%|█████████▌| 4964/5198 [1:27:24<1:56:34, 29.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:25:09,359] [INFO] [logging.py:96:log_dist] [Rank 0] step=4963, skipped=0, lr=[4.5122515605884174e-07], mom=[(0.9, 0.999)]
steps: 4963 loss: 1.4582 iter time (s): 28.725 samples/sec: 4.456

100%|██████████| 1/1 [00:29<00:00, 29.54s/it][A100%|██████████| 1/1 [00:29<00:00, 29.54s/it]
 95%|█████████▌| 4964/5198 [1:27:35<1:56:40, 29.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.41s/it][A100%|██████████| 1/1 [00:29<00:00, 29.42s/it]
 95%|█████████▌| 4964/5198 [1:27:25<1:56:30, 29.87s/it]
100%|██████████| 1/1 [00:29<00:00, 29.56s/it][A100%|██████████| 1/1 [00:29<00:00, 29.56s/it]
 95%|█████████▌| 4964/5198 [1:27:33<1:56:39, 29.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.46s/it][A100%|██████████| 1/1 [00:29<00:00, 29.46s/it]
 95%|█████████▌| 4964/5198 [1:27:28<1:56:29, 29.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.46s/it][A100%|██████████| 1/1 [00:29<00:00, 29.46s/it]
 95%|█████████▌| 4964/5198 [1:27:21<1:56:31, 29.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.46s/it][A100%|██████████| 1/1 [00:29<00:00, 29.46s/it]
 95%|█████████▌| 4964/5198 [1:27:07<1:56:31, 29.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.46s/it][A100%|██████████| 1/1 [00:29<00:00, 29.46s/it]
 95%|█████████▌| 4964/5198 [1:27:12<1:56:31, 29.88s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4654
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.58s/it][A100%|██████████| 1/1 [00:30<00:00, 30.58s/it]
 96%|█████████▌| 4965/5198 [1:27:54<1:57:02, 30.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:25:40,118] [INFO] [logging.py:96:log_dist] [Rank 0] step=4964, skipped=0, lr=[4.5005146789910145e-07], mom=[(0.9, 0.999)]
steps: 4964 loss: 1.4478 iter time (s): 30.016 samples/sec: 4.264

100%|██████████| 1/1 [00:30<00:00, 30.60s/it][A100%|██████████| 1/1 [00:30<00:00, 30.60s/it]
 96%|█████████▌| 4965/5198 [1:28:06<1:56:59, 30.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.62s/it][A100%|██████████| 1/1 [00:30<00:00, 30.62s/it]
 96%|█████████▌| 4965/5198 [1:28:04<1:57:00, 30.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.75s/it][A100%|██████████| 1/1 [00:30<00:00, 30.75s/it]
 96%|█████████▌| 4965/5198 [1:27:56<1:57:02, 30.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.74s/it][A100%|██████████| 1/1 [00:30<00:00, 30.74s/it]
 96%|█████████▌| 4965/5198 [1:27:58<1:57:01, 30.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.76s/it][A100%|██████████| 1/1 [00:30<00:00, 30.76s/it]
 96%|█████████▌| 4965/5198 [1:27:52<1:57:03, 30.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.77s/it][A100%|██████████| 1/1 [00:30<00:00, 30.77s/it]
 96%|█████████▌| 4965/5198 [1:27:38<1:57:04, 30.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.77s/it][A100%|██████████| 1/1 [00:30<00:00, 30.77s/it]
 96%|█████████▌| 4965/5198 [1:27:42<1:57:04, 30.15s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4655
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.86s/it][A100%|██████████| 1/1 [00:29<00:00, 29.86s/it]
 96%|█████████▌| 4966/5198 [1:28:24<1:56:21, 30.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:26:10,066] [INFO] [logging.py:96:log_dist] [Rank 0] step=4965, skipped=0, lr=[4.4887923963620515e-07], mom=[(0.9, 0.999)]
steps: 4965 loss: 1.4535 iter time (s): 29.189 samples/sec: 4.385

100%|██████████| 1/1 [00:30<00:00, 30.00s/it][A100%|██████████| 1/1 [00:30<00:00, 30.00s/it]
 96%|█████████▌| 4966/5198 [1:28:36<1:56:21, 30.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.99s/it][A100%|██████████| 1/1 [00:29<00:00, 29.99s/it]
 96%|█████████▌| 4966/5198 [1:28:34<1:56:21, 30.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.97s/it][A100%|██████████| 1/1 [00:29<00:00, 29.97s/it]
 96%|█████████▌| 4966/5198 [1:28:26<1:56:20, 30.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.99s/it][A100%|██████████| 1/1 [00:29<00:00, 29.99s/it]
 96%|█████████▌| 4966/5198 [1:28:29<1:56:22, 30.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.94s/it][A100%|██████████| 1/1 [00:29<00:00, 29.94s/it]
 96%|█████████▌| 4966/5198 [1:28:08<1:56:20, 30.09s/it]
100%|██████████| 1/1 [00:29<00:00, 29.97s/it][A100%|██████████| 1/1 [00:29<00:00, 29.97s/it]
 96%|█████████▌| 4966/5198 [1:28:22<1:56:21, 30.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.95s/it][A100%|██████████| 1/1 [00:29<00:00, 29.95s/it]
 96%|█████████▌| 4966/5198 [1:28:12<1:56:20, 30.09s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4656
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.71s/it][A100%|██████████| 1/1 [00:29<00:00, 29.71s/it]
 96%|█████████▌| 4967/5198 [1:28:54<1:55:33, 30.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:26:39,880] [INFO] [logging.py:96:log_dist] [Rank 0] step=4966, skipped=0, lr=[4.477084716462333e-07], mom=[(0.9, 0.999)]
steps: 4966 loss: 1.4902 iter time (s): 29.050 samples/sec: 4.406

100%|██████████| 1/1 [00:29<00:00, 29.68s/it][A100%|██████████| 1/1 [00:29<00:00, 29.68s/it]
 96%|█████████▌| 4967/5198 [1:29:06<1:55:23, 29.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.72s/it][A100%|██████████| 1/1 [00:29<00:00, 29.72s/it]
 96%|█████████▌| 4967/5198 [1:29:04<1:55:25, 29.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.71s/it][A100%|██████████| 1/1 [00:29<00:00, 29.72s/it]
 96%|█████████▌| 4967/5198 [1:28:56<1:55:25, 29.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.68s/it][A100%|██████████| 1/1 [00:29<00:00, 29.68s/it]
 96%|█████████▌| 4967/5198 [1:28:58<1:55:23, 29.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.65s/it][A100%|██████████| 1/1 [00:29<00:00, 29.65s/it]
 96%|█████████▌| 4967/5198 [1:28:52<1:55:21, 29.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.69s/it][A100%|██████████| 1/1 [00:29<00:00, 29.69s/it]
 96%|█████████▌| 4967/5198 [1:28:37<1:55:23, 29.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.69s/it][A100%|██████████| 1/1 [00:29<00:00, 29.69s/it]
 96%|█████████▌| 4967/5198 [1:28:42<1:55:23, 29.97s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4657
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.03s/it][A100%|██████████| 1/1 [00:30<00:00, 30.03s/it]
 96%|█████████▌| 4968/5198 [1:29:24<1:55:16, 30.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:27:10,135] [INFO] [logging.py:96:log_dist] [Rank 0] step=4967, skipped=0, lr=[4.465391643047983e-07], mom=[(0.9, 0.999)]
steps: 4967 loss: 1.5095 iter time (s): 29.612 samples/sec: 4.323

100%|██████████| 1/1 [00:30<00:00, 30.26s/it][A100%|██████████| 1/1 [00:30<00:00, 30.26s/it]
 96%|█████████▌| 4968/5198 [1:29:36<1:55:14, 30.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.24s/it][A100%|██████████| 1/1 [00:30<00:00, 30.24s/it]
 96%|█████████▌| 4968/5198 [1:29:34<1:55:13, 30.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.31s/it][A100%|██████████| 1/1 [00:30<00:00, 30.31s/it]
 96%|█████████▌| 4968/5198 [1:29:26<1:55:19, 30.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.31s/it][A100%|██████████| 1/1 [00:30<00:00, 30.31s/it]
 96%|█████████▌| 4968/5198 [1:29:29<1:55:17, 30.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.36s/it][A100%|██████████| 1/1 [00:30<00:00, 30.36s/it]
 96%|█████████▌| 4968/5198 [1:29:22<1:55:19, 30.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.33s/it][A100%|██████████| 1/1 [00:30<00:00, 30.33s/it]
 96%|█████████▌| 4968/5198 [1:29:08<1:55:18, 30.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.33s/it][A100%|██████████| 1/1 [00:30<00:00, 30.33s/it]
 96%|█████████▌| 4968/5198 [1:29:12<1:55:18, 30.08s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4658
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.95s/it][A100%|██████████| 1/1 [00:31<00:00, 31.95s/it]
 96%|█████████▌| 4969/5198 [1:29:56<1:57:03, 30.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:27:42,256] [INFO] [logging.py:96:log_dist] [Rank 0] step=4968, skipped=0, lr=[4.453713179870409e-07], mom=[(0.9, 0.999)]
steps: 4968 loss: 1.4207 iter time (s): 31.404 samples/sec: 4.076

100%|██████████| 1/1 [00:32<00:00, 32.21s/it][A100%|██████████| 1/1 [00:32<00:00, 32.21s/it]
 96%|█████████▌| 4969/5198 [1:30:08<1:57:12, 30.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.18s/it][A100%|██████████| 1/1 [00:32<00:00, 32.18s/it]
 96%|█████████▌| 4969/5198 [1:30:06<1:57:09, 30.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.09s/it][A100%|██████████| 1/1 [00:32<00:00, 32.09s/it]
 96%|█████████▌| 4969/5198 [1:29:58<1:57:07, 30.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.11s/it][A100%|██████████| 1/1 [00:32<00:00, 32.11s/it]
 96%|█████████▌| 4969/5198 [1:30:01<1:57:07, 30.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.05s/it][A100%|██████████| 1/1 [00:32<00:00, 32.06s/it]
 96%|█████████▌| 4969/5198 [1:29:54<1:57:05, 30.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.09s/it][A100%|██████████| 1/1 [00:32<00:00, 32.09s/it]
 96%|█████████▌| 4969/5198 [1:29:40<1:57:07, 30.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.09s/it][A100%|██████████| 1/1 [00:32<00:00, 32.09s/it]
 96%|█████████▌| 4969/5198 [1:29:44<1:57:06, 30.68s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4659
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.21s/it][A100%|██████████| 1/1 [00:32<00:00, 32.21s/it]
 96%|█████████▌| 4970/5198 [1:30:29<1:58:26, 31.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:28:14,559] [INFO] [logging.py:96:log_dist] [Rank 0] step=4969, skipped=0, lr=[4.4420493306763624e-07], mom=[(0.9, 0.999)]
steps: 4969 loss: 1.4375 iter time (s): 31.602 samples/sec: 4.050

100%|██████████| 1/1 [00:32<00:00, 32.27s/it][A100%|██████████| 1/1 [00:32<00:00, 32.27s/it]
 96%|█████████▌| 4970/5198 [1:30:40<1:58:29, 31.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.34s/it][A100%|██████████| 1/1 [00:32<00:00, 32.34s/it]
 96%|█████████▌| 4970/5198 [1:30:39<1:58:32, 31.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.36s/it][A100%|██████████| 1/1 [00:32<00:00, 32.36s/it]
 96%|█████████▌| 4970/5198 [1:30:30<1:58:32, 31.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.30s/it][A100%|██████████| 1/1 [00:32<00:00, 32.30s/it]
 96%|█████████▌| 4970/5198 [1:30:33<1:58:28, 31.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.34s/it][A100%|██████████| 1/1 [00:32<00:00, 32.34s/it]
 96%|█████████▌| 4970/5198 [1:30:12<1:58:30, 31.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.40s/it][A100%|██████████| 1/1 [00:32<00:00, 32.40s/it]
 96%|█████████▌| 4970/5198 [1:30:27<1:58:32, 31.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.37s/it][A100%|██████████| 1/1 [00:32<00:00, 32.37s/it]
 96%|█████████▌| 4970/5198 [1:30:17<1:58:31, 31.19s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4660
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.58s/it][A100%|██████████| 1/1 [00:30<00:00, 30.58s/it]
 96%|█████████▌| 4971/5198 [1:30:59<1:57:25, 31.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:28:45,256] [INFO] [logging.py:96:log_dist] [Rank 0] step=4970, skipped=0, lr=[4.4304000992078904e-07], mom=[(0.9, 0.999)]
steps: 4970 loss: 1.4966 iter time (s): 29.931 samples/sec: 4.276

100%|██████████| 1/1 [00:30<00:00, 30.75s/it][A100%|██████████| 1/1 [00:30<00:00, 30.75s/it]
 96%|█████████▌| 4971/5198 [1:31:11<1:57:29, 31.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.67s/it][A100%|██████████| 1/1 [00:30<00:00, 30.67s/it]
 96%|█████████▌| 4971/5198 [1:31:09<1:57:26, 31.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.72s/it][A100%|██████████| 1/1 [00:30<00:00, 30.72s/it]
 96%|█████████▌| 4971/5198 [1:31:01<1:57:29, 31.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.73s/it][A100%|██████████| 1/1 [00:30<00:00, 30.73s/it]
 96%|█████████▌| 4971/5198 [1:31:04<1:57:27, 31.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.71s/it][A100%|██████████| 1/1 [00:30<00:00, 30.71s/it]
 96%|█████████▌| 4971/5198 [1:30:57<1:57:29, 31.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.75s/it][A100%|██████████| 1/1 [00:30<00:00, 30.75s/it]
 96%|█████████▌| 4971/5198 [1:30:43<1:57:29, 31.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.72s/it][A100%|██████████| 1/1 [00:30<00:00, 30.72s/it]
 96%|█████████▌| 4971/5198 [1:30:48<1:57:28, 31.05s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4661
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.41s/it][A100%|██████████| 1/1 [00:28<00:00, 28.41s/it]
 96%|█████████▌| 4972/5198 [1:31:28<1:54:06, 30.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:29:13,759] [INFO] [logging.py:96:log_dist] [Rank 0] step=4971, skipped=0, lr=[4.418765489202369e-07], mom=[(0.9, 0.999)]
steps: 4971 loss: 1.4993 iter time (s): 27.707 samples/sec: 4.620

100%|██████████| 1/1 [00:28<00:00, 28.38s/it][A100%|██████████| 1/1 [00:28<00:00, 28.38s/it]
 96%|█████████▌| 4972/5198 [1:31:40<1:53:57, 30.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.43s/it][A100%|██████████| 1/1 [00:28<00:00, 28.43s/it]
 96%|█████████▌| 4972/5198 [1:31:38<1:53:58, 30.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.38s/it][A100%|██████████| 1/1 [00:28<00:00, 28.39s/it]
 96%|█████████▌| 4972/5198 [1:31:29<1:53:58, 30.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.39s/it][A100%|██████████| 1/1 [00:28<00:00, 28.39s/it]
 96%|█████████▌| 4972/5198 [1:31:32<1:53:56, 30.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.34s/it][A100%|██████████| 1/1 [00:28<00:00, 28.34s/it]
 96%|█████████▌| 4972/5198 [1:31:26<1:53:54, 30.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.34s/it][A100%|██████████| 1/1 [00:28<00:00, 28.34s/it]
 96%|█████████▌| 4972/5198 [1:31:11<1:53:54, 30.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.34s/it][A100%|██████████| 1/1 [00:28<00:00, 28.34s/it]
 96%|█████████▌| 4972/5198 [1:31:16<1:53:54, 30.24s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4662
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.36s/it][A100%|██████████| 1/1 [00:28<00:00, 28.36s/it]
 96%|█████████▌| 4973/5198 [1:31:56<1:51:33, 29.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:29:42,227] [INFO] [logging.py:96:log_dist] [Rank 0] step=4972, skipped=0, lr=[4.407145504392455e-07], mom=[(0.9, 0.999)]
steps: 4972 loss: 1.5131 iter time (s): 27.824 samples/sec: 4.600

100%|██████████| 1/1 [00:28<00:00, 28.39s/it][A100%|██████████| 1/1 [00:28<00:00, 28.39s/it]
 96%|█████████▌| 4973/5198 [1:32:08<1:51:21, 29.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.42s/it][A100%|██████████| 1/1 [00:28<00:00, 28.42s/it]
 96%|█████████▌| 4973/5198 [1:32:06<1:51:24, 29.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.42s/it][A100%|██████████| 1/1 [00:28<00:00, 28.42s/it]
 96%|█████████▌| 4973/5198 [1:31:58<1:51:24, 29.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.50s/it][A100%|██████████| 1/1 [00:28<00:00, 28.50s/it]
 96%|█████████▌| 4973/5198 [1:32:01<1:51:28, 29.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.45s/it][A100%|██████████| 1/1 [00:28<00:00, 28.45s/it]
 96%|█████████▌| 4973/5198 [1:31:54<1:51:24, 29.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.46s/it][A100%|██████████| 1/1 [00:28<00:00, 28.46s/it]
 96%|█████████▌| 4973/5198 [1:31:40<1:51:24, 29.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.46s/it][A100%|██████████| 1/1 [00:28<00:00, 28.47s/it]
 96%|█████████▌| 4973/5198 [1:31:44<1:51:24, 29.71s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4663
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.82s/it][A100%|██████████| 1/1 [00:33<00:00, 33.82s/it]
 96%|█████████▌| 4974/5198 [1:32:30<1:55:48, 31.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:30:16,427] [INFO] [logging.py:96:log_dist] [Rank 0] step=4973, skipped=0, lr=[4.3955401485061324e-07], mom=[(0.9, 0.999)]
steps: 4973 loss: 1.4763 iter time (s): 33.555 samples/sec: 3.815

100%|██████████| 1/1 [00:34<00:00, 34.31s/it][A100%|██████████| 1/1 [00:34<00:00, 34.31s/it]
 96%|█████████▌| 4974/5198 [1:32:42<1:56:02, 31.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.38s/it][A100%|██████████| 1/1 [00:34<00:00, 34.38s/it]
 96%|█████████▌| 4974/5198 [1:32:41<1:56:09, 31.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.35s/it][A100%|██████████| 1/1 [00:34<00:00, 34.35s/it]
 96%|█████████▌| 4974/5198 [1:32:32<1:56:07, 31.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.30s/it][A100%|██████████| 1/1 [00:34<00:00, 34.30s/it]
 96%|█████████▌| 4974/5198 [1:32:35<1:56:06, 31.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.37s/it][A100%|██████████| 1/1 [00:34<00:00, 34.37s/it]
 96%|█████████▌| 4974/5198 [1:32:29<1:56:08, 31.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.38s/it][A100%|██████████| 1/1 [00:34<00:00, 34.38s/it]
 96%|█████████▌| 4974/5198 [1:32:14<1:56:08, 31.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.37s/it][A100%|██████████| 1/1 [00:34<00:00, 34.37s/it]
 96%|█████████▌| 4974/5198 [1:32:19<1:56:08, 31.11s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4664
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.19s/it][A100%|██████████| 1/1 [00:29<00:00, 29.19s/it]
 96%|█████████▌| 4975/5198 [1:33:00<1:53:24, 30.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:30:45,578] [INFO] [logging.py:96:log_dist] [Rank 0] step=4974, skipped=0, lr=[4.3839494252666945e-07], mom=[(0.9, 0.999)]
steps: 4974 loss: 1.5594 iter time (s): 28.335 samples/sec: 4.517

100%|██████████| 1/1 [00:29<00:00, 29.11s/it][A100%|██████████| 1/1 [00:29<00:00, 29.11s/it]
 96%|█████████▌| 4975/5198 [1:33:11<1:53:19, 30.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.09s/it][A100%|██████████| 1/1 [00:29<00:00, 29.09s/it]
 96%|█████████▌| 4975/5198 [1:33:10<1:53:23, 30.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.01s/it][A100%|██████████| 1/1 [00:29<00:00, 29.01s/it]
 96%|█████████▌| 4975/5198 [1:33:01<1:53:16, 30.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.05s/it][A100%|██████████| 1/1 [00:29<00:00, 29.05s/it]
 96%|█████████▌| 4975/5198 [1:33:04<1:53:18, 30.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.02s/it][A100%|██████████| 1/1 [00:29<00:00, 29.02s/it]
 96%|█████████▌| 4975/5198 [1:32:58<1:53:18, 30.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.01s/it][A100%|██████████| 1/1 [00:29<00:00, 29.01s/it]
 96%|█████████▌| 4975/5198 [1:32:48<1:53:17, 30.48s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_310
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.03s/it][A100%|██████████| 1/1 [00:29<00:00, 29.03s/it]
 96%|█████████▌| 4975/5198 [1:32:43<1:53:19, 30.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:23<00:00, 23.45s/it][A100%|██████████| 1/1 [00:23<00:00, 23.45s/it]
 96%|█████████▌| 4976/5198 [1:33:23<1:45:14, 28.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:31:09,306] [INFO] [logging.py:96:log_dist] [Rank 0] step=4975, skipped=0, lr=[4.3723733383927283e-07], mom=[(0.9, 0.999)]
steps: 4975 loss: 1.9534 iter time (s): 23.072 samples/sec: 5.548

100%|██████████| 1/1 [00:23<00:00, 23.94s/it][A100%|██████████| 1/1 [00:23<00:00, 23.94s/it]
 96%|█████████▌| 4976/5198 [1:33:35<1:45:33, 28.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:23<00:00, 23.88s/it][A100%|██████████| 1/1 [00:23<00:00, 23.88s/it]
 96%|█████████▌| 4976/5198 [1:33:33<1:45:31, 28.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.04s/it][A100%|██████████| 1/1 [00:24<00:00, 24.04s/it]
 96%|█████████▌| 4976/5198 [1:33:25<1:45:38, 28.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.06s/it][A100%|██████████| 1/1 [00:24<00:00, 24.06s/it]
 96%|█████████▌| 4976/5198 [1:33:28<1:45:40, 28.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.11s/it][A100%|██████████| 1/1 [00:24<00:00, 24.11s/it]
 96%|█████████▌| 4976/5198 [1:33:07<1:45:44, 28.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.16s/it][A100%|██████████| 1/1 [00:24<00:00, 24.16s/it]
 96%|█████████▌| 4976/5198 [1:33:22<1:45:46, 28.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.15s/it][A100%|██████████| 1/1 [00:24<00:00, 24.15s/it]
 96%|█████████▌| 4976/5198 [1:33:12<1:45:45, 28.58s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4665
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:40<00:00, 40.93s/it][A100%|██████████| 1/1 [00:40<00:00, 40.93s/it]
 96%|█████████▌| 4977/5198 [1:34:05<1:58:46, 32.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:31:50,659] [INFO] [logging.py:96:log_dist] [Rank 0] step=4976, skipped=0, lr=[4.360811891598124e-07], mom=[(0.9, 0.999)]
steps: 4976 loss: 1.3630 iter time (s): 40.245 samples/sec: 3.181

100%|██████████| 1/1 [00:41<00:00, 41.32s/it][A100%|██████████| 1/1 [00:41<00:00, 41.32s/it]
 96%|█████████▌| 4977/5198 [1:34:17<1:59:14, 32.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:41<00:00, 41.32s/it][A100%|██████████| 1/1 [00:41<00:00, 41.32s/it]
 96%|█████████▌| 4977/5198 [1:34:15<1:59:12, 32.36s/it]
100%|██████████| 1/1 [00:41<00:00, 41.16s/it][A100%|██████████| 1/1 [00:41<00:00, 41.16s/it]
 96%|█████████▌| 4977/5198 [1:34:06<1:59:06, 32.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:41<00:00, 41.16s/it][A100%|██████████| 1/1 [00:41<00:00, 41.16s/it]
 96%|█████████▌| 4977/5198 [1:34:09<1:59:07, 32.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:41<00:00, 41.08s/it][A100%|██████████| 1/1 [00:41<00:00, 41.08s/it]
 96%|█████████▌| 4977/5198 [1:34:03<1:59:07, 32.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:41<00:00, 41.22s/it][A100%|██████████| 1/1 [00:41<00:00, 41.22s/it]
 96%|█████████▌| 4977/5198 [1:33:48<1:59:14, 32.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:41<00:00, 41.98s/it][A100%|██████████| 1/1 [00:41<00:00, 41.98s/it]
 96%|█████████▌| 4977/5198 [1:33:54<2:00:05, 32.61s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4666
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.62s/it][A100%|██████████| 1/1 [00:31<00:00, 31.62s/it]
 96%|█████████▌| 4978/5198 [1:34:36<1:57:47, 32.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:32:22,165] [INFO] [logging.py:96:log_dist] [Rank 0] step=4977, skipped=0, lr=[4.3492650885920876e-07], mom=[(0.9, 0.999)]
steps: 4977 loss: 1.4904 iter time (s): 29.752 samples/sec: 4.302

100%|██████████| 1/1 [00:31<00:00, 31.43s/it][A100%|██████████| 1/1 [00:31<00:00, 31.43s/it]
 96%|█████████▌| 4978/5198 [1:34:48<1:57:40, 32.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.36s/it][A100%|██████████| 1/1 [00:31<00:00, 31.36s/it]
 96%|█████████▌| 4978/5198 [1:34:46<1:57:36, 32.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.41s/it][A100%|██████████| 1/1 [00:31<00:00, 31.41s/it]
 96%|█████████▌| 4978/5198 [1:34:38<1:57:33, 32.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.44s/it][A100%|██████████| 1/1 [00:31<00:00, 31.44s/it]
 96%|█████████▌| 4978/5198 [1:34:41<1:57:36, 32.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.29s/it][A100%|██████████| 1/1 [00:31<00:00, 31.29s/it]
 96%|█████████▌| 4978/5198 [1:34:20<1:57:31, 32.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.42s/it][A100%|██████████| 1/1 [00:31<00:00, 31.42s/it]
 96%|█████████▌| 4978/5198 [1:34:34<1:57:35, 32.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.55s/it][A100%|██████████| 1/1 [00:30<00:00, 30.55s/it]
 96%|█████████▌| 4978/5198 [1:34:24<1:57:18, 31.99s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4667
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.64s/it][A100%|██████████| 1/1 [00:31<00:00, 31.64s/it]
 96%|█████████▌| 4979/5198 [1:35:08<1:56:52, 32.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:32:53,986] [INFO] [logging.py:96:log_dist] [Rank 0] step=4978, skipped=0, lr=[4.33773293307913e-07], mom=[(0.9, 0.999)]
steps: 4978 loss: 1.5371 iter time (s): 31.016 samples/sec: 4.127

100%|██████████| 1/1 [00:31<00:00, 31.69s/it][A100%|██████████| 1/1 [00:31<00:00, 31.69s/it]
 96%|█████████▌| 4979/5198 [1:35:20<1:56:42, 31.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.71s/it][A100%|██████████| 1/1 [00:31<00:00, 31.71s/it]
 96%|█████████▌| 4979/5198 [1:35:18<1:56:41, 31.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.78s/it][A100%|██████████| 1/1 [00:31<00:00, 31.78s/it]
 96%|█████████▌| 4979/5198 [1:35:10<1:56:43, 31.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.65s/it][A100%|██████████| 1/1 [00:31<00:00, 31.65s/it]
 96%|█████████▌| 4979/5198 [1:35:12<1:56:37, 31.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.69s/it][A100%|██████████| 1/1 [00:31<00:00, 31.69s/it]
 96%|█████████▌| 4979/5198 [1:35:06<1:56:38, 31.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.73s/it][A100%|██████████| 1/1 [00:31<00:00, 31.73s/it]
 96%|█████████▌| 4979/5198 [1:34:51<1:56:38, 31.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.70s/it][A100%|██████████| 1/1 [00:31<00:00, 31.70s/it]
 96%|█████████▌| 4979/5198 [1:34:56<1:56:27, 31.91s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4668
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.33s/it][A100%|██████████| 1/1 [00:35<00:00, 35.33s/it]
 96%|█████████▌| 4980/5198 [1:35:44<2:00:07, 33.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:33:29,669] [INFO] [logging.py:96:log_dist] [Rank 0] step=4979, skipped=0, lr=[4.3262154287590327e-07], mom=[(0.9, 0.999)]
steps: 4979 loss: 1.4231 iter time (s): 34.990 samples/sec: 3.658

100%|██████████| 1/1 [00:35<00:00, 35.66s/it][A100%|██████████| 1/1 [00:35<00:00, 35.66s/it]
 96%|█████████▌| 4980/5198 [1:35:55<2:00:12, 33.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.70s/it][A100%|██████████| 1/1 [00:35<00:00, 35.70s/it]
 96%|█████████▌| 4980/5198 [1:35:54<2:00:13, 33.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.73s/it][A100%|██████████| 1/1 [00:35<00:00, 35.73s/it]
 96%|█████████▌| 4980/5198 [1:35:45<2:00:17, 33.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.87s/it][A100%|██████████| 1/1 [00:35<00:00, 35.87s/it]
 96%|█████████▌| 4980/5198 [1:35:48<2:00:22, 33.13s/it]
100%|██████████| 1/1 [00:35<00:00, 35.77s/it][A100%|██████████| 1/1 [00:35<00:00, 35.77s/it]
 96%|█████████▌| 4980/5198 [1:35:42<2:00:16, 33.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.78s/it][A100%|██████████| 1/1 [00:35<00:00, 35.78s/it]
 96%|█████████▌| 4980/5198 [1:35:27<2:00:17, 33.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.78s/it][A100%|██████████| 1/1 [00:35<00:00, 35.78s/it]
 96%|█████████▌| 4980/5198 [1:35:32<2:00:09, 33.07s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4669
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.87s/it][A100%|██████████| 1/1 [00:30<00:00, 30.87s/it]
 96%|█████████▌| 4981/5198 [1:36:15<1:57:21, 32.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:34:00,407] [INFO] [logging.py:96:log_dist] [Rank 0] step=4980, skipped=0, lr=[4.3147125793269026e-07], mom=[(0.9, 0.999)]
steps: 4980 loss: 1.5705 iter time (s): 29.938 samples/sec: 4.275

100%|██████████| 1/1 [00:30<00:00, 30.82s/it][A100%|██████████| 1/1 [00:30<00:00, 30.82s/it]
 96%|█████████▌| 4981/5198 [1:36:26<1:57:12, 32.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.73s/it][A100%|██████████| 1/1 [00:30<00:00, 30.73s/it]
 96%|█████████▌| 4981/5198 [1:36:24<1:57:07, 32.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.69s/it][A100%|██████████| 1/1 [00:30<00:00, 30.69s/it]
 96%|█████████▌| 4981/5198 [1:36:16<1:57:07, 32.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.62s/it][A100%|██████████| 1/1 [00:30<00:00, 30.62s/it]
 96%|█████████▌| 4981/5198 [1:36:19<1:57:06, 32.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.67s/it][A100%|██████████| 1/1 [00:30<00:00, 30.67s/it]
 96%|█████████▌| 4981/5198 [1:36:12<1:57:05, 32.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.67s/it][A100%|██████████| 1/1 [00:30<00:00, 30.67s/it]
 96%|█████████▌| 4981/5198 [1:35:58<1:57:05, 32.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.67s/it][A100%|██████████| 1/1 [00:30<00:00, 30.67s/it]
 96%|█████████▌| 4981/5198 [1:36:03<1:57:00, 32.35s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4670
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.49s/it][A100%|██████████| 1/1 [00:34<00:00, 34.49s/it]
 96%|█████████▌| 4982/5198 [1:36:49<1:59:14, 33.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:34:35,343] [INFO] [logging.py:96:log_dist] [Rank 0] step=4981, skipped=0, lr=[4.303224388473147e-07], mom=[(0.9, 0.999)]
steps: 4981 loss: 1.5386 iter time (s): 34.203 samples/sec: 3.742

100%|██████████| 1/1 [00:34<00:00, 34.86s/it][A100%|██████████| 1/1 [00:34<00:00, 34.86s/it]
 96%|█████████▌| 4982/5198 [1:37:01<1:59:20, 33.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.90s/it][A100%|██████████| 1/1 [00:34<00:00, 34.90s/it]
 96%|█████████▌| 4982/5198 [1:36:59<1:59:18, 33.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.97s/it][A100%|██████████| 1/1 [00:34<00:00, 34.97s/it]
 96%|█████████▌| 4982/5198 [1:36:51<1:59:22, 33.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.91s/it][A100%|██████████| 1/1 [00:34<00:00, 34.91s/it]
 96%|█████████▌| 4982/5198 [1:36:54<1:59:18, 33.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.95s/it][A100%|██████████| 1/1 [00:34<00:00, 34.95s/it]
 96%|█████████▌| 4982/5198 [1:36:33<1:59:20, 33.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.99s/it][A100%|██████████| 1/1 [00:34<00:00, 34.99s/it]
 96%|█████████▌| 4982/5198 [1:36:47<1:59:23, 33.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.97s/it][A100%|██████████| 1/1 [00:34<00:00, 34.97s/it]
 96%|█████████▌| 4982/5198 [1:36:38<1:59:18, 33.14s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4671
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.34s/it][A100%|██████████| 1/1 [00:32<00:00, 32.34s/it]
 96%|█████████▌| 4983/5198 [1:37:22<1:58:00, 32.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:35:07,636] [INFO] [logging.py:96:log_dist] [Rank 0] step=4982, skipped=0, lr=[4.2917508598834535e-07], mom=[(0.9, 0.999)]
steps: 4982 loss: 1.3858 iter time (s): 31.518 samples/sec: 4.061

100%|██████████| 1/1 [00:32<00:00, 32.27s/it][A100%|██████████| 1/1 [00:32<00:00, 32.27s/it]
 96%|█████████▌| 4983/5198 [1:37:33<1:57:50, 32.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.27s/it][A100%|██████████| 1/1 [00:32<00:00, 32.27s/it]
 96%|█████████▌| 4983/5198 [1:37:32<1:57:49, 32.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.27s/it][A100%|██████████| 1/1 [00:32<00:00, 32.27s/it]
 96%|█████████▌| 4983/5198 [1:37:23<1:57:52, 32.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.26s/it][A100%|██████████| 1/1 [00:32<00:00, 32.26s/it]
 96%|█████████▌| 4983/5198 [1:37:26<1:57:49, 32.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.21s/it][A100%|██████████| 1/1 [00:32<00:00, 32.21s/it]
 96%|█████████▌| 4983/5198 [1:37:20<1:57:49, 32.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.24s/it][A100%|██████████| 1/1 [00:32<00:00, 32.24s/it]
 96%|█████████▌| 4983/5198 [1:37:05<1:57:49, 32.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.22s/it][A100%|██████████| 1/1 [00:32<00:00, 32.22s/it]
 96%|█████████▌| 4983/5198 [1:37:10<1:57:46, 32.87s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4672
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.45s/it][A100%|██████████| 1/1 [00:29<00:00, 29.45s/it]
 96%|█████████▌| 4984/5198 [1:37:51<1:53:54, 31.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:35:37,267] [INFO] [logging.py:96:log_dist] [Rank 0] step=4983, skipped=0, lr=[4.2802919972388315e-07], mom=[(0.9, 0.999)]
steps: 4983 loss: 1.4308 iter time (s): 28.920 samples/sec: 4.426

100%|██████████| 1/1 [00:29<00:00, 29.60s/it][A100%|██████████| 1/1 [00:29<00:00, 29.60s/it]
 96%|█████████▌| 4984/5198 [1:38:03<1:53:47, 31.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.70s/it][A100%|██████████| 1/1 [00:29<00:00, 29.70s/it]
 96%|█████████▌| 4984/5198 [1:38:01<1:53:52, 31.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.58s/it][A100%|██████████| 1/1 [00:29<00:00, 29.58s/it]
 96%|█████████▌| 4984/5198 [1:37:53<1:53:47, 31.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.63s/it][A100%|██████████| 1/1 [00:29<00:00, 29.63s/it]
 96%|█████████▌| 4984/5198 [1:37:56<1:53:48, 31.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.60s/it][A100%|██████████| 1/1 [00:29<00:00, 29.60s/it]
 96%|█████████▌| 4984/5198 [1:37:49<1:53:46, 31.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.61s/it][A100%|██████████| 1/1 [00:29<00:00, 29.61s/it]
 96%|█████████▌| 4984/5198 [1:37:35<1:53:47, 31.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.60s/it][A100%|██████████| 1/1 [00:29<00:00, 29.61s/it]
 96%|█████████▌| 4984/5198 [1:37:39<1:53:44, 31.89s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4673
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.93s/it][A100%|██████████| 1/1 [00:30<00:00, 30.93s/it]
 96%|█████████▌| 4985/5198 [1:38:23<1:52:29, 31.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:36:08,389] [INFO] [logging.py:96:log_dist] [Rank 0] step=4984, skipped=0, lr=[4.2688478042155453e-07], mom=[(0.9, 0.999)]
steps: 4984 loss: 1.4281 iter time (s): 30.430 samples/sec: 4.206

100%|██████████| 1/1 [00:31<00:00, 31.15s/it][A100%|██████████| 1/1 [00:31<00:00, 31.15s/it]
 96%|█████████▌| 4985/5198 [1:38:34<1:52:27, 31.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.06s/it][A100%|██████████| 1/1 [00:31<00:00, 31.06s/it]
 96%|█████████▌| 4985/5198 [1:38:32<1:52:25, 31.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.13s/it][A100%|██████████| 1/1 [00:31<00:00, 31.13s/it]
 96%|█████████▌| 4985/5198 [1:38:24<1:52:26, 31.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.10s/it][A100%|██████████| 1/1 [00:31<00:00, 31.10s/it]
 96%|█████████▌| 4985/5198 [1:38:27<1:52:25, 31.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.12s/it][A100%|██████████| 1/1 [00:31<00:00, 31.13s/it]
 96%|█████████▌| 4985/5198 [1:38:06<1:52:25, 31.67s/it]
100%|██████████| 1/1 [00:31<00:00, 31.16s/it][A100%|██████████| 1/1 [00:31<00:00, 31.16s/it]
 96%|█████████▌| 4985/5198 [1:38:20<1:52:27, 31.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.14s/it][A100%|██████████| 1/1 [00:31<00:00, 31.14s/it]
 96%|█████████▌| 4985/5198 [1:38:11<1:52:24, 31.67s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4674
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.31s/it][A100%|██████████| 1/1 [00:31<00:00, 31.31s/it]
 96%|█████████▌| 4986/5198 [1:38:54<1:51:44, 31.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:36:39,884] [INFO] [logging.py:96:log_dist] [Rank 0] step=4985, skipped=0, lr=[4.257418284485189e-07], mom=[(0.9, 0.999)]
steps: 4985 loss: 1.4171 iter time (s): 30.783 samples/sec: 4.158

100%|██████████| 1/1 [00:31<00:00, 31.54s/it][A100%|██████████| 1/1 [00:31<00:00, 31.54s/it]
 96%|█████████▌| 4986/5198 [1:39:06<1:51:47, 31.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.58s/it][A100%|██████████| 1/1 [00:31<00:00, 31.58s/it]
 96%|█████████▌| 4986/5198 [1:39:04<1:51:48, 31.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.55s/it][A100%|██████████| 1/1 [00:31<00:00, 31.55s/it]
 96%|█████████▌| 4986/5198 [1:38:56<1:51:47, 31.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.53s/it][A100%|██████████| 1/1 [00:31<00:00, 31.53s/it]
 96%|█████████▌| 4986/5198 [1:38:58<1:51:45, 31.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.57s/it][A100%|██████████| 1/1 [00:31<00:00, 31.57s/it]
 96%|█████████▌| 4986/5198 [1:38:52<1:51:49, 31.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.59s/it][A100%|██████████| 1/1 [00:31<00:00, 31.59s/it]
 96%|█████████▌| 4986/5198 [1:38:37<1:51:49, 31.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.57s/it][A100%|██████████| 1/1 [00:31<00:00, 31.58s/it]
 96%|█████████▌| 4986/5198 [1:38:42<1:51:47, 31.64s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4675
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.37s/it][A100%|██████████| 1/1 [00:31<00:00, 31.37s/it]
 96%|█████████▌| 4987/5198 [1:39:26<1:51:04, 31.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:37:11,391] [INFO] [logging.py:96:log_dist] [Rank 0] step=4986, skipped=0, lr=[4.246003441714631e-07], mom=[(0.9, 0.999)]
steps: 4986 loss: 1.4077 iter time (s): 30.710 samples/sec: 4.168

100%|██████████| 1/1 [00:31<00:00, 31.43s/it][A100%|██████████| 1/1 [00:31<00:00, 31.43s/it]
 96%|█████████▌| 4987/5198 [1:39:37<1:51:03, 31.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.41s/it][A100%|██████████| 1/1 [00:31<00:00, 31.41s/it]
 96%|█████████▌| 4987/5198 [1:39:35<1:51:03, 31.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.44s/it][A100%|██████████| 1/1 [00:31<00:00, 31.44s/it]
 96%|█████████▌| 4987/5198 [1:39:27<1:51:03, 31.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.50s/it][A100%|██████████| 1/1 [00:31<00:00, 31.50s/it]
 96%|█████████▌| 4987/5198 [1:39:30<1:51:06, 31.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.40s/it][A100%|██████████| 1/1 [00:31<00:00, 31.40s/it]
 96%|█████████▌| 4987/5198 [1:39:23<1:51:02, 31.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.44s/it][A100%|██████████| 1/1 [00:31<00:00, 31.44s/it]
 96%|█████████▌| 4987/5198 [1:39:09<1:51:04, 31.59s/it]
100%|██████████| 1/1 [00:31<00:00, 31.43s/it][A100%|██████████| 1/1 [00:31<00:00, 31.43s/it]
 96%|█████████▌| 4987/5198 [1:39:14<1:51:03, 31.58s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4676

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.39s/it][A100%|██████████| 1/1 [00:34<00:00, 34.39s/it]
 96%|█████████▌| 4988/5198 [1:40:00<1:53:39, 32.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:37:46,014] [INFO] [logging.py:96:log_dist] [Rank 0] step=4987, skipped=0, lr=[4.234603279566046e-07], mom=[(0.9, 0.999)]
steps: 4987 loss: 1.4870 iter time (s): 33.892 samples/sec: 3.777

100%|██████████| 1/1 [00:34<00:00, 34.66s/it][A100%|██████████| 1/1 [00:34<00:00, 34.66s/it]
 96%|█████████▌| 4988/5198 [1:40:12<1:53:46, 32.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.66s/it][A100%|██████████| 1/1 [00:34<00:00, 34.66s/it]
 96%|█████████▌| 4988/5198 [1:40:10<1:53:46, 32.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.67s/it][A100%|██████████| 1/1 [00:34<00:00, 34.67s/it]
 96%|█████████▌| 4988/5198 [1:40:02<1:53:47, 32.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.63s/it][A100%|██████████| 1/1 [00:34<00:00, 34.63s/it]
 96%|█████████▌| 4988/5198 [1:40:04<1:53:46, 32.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.66s/it][A100%|██████████| 1/1 [00:34<00:00, 34.66s/it]
 96%|█████████▌| 4988/5198 [1:39:58<1:53:45, 32.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.67s/it][A100%|██████████| 1/1 [00:34<00:00, 34.67s/it]
 96%|█████████▌| 4988/5198 [1:39:44<1:53:48, 32.52s/it]
100%|██████████| 1/1 [00:34<00:00, 34.68s/it][A100%|██████████| 1/1 [00:34<00:00, 34.68s/it]
 96%|█████████▌| 4988/5198 [1:39:48<1:53:47, 32.51s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4677

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.43s/it][A100%|██████████| 1/1 [00:30<00:00, 30.43s/it]
 96%|█████████▌| 4989/5198 [1:40:31<1:51:07, 31.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:38:16,406] [INFO] [logging.py:96:log_dist] [Rank 0] step=4988, skipped=0, lr=[4.223217801696876e-07], mom=[(0.9, 0.999)]
steps: 4988 loss: 1.4278 iter time (s): 29.602 samples/sec: 4.324

100%|██████████| 1/1 [00:30<00:00, 30.39s/it][A100%|██████████| 1/1 [00:30<00:00, 30.39s/it]
 96%|█████████▌| 4989/5198 [1:40:42<1:51:01, 31.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.33s/it][A100%|██████████| 1/1 [00:30<00:00, 30.33s/it]
 96%|█████████▌| 4989/5198 [1:40:40<1:50:57, 31.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.32s/it][A100%|██████████| 1/1 [00:30<00:00, 30.32s/it]
 96%|█████████▌| 4989/5198 [1:40:35<1:50:57, 31.85s/it]
100%|██████████| 1/1 [00:30<00:00, 30.38s/it][A100%|██████████| 1/1 [00:30<00:00, 30.38s/it]
 96%|█████████▌| 4989/5198 [1:40:32<1:51:01, 31.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.28s/it][A100%|██████████| 1/1 [00:30<00:00, 30.28s/it]
 96%|█████████▌| 4989/5198 [1:40:14<1:50:56, 31.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.35s/it][A100%|██████████| 1/1 [00:30<00:00, 30.35s/it]
 96%|█████████▌| 4989/5198 [1:40:28<1:50:58, 31.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.33s/it][A100%|██████████| 1/1 [00:30<00:00, 30.33s/it]
 96%|█████████▌| 4989/5198 [1:40:19<1:50:58, 31.86s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4678
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.54s/it][A100%|██████████| 1/1 [00:30<00:00, 30.54s/it]
 96%|█████████▌| 4990/5198 [1:41:01<1:49:21, 31.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:38:47,166] [INFO] [logging.py:96:log_dist] [Rank 0] step=4989, skipped=0, lr=[4.211847011759884e-07], mom=[(0.9, 0.999)]
steps: 4989 loss: 1.4289 iter time (s): 30.029 samples/sec: 4.263

100%|██████████| 1/1 [00:30<00:00, 30.66s/it][A100%|██████████| 1/1 [00:30<00:00, 30.66s/it]
 96%|█████████▌| 4990/5198 [1:41:13<1:49:14, 31.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.75s/it][A100%|██████████| 1/1 [00:30<00:00, 30.75s/it]
 96%|█████████▌| 4990/5198 [1:41:11<1:49:17, 31.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.65s/it][A100%|██████████| 1/1 [00:30<00:00, 30.65s/it]
 96%|█████████▌| 4990/5198 [1:41:03<1:49:13, 31.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.73s/it][A100%|██████████| 1/1 [00:30<00:00, 30.73s/it]
 96%|█████████▌| 4990/5198 [1:41:05<1:49:16, 31.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.67s/it][A100%|██████████| 1/1 [00:30<00:00, 30.67s/it]
 96%|█████████▌| 4990/5198 [1:40:59<1:49:12, 31.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.72s/it][A100%|██████████| 1/1 [00:30<00:00, 30.72s/it]
 96%|█████████▌| 4990/5198 [1:40:45<1:49:14, 31.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.69s/it][A100%|██████████| 1/1 [00:30<00:00, 30.69s/it]
 96%|█████████▌| 4990/5198 [1:40:49<1:49:13, 31.51s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4679
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.84s/it][A100%|██████████| 1/1 [00:31<00:00, 31.84s/it]
 96%|█████████▌| 4991/5198 [1:41:33<1:49:17, 31.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:39:19,227] [INFO] [logging.py:96:log_dist] [Rank 0] step=4990, skipped=0, lr=[4.200490913403085e-07], mom=[(0.9, 0.999)]
steps: 4990 loss: 1.5201 iter time (s): 31.397 samples/sec: 4.077

100%|██████████| 1/1 [00:32<00:00, 32.10s/it][A100%|██████████| 1/1 [00:32<00:00, 32.10s/it]
 96%|█████████▌| 4991/5198 [1:41:45<1:49:20, 31.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.07s/it][A100%|██████████| 1/1 [00:32<00:00, 32.07s/it]
 96%|█████████▌| 4991/5198 [1:41:43<1:49:20, 31.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.13s/it][A100%|██████████| 1/1 [00:32<00:00, 32.13s/it]
 96%|█████████▌| 4991/5198 [1:41:35<1:49:21, 31.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.07s/it][A100%|██████████| 1/1 [00:32<00:00, 32.07s/it]
 96%|█████████▌| 4991/5198 [1:41:38<1:49:19, 31.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.18s/it][A100%|██████████| 1/1 [00:32<00:00, 32.18s/it]
 96%|█████████▌| 4991/5198 [1:41:31<1:49:23, 31.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.15s/it][A100%|██████████| 1/1 [00:32<00:00, 32.15s/it]
 96%|█████████▌| 4991/5198 [1:41:17<1:49:23, 31.71s/it]
100%|██████████| 1/1 [00:32<00:00, 32.14s/it][A100%|██████████| 1/1 [00:32<00:00, 32.14s/it]
 96%|█████████▌| 4991/5198 [1:41:21<1:49:21, 31.70s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_311
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:23<00:00, 23.70s/it][A100%|██████████| 1/1 [00:23<00:00, 23.70s/it]
 96%|█████████▌| 4992/5198 [1:41:57<1:40:41, 29.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:39:43,109] [INFO] [logging.py:96:log_dist] [Rank 0] step=4991, skipped=0, lr=[4.1891495102697974e-07], mom=[(0.9, 0.999)]
steps: 4991 loss: 1.8521 iter time (s): 23.161 samples/sec: 5.527

100%|██████████| 1/1 [00:24<00:00, 24.14s/it][A100%|██████████| 1/1 [00:24<00:00, 24.14s/it]
 96%|█████████▌| 4992/5198 [1:42:09<1:41:02, 29.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.21s/it][A100%|██████████| 1/1 [00:24<00:00, 24.21s/it]
 96%|█████████▌| 4992/5198 [1:42:07<1:41:07, 29.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.17s/it][A100%|██████████| 1/1 [00:24<00:00, 24.17s/it]
 96%|█████████▌| 4992/5198 [1:41:59<1:41:05, 29.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.33s/it][A100%|██████████| 1/1 [00:24<00:00, 24.33s/it]
 96%|█████████▌| 4992/5198 [1:42:02<1:41:13, 29.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.34s/it][A100%|██████████| 1/1 [00:24<00:00, 24.34s/it]
 96%|█████████▌| 4992/5198 [1:41:41<1:41:16, 29.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.38s/it][A100%|██████████| 1/1 [00:24<00:00, 24.38s/it]
 96%|█████████▌| 4992/5198 [1:41:56<1:41:19, 29.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.40s/it][A100%|██████████| 1/1 [00:24<00:00, 24.40s/it]
 96%|█████████▌| 4992/5198 [1:41:46<1:41:19, 29.51s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4680
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.60s/it][A100%|██████████| 1/1 [00:32<00:00, 32.60s/it]
 96%|█████████▌| 4993/5198 [1:42:30<1:43:41, 30.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:40:15,818] [INFO] [logging.py:96:log_dist] [Rank 0] step=4992, skipped=0, lr=[4.177822805998628e-07], mom=[(0.9, 0.999)]
steps: 4992 loss: 1.5063 iter time (s): 31.444 samples/sec: 4.071

100%|██████████| 1/1 [00:32<00:00, 32.48s/it][A100%|██████████| 1/1 [00:32<00:00, 32.48s/it]
 96%|█████████▌| 4993/5198 [1:42:42<1:43:41, 30.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.43s/it][A100%|██████████| 1/1 [00:32<00:00, 32.43s/it]
 96%|█████████▌| 4993/5198 [1:42:40<1:43:41, 30.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.44s/it][A100%|██████████| 1/1 [00:32<00:00, 32.44s/it]
 96%|█████████▌| 4993/5198 [1:42:32<1:43:40, 30.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.30s/it][A100%|██████████| 1/1 [00:32<00:00, 32.30s/it]
 96%|█████████▌| 4993/5198 [1:42:34<1:43:38, 30.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.22s/it][A100%|██████████| 1/1 [00:32<00:00, 32.22s/it]
 96%|█████████▌| 4993/5198 [1:42:28<1:43:36, 30.33s/it]
100%|██████████| 1/1 [00:32<00:00, 32.24s/it][A100%|██████████| 1/1 [00:32<00:00, 32.24s/it]
 96%|█████████▌| 4993/5198 [1:42:13<1:43:36, 30.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.21s/it][A100%|██████████| 1/1 [00:32<00:00, 32.21s/it]
 96%|█████████▌| 4993/5198 [1:42:18<1:43:35, 30.32s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4681
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.85s/it][A100%|██████████| 1/1 [00:34<00:00, 34.85s/it]
 96%|█████████▌| 4994/5198 [1:43:05<1:48:00, 31.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:40:50,982] [INFO] [logging.py:96:log_dist] [Rank 0] step=4993, skipped=0, lr=[4.166510804223467e-07], mom=[(0.9, 0.999)]
steps: 4993 loss: 1.4260 iter time (s): 34.392 samples/sec: 3.722

100%|██████████| 1/1 [00:35<00:00, 35.20s/it][A100%|██████████| 1/1 [00:35<00:00, 35.20s/it]
 96%|█████████▌| 4994/5198 [1:43:15<1:48:08, 31.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.38s/it][A100%|██████████| 1/1 [00:35<00:00, 35.38s/it]
 96%|█████████▌| 4994/5198 [1:43:17<1:48:19, 31.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.21s/it][A100%|██████████| 1/1 [00:35<00:00, 35.21s/it]
 96%|█████████▌| 4994/5198 [1:43:09<1:48:06, 31.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.26s/it][A100%|██████████| 1/1 [00:35<00:00, 35.26s/it]
 96%|█████████▌| 4994/5198 [1:43:07<1:48:11, 31.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.28s/it][A100%|██████████| 1/1 [00:35<00:00, 35.28s/it]
 96%|█████████▌| 4994/5198 [1:42:53<1:48:09, 31.81s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4682
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.47s/it][A100%|██████████| 1/1 [00:35<00:00, 35.47s/it]
 96%|█████████▌| 4994/5198 [1:42:49<1:48:21, 31.87s/it]
100%|██████████| 1/1 [00:35<00:00, 35.48s/it][A100%|██████████| 1/1 [00:35<00:00, 35.48s/it]
 96%|█████████▌| 4994/5198 [1:43:03<1:48:22, 31.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.70s/it][A100%|██████████| 1/1 [00:30<00:00, 30.70s/it]
 96%|█████████▌| 4995/5198 [1:43:36<1:46:33, 31.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:41:21,659] [INFO] [logging.py:96:log_dist] [Rank 0] step=4994, skipped=0, lr=[4.1552135085734926e-07], mom=[(0.9, 0.999)]
steps: 4994 loss: 1.4696 iter time (s): 29.785 samples/sec: 4.298

100%|██████████| 1/1 [00:30<00:00, 30.39s/it][A100%|██████████| 1/1 [00:30<00:00, 30.39s/it]
 96%|█████████▌| 4995/5198 [1:43:47<1:46:18, 31.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.58s/it][A100%|██████████| 1/1 [00:30<00:00, 30.58s/it]
 96%|█████████▌| 4995/5198 [1:43:46<1:46:22, 31.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.51s/it][A100%|██████████| 1/1 [00:30<00:00, 30.51s/it]
 96%|█████████▌| 4995/5198 [1:43:37<1:46:20, 31.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.65s/it][A100%|██████████| 1/1 [00:30<00:00, 30.65s/it]
 96%|█████████▌| 4995/5198 [1:43:40<1:46:25, 31.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.33s/it][A100%|██████████| 1/1 [00:30<00:00, 30.33s/it]
 96%|█████████▌| 4995/5198 [1:43:34<1:46:16, 31.41s/it]
100%|██████████| 1/1 [00:30<00:00, 30.33s/it][A100%|██████████| 1/1 [00:30<00:00, 30.33s/it]
 96%|█████████▌| 4995/5198 [1:43:19<1:46:16, 31.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.52s/it][A100%|██████████| 1/1 [00:30<00:00, 30.53s/it]
 96%|█████████▌| 4995/5198 [1:43:24<1:46:19, 31.43s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4683
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.85s/it][A100%|██████████| 1/1 [00:30<00:00, 30.85s/it]
 96%|█████████▌| 4996/5198 [1:44:07<1:45:32, 31.35s/it][2024-09-02 00:41:52,461] [INFO] [logging.py:96:log_dist] [Rank 0] step=4995, skipped=0, lr=[4.143930922673144e-07], mom=[(0.9, 0.999)]
steps: 4995 loss: 1.3994 iter time (s): 30.055 samples/sec: 4.259

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.79s/it][A100%|██████████| 1/1 [00:30<00:00, 30.79s/it]
 96%|█████████▌| 4996/5198 [1:44:18<1:45:09, 31.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.78s/it][A100%|██████████| 1/1 [00:30<00:00, 30.78s/it]
 96%|█████████▌| 4996/5198 [1:44:16<1:45:11, 31.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.83s/it][A100%|██████████| 1/1 [00:30<00:00, 30.83s/it]
 96%|█████████▌| 4996/5198 [1:44:08<1:45:13, 31.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.76s/it][A100%|██████████| 1/1 [00:30<00:00, 30.76s/it]
 96%|█████████▌| 4996/5198 [1:44:11<1:45:12, 31.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.76s/it][A100%|██████████| 1/1 [00:30<00:00, 30.76s/it]
 96%|█████████▌| 4996/5198 [1:44:05<1:45:06, 31.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.78s/it][A100%|██████████| 1/1 [00:30<00:00, 30.78s/it]
 96%|█████████▌| 4996/5198 [1:43:50<1:45:07, 31.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.79s/it][A100%|██████████| 1/1 [00:30<00:00, 30.79s/it]
 96%|█████████▌| 4996/5198 [1:43:55<1:45:10, 31.24s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4684
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.25s/it][A100%|██████████| 1/1 [00:31<00:00, 31.25s/it]
 96%|█████████▌| 4997/5198 [1:44:38<1:45:05, 31.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:42:24,167] [INFO] [logging.py:96:log_dist] [Rank 0] step=4996, skipped=0, lr=[4.132663050142157e-07], mom=[(0.9, 0.999)]
steps: 4996 loss: 1.3724 iter time (s): 30.962 samples/sec: 4.134

100%|██████████| 1/1 [00:31<00:00, 31.73s/it][A100%|██████████| 1/1 [00:31<00:00, 31.73s/it]
 96%|█████████▌| 4997/5198 [1:44:50<1:45:08, 31.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.76s/it][A100%|██████████| 1/1 [00:31<00:00, 31.76s/it]
 96%|█████████▌| 4997/5198 [1:44:48<1:45:11, 31.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.79s/it][A100%|██████████| 1/1 [00:31<00:00, 31.79s/it]
 96%|█████████▌| 4997/5198 [1:44:40<1:45:14, 31.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.83s/it][A100%|██████████| 1/1 [00:31<00:00, 31.83s/it]
 96%|█████████▌| 4997/5198 [1:44:43<1:45:16, 31.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.86s/it][A100%|██████████| 1/1 [00:31<00:00, 31.86s/it]
 96%|█████████▌| 4997/5198 [1:44:36<1:45:13, 31.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.89s/it][A100%|██████████| 1/1 [00:31<00:00, 31.89s/it]
 96%|█████████▌| 4997/5198 [1:44:22<1:45:16, 31.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.90s/it][A100%|██████████| 1/1 [00:31<00:00, 31.90s/it]
 96%|█████████▌| 4997/5198 [1:44:27<1:45:18, 31.44s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4685
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.50s/it][A100%|██████████| 1/1 [00:33<00:00, 33.50s/it]
 96%|█████████▌| 4998/5198 [1:45:12<1:46:51, 32.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:42:57,866] [INFO] [logging.py:96:log_dist] [Rank 0] step=4997, skipped=0, lr=[4.121409894595545e-07], mom=[(0.9, 0.999)]
steps: 4997 loss: 1.4465 iter time (s): 32.759 samples/sec: 3.907

100%|██████████| 1/1 [00:33<00:00, 33.67s/it][A100%|██████████| 1/1 [00:33<00:00, 33.67s/it]
 96%|█████████▌| 4998/5198 [1:45:24<1:46:54, 32.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.57s/it][A100%|██████████| 1/1 [00:33<00:00, 33.57s/it]
 96%|█████████▌| 4998/5198 [1:45:22<1:46:50, 32.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.61s/it][A100%|██████████| 1/1 [00:33<00:00, 33.61s/it]
 96%|█████████▌| 4998/5198 [1:45:14<1:46:55, 32.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.56s/it][A100%|██████████| 1/1 [00:33<00:00, 33.56s/it]
 96%|█████████▌| 4998/5198 [1:45:16<1:46:53, 32.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.59s/it][A100%|██████████| 1/1 [00:33<00:00, 33.59s/it]
 96%|█████████▌| 4998/5198 [1:45:10<1:46:53, 32.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.61s/it][A100%|██████████| 1/1 [00:33<00:00, 33.61s/it]
 96%|█████████▌| 4998/5198 [1:44:55<1:46:56, 32.08s/it]
100%|██████████| 1/1 [00:33<00:00, 33.57s/it][A100%|██████████| 1/1 [00:33<00:00, 33.57s/it]
 96%|█████████▌| 4998/5198 [1:45:00<1:46:56, 32.08s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4686

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.91s/it][A100%|██████████| 1/1 [00:32<00:00, 32.91s/it]
 96%|█████████▌| 4999/5198 [1:45:45<1:47:18, 32.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:43:30,907] [INFO] [logging.py:96:log_dist] [Rank 0] step=4998, skipped=0, lr=[4.110171459643609e-07], mom=[(0.9, 0.999)]
steps: 4998 loss: 1.4909 iter time (s): 32.219 samples/sec: 3.973

100%|██████████| 1/1 [00:33<00:00, 33.02s/it][A100%|██████████| 1/1 [00:33<00:00, 33.02s/it]
 96%|█████████▌| 4999/5198 [1:45:57<1:47:19, 32.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.04s/it][A100%|██████████| 1/1 [00:33<00:00, 33.04s/it]
 96%|█████████▌| 4999/5198 [1:45:55<1:47:18, 32.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.95s/it][A100%|██████████| 1/1 [00:32<00:00, 32.95s/it]
 96%|█████████▌| 4999/5198 [1:45:47<1:47:15, 32.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.00s/it][A100%|██████████| 1/1 [00:33<00:00, 33.00s/it]
 96%|█████████▌| 4999/5198 [1:45:49<1:47:17, 32.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.95s/it][A100%|██████████| 1/1 [00:32<00:00, 32.95s/it]
 96%|█████████▌| 4999/5198 [1:45:43<1:47:14, 32.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.92s/it][A100%|██████████| 1/1 [00:32<00:00, 32.92s/it]
 96%|█████████▌| 4999/5198 [1:45:28<1:47:14, 32.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.94s/it][A100%|██████████| 1/1 [00:32<00:00, 32.94s/it]
 96%|█████████▌| 4999/5198 [1:45:33<1:47:15, 32.34s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4687
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.49s/it][A100%|██████████| 1/1 [00:31<00:00, 31.49s/it]
 96%|█████████▌| 5000/5198 [1:46:17<1:46:03, 32.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:44:02,452] [INFO] [logging.py:96:log_dist] [Rank 0] step=4999, skipped=0, lr=[4.0989477488919076e-07], mom=[(0.9, 0.999)]
steps: 4999 loss: 1.4911 iter time (s): 30.821 samples/sec: 4.153

100%|██████████| 1/1 [00:31<00:00, 31.51s/it][A100%|██████████| 1/1 [00:31<00:00, 31.51s/it]
 96%|█████████▌| 5000/5198 [1:46:28<1:45:57, 32.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.59s/it][A100%|██████████| 1/1 [00:31<00:00, 31.59s/it]
 96%|█████████▌| 5000/5198 [1:46:26<1:46:01, 32.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.48s/it][A100%|██████████| 1/1 [00:31<00:00, 31.48s/it]
 96%|█████████▌| 5000/5198 [1:46:21<1:45:54, 32.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.60s/it][A100%|██████████| 1/1 [00:31<00:00, 31.60s/it]
 96%|█████████▌| 5000/5198 [1:46:18<1:46:00, 32.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.53s/it][A100%|██████████| 1/1 [00:31<00:00, 31.53s/it]
 96%|█████████▌| 5000/5198 [1:46:15<1:45:54, 32.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.54s/it][A100%|██████████| 1/1 [00:31<00:00, 31.54s/it]
 96%|█████████▌| 5000/5198 [1:46:00<1:45:55, 32.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.54s/it][A100%|██████████| 1/1 [00:31<00:00, 31.54s/it]
 96%|█████████▌| 5000/5198 [1:46:05<1:45:55, 32.10s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4688
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.45s/it][A100%|██████████| 1/1 [00:33<00:00, 33.45s/it]
 96%|█████████▌| 5001/5198 [1:46:50<1:46:59, 32.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:44:36,200] [INFO] [logging.py:96:log_dist] [Rank 0] step=5000, skipped=0, lr=[4.087738765941292e-07], mom=[(0.9, 0.999)]
steps: 5000 loss: 1.5007 iter time (s): 33.027 samples/sec: 3.876

100%|██████████| 1/1 [00:33<00:00, 33.75s/it][A100%|██████████| 1/1 [00:33<00:00, 33.75s/it]
 96%|█████████▌| 5001/5198 [1:47:02<1:47:02, 32.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.73s/it][A100%|██████████| 1/1 [00:33<00:00, 33.73s/it]
 96%|█████████▌| 5001/5198 [1:47:00<1:47:04, 32.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.74s/it][A100%|██████████| 1/1 [00:33<00:00, 33.74s/it]
 96%|█████████▌| 5001/5198 [1:46:52<1:47:04, 32.61s/it]
100%|██████████| 1/1 [00:33<00:00, 33.78s/it][A100%|██████████| 1/1 [00:33<00:00, 33.78s/it]
 96%|█████████▌| 5001/5198 [1:46:55<1:47:02, 32.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.78s/it][A100%|██████████| 1/1 [00:33<00:00, 33.78s/it]
 96%|█████████▌| 5001/5198 [1:46:48<1:47:02, 32.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.77s/it][A100%|██████████| 1/1 [00:33<00:00, 33.77s/it]
 96%|█████████▌| 5001/5198 [1:46:34<1:47:02, 32.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.77s/it][A100%|██████████| 1/1 [00:33<00:00, 33.77s/it]
 96%|█████████▌| 5001/5198 [1:46:38<1:47:02, 32.60s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4689
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.53s/it][A100%|██████████| 1/1 [00:31<00:00, 31.53s/it]
 96%|█████████▌| 5002/5198 [1:47:22<1:45:32, 32.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:45:07,764] [INFO] [logging.py:96:log_dist] [Rank 0] step=5001, skipped=0, lr=[4.0765445143878787e-07], mom=[(0.9, 0.999)]
steps: 5001 loss: 1.5730 iter time (s): 30.817 samples/sec: 4.154

100%|██████████| 1/1 [00:31<00:00, 31.53s/it][A100%|██████████| 1/1 [00:31<00:00, 31.54s/it]
 96%|█████████▌| 5002/5198 [1:47:34<1:45:27, 32.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.47s/it][A100%|██████████| 1/1 [00:31<00:00, 31.47s/it]
 96%|█████████▌| 5002/5198 [1:47:32<1:45:25, 32.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.48s/it][A100%|██████████| 1/1 [00:31<00:00, 31.48s/it]
 96%|█████████▌| 5002/5198 [1:47:26<1:45:24, 32.27s/it]
100%|██████████| 1/1 [00:31<00:00, 31.49s/it][A100%|██████████| 1/1 [00:31<00:00, 31.49s/it]
 96%|█████████▌| 5002/5198 [1:47:23<1:45:26, 32.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.51s/it][A100%|██████████| 1/1 [00:31<00:00, 31.51s/it]
 96%|█████████▌| 5002/5198 [1:47:20<1:45:26, 32.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.50s/it][A100%|██████████| 1/1 [00:31<00:00, 31.50s/it]
 96%|█████████▌| 5002/5198 [1:47:05<1:45:25, 32.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.50s/it][A100%|██████████| 1/1 [00:31<00:00, 31.50s/it]
 96%|█████████▌| 5002/5198 [1:47:10<1:45:25, 32.27s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4690
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.31s/it][A100%|██████████| 1/1 [00:31<00:00, 31.31s/it]
 96%|█████████▌| 5003/5198 [1:47:53<1:44:09, 32.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:45:39,160] [INFO] [logging.py:96:log_dist] [Rank 0] step=5002, skipped=0, lr=[4.065364997823059e-07], mom=[(0.9, 0.999)]
steps: 5002 loss: 1.4697 iter time (s): 30.699 samples/sec: 4.169

100%|██████████| 1/1 [00:31<00:00, 31.42s/it][A100%|██████████| 1/1 [00:31<00:00, 31.42s/it]
 96%|█████████▌| 5003/5198 [1:48:05<1:44:05, 32.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.45s/it][A100%|██████████| 1/1 [00:31<00:00, 31.45s/it]
 96%|█████████▌| 5003/5198 [1:48:03<1:44:05, 32.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.38s/it][A100%|██████████| 1/1 [00:31<00:00, 31.38s/it]
 96%|█████████▌| 5003/5198 [1:47:55<1:44:02, 32.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.46s/it][A100%|██████████| 1/1 [00:31<00:00, 31.46s/it]
 96%|█████████▌| 5003/5198 [1:47:58<1:44:05, 32.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.39s/it][A100%|██████████| 1/1 [00:31<00:00, 31.39s/it]
 96%|█████████▌| 5003/5198 [1:47:51<1:44:02, 32.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.42s/it][A100%|██████████| 1/1 [00:31<00:00, 31.42s/it]
 96%|█████████▌| 5003/5198 [1:47:37<1:44:04, 32.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.42s/it][A100%|██████████| 1/1 [00:31<00:00, 31.42s/it]
 96%|█████████▌| 5003/5198 [1:47:41<1:44:04, 32.02s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4691
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.95s/it][A100%|██████████| 1/1 [00:29<00:00, 29.95s/it]
 96%|█████████▋| 5004/5198 [1:48:23<1:41:45, 31.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:46:09,328] [INFO] [logging.py:96:log_dist] [Rank 0] step=5003, skipped=0, lr=[4.0542002198335095e-07], mom=[(0.9, 0.999)]
steps: 5003 loss: 1.4596 iter time (s): 29.442 samples/sec: 4.348

100%|██████████| 1/1 [00:30<00:00, 30.27s/it][A100%|██████████| 1/1 [00:30<00:00, 30.27s/it]
 96%|█████████▋| 5004/5198 [1:48:35<1:41:51, 31.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.28s/it][A100%|██████████| 1/1 [00:30<00:00, 30.28s/it]
 96%|█████████▋| 5004/5198 [1:48:33<1:41:52, 31.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.22s/it][A100%|██████████| 1/1 [00:30<00:00, 30.22s/it]
 96%|█████████▋| 5004/5198 [1:48:25<1:41:46, 31.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.23s/it][A100%|██████████| 1/1 [00:30<00:00, 30.23s/it]
 96%|█████████▋| 5004/5198 [1:48:28<1:41:48, 31.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.27s/it][A100%|██████████| 1/1 [00:30<00:00, 30.27s/it]
 96%|█████████▋| 5004/5198 [1:48:21<1:41:49, 31.49s/it]
100%|██████████| 1/1 [00:30<00:00, 30.22s/it][A100%|██████████| 1/1 [00:30<00:00, 30.22s/it]
 96%|█████████▋| 5004/5198 [1:48:07<1:41:47, 31.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.22s/it][A100%|██████████| 1/1 [00:30<00:00, 30.22s/it]
 96%|█████████▋| 5004/5198 [1:48:12<1:41:47, 31.48s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4692
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.49s/it][A100%|██████████| 1/1 [00:30<00:00, 30.49s/it]
 96%|█████████▋| 5005/5198 [1:48:54<1:40:29, 31.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:46:40,004] [INFO] [logging.py:96:log_dist] [Rank 0] step=5004, skipped=0, lr=[4.0430501840011574e-07], mom=[(0.9, 0.999)]
steps: 5004 loss: 1.4257 iter time (s): 29.894 samples/sec: 4.282

100%|██████████| 1/1 [00:30<00:00, 30.57s/it][A100%|██████████| 1/1 [00:30<00:00, 30.57s/it]
 96%|█████████▋| 5005/5198 [1:49:06<1:40:26, 31.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.54s/it][A100%|██████████| 1/1 [00:30<00:00, 30.54s/it]
 96%|█████████▋| 5005/5198 [1:49:04<1:40:25, 31.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.61s/it][A100%|██████████| 1/1 [00:30<00:00, 30.61s/it]
 96%|█████████▋| 5005/5198 [1:48:56<1:40:25, 31.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.59s/it][A100%|██████████| 1/1 [00:30<00:00, 30.59s/it]
 96%|█████████▋| 5005/5198 [1:48:58<1:40:25, 31.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.55s/it][A100%|██████████| 1/1 [00:30<00:00, 30.55s/it]
 96%|█████████▋| 5005/5198 [1:48:52<1:40:23, 31.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.58s/it][A100%|██████████| 1/1 [00:30<00:00, 30.58s/it]
 96%|█████████▋| 5005/5198 [1:48:37<1:40:24, 31.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.58s/it][A100%|██████████| 1/1 [00:30<00:00, 30.59s/it]
 96%|█████████▋| 5005/5198 [1:48:42<1:40:24, 31.21s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4693
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:27<00:00, 27.91s/it][A100%|██████████| 1/1 [00:27<00:00, 27.91s/it]
 96%|█████████▋| 5006/5198 [1:49:22<1:36:55, 30.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:47:08,022] [INFO] [logging.py:96:log_dist] [Rank 0] step=5005, skipped=0, lr=[4.0319148939032263e-07], mom=[(0.9, 0.999)]
steps: 5005 loss: 1.4327 iter time (s): 27.316 samples/sec: 4.686

100%|██████████| 1/1 [00:27<00:00, 27.98s/it][A100%|██████████| 1/1 [00:27<00:00, 27.98s/it]
 96%|█████████▋| 5006/5198 [1:49:34<1:36:48, 30.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:27<00:00, 27.99s/it][A100%|██████████| 1/1 [00:27<00:00, 27.99s/it]
 96%|█████████▋| 5006/5198 [1:49:32<1:36:48, 30.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:27<00:00, 27.98s/it][A100%|██████████| 1/1 [00:27<00:00, 27.98s/it]
 96%|█████████▋| 5006/5198 [1:49:24<1:36:48, 30.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:27<00:00, 27.95s/it][A100%|██████████| 1/1 [00:27<00:00, 27.95s/it]
 96%|█████████▋| 5006/5198 [1:49:26<1:36:46, 30.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:27<00:00, 27.98s/it][A100%|██████████| 1/1 [00:27<00:00, 27.98s/it]
 96%|█████████▋| 5006/5198 [1:49:20<1:36:46, 30.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:27<00:00, 27.97s/it][A100%|██████████| 1/1 [00:27<00:00, 27.97s/it]
 96%|█████████▋| 5006/5198 [1:49:05<1:36:46, 30.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:27<00:00, 27.96s/it][A100%|██████████| 1/1 [00:27<00:00, 27.96s/it]
 96%|█████████▋| 5006/5198 [1:49:10<1:36:46, 30.24s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4694
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.08s/it][A100%|██████████| 1/1 [00:30<00:00, 30.08s/it]
 96%|█████████▋| 5007/5198 [1:49:53<1:36:23, 30.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:47:38,333] [INFO] [logging.py:96:log_dist] [Rank 0] step=5006, skipped=0, lr=[4.020794353112169e-07], mom=[(0.9, 0.999)]
steps: 5006 loss: 1.4648 iter time (s): 29.659 samples/sec: 4.316

100%|██████████| 1/1 [00:30<00:00, 30.39s/it][A100%|██████████| 1/1 [00:30<00:00, 30.39s/it]
 96%|█████████▋| 5007/5198 [1:50:04<1:36:26, 30.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.42s/it][A100%|██████████| 1/1 [00:30<00:00, 30.42s/it]
 96%|█████████▋| 5007/5198 [1:50:02<1:36:28, 30.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.35s/it][A100%|██████████| 1/1 [00:30<00:00, 30.35s/it]
 96%|█████████▋| 5007/5198 [1:49:54<1:36:24, 30.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.48s/it][A100%|██████████| 1/1 [00:30<00:00, 30.48s/it]
 96%|█████████▋| 5007/5198 [1:49:57<1:36:30, 30.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.43s/it][A100%|██████████| 1/1 [00:30<00:00, 30.43s/it]
 96%|█████████▋| 5007/5198 [1:49:50<1:36:27, 30.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.44s/it][A100%|██████████| 1/1 [00:30<00:00, 30.44s/it]
 96%|█████████▋| 5007/5198 [1:49:36<1:36:27, 30.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.44s/it][A100%|██████████| 1/1 [00:30<00:00, 30.44s/it]
 96%|█████████▋| 5007/5198 [1:49:41<1:36:27, 30.30s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_312
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:23<00:00, 23.10s/it][A100%|██████████| 1/1 [00:23<00:00, 23.10s/it]
 96%|█████████▋| 5008/5198 [1:50:16<1:29:09, 28.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:48:01,615] [INFO] [logging.py:96:log_dist] [Rank 0] step=5007, skipped=0, lr=[4.009688565195746e-07], mom=[(0.9, 0.999)]
steps: 5007 loss: 1.9182 iter time (s): 22.516 samples/sec: 5.685

100%|██████████| 1/1 [00:23<00:00, 23.25s/it][A100%|██████████| 1/1 [00:23<00:00, 23.25s/it]
 96%|█████████▋| 5008/5198 [1:50:27<1:29:15, 28.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:23<00:00, 23.30s/it][A100%|██████████| 1/1 [00:23<00:00, 23.30s/it]
 96%|█████████▋| 5008/5198 [1:50:26<1:29:19, 28.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:23<00:00, 23.41s/it][A100%|██████████| 1/1 [00:23<00:00, 23.41s/it]
 96%|█████████▋| 5008/5198 [1:50:17<1:29:22, 28.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:23<00:00, 23.33s/it][A100%|██████████| 1/1 [00:23<00:00, 23.33s/it]
 96%|█████████▋| 5008/5198 [1:50:20<1:29:21, 28.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:23<00:00, 23.38s/it][A100%|██████████| 1/1 [00:23<00:00, 23.38s/it]
 96%|█████████▋| 5008/5198 [1:50:14<1:29:23, 28.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:23<00:00, 23.38s/it][A100%|██████████| 1/1 [00:23<00:00, 23.38s/it]
 96%|█████████▋| 5008/5198 [1:50:04<1:29:23, 28.23s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4695

Training on 128 of 128 sentences.
100%|██████████| 1/1 [00:23<00:00, 23.40s/it][A100%|██████████| 1/1 [00:23<00:00, 23.40s/it]
 96%|█████████▋| 5008/5198 [1:49:59<1:29:24, 28.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 31.00s/it][A100%|██████████| 1/1 [00:31<00:00, 31.00s/it]
 96%|█████████▋| 5009/5198 [1:50:47<1:31:30, 29.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:48:32,690] [INFO] [logging.py:96:log_dist] [Rank 0] step=5008, skipped=0, lr=[3.998597533716973e-07], mom=[(0.9, 0.999)]
steps: 5008 loss: 1.5712 iter time (s): 30.192 samples/sec: 4.239

100%|██████████| 1/1 [00:30<00:00, 30.97s/it][A100%|██████████| 1/1 [00:30<00:00, 30.97s/it]
 96%|█████████▋| 5009/5198 [1:50:58<1:31:25, 29.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.92s/it][A100%|██████████| 1/1 [00:30<00:00, 30.92s/it]
 96%|█████████▋| 5009/5198 [1:50:57<1:31:25, 29.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.87s/it][A100%|██████████| 1/1 [00:30<00:00, 30.87s/it]
 96%|█████████▋| 5009/5198 [1:50:48<1:31:24, 29.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.89s/it][A100%|██████████| 1/1 [00:30<00:00, 30.89s/it]
 96%|█████████▋| 5009/5198 [1:50:51<1:31:25, 29.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.87s/it][A100%|██████████| 1/1 [00:30<00:00, 30.87s/it]
 96%|█████████▋| 5009/5198 [1:50:45<1:31:25, 29.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.85s/it][A100%|██████████| 1/1 [00:30<00:00, 30.85s/it]
 96%|█████████▋| 5009/5198 [1:50:30<1:31:24, 29.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.87s/it][A100%|██████████| 1/1 [00:30<00:00, 30.87s/it]
 96%|█████████▋| 5009/5198 [1:50:35<1:31:24, 29.02s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4696
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.54s/it][A100%|██████████| 1/1 [00:30<00:00, 30.54s/it]
 96%|█████████▋| 5010/5198 [1:51:18<1:32:33, 29.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:49:03,361] [INFO] [logging.py:96:log_dist] [Rank 0] step=5009, skipped=0, lr=[3.98752126223412e-07], mom=[(0.9, 0.999)]
steps: 5009 loss: 1.4573 iter time (s): 29.985 samples/sec: 4.269

100%|██████████| 1/1 [00:30<00:00, 30.77s/it][A100%|██████████| 1/1 [00:30<00:00, 30.77s/it]
 96%|█████████▋| 5010/5198 [1:51:29<1:32:35, 29.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.74s/it][A100%|██████████| 1/1 [00:30<00:00, 30.74s/it]
 96%|█████████▋| 5010/5198 [1:51:27<1:32:33, 29.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.71s/it][A100%|██████████| 1/1 [00:30<00:00, 30.71s/it]
 96%|█████████▋| 5010/5198 [1:51:22<1:32:31, 29.53s/it]
100%|██████████| 1/1 [00:30<00:00, 30.79s/it][A100%|██████████| 1/1 [00:30<00:00, 30.79s/it]
 96%|█████████▋| 5010/5198 [1:51:19<1:32:36, 29.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.74s/it][A100%|██████████| 1/1 [00:30<00:00, 30.74s/it]
 96%|█████████▋| 5010/5198 [1:51:15<1:32:33, 29.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.73s/it][A100%|██████████| 1/1 [00:30<00:00, 30.73s/it]
 96%|█████████▋| 5010/5198 [1:51:01<1:32:32, 29.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.73s/it][A100%|██████████| 1/1 [00:30<00:00, 30.73s/it]
 96%|█████████▋| 5010/5198 [1:51:06<1:32:32, 29.54s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4697
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.95s/it][A100%|██████████| 1/1 [00:30<00:00, 30.95s/it]
 96%|█████████▋| 5011/5198 [1:51:49<1:33:32, 30.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:49:34,485] [INFO] [logging.py:96:log_dist] [Rank 0] step=5010, skipped=0, lr=[3.9764597543007333e-07], mom=[(0.9, 0.999)]
steps: 5010 loss: 1.4362 iter time (s): 30.374 samples/sec: 4.214

100%|██████████| 1/1 [00:31<00:00, 31.08s/it][A100%|██████████| 1/1 [00:31<00:00, 31.08s/it]
 96%|█████████▋| 5011/5198 [1:52:00<1:33:32, 30.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.12s/it][A100%|██████████| 1/1 [00:31<00:00, 31.12s/it]
 96%|█████████▋| 5011/5198 [1:51:58<1:33:33, 30.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.09s/it][A100%|██████████| 1/1 [00:31<00:00, 31.09s/it]
 96%|█████████▋| 5011/5198 [1:51:53<1:33:30, 30.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.10s/it][A100%|██████████| 1/1 [00:31<00:00, 31.10s/it]
 96%|█████████▋| 5011/5198 [1:51:50<1:33:33, 30.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.06s/it][A100%|██████████| 1/1 [00:31<00:00, 31.06s/it]
 96%|█████████▋| 5011/5198 [1:51:47<1:33:29, 30.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.09s/it][A100%|██████████| 1/1 [00:31<00:00, 31.09s/it]
 96%|█████████▋| 5011/5198 [1:51:32<1:33:30, 30.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.10s/it][A100%|██████████| 1/1 [00:31<00:00, 31.10s/it]
 96%|█████████▋| 5011/5198 [1:51:37<1:33:31, 30.01s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4698
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.07s/it][A100%|██████████| 1/1 [00:32<00:00, 32.07s/it]
 96%|█████████▋| 5012/5198 [1:52:21<1:35:07, 30.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:50:06,824] [INFO] [logging.py:96:log_dist] [Rank 0] step=5011, skipped=0, lr=[3.9654130134656293e-07], mom=[(0.9, 0.999)]
steps: 5011 loss: 1.4306 iter time (s): 31.608 samples/sec: 4.050

100%|██████████| 1/1 [00:32<00:00, 32.35s/it][A100%|██████████| 1/1 [00:32<00:00, 32.35s/it]
 96%|█████████▋| 5012/5198 [1:52:33<1:35:13, 30.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.30s/it][A100%|██████████| 1/1 [00:32<00:00, 32.30s/it]
 96%|█████████▋| 5012/5198 [1:52:31<1:35:11, 30.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.38s/it][A100%|██████████| 1/1 [00:32<00:00, 32.38s/it]
 96%|█████████▋| 5012/5198 [1:52:23<1:35:16, 30.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.42s/it][A100%|██████████| 1/1 [00:32<00:00, 32.42s/it]
 96%|█████████▋| 5012/5198 [1:52:25<1:35:15, 30.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.42s/it][A100%|██████████| 1/1 [00:32<00:00, 32.42s/it]
 96%|█████████▋| 5012/5198 [1:52:19<1:35:15, 30.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.42s/it][A100%|██████████| 1/1 [00:32<00:00, 32.42s/it]
 96%|█████████▋| 5012/5198 [1:52:04<1:35:15, 30.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.41s/it][A100%|██████████| 1/1 [00:32<00:00, 32.41s/it]
 96%|█████████▋| 5012/5198 [1:52:09<1:35:15, 30.73s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4699
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.95s/it][A100%|██████████| 1/1 [00:31<00:00, 31.95s/it]
 96%|█████████▋| 5013/5198 [1:52:53<1:35:55, 31.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:50:38,868] [INFO] [logging.py:96:log_dist] [Rank 0] step=5012, skipped=0, lr=[3.954381043272857e-07], mom=[(0.9, 0.999)]
steps: 5012 loss: 1.4491 iter time (s): 31.235 samples/sec: 4.098

100%|██████████| 1/1 [00:31<00:00, 31.98s/it][A100%|██████████| 1/1 [00:31<00:00, 31.98s/it]
 96%|█████████▋| 5013/5198 [1:53:03<1:35:51, 31.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.10s/it][A100%|██████████| 1/1 [00:32<00:00, 32.10s/it]
 96%|█████████▋| 5013/5198 [1:53:05<1:36:00, 31.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.92s/it][A100%|██████████| 1/1 [00:31<00:00, 31.92s/it]
 96%|█████████▋| 5013/5198 [1:52:55<1:35:51, 31.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.97s/it][A100%|██████████| 1/1 [00:31<00:00, 31.97s/it]
 96%|█████████▋| 5013/5198 [1:52:57<1:35:54, 31.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 32.00s/it][A100%|██████████| 1/1 [00:31<00:00, 32.00s/it]
 96%|█████████▋| 5013/5198 [1:52:51<1:35:55, 31.11s/it]
100%|██████████| 1/1 [00:31<00:00, 31.96s/it][A100%|██████████| 1/1 [00:31<00:00, 31.96s/it]
 96%|█████████▋| 5013/5198 [1:52:36<1:35:53, 31.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.99s/it][A100%|██████████| 1/1 [00:31<00:00, 31.99s/it]
 96%|█████████▋| 5013/5198 [1:52:41<1:35:55, 31.11s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4700
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.08s/it][A100%|██████████| 1/1 [00:31<00:00, 31.08s/it]
 96%|█████████▋| 5014/5198 [1:53:24<1:35:29, 31.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:51:10,085] [INFO] [logging.py:96:log_dist] [Rank 0] step=5013, skipped=0, lr=[3.9433638472617546e-07], mom=[(0.9, 0.999)]
steps: 5013 loss: 1.4915 iter time (s): 30.458 samples/sec: 4.202

100%|██████████| 1/1 [00:31<00:00, 31.08s/it][A100%|██████████| 1/1 [00:31<00:00, 31.08s/it]
 96%|█████████▋| 5014/5198 [1:53:36<1:35:26, 31.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.23s/it][A100%|██████████| 1/1 [00:31<00:00, 31.23s/it]
 96%|█████████▋| 5014/5198 [1:53:34<1:35:29, 31.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.16s/it][A100%|██████████| 1/1 [00:31<00:00, 31.16s/it]
 96%|█████████▋| 5014/5198 [1:53:26<1:35:25, 31.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.10s/it][A100%|██████████| 1/1 [00:31<00:00, 31.10s/it]
 96%|█████████▋| 5014/5198 [1:53:22<1:35:23, 31.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.21s/it][A100%|██████████| 1/1 [00:31<00:00, 31.21s/it]
 96%|█████████▋| 5014/5198 [1:53:28<1:35:29, 31.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.16s/it][A100%|██████████| 1/1 [00:31<00:00, 31.16s/it]
 96%|█████████▋| 5014/5198 [1:53:08<1:35:26, 31.12s/it]
100%|██████████| 1/1 [00:31<00:00, 31.13s/it][A100%|██████████| 1/1 [00:31<00:00, 31.13s/it]
 96%|█████████▋| 5014/5198 [1:53:12<1:35:25, 31.12s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4701

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.26s/it][A100%|██████████| 1/1 [00:31<00:00, 31.26s/it]
 96%|█████████▋| 5015/5198 [1:53:56<1:35:12, 31.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:51:41,465] [INFO] [logging.py:96:log_dist] [Rank 0] step=5014, skipped=0, lr=[3.932361428966917e-07], mom=[(0.9, 0.999)]
steps: 5014 loss: 1.4152 iter time (s): 30.704 samples/sec: 4.169

100%|██████████| 1/1 [00:31<00:00, 31.34s/it][A100%|██████████| 1/1 [00:31<00:00, 31.34s/it]
 96%|█████████▋| 5015/5198 [1:54:07<1:35:07, 31.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.40s/it][A100%|██████████| 1/1 [00:31<00:00, 31.40s/it]
 96%|█████████▋| 5015/5198 [1:54:05<1:35:12, 31.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.42s/it][A100%|██████████| 1/1 [00:31<00:00, 31.42s/it]
 96%|█████████▋| 5015/5198 [1:53:57<1:35:11, 31.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.37s/it][A100%|██████████| 1/1 [00:31<00:00, 31.37s/it]
 96%|█████████▋| 5015/5198 [1:54:00<1:35:11, 31.21s/it]
100%|██████████| 1/1 [00:31<00:00, 31.39s/it][A100%|██████████| 1/1 [00:31<00:00, 31.39s/it]
 96%|█████████▋| 5015/5198 [1:53:53<1:35:08, 31.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.38s/it][A100%|██████████| 1/1 [00:31<00:00, 31.38s/it]
 96%|█████████▋| 5015/5198 [1:53:39<1:35:09, 31.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.39s/it][A100%|██████████| 1/1 [00:31<00:00, 31.39s/it]
 96%|█████████▋| 5015/5198 [1:53:44<1:35:09, 31.20s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4702
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.12s/it][A100%|██████████| 1/1 [00:34<00:00, 34.12s/it]
 96%|█████████▋| 5016/5198 [1:54:30<1:37:27, 32.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:52:15,821] [INFO] [logging.py:96:log_dist] [Rank 0] step=5015, skipped=0, lr=[3.921373791918186e-07], mom=[(0.9, 0.999)]
steps: 5015 loss: 1.4347 iter time (s): 33.665 samples/sec: 3.802

100%|██████████| 1/1 [00:34<00:00, 34.35s/it][A100%|██████████| 1/1 [00:34<00:00, 34.35s/it]
 96%|█████████▋| 5016/5198 [1:54:42<1:37:29, 32.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.31s/it][A100%|██████████| 1/1 [00:34<00:00, 34.31s/it]
 96%|█████████▋| 5016/5198 [1:54:40<1:37:30, 32.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.36s/it][A100%|██████████| 1/1 [00:34<00:00, 34.36s/it]
 96%|█████████▋| 5016/5198 [1:54:32<1:37:32, 32.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.35s/it][A100%|██████████| 1/1 [00:34<00:00, 34.35s/it]
 96%|█████████▋| 5016/5198 [1:54:34<1:37:31, 32.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.39s/it][A100%|██████████| 1/1 [00:34<00:00, 34.39s/it]
 96%|█████████▋| 5016/5198 [1:54:28<1:37:32, 32.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.40s/it][A100%|██████████| 1/1 [00:34<00:00, 34.40s/it]
 96%|█████████▋| 5016/5198 [1:54:13<1:37:33, 32.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.40s/it][A100%|██████████| 1/1 [00:34<00:00, 34.40s/it]
 96%|█████████▋| 5016/5198 [1:54:18<1:37:33, 32.16s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4703
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.22s/it][A100%|██████████| 1/1 [00:30<00:00, 30.22s/it]
 97%|█████████▋| 5017/5198 [1:55:00<1:35:20, 31.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:52:46,036] [INFO] [logging.py:96:log_dist] [Rank 0] step=5016, skipped=0, lr=[3.9104009396406813e-07], mom=[(0.9, 0.999)]
steps: 5016 loss: 1.5025 iter time (s): 29.474 samples/sec: 4.343

100%|██████████| 1/1 [00:30<00:00, 30.19s/it][A100%|██████████| 1/1 [00:30<00:00, 30.19s/it]
 97%|█████████▋| 5017/5198 [1:55:12<1:35:12, 31.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.17s/it][A100%|██████████| 1/1 [00:30<00:00, 30.18s/it]
 97%|█████████▋| 5017/5198 [1:55:10<1:35:11, 31.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.12s/it][A100%|██████████| 1/1 [00:30<00:00, 30.12s/it]
 97%|█████████▋| 5017/5198 [1:55:02<1:35:10, 31.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.16s/it][A100%|██████████| 1/1 [00:30<00:00, 30.16s/it]
 97%|█████████▋| 5017/5198 [1:55:04<1:35:11, 31.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.16s/it][A100%|██████████| 1/1 [00:30<00:00, 30.16s/it]
 97%|█████████▋| 5017/5198 [1:54:58<1:35:12, 31.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.12s/it][A100%|██████████| 1/1 [00:30<00:00, 30.12s/it]
 97%|█████████▋| 5017/5198 [1:54:43<1:35:10, 31.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.12s/it][A100%|██████████| 1/1 [00:30<00:00, 30.12s/it]
 97%|█████████▋| 5017/5198 [1:54:48<1:35:10, 31.55s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4704
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.62s/it][A100%|██████████| 1/1 [00:30<00:00, 30.62s/it]
 97%|█████████▋| 5018/5198 [1:55:31<1:34:02, 31.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:53:16,826] [INFO] [logging.py:96:log_dist] [Rank 0] step=5017, skipped=0, lr=[3.899442875654748e-07], mom=[(0.9, 0.999)]
steps: 5017 loss: 1.4833 iter time (s): 30.137 samples/sec: 4.247

100%|██████████| 1/1 [00:30<00:00, 30.78s/it][A100%|██████████| 1/1 [00:30<00:00, 30.79s/it]
 97%|█████████▋| 5018/5198 [1:55:43<1:33:59, 31.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.75s/it][A100%|██████████| 1/1 [00:30<00:00, 30.75s/it]
 97%|█████████▋| 5018/5198 [1:55:41<1:33:57, 31.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.80s/it][A100%|██████████| 1/1 [00:30<00:00, 30.80s/it]
 97%|█████████▋| 5018/5198 [1:55:35<1:33:59, 31.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.90s/it][A100%|██████████| 1/1 [00:30<00:00, 30.90s/it]
 97%|█████████▋| 5018/5198 [1:55:33<1:34:04, 31.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.84s/it][A100%|██████████| 1/1 [00:30<00:00, 30.84s/it]
 97%|█████████▋| 5018/5198 [1:55:29<1:34:02, 31.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.85s/it][A100%|██████████| 1/1 [00:30<00:00, 30.85s/it]
 97%|█████████▋| 5018/5198 [1:55:14<1:34:01, 31.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.84s/it][A100%|██████████| 1/1 [00:30<00:00, 30.84s/it]
 97%|█████████▋| 5018/5198 [1:55:19<1:34:01, 31.34s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4705
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.71s/it][A100%|██████████| 1/1 [00:30<00:00, 30.71s/it]
 97%|█████████▋| 5019/5198 [1:56:02<1:33:06, 31.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:53:47,721] [INFO] [logging.py:96:log_dist] [Rank 0] step=5018, skipped=0, lr=[3.888499603476014e-07], mom=[(0.9, 0.999)]
steps: 5018 loss: 1.4557 iter time (s): 30.181 samples/sec: 4.241

100%|██████████| 1/1 [00:30<00:00, 30.98s/it][A100%|██████████| 1/1 [00:30<00:00, 30.98s/it]
 97%|█████████▋| 5019/5198 [1:56:14<1:33:09, 31.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.94s/it][A100%|██████████| 1/1 [00:30<00:00, 30.94s/it]
 97%|█████████▋| 5019/5198 [1:56:12<1:33:06, 31.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.77s/it][A100%|██████████| 1/1 [00:30<00:00, 30.77s/it]
 97%|█████████▋| 5019/5198 [1:56:03<1:33:02, 31.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.85s/it][A100%|██████████| 1/1 [00:30<00:00, 30.85s/it]
 97%|█████████▋| 5019/5198 [1:56:00<1:33:04, 31.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.95s/it][A100%|██████████| 1/1 [00:30<00:00, 30.95s/it]
 97%|█████████▋| 5019/5198 [1:56:06<1:33:08, 31.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.88s/it][A100%|██████████| 1/1 [00:30<00:00, 30.89s/it]
 97%|█████████▋| 5019/5198 [1:55:45<1:33:05, 31.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.89s/it][A100%|██████████| 1/1 [00:30<00:00, 30.89s/it]
 97%|█████████▋| 5019/5198 [1:55:50<1:33:06, 31.21s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4706
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.48s/it][A100%|██████████| 1/1 [00:34<00:00, 34.48s/it]
 97%|█████████▋| 5020/5198 [1:56:36<1:35:36, 32.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:54:22,411] [INFO] [logging.py:96:log_dist] [Rank 0] step=5019, skipped=0, lr=[3.8775711266153546e-07], mom=[(0.9, 0.999)]
steps: 5019 loss: 1.4880 iter time (s): 33.980 samples/sec: 3.767

100%|██████████| 1/1 [00:34<00:00, 34.66s/it][A100%|██████████| 1/1 [00:34<00:00, 34.66s/it]
 97%|█████████▋| 5020/5198 [1:56:48<1:35:42, 32.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.74s/it][A100%|██████████| 1/1 [00:34<00:00, 34.74s/it]
 97%|█████████▋| 5020/5198 [1:56:46<1:35:44, 32.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.85s/it][A100%|██████████| 1/1 [00:34<00:00, 34.85s/it]
 97%|█████████▋| 5020/5198 [1:56:38<1:35:47, 32.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.77s/it][A100%|██████████| 1/1 [00:34<00:00, 34.77s/it]
 97%|█████████▋| 5020/5198 [1:56:41<1:35:47, 32.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.84s/it][A100%|██████████| 1/1 [00:34<00:00, 34.84s/it]
 97%|█████████▋| 5020/5198 [1:56:35<1:35:48, 32.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.83s/it][A100%|██████████| 1/1 [00:34<00:00, 34.84s/it]
 97%|█████████▋| 5020/5198 [1:56:20<1:35:48, 32.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.84s/it][A100%|██████████| 1/1 [00:34<00:00, 34.84s/it]
 97%|█████████▋| 5020/5198 [1:56:25<1:35:48, 32.30s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4707
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.37s/it][A100%|██████████| 1/1 [00:31<00:00, 31.37s/it]
 97%|█████████▋| 5021/5198 [1:57:08<1:34:27, 32.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:54:53,838] [INFO] [logging.py:96:log_dist] [Rank 0] step=5020, skipped=0, lr=[3.866657448578891e-07], mom=[(0.9, 0.999)]
steps: 5020 loss: 1.4579 iter time (s): 30.563 samples/sec: 4.188

100%|██████████| 1/1 [00:31<00:00, 31.34s/it][A100%|██████████| 1/1 [00:31<00:00, 31.34s/it]
 97%|█████████▋| 5021/5198 [1:57:20<1:34:22, 31.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.40s/it][A100%|██████████| 1/1 [00:31<00:00, 31.40s/it]
 97%|█████████▋| 5021/5198 [1:57:18<1:34:25, 32.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.24s/it][A100%|██████████| 1/1 [00:31<00:00, 31.24s/it]
 97%|█████████▋| 5021/5198 [1:57:10<1:34:19, 31.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.24s/it][A100%|██████████| 1/1 [00:31<00:00, 31.24s/it]
 97%|█████████▋| 5021/5198 [1:57:12<1:34:19, 31.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.25s/it][A100%|██████████| 1/1 [00:31<00:00, 31.25s/it]
 97%|█████████▋| 5021/5198 [1:57:06<1:34:20, 31.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.20s/it][A100%|██████████| 1/1 [00:31<00:00, 31.20s/it]
 97%|█████████▋| 5021/5198 [1:56:51<1:34:18, 31.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.22s/it][A100%|██████████| 1/1 [00:31<00:00, 31.22s/it]
 97%|█████████▋| 5021/5198 [1:56:56<1:34:19, 31.98s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4708
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.98s/it][A100%|██████████| 1/1 [00:32<00:00, 32.98s/it]
 97%|█████████▋| 5022/5198 [1:57:41<1:34:53, 32.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:55:27,025] [INFO] [logging.py:96:log_dist] [Rank 0] step=5021, skipped=0, lr=[3.855758572868011e-07], mom=[(0.9, 0.999)]
steps: 5021 loss: 1.5663 iter time (s): 32.523 samples/sec: 3.936

100%|██████████| 1/1 [00:33<00:00, 33.24s/it][A100%|██████████| 1/1 [00:33<00:00, 33.24s/it]
 97%|█████████▋| 5022/5198 [1:57:53<1:34:56, 32.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.20s/it][A100%|██████████| 1/1 [00:33<00:00, 33.20s/it]
 97%|█████████▋| 5022/5198 [1:57:51<1:34:56, 32.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.26s/it][A100%|██████████| 1/1 [00:33<00:00, 33.26s/it]
 97%|█████████▋| 5022/5198 [1:57:43<1:34:56, 32.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.31s/it][A100%|██████████| 1/1 [00:33<00:00, 33.31s/it]
 97%|█████████▋| 5022/5198 [1:57:45<1:34:58, 32.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.32s/it][A100%|██████████| 1/1 [00:33<00:00, 33.32s/it]
 97%|█████████▋| 5022/5198 [1:57:39<1:34:59, 32.39s/it]
100%|██████████| 1/1 [00:33<00:00, 33.29s/it][A100%|██████████| 1/1 [00:33<00:00, 33.29s/it]
 97%|█████████▋| 5022/5198 [1:57:29<1:34:57, 32.37s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4709

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

100%|██████████| 1/1 [00:33<00:00, 33.32s/it][A100%|██████████| 1/1 [00:33<00:00, 33.32s/it]
 97%|█████████▋| 5022/5198 [1:57:25<1:34:58, 32.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.39s/it][A100%|██████████| 1/1 [00:31<00:00, 31.40s/it]
 97%|█████████▋| 5023/5198 [1:58:13<1:33:41, 32.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:55:58,594] [INFO] [logging.py:96:log_dist] [Rank 0] step=5022, skipped=0, lr=[3.844874502979335e-07], mom=[(0.9, 0.999)]
steps: 5022 loss: 1.4771 iter time (s): 30.798 samples/sec: 4.156

100%|██████████| 1/1 [00:31<00:00, 31.58s/it][A100%|██████████| 1/1 [00:31<00:00, 31.58s/it]
 97%|█████████▋| 5023/5198 [1:58:24<1:33:43, 32.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.58s/it][A100%|██████████| 1/1 [00:31<00:00, 31.58s/it]
 97%|█████████▋| 5023/5198 [1:58:23<1:33:43, 32.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.54s/it][A100%|██████████| 1/1 [00:31<00:00, 31.54s/it]
 97%|█████████▋| 5023/5198 [1:58:14<1:33:40, 32.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.54s/it][A100%|██████████| 1/1 [00:31<00:00, 31.54s/it]
 97%|█████████▋| 5023/5198 [1:58:17<1:33:42, 32.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.51s/it][A100%|██████████| 1/1 [00:31<00:00, 31.51s/it]
 97%|█████████▋| 5023/5198 [1:58:11<1:33:41, 32.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.54s/it][A100%|██████████| 1/1 [00:31<00:00, 31.54s/it]
 97%|█████████▋| 5023/5198 [1:57:56<1:33:42, 32.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.56s/it][A100%|██████████| 1/1 [00:31<00:00, 31.56s/it]
 97%|█████████▋| 5023/5198 [1:58:01<1:33:42, 32.13s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_313
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.24s/it][A100%|██████████| 1/1 [00:24<00:00, 24.24s/it]
 97%|█████████▋| 5024/5198 [1:58:37<1:26:29, 29.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:56:23,135] [INFO] [logging.py:96:log_dist] [Rank 0] step=5023, skipped=0, lr=[3.834005242404742e-07], mom=[(0.9, 0.999)]
steps: 5023 loss: 2.0644 iter time (s): 23.804 samples/sec: 5.377

100%|██████████| 1/1 [00:24<00:00, 24.71s/it][A100%|██████████| 1/1 [00:24<00:00, 24.71s/it]
 97%|█████████▋| 5024/5198 [1:58:49<1:26:44, 29.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.72s/it][A100%|██████████| 1/1 [00:24<00:00, 24.73s/it]
 97%|█████████▋| 5024/5198 [1:58:47<1:26:44, 29.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.68s/it][A100%|██████████| 1/1 [00:24<00:00, 24.68s/it]
 97%|█████████▋| 5024/5198 [1:58:39<1:26:40, 29.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.62s/it][A100%|██████████| 1/1 [00:24<00:00, 24.62s/it]
 97%|█████████▋| 5024/5198 [1:58:42<1:26:38, 29.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.61s/it][A100%|██████████| 1/1 [00:24<00:00, 24.61s/it]
 97%|█████████▋| 5024/5198 [1:58:35<1:26:38, 29.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.64s/it][A100%|██████████| 1/1 [00:24<00:00, 24.64s/it]
 97%|█████████▋| 5024/5198 [1:58:21<1:26:40, 29.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.65s/it][A100%|██████████| 1/1 [00:24<00:00, 24.65s/it]
 97%|█████████▋| 5024/5198 [1:58:26<1:26:40, 29.89s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4710
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.83s/it][A100%|██████████| 1/1 [00:31<00:00, 31.83s/it]
 97%|█████████▋| 5025/5198 [1:59:09<1:27:52, 30.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:56:55,053] [INFO] [logging.py:96:log_dist] [Rank 0] step=5024, skipped=0, lr=[3.823150794631371e-07], mom=[(0.9, 0.999)]
steps: 5024 loss: 1.4478 iter time (s): 31.044 samples/sec: 4.123

100%|██████████| 1/1 [00:31<00:00, 31.67s/it][A100%|██████████| 1/1 [00:31<00:00, 31.67s/it]
 97%|█████████▋| 5025/5198 [1:59:21<1:27:45, 30.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.75s/it][A100%|██████████| 1/1 [00:31<00:00, 31.75s/it]
 97%|█████████▋| 5025/5198 [1:59:19<1:27:50, 30.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.83s/it][A100%|██████████| 1/1 [00:31<00:00, 31.83s/it]
 97%|█████████▋| 5025/5198 [1:59:11<1:27:52, 30.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.83s/it][A100%|██████████| 1/1 [00:31<00:00, 31.83s/it]
 97%|█████████▋| 5025/5198 [1:59:13<1:27:50, 30.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.84s/it][A100%|██████████| 1/1 [00:31<00:00, 31.84s/it]
 97%|█████████▋| 5025/5198 [1:59:07<1:27:50, 30.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.79s/it][A100%|██████████| 1/1 [00:31<00:00, 31.80s/it]
 97%|█████████▋| 5025/5198 [1:58:53<1:27:49, 30.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.79s/it][A100%|██████████| 1/1 [00:31<00:00, 31.79s/it]
 97%|█████████▋| 5025/5198 [1:58:57<1:27:49, 30.46s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4711
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.82s/it][A100%|██████████| 1/1 [00:31<00:00, 31.82s/it]
 97%|█████████▋| 5026/5198 [1:59:41<1:28:38, 30.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:57:27,061] [INFO] [logging.py:96:log_dist] [Rank 0] step=5025, skipped=0, lr=[3.812311163141594e-07], mom=[(0.9, 0.999)]
steps: 5025 loss: 1.4578 iter time (s): 31.247 samples/sec: 4.096

100%|██████████| 1/1 [00:32<00:00, 32.07s/it][A100%|██████████| 1/1 [00:32<00:00, 32.07s/it]
 97%|█████████▋| 5026/5198 [1:59:53<1:28:40, 30.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.91s/it][A100%|██████████| 1/1 [00:31<00:00, 31.91s/it]
 97%|█████████▋| 5026/5198 [1:59:51<1:28:34, 30.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.94s/it][A100%|██████████| 1/1 [00:31<00:00, 31.94s/it]
 97%|█████████▋| 5026/5198 [1:59:43<1:28:37, 30.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.92s/it][A100%|██████████| 1/1 [00:31<00:00, 31.93s/it]
 97%|█████████▋| 5026/5198 [1:59:45<1:28:35, 30.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.99s/it][A100%|██████████| 1/1 [00:31<00:00, 31.99s/it]
 97%|█████████▋| 5026/5198 [1:59:39<1:28:38, 30.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.98s/it][A100%|██████████| 1/1 [00:31<00:00, 31.98s/it]
 97%|█████████▋| 5026/5198 [1:59:25<1:28:37, 30.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.99s/it][A100%|██████████| 1/1 [00:31<00:00, 31.99s/it]
 97%|█████████▋| 5026/5198 [1:59:29<1:28:38, 30.92s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4712
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.66s/it][A100%|██████████| 1/1 [00:31<00:00, 31.66s/it]
 97%|█████████▋| 5027/5198 [2:00:13<1:28:52, 31.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:57:58,788] [INFO] [logging.py:96:log_dist] [Rank 0] step=5026, skipped=0, lr=[3.801486351413025e-07], mom=[(0.9, 0.999)]
steps: 5026 loss: 1.4342 iter time (s): 30.985 samples/sec: 4.131

100%|██████████| 1/1 [00:31<00:00, 31.69s/it][A100%|██████████| 1/1 [00:31<00:00, 31.69s/it]
 97%|█████████▋| 5027/5198 [2:00:25<1:28:48, 31.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.78s/it][A100%|██████████| 1/1 [00:31<00:00, 31.78s/it]
 97%|█████████▋| 5027/5198 [2:00:23<1:28:50, 31.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.74s/it][A100%|██████████| 1/1 [00:31<00:00, 31.74s/it]
 97%|█████████▋| 5027/5198 [2:00:15<1:28:49, 31.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.78s/it][A100%|██████████| 1/1 [00:31<00:00, 31.78s/it]
 97%|█████████▋| 5027/5198 [2:00:17<1:28:50, 31.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.72s/it][A100%|██████████| 1/1 [00:31<00:00, 31.72s/it]
 97%|█████████▋| 5027/5198 [1:59:56<1:28:48, 31.16s/it]
100%|██████████| 1/1 [00:31<00:00, 31.75s/it][A100%|██████████| 1/1 [00:31<00:00, 31.75s/it]
 97%|█████████▋| 5027/5198 [2:00:11<1:28:50, 31.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.74s/it][A100%|██████████| 1/1 [00:31<00:00, 31.74s/it]
 97%|█████████▋| 5027/5198 [2:00:01<1:28:49, 31.17s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4713
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.52s/it][A100%|██████████| 1/1 [00:35<00:00, 35.52s/it]
 97%|█████████▋| 5028/5198 [2:00:49<1:32:09, 32.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:58:34,602] [INFO] [logging.py:96:log_dist] [Rank 0] step=5027, skipped=0, lr=[3.7906763629185554e-07], mom=[(0.9, 0.999)]
steps: 5027 loss: 1.5145 iter time (s): 35.053 samples/sec: 3.652

100%|██████████| 1/1 [00:35<00:00, 35.85s/it][A100%|██████████| 1/1 [00:35<00:00, 35.85s/it]
 97%|█████████▋| 5028/5198 [2:01:00<1:32:17, 32.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.78s/it][A100%|██████████| 1/1 [00:35<00:00, 35.78s/it]
 97%|█████████▋| 5028/5198 [2:00:59<1:32:14, 32.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.79s/it][A100%|██████████| 1/1 [00:35<00:00, 35.79s/it]
 97%|█████████▋| 5028/5198 [2:00:50<1:32:14, 32.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.75s/it][A100%|██████████| 1/1 [00:35<00:00, 35.76s/it]
 97%|█████████▋| 5028/5198 [2:00:53<1:32:13, 32.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.74s/it][A100%|██████████| 1/1 [00:35<00:00, 35.74s/it]
 97%|█████████▋| 5028/5198 [2:00:47<1:32:12, 32.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.77s/it][A100%|██████████| 1/1 [00:35<00:00, 35.77s/it]
 97%|█████████▋| 5028/5198 [2:00:32<1:32:13, 32.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.76s/it][A100%|██████████| 1/1 [00:35<00:00, 35.77s/it]
 97%|█████████▋| 5028/5198 [2:00:37<1:32:13, 32.55s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4714
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.75s/it][A100%|██████████| 1/1 [00:31<00:00, 31.75s/it]
 97%|█████████▋| 5029/5198 [2:01:21<1:31:05, 32.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:59:06,404] [INFO] [logging.py:96:log_dist] [Rank 0] step=5028, skipped=0, lr=[3.77988120112627e-07], mom=[(0.9, 0.999)]
steps: 5028 loss: 1.5063 iter time (s): 31.084 samples/sec: 4.118

100%|██████████| 1/1 [00:31<00:00, 31.72s/it][A100%|██████████| 1/1 [00:31<00:00, 31.72s/it]
 97%|█████████▋| 5029/5198 [2:01:32<1:31:02, 32.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.91s/it][A100%|██████████| 1/1 [00:31<00:00, 31.91s/it]
 97%|█████████▋| 5029/5198 [2:01:31<1:31:10, 32.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.98s/it][A100%|██████████| 1/1 [00:31<00:00, 31.98s/it]
 97%|█████████▋| 5029/5198 [2:01:25<1:31:12, 32.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.05s/it][A100%|██████████| 1/1 [00:32<00:00, 32.05s/it]
 97%|█████████▋| 5029/5198 [2:01:22<1:31:16, 32.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.02s/it][A100%|██████████| 1/1 [00:32<00:00, 32.02s/it]
 97%|█████████▋| 5029/5198 [2:01:04<1:31:13, 32.39s/it]
100%|██████████| 1/1 [00:32<00:00, 32.05s/it][A100%|██████████| 1/1 [00:32<00:00, 32.05s/it]
 97%|█████████▋| 5029/5198 [2:01:19<1:31:15, 32.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.02s/it][A100%|██████████| 1/1 [00:32<00:00, 32.02s/it]
 97%|█████████▋| 5029/5198 [2:01:09<1:31:13, 32.39s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4715
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.60s/it][A100%|██████████| 1/1 [00:30<00:00, 30.60s/it]
 97%|█████████▋| 5030/5198 [2:01:51<1:29:14, 31.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 00:59:37,155] [INFO] [logging.py:96:log_dist] [Rank 0] step=5029, skipped=0, lr=[3.769100869499539e-07], mom=[(0.9, 0.999)]
steps: 5029 loss: 1.3658 iter time (s): 29.813 samples/sec: 4.293

100%|██████████| 1/1 [00:30<00:00, 30.79s/it][A100%|██████████| 1/1 [00:30<00:00, 30.79s/it]
 97%|█████████▋| 5030/5198 [2:02:03<1:29:13, 31.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.61s/it][A100%|██████████| 1/1 [00:30<00:00, 30.61s/it]
 97%|█████████▋| 5030/5198 [2:02:01<1:29:10, 31.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.52s/it][A100%|██████████| 1/1 [00:30<00:00, 30.52s/it]
 97%|█████████▋| 5030/5198 [2:01:53<1:29:09, 31.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.62s/it][A100%|██████████| 1/1 [00:30<00:00, 30.62s/it]
 97%|█████████▋| 5030/5198 [2:01:56<1:29:11, 31.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.57s/it][A100%|██████████| 1/1 [00:30<00:00, 30.57s/it]
 97%|█████████▋| 5030/5198 [2:01:49<1:29:10, 31.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.59s/it][A100%|██████████| 1/1 [00:30<00:00, 30.59s/it]
 97%|█████████▋| 5030/5198 [2:01:35<1:29:11, 31.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.58s/it][A100%|██████████| 1/1 [00:30<00:00, 30.58s/it]
 97%|█████████▋| 5030/5198 [2:01:39<1:29:10, 31.85s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4716
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.97s/it][A100%|██████████| 1/1 [00:30<00:00, 30.97s/it]
 97%|█████████▋| 5031/5198 [2:02:22<1:28:04, 31.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:00:08,321] [INFO] [logging.py:96:log_dist] [Rank 0] step=5030, skipped=0, lr=[3.7583353714969567e-07], mom=[(0.9, 0.999)]
steps: 5030 loss: 1.4792 iter time (s): 30.393 samples/sec: 4.211

100%|██████████| 1/1 [00:31<00:00, 31.16s/it][A100%|██████████| 1/1 [00:31<00:00, 31.16s/it]
 97%|█████████▋| 5031/5198 [2:02:34<1:28:06, 31.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.05s/it][A100%|██████████| 1/1 [00:31<00:00, 31.05s/it]
 97%|█████████▋| 5031/5198 [2:02:32<1:27:59, 31.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.14s/it][A100%|██████████| 1/1 [00:31<00:00, 31.15s/it]
 97%|█████████▋| 5031/5198 [2:02:24<1:28:03, 31.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.14s/it][A100%|██████████| 1/1 [00:31<00:00, 31.14s/it]
 97%|█████████▋| 5031/5198 [2:02:27<1:28:04, 31.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.13s/it][A100%|██████████| 1/1 [00:31<00:00, 31.13s/it]
 97%|█████████▋| 5031/5198 [2:02:20<1:28:03, 31.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.18s/it][A100%|██████████| 1/1 [00:31<00:00, 31.18s/it]
 97%|█████████▋| 5031/5198 [2:02:06<1:28:05, 31.65s/it]
100%|██████████| 1/1 [00:31<00:00, 31.17s/it][A100%|██████████| 1/1 [00:31<00:00, 31.17s/it]
 97%|█████████▋| 5031/5198 [2:02:11<1:28:05, 31.65s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4717

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.91s/it][A100%|██████████| 1/1 [00:28<00:00, 28.91s/it]
 97%|█████████▋| 5032/5198 [2:02:52<1:25:26, 30.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:00:37,327] [INFO] [logging.py:96:log_dist] [Rank 0] step=5031, skipped=0, lr=[3.7475847105723583e-07], mom=[(0.9, 0.999)]
steps: 5031 loss: 1.5091 iter time (s): 28.221 samples/sec: 4.536

100%|██████████| 1/1 [00:28<00:00, 28.94s/it][A100%|██████████| 1/1 [00:28<00:00, 28.94s/it]
 97%|█████████▋| 5032/5198 [2:03:03<1:25:19, 30.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.02s/it][A100%|██████████| 1/1 [00:29<00:00, 29.02s/it]
 97%|█████████▋| 5032/5198 [2:03:01<1:25:18, 30.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 29.00s/it][A100%|██████████| 1/1 [00:28<00:00, 29.00s/it]
 97%|█████████▋| 5032/5198 [2:02:53<1:25:20, 30.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.96s/it][A100%|██████████| 1/1 [00:28<00:00, 28.97s/it]
 97%|█████████▋| 5032/5198 [2:02:56<1:25:19, 30.84s/it]
100%|██████████| 1/1 [00:28<00:00, 28.92s/it][A100%|██████████| 1/1 [00:28<00:00, 28.92s/it]
 97%|█████████▋| 5032/5198 [2:02:49<1:25:16, 30.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.89s/it][A100%|██████████| 1/1 [00:28<00:00, 28.89s/it]
 97%|█████████▋| 5032/5198 [2:02:35<1:25:17, 30.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.90s/it][A100%|██████████| 1/1 [00:28<00:00, 28.90s/it]
 97%|█████████▋| 5032/5198 [2:02:40<1:25:16, 30.82s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4718
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.50s/it][A100%|██████████| 1/1 [00:31<00:00, 31.50s/it]
 97%|█████████▋| 5033/5198 [2:03:23<1:25:33, 31.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:01:08,986] [INFO] [logging.py:96:log_dist] [Rank 0] step=5032, skipped=0, lr=[3.736848890174835e-07], mom=[(0.9, 0.999)]
steps: 5032 loss: 1.4209 iter time (s): 30.977 samples/sec: 4.132

100%|██████████| 1/1 [00:31<00:00, 31.68s/it][A100%|██████████| 1/1 [00:31<00:00, 31.68s/it]
 97%|█████████▋| 5033/5198 [2:03:35<1:25:30, 31.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.69s/it][A100%|██████████| 1/1 [00:31<00:00, 31.69s/it]
 97%|█████████▋| 5033/5198 [2:03:33<1:25:30, 31.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.62s/it][A100%|██████████| 1/1 [00:31<00:00, 31.62s/it]
 97%|█████████▋| 5033/5198 [2:03:25<1:25:28, 31.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.67s/it][A100%|██████████| 1/1 [00:31<00:00, 31.67s/it]
 97%|█████████▋| 5033/5198 [2:03:27<1:25:30, 31.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.69s/it][A100%|██████████| 1/1 [00:31<00:00, 31.69s/it]
 97%|█████████▋| 5033/5198 [2:03:21<1:25:28, 31.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.70s/it][A100%|██████████| 1/1 [00:31<00:00, 31.70s/it]
 97%|█████████▋| 5033/5198 [2:03:06<1:25:29, 31.09s/it]
100%|██████████| 1/1 [00:31<00:00, 31.69s/it][A100%|██████████| 1/1 [00:31<00:00, 31.69s/it]
 97%|█████████▋| 5033/5198 [2:03:11<1:25:29, 31.09s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4719

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.68s/it][A100%|██████████| 1/1 [00:29<00:00, 29.68s/it]
 97%|█████████▋| 5034/5198 [2:03:53<1:23:56, 30.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:01:38,733] [INFO] [logging.py:96:log_dist] [Rank 0] step=5033, skipped=0, lr=[3.7261279137487027e-07], mom=[(0.9, 0.999)]
steps: 5033 loss: 1.4147 iter time (s): 29.025 samples/sec: 4.410

100%|██████████| 1/1 [00:29<00:00, 29.73s/it][A100%|██████████| 1/1 [00:29<00:00, 29.73s/it]
 97%|█████████▋| 5034/5198 [2:04:05<1:23:53, 30.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.76s/it][A100%|██████████| 1/1 [00:29<00:00, 29.76s/it]
 97%|█████████▋| 5034/5198 [2:04:03<1:23:54, 30.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.72s/it][A100%|██████████| 1/1 [00:29<00:00, 29.72s/it]
 97%|█████████▋| 5034/5198 [2:03:54<1:23:50, 30.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.67s/it][A100%|██████████| 1/1 [00:29<00:00, 29.67s/it]
 97%|█████████▋| 5034/5198 [2:03:57<1:23:49, 30.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.72s/it][A100%|██████████| 1/1 [00:29<00:00, 29.72s/it]
 97%|█████████▋| 5034/5198 [2:03:51<1:23:51, 30.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.70s/it][A100%|██████████| 1/1 [00:29<00:00, 29.70s/it]
 97%|█████████▋| 5034/5198 [2:03:41<1:23:50, 30.67s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4720
Training on 128 of 128 sentences.

100%|██████████| 1/1 [00:29<00:00, 29.71s/it][A100%|██████████| 1/1 [00:29<00:00, 29.71s/it]
 97%|█████████▋| 5034/5198 [2:03:36<1:23:51, 30.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.36s/it][A100%|██████████| 1/1 [00:32<00:00, 32.36s/it]
 97%|█████████▋| 5035/5198 [2:04:25<1:24:54, 31.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:02:11,375] [INFO] [logging.py:96:log_dist] [Rank 0] step=5034, skipped=0, lr=[3.715421784733504e-07], mom=[(0.9, 0.999)]
steps: 5034 loss: 1.4702 iter time (s): 31.957 samples/sec: 4.005

100%|██████████| 1/1 [00:32<00:00, 32.63s/it][A100%|██████████| 1/1 [00:32<00:00, 32.63s/it]
 97%|█████████▋| 5035/5198 [2:04:37<1:24:57, 31.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.64s/it][A100%|██████████| 1/1 [00:32<00:00, 32.64s/it]
 97%|█████████▋| 5035/5198 [2:04:35<1:24:58, 31.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.71s/it][A100%|██████████| 1/1 [00:32<00:00, 32.71s/it]
 97%|█████████▋| 5035/5198 [2:04:27<1:24:59, 31.29s/it]
100%|██████████| 1/1 [00:32<00:00, 32.66s/it][A100%|██████████| 1/1 [00:32<00:00, 32.66s/it]
 97%|█████████▋| 5035/5198 [2:04:30<1:24:57, 31.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.70s/it][A100%|██████████| 1/1 [00:32<00:00, 32.70s/it]
 97%|█████████▋| 5035/5198 [2:04:23<1:24:59, 31.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.72s/it][A100%|██████████| 1/1 [00:32<00:00, 32.72s/it]
 97%|█████████▋| 5035/5198 [2:04:09<1:25:00, 31.29s/it]
100%|██████████| 1/1 [00:32<00:00, 32.72s/it][A100%|██████████| 1/1 [00:32<00:00, 32.73s/it]
 97%|█████████▋| 5035/5198 [2:04:14<1:25:00, 31.29s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4721

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.81s/it][A100%|██████████| 1/1 [00:29<00:00, 29.81s/it]
 97%|█████████▋| 5036/5198 [2:04:55<1:23:21, 30.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:02:41,254] [INFO] [logging.py:96:log_dist] [Rank 0] step=5035, skipped=0, lr=[3.704730506564039e-07], mom=[(0.9, 0.999)]
steps: 5035 loss: 1.4351 iter time (s): 29.107 samples/sec: 4.398

100%|██████████| 1/1 [00:29<00:00, 29.84s/it][A100%|██████████| 1/1 [00:29<00:00, 29.84s/it]
 97%|█████████▋| 5036/5198 [2:05:07<1:23:17, 30.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.85s/it][A100%|██████████| 1/1 [00:29<00:00, 29.85s/it]
 97%|█████████▋| 5036/5198 [2:05:05<1:23:18, 30.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.81s/it][A100%|██████████| 1/1 [00:29<00:00, 29.81s/it]
 97%|█████████▋| 5036/5198 [2:04:57<1:23:17, 30.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.86s/it][A100%|██████████| 1/1 [00:29<00:00, 29.86s/it]
 97%|█████████▋| 5036/5198 [2:05:00<1:23:17, 30.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.84s/it][A100%|██████████| 1/1 [00:29<00:00, 29.84s/it]
 97%|█████████▋| 5036/5198 [2:04:53<1:23:18, 30.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.79s/it][A100%|██████████| 1/1 [00:29<00:00, 29.79s/it]
 97%|█████████▋| 5036/5198 [2:04:39<1:23:16, 30.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.83s/it][A100%|██████████| 1/1 [00:29<00:00, 29.83s/it]
 97%|█████████▋| 5036/5198 [2:04:43<1:23:18, 30.85s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4722
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.96s/it][A100%|██████████| 1/1 [00:28<00:00, 28.96s/it]
 97%|█████████▋| 5037/5198 [2:05:25<1:21:24, 30.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:03:10,312] [INFO] [logging.py:96:log_dist] [Rank 0] step=5036, skipped=0, lr=[3.694054082670334e-07], mom=[(0.9, 0.999)]
steps: 5036 loss: 1.4656 iter time (s): 28.327 samples/sec: 4.519

100%|██████████| 1/1 [00:29<00:00, 29.05s/it][A100%|██████████| 1/1 [00:29<00:00, 29.05s/it]
 97%|█████████▋| 5037/5198 [2:05:36<1:21:20, 30.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.02s/it][A100%|██████████| 1/1 [00:29<00:00, 29.02s/it]
 97%|█████████▋| 5037/5198 [2:05:34<1:21:19, 30.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.05s/it][A100%|██████████| 1/1 [00:29<00:00, 29.05s/it]
 97%|█████████▋| 5037/5198 [2:05:26<1:21:20, 30.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.03s/it][A100%|██████████| 1/1 [00:29<00:00, 29.03s/it]
 97%|█████████▋| 5037/5198 [2:05:29<1:21:19, 30.31s/it]

100%|██████████| 1/1 [00:28<00:00, 28.97s/it][A  0%|          | 0/1 [00:00<?, ?it/s][A100%|██████████| 1/1 [00:28<00:00, 28.97s/it]
 97%|█████████▋| 5037/5198 [2:05:22<1:21:16, 30.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.99s/it][A100%|██████████| 1/1 [00:28<00:00, 29.00s/it]
 97%|█████████▋| 5037/5198 [2:05:08<1:21:16, 30.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.97s/it][A100%|██████████| 1/1 [00:28<00:00, 28.97s/it]
 97%|█████████▋| 5037/5198 [2:05:12<1:21:16, 30.29s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4723
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.44s/it][A100%|██████████| 1/1 [00:29<00:00, 29.44s/it]
 97%|█████████▋| 5038/5198 [2:05:54<1:20:19, 30.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:03:39,936] [INFO] [logging.py:96:log_dist] [Rank 0] step=5037, skipped=0, lr=[3.6833925164776533e-07], mom=[(0.9, 0.999)]
steps: 5037 loss: 1.4309 iter time (s): 28.981 samples/sec: 4.417

100%|██████████| 1/1 [00:29<00:00, 29.66s/it][A100%|██████████| 1/1 [00:29<00:00, 29.66s/it]
 97%|█████████▋| 5038/5198 [2:06:06<1:20:18, 30.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.61s/it][A100%|██████████| 1/1 [00:29<00:00, 29.61s/it]
 97%|█████████▋| 5038/5198 [2:06:04<1:20:15, 30.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.59s/it][A100%|██████████| 1/1 [00:29<00:00, 29.59s/it]
 97%|█████████▋| 5038/5198 [2:05:56<1:20:15, 30.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.63s/it][A100%|██████████| 1/1 [00:29<00:00, 29.63s/it]
 97%|█████████▋| 5038/5198 [2:05:58<1:20:17, 30.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.68s/it][A100%|██████████| 1/1 [00:29<00:00, 29.68s/it]
 97%|█████████▋| 5038/5198 [2:05:52<1:20:17, 30.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.65s/it][A100%|██████████| 1/1 [00:29<00:00, 29.65s/it]
 97%|█████████▋| 5038/5198 [2:05:37<1:20:15, 30.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.65s/it][A100%|██████████| 1/1 [00:29<00:00, 29.65s/it]
 97%|█████████▋| 5038/5198 [2:05:42<1:20:16, 30.10s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4724
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.47s/it][A100%|██████████| 1/1 [00:31<00:00, 31.47s/it]
 97%|█████████▋| 5039/5198 [2:06:26<1:21:01, 30.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:04:11,546] [INFO] [logging.py:96:log_dist] [Rank 0] step=5038, skipped=0, lr=[3.672745811406495e-07], mom=[(0.9, 0.999)]
steps: 5038 loss: 1.4613 iter time (s): 30.931 samples/sec: 4.138

100%|██████████| 1/1 [00:31<00:00, 31.61s/it][A100%|██████████| 1/1 [00:31<00:00, 31.61s/it]
 97%|█████████▋| 5039/5198 [2:06:37<1:21:00, 30.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.64s/it][A100%|██████████| 1/1 [00:31<00:00, 31.65s/it]
 97%|█████████▋| 5039/5198 [2:06:35<1:20:59, 30.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.61s/it][A100%|██████████| 1/1 [00:31<00:00, 31.61s/it]
 97%|█████████▋| 5039/5198 [2:06:27<1:20:57, 30.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.59s/it][A100%|██████████| 1/1 [00:31<00:00, 31.60s/it]
 97%|█████████▋| 5039/5198 [2:06:30<1:20:58, 30.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.57s/it][A100%|██████████| 1/1 [00:31<00:00, 31.57s/it]
 97%|█████████▋| 5039/5198 [2:06:24<1:20:57, 30.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.57s/it][A100%|██████████| 1/1 [00:31<00:00, 31.57s/it]
 97%|█████████▋| 5039/5198 [2:06:09<1:20:56, 30.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.57s/it][A100%|██████████| 1/1 [00:31<00:00, 31.57s/it]
 97%|█████████▋| 5039/5198 [2:06:14<1:20:56, 30.54s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_314
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:22<00:00, 22.66s/it][A100%|██████████| 1/1 [00:22<00:00, 22.67s/it]
[2024-09-02 01:04:34,466] [INFO] [logging.py:96:log_dist] [Rank 0] step=5039, skipped=0, lr=[3.662113970872573e-07], mom=[(0.9, 0.999)]
steps: 5039 loss: 1.9910 iter time (s): 22.299 samples/sec: 5.740

100%|██████████| 1/1 [00:23<00:00, 23.03s/it][A100%|██████████| 1/1 [00:23<00:00, 23.03s/it]

100%|██████████| 1/1 [00:23<00:00, 23.07s/it][A100%|██████████| 1/1 [00:23<00:00, 23.07s/it]

100%|██████████| 1/1 [00:23<00:00, 23.15s/it][A100%|██████████| 1/1 [00:23<00:00, 23.15s/it]

100%|██████████| 1/1 [00:23<00:00, 23.13s/it][A100%|██████████| 1/1 [00:23<00:00, 23.13s/it]

100%|██████████| 1/1 [00:23<00:00, 23.16s/it][A100%|██████████| 1/1 [00:23<00:00, 23.16s/it]

100%|██████████| 1/1 [00:23<00:00, 23.18s/it][A100%|██████████| 1/1 [00:23<00:00, 23.18s/it]

100%|██████████| 1/1 [00:23<00:00, 23.18s/it][A100%|██████████| 1/1 [00:23<00:00, 23.18s/it]
Checkpointing at shard 5039
[2024-09-02 01:04:35,370] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step5039 is about to be saved!
[2024-09-02 01:04:35,875] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step5039/layer_00-model_states.pt...
[2024-09-02 01:04:37,547] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step5039/layer_02-model_states.pt...
[2024-09-02 01:04:37,746] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step5039/layer_06-model_states.pt...
[2024-09-02 01:04:38,245] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step5039/layer_05-model_states.pt...
[2024-09-02 01:04:38,332] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step5039/layer_07-model_states.pt...
[2024-09-02 01:04:38,361] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step5039/layer_08-model_states.pt...
[2024-09-02 01:04:40,122] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step5039/layer_00-model_states.pt.
[2024-09-02 01:04:41,838] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step5039/layer_01-model_states.pt...
[2024-09-02 01:04:43,644] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step5039/layer_03-model_states.pt...
[2024-09-02 01:04:43,663] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step5039/layer_04-model_states.pt...
[2024-09-02 01:05:37,642] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step5039/layer_06-model_states.pt.
[2024-09-02 01:05:37,685] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step5039/mp_rank_05_model_states.pt...
[2024-09-02 01:05:37,810] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step5039/mp_rank_05_model_states.pt.
[2024-09-02 01:05:37,810] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step5039 is ready now!
[2024-09-02 01:05:37,879] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step5039/layer_02-model_states.pt.
[2024-09-02 01:05:37,901] [INFO] [logging.py:96:log_dist] [Rank 1] Saving model checkpoint: /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step5039/mp_rank_01_model_states.pt
[2024-09-02 01:05:37,901] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step5039/mp_rank_01_model_states.pt...
[2024-09-02 01:05:38,035] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step5039/mp_rank_01_model_states.pt.
[2024-09-02 01:05:38,035] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step5039 is ready now!
[2024-09-02 01:05:39,055] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step5039/layer_05-model_states.pt.
[2024-09-02 01:05:39,078] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step5039/mp_rank_04_model_states.pt...
[2024-09-02 01:05:39,116] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step5039/layer_07-model_states.pt.
[2024-09-02 01:05:39,138] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step5039/mp_rank_06_model_states.pt...
[2024-09-02 01:05:39,181] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step5039/mp_rank_04_model_states.pt.
[2024-09-02 01:05:39,181] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step5039 is ready now!
[2024-09-02 01:05:39,231] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step5039/mp_rank_06_model_states.pt.
[2024-09-02 01:05:39,231] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step5039 is ready now!
[2024-09-02 01:05:39,728] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step5039/layer_08-model_states.pt.
[2024-09-02 01:05:39,789] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step5039/layer_09-model_states.pt...
[2024-09-02 01:05:40,527] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step5039/layer_09-model_states.pt.
[2024-09-02 01:05:40,530] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step5039/mp_rank_07_model_states.pt...
[2024-09-02 01:05:40,599] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step5039/mp_rank_07_model_states.pt.
[2024-09-02 01:05:40,600] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step5039 is ready now!
[2024-09-02 01:05:42,652] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step5039/layer_01-model_states.pt.
[2024-09-02 01:05:42,677] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step5039/mp_rank_00_model_states.pt
[2024-09-02 01:05:42,677] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step5039/mp_rank_00_model_states.pt...
[2024-09-02 01:05:42,967] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step5039/mp_rank_00_model_states.pt.
[2024-09-02 01:05:42,967] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step5039 is ready now!
[2024-09-02 01:05:43,316] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step5039/layer_03-model_states.pt.
[2024-09-02 01:05:43,332] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step5039/layer_04-model_states.pt.
[2024-09-02 01:05:43,336] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step5039/mp_rank_02_model_states.pt...
[2024-09-02 01:05:43,356] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step5039/mp_rank_03_model_states.pt...
[2024-09-02 01:05:43,369] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step5039/mp_rank_02_model_states.pt.
[2024-09-02 01:05:43,369] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step5039 is ready now!
[2024-09-02 01:05:43,389] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_lora_32_64_4_top1_checkpoint/global_step5039/mp_rank_03_model_states.pt.
[2024-09-02 01:05:43,389] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step5039 is ready now!
Checkpoint saved using --- 68.01926469802856 seconds ---
 97%|█████████▋| 5040/5198 [2:07:45<2:08:21, 48.74s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4725
 97%|█████████▋| 5040/5198 [2:07:55<2:08:23, 48.76s/it] 97%|█████████▋| 5040/5198 [2:08:01<2:08:25, 48.77s/it] 97%|█████████▋| 5040/5198 [2:08:09<2:08:39, 48.86s/it] 97%|█████████▋| 5040/5198 [2:08:07<2:08:34, 48.82s/it] 97%|█████████▋| 5040/5198 [2:07:59<2:08:28, 48.79s/it] 97%|█████████▋| 5040/5198 [2:07:58<2:09:10, 49.05s/it] 97%|█████████▋| 5040/5198 [2:07:40<2:08:22, 48.75s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A

  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.26s/it][A100%|██████████| 1/1 [00:29<00:00, 29.26s/it]
 97%|█████████▋| 5041/5198 [2:08:27<1:53:01, 43.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:06:13,271] [INFO] [logging.py:96:log_dist] [Rank 0] step=5040, skipped=0, lr=[3.651496998286858e-07], mom=[(0.9, 0.999)]
steps: 5040 loss: 1.4464 iter time (s): 29.619 samples/sec: 4.322

100%|██████████| 1/1 [00:29<00:00, 29.96s/it][A100%|██████████| 1/1 [00:29<00:00, 29.96s/it]
 97%|█████████▋| 5041/5198 [2:08:39<1:53:12, 43.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.03s/it][A100%|██████████| 1/1 [00:30<00:00, 30.04s/it]
 97%|█████████▋| 5041/5198 [2:08:37<1:53:12, 43.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.15s/it][A100%|██████████| 1/1 [00:30<00:00, 30.15s/it]
 97%|█████████▋| 5041/5198 [2:08:29<1:53:14, 43.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.21s/it][A100%|██████████| 1/1 [00:30<00:00, 30.21s/it]
 97%|█████████▋| 5041/5198 [2:08:32<1:53:15, 43.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.25s/it][A100%|██████████| 1/1 [00:30<00:00, 30.25s/it]
 97%|█████████▋| 5041/5198 [2:08:25<1:53:15, 43.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.28s/it][A100%|██████████| 1/1 [00:30<00:00, 30.28s/it]
 97%|█████████▋| 5041/5198 [2:08:11<1:53:16, 43.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.29s/it][A100%|██████████| 1/1 [00:30<00:00, 30.29s/it]
 97%|█████████▋| 5041/5198 [2:08:15<1:53:16, 43.29s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4726
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.75s/it][A100%|██████████| 1/1 [00:36<00:00, 36.76s/it]
 97%|█████████▋| 5042/5198 [2:09:04<1:47:24, 41.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:06:50,374] [INFO] [logging.py:96:log_dist] [Rank 0] step=5041, skipped=0, lr=[3.640894897055529e-07], mom=[(0.9, 0.999)]
steps: 5041 loss: 1.4430 iter time (s): 36.417 samples/sec: 3.515

100%|██████████| 1/1 [00:37<00:00, 37.07s/it][A100%|██████████| 1/1 [00:37<00:00, 37.07s/it]
 97%|█████████▋| 5042/5198 [2:09:16<1:47:40, 41.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.08s/it][A100%|██████████| 1/1 [00:37<00:00, 37.08s/it]
 97%|█████████▋| 5042/5198 [2:09:14<1:47:40, 41.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.30s/it][A100%|██████████| 1/1 [00:37<00:00, 37.30s/it]
 97%|█████████▋| 5042/5198 [2:09:06<1:47:51, 41.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.26s/it][A100%|██████████| 1/1 [00:37<00:00, 37.26s/it]
 97%|█████████▋| 5042/5198 [2:09:09<1:47:50, 41.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.44s/it][A100%|██████████| 1/1 [00:37<00:00, 37.44s/it]
 97%|█████████▋| 5042/5198 [2:09:03<1:47:58, 41.53s/it]
100%|██████████| 1/1 [00:37<00:00, 37.40s/it][A100%|██████████| 1/1 [00:37<00:00, 37.40s/it]
 97%|█████████▋| 5042/5198 [2:08:53<1:47:57, 41.52s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4727
Training on 128 of 128 sentences.


  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.57s/it][A100%|██████████| 1/1 [00:37<00:00, 37.57s/it]
 97%|█████████▋| 5042/5198 [2:08:48<1:48:05, 41.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.85s/it][A100%|██████████| 1/1 [00:31<00:00, 31.85s/it]
 97%|█████████▋| 5043/5198 [2:09:36<1:39:32, 38.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:07:22,265] [INFO] [logging.py:96:log_dist] [Rank 0] step=5042, skipped=0, lr=[3.630307670580012e-07], mom=[(0.9, 0.999)]
steps: 5042 loss: 1.4779 iter time (s): 30.897 samples/sec: 4.143

100%|██████████| 1/1 [00:31<00:00, 31.85s/it][A100%|██████████| 1/1 [00:31<00:00, 31.85s/it]
 97%|█████████▋| 5043/5198 [2:09:48<1:39:34, 38.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.93s/it][A100%|██████████| 1/1 [00:31<00:00, 31.93s/it]
 97%|█████████▋| 5043/5198 [2:09:46<1:39:39, 38.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.66s/it][A100%|██████████| 1/1 [00:31<00:00, 31.66s/it]
 97%|█████████▋| 5043/5198 [2:09:41<1:39:33, 38.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.75s/it][A100%|██████████| 1/1 [00:31<00:00, 31.75s/it]
 97%|█████████▋| 5043/5198 [2:09:38<1:39:37, 38.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.56s/it][A100%|██████████| 1/1 [00:31<00:00, 31.56s/it]
 97%|█████████▋| 5043/5198 [2:09:34<1:39:34, 38.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.45s/it][A100%|██████████| 1/1 [00:31<00:00, 31.45s/it]
 97%|█████████▋| 5043/5198 [2:09:20<1:39:33, 38.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.63s/it][A100%|██████████| 1/1 [00:31<00:00, 31.63s/it]
 97%|█████████▋| 5043/5198 [2:09:24<1:39:36, 38.56s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4728
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.04s/it][A100%|██████████| 1/1 [00:30<00:00, 30.04s/it]
 97%|█████████▋| 5044/5198 [2:10:07<1:32:29, 36.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:07:52,495] [INFO] [logging.py:96:log_dist] [Rank 0] step=5043, skipped=0, lr=[3.6197353222569453e-07], mom=[(0.9, 0.999)]
steps: 5043 loss: 1.3344 iter time (s): 29.489 samples/sec: 4.341

100%|██████████| 1/1 [00:30<00:00, 30.22s/it][A100%|██████████| 1/1 [00:30<00:00, 30.22s/it]
 97%|█████████▋| 5044/5198 [2:10:18<1:32:31, 36.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.16s/it][A100%|██████████| 1/1 [00:30<00:00, 30.16s/it]
 97%|█████████▋| 5044/5198 [2:10:16<1:32:32, 36.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.13s/it][A100%|██████████| 1/1 [00:30<00:00, 30.13s/it]
 97%|█████████▋| 5044/5198 [2:10:08<1:32:30, 36.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.24s/it][A100%|██████████| 1/1 [00:30<00:00, 30.24s/it]
 97%|█████████▋| 5044/5198 [2:10:11<1:32:32, 36.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.18s/it][A100%|██████████| 1/1 [00:30<00:00, 30.18s/it]
 97%|█████████▋| 5044/5198 [2:09:50<1:32:29, 36.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.24s/it][A100%|██████████| 1/1 [00:30<00:00, 30.24s/it]
 97%|█████████▋| 5044/5198 [2:10:05<1:32:32, 36.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.19s/it][A100%|██████████| 1/1 [00:30<00:00, 30.19s/it]
 97%|█████████▋| 5044/5198 [2:09:55<1:32:31, 36.05s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4729
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:39<00:00, 39.43s/it][A100%|██████████| 1/1 [00:39<00:00, 39.43s/it]
 97%|█████████▋| 5045/5198 [2:10:46<1:34:36, 37.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:08:32,335] [INFO] [logging.py:96:log_dist] [Rank 0] step=5044, skipped=0, lr=[3.60917785547821e-07], mom=[(0.9, 0.999)]
steps: 5044 loss: 1.4710 iter time (s): 39.135 samples/sec: 3.271

100%|██████████| 1/1 [00:39<00:00, 39.79s/it][A100%|██████████| 1/1 [00:39<00:00, 39.79s/it]
 97%|█████████▋| 5045/5198 [2:10:58<1:34:47, 37.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:39<00:00, 39.80s/it][A100%|██████████| 1/1 [00:39<00:00, 39.81s/it]
 97%|█████████▋| 5045/5198 [2:10:56<1:34:48, 37.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:39<00:00, 39.84s/it][A100%|██████████| 1/1 [00:39<00:00, 39.84s/it]
 97%|█████████▋| 5045/5198 [2:10:48<1:34:49, 37.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:39<00:00, 39.89s/it][A100%|██████████| 1/1 [00:39<00:00, 39.89s/it]
 97%|█████████▋| 5045/5198 [2:10:51<1:34:52, 37.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:39<00:00, 39.80s/it][A100%|██████████| 1/1 [00:39<00:00, 39.80s/it]
 97%|█████████▋| 5045/5198 [2:10:44<1:34:49, 37.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:39<00:00, 39.84s/it][A100%|██████████| 1/1 [00:39<00:00, 39.84s/it]
 97%|█████████▋| 5045/5198 [2:10:30<1:34:48, 37.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:39<00:00, 39.84s/it][A100%|██████████| 1/1 [00:39<00:00, 39.84s/it]
 97%|█████████▋| 5045/5198 [2:10:35<1:34:49, 37.19s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4730
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.27s/it][A100%|██████████| 1/1 [00:30<00:00, 30.27s/it]
 97%|█████████▋| 5046/5198 [2:11:17<1:28:53, 35.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:09:02,415] [INFO] [logging.py:96:log_dist] [Rank 0] step=5045, skipped=0, lr=[3.598635273630895e-07], mom=[(0.9, 0.999)]
steps: 5045 loss: 1.4946 iter time (s): 29.363 samples/sec: 4.359

100%|██████████| 1/1 [00:30<00:00, 30.15s/it][A100%|██████████| 1/1 [00:30<00:00, 30.15s/it]
 97%|█████████▋| 5046/5198 [2:11:28<1:28:50, 35.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.06s/it][A100%|██████████| 1/1 [00:30<00:00, 30.06s/it]
 97%|█████████▋| 5046/5198 [2:11:26<1:28:47, 35.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.06s/it][A100%|██████████| 1/1 [00:30<00:00, 30.06s/it]
 97%|█████████▋| 5046/5198 [2:11:18<1:28:47, 35.05s/it]
100%|██████████| 1/1 [00:29<00:00, 29.96s/it][A100%|██████████| 1/1 [00:29<00:00, 29.96s/it]
 97%|█████████▋| 5046/5198 [2:11:21<1:28:45, 35.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.03s/it][A100%|██████████| 1/1 [00:30<00:00, 30.03s/it]
 97%|█████████▋| 5046/5198 [2:11:14<1:28:46, 35.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.05s/it][A100%|██████████| 1/1 [00:30<00:00, 30.05s/it]
 97%|█████████▋| 5046/5198 [2:11:00<1:28:46, 35.04s/it]
100%|██████████| 1/1 [00:30<00:00, 30.02s/it][A100%|██████████| 1/1 [00:30<00:00, 30.03s/it]
 97%|█████████▋| 5046/5198 [2:11:05<1:28:46, 35.04s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4731

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:39<00:00, 39.08s/it][A100%|██████████| 1/1 [00:39<00:00, 39.08s/it]
 97%|█████████▋| 5047/5198 [2:11:56<1:31:26, 36.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:09:41,983] [INFO] [logging.py:96:log_dist] [Rank 0] step=5046, skipped=0, lr=[3.5881075800973184e-07], mom=[(0.9, 0.999)]
steps: 5046 loss: 1.4908 iter time (s): 38.903 samples/sec: 3.290

100%|██████████| 1/1 [00:39<00:00, 39.51s/it][A100%|██████████| 1/1 [00:39<00:00, 39.51s/it]
 97%|█████████▋| 5047/5198 [2:12:08<1:31:36, 36.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:39<00:00, 39.57s/it][A100%|██████████| 1/1 [00:39<00:00, 39.57s/it]
 97%|█████████▋| 5047/5198 [2:12:06<1:31:37, 36.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:39<00:00, 39.53s/it][A100%|██████████| 1/1 [00:39<00:00, 39.53s/it]
 97%|█████████▋| 5047/5198 [2:11:58<1:31:35, 36.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:39<00:00, 39.66s/it][A100%|██████████| 1/1 [00:39<00:00, 39.67s/it]
 97%|█████████▋| 5047/5198 [2:12:00<1:31:40, 36.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:39<00:00, 39.65s/it][A100%|██████████| 1/1 [00:39<00:00, 39.65s/it]
 97%|█████████▋| 5047/5198 [2:11:54<1:31:40, 36.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:39<00:00, 39.63s/it][A100%|██████████| 1/1 [00:39<00:00, 39.63s/it]
 97%|█████████▋| 5047/5198 [2:11:44<1:31:39, 36.42s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4732
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:39<00:00, 39.66s/it][A100%|██████████| 1/1 [00:39<00:00, 39.66s/it]
 97%|█████████▋| 5047/5198 [2:11:40<1:31:40, 36.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.41s/it][A100%|██████████| 1/1 [00:32<00:00, 32.41s/it]
 97%|█████████▋| 5048/5198 [2:12:28<1:27:58, 35.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:10:14,235] [INFO] [logging.py:96:log_dist] [Rank 0] step=5047, skipped=0, lr=[3.577594778255041e-07], mom=[(0.9, 0.999)]
steps: 5047 loss: 1.4405 iter time (s): 31.521 samples/sec: 4.061

100%|██████████| 1/1 [00:32<00:00, 32.28s/it][A100%|██████████| 1/1 [00:32<00:00, 32.28s/it]
 97%|█████████▋| 5048/5198 [2:12:40<1:27:55, 35.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.31s/it][A100%|██████████| 1/1 [00:32<00:00, 32.31s/it]
 97%|█████████▋| 5048/5198 [2:12:38<1:27:56, 35.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.15s/it][A100%|██████████| 1/1 [00:32<00:00, 32.15s/it]
 97%|█████████▋| 5048/5198 [2:12:33<1:27:51, 35.15s/it]
100%|██████████| 1/1 [00:32<00:00, 32.30s/it][A100%|██████████| 1/1 [00:32<00:00, 32.30s/it]
 97%|█████████▋| 5048/5198 [2:12:30<1:27:55, 35.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.17s/it][A100%|██████████| 1/1 [00:32<00:00, 32.17s/it]
 97%|█████████▋| 5048/5198 [2:12:26<1:27:52, 35.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.19s/it][A100%|██████████| 1/1 [00:32<00:00, 32.19s/it]
 97%|█████████▋| 5048/5198 [2:12:12<1:27:53, 35.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.22s/it][A100%|██████████| 1/1 [00:32<00:00, 32.22s/it]
 97%|█████████▋| 5048/5198 [2:12:16<1:27:54, 35.16s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4733
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.31s/it][A100%|██████████| 1/1 [00:32<00:00, 32.31s/it]
 97%|█████████▋| 5049/5198 [2:13:01<1:25:22, 34.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:10:46,786] [INFO] [logging.py:96:log_dist] [Rank 0] step=5048, skipped=0, lr=[3.5670968714768146e-07], mom=[(0.9, 0.999)]
steps: 5048 loss: 1.4584 iter time (s): 31.846 samples/sec: 4.019

100%|██████████| 1/1 [00:32<00:00, 32.53s/it][A100%|██████████| 1/1 [00:32<00:00, 32.53s/it]
 97%|█████████▋| 5049/5198 [2:13:13<1:25:22, 34.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.52s/it][A100%|██████████| 1/1 [00:32<00:00, 32.52s/it]
 97%|█████████▋| 5049/5198 [2:13:11<1:25:23, 34.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.53s/it][A100%|██████████| 1/1 [00:32<00:00, 32.53s/it]
 97%|█████████▋| 5049/5198 [2:13:03<1:25:22, 34.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.60s/it][A100%|██████████| 1/1 [00:32<00:00, 32.60s/it]
 97%|█████████▋| 5049/5198 [2:13:05<1:25:23, 34.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.57s/it][A100%|██████████| 1/1 [00:32<00:00, 32.57s/it]
 97%|█████████▋| 5049/5198 [2:12:59<1:25:22, 34.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.59s/it][A100%|██████████| 1/1 [00:32<00:00, 32.59s/it]
 97%|█████████▋| 5049/5198 [2:12:44<1:25:23, 34.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.59s/it][A100%|██████████| 1/1 [00:32<00:00, 32.59s/it]
 97%|█████████▋| 5049/5198 [2:12:49<1:25:24, 34.39s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4734
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.57s/it][A100%|██████████| 1/1 [00:32<00:00, 32.57s/it]
 97%|█████████▋| 5050/5198 [2:13:34<1:23:35, 33.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:11:19,531] [INFO] [logging.py:96:log_dist] [Rank 0] step=5049, skipped=0, lr=[3.556613863130648e-07], mom=[(0.9, 0.999)]
steps: 5049 loss: 1.5629 iter time (s): 31.995 samples/sec: 4.001

100%|██████████| 1/1 [00:32<00:00, 32.76s/it][A100%|██████████| 1/1 [00:32<00:00, 32.76s/it]
 97%|█████████▋| 5050/5198 [2:13:45<1:23:36, 33.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.82s/it][A100%|██████████| 1/1 [00:32<00:00, 32.82s/it]
 97%|█████████▋| 5050/5198 [2:13:44<1:23:39, 33.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.79s/it][A100%|██████████| 1/1 [00:32<00:00, 32.79s/it]
 97%|█████████▋| 5050/5198 [2:13:35<1:23:37, 33.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.79s/it][A100%|██████████| 1/1 [00:32<00:00, 32.79s/it]
 97%|█████████▋| 5050/5198 [2:13:38<1:23:38, 33.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.76s/it][A100%|██████████| 1/1 [00:32<00:00, 32.76s/it]
 97%|█████████▋| 5050/5198 [2:13:32<1:23:36, 33.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.73s/it][A100%|██████████| 1/1 [00:32<00:00, 32.73s/it]
 97%|█████████▋| 5050/5198 [2:13:17<1:23:35, 33.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.74s/it][A100%|██████████| 1/1 [00:32<00:00, 32.74s/it]
 97%|█████████▋| 5050/5198 [2:13:22<1:23:36, 33.90s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4735
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.86s/it][A100%|██████████| 1/1 [00:30<00:00, 30.87s/it]
 97%|█████████▋| 5051/5198 [2:14:05<1:20:56, 33.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:11:50,468] [INFO] [logging.py:96:log_dist] [Rank 0] step=5050, skipped=0, lr=[3.5461457565797254e-07], mom=[(0.9, 0.999)]
steps: 5050 loss: 1.5521 iter time (s): 30.191 samples/sec: 4.240

100%|██████████| 1/1 [00:30<00:00, 30.91s/it][A100%|██████████| 1/1 [00:30<00:00, 30.91s/it]
 97%|█████████▋| 5051/5198 [2:14:16<1:20:51, 33.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.96s/it][A100%|██████████| 1/1 [00:30<00:00, 30.96s/it]
 97%|█████████▋| 5051/5198 [2:14:15<1:20:55, 33.03s/it]
100%|██████████| 1/1 [00:30<00:00, 30.89s/it][A100%|██████████| 1/1 [00:30<00:00, 30.89s/it]
 97%|█████████▋| 5051/5198 [2:14:06<1:20:51, 33.00s/it]
100%|██████████| 1/1 [00:30<00:00, 30.84s/it][A100%|██████████| 1/1 [00:30<00:00, 30.84s/it]
 97%|█████████▋| 5051/5198 [2:14:09<1:20:49, 32.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.85s/it][A100%|██████████| 1/1 [00:30<00:00, 30.85s/it]
 97%|█████████▋| 5051/5198 [2:13:53<1:20:48, 32.99s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4736
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.03s/it][A100%|██████████| 1/1 [00:31<00:00, 31.03s/it]
 97%|█████████▋| 5051/5198 [2:14:03<1:20:56, 33.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.21s/it][A100%|██████████| 1/1 [00:31<00:00, 31.21s/it]
 97%|█████████▋| 5051/5198 [2:13:48<1:21:03, 33.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.28s/it][A100%|██████████| 1/1 [00:30<00:00, 30.28s/it]
 97%|█████████▋| 5052/5198 [2:14:35<1:18:28, 32.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:12:20,905] [INFO] [logging.py:96:log_dist] [Rank 0] step=5051, skipped=0, lr=[3.5356925551824907e-07], mom=[(0.9, 0.999)]
steps: 5051 loss: 1.4659 iter time (s): 29.759 samples/sec: 4.301

100%|██████████| 1/1 [00:30<00:00, 30.42s/it][A100%|██████████| 1/1 [00:30<00:00, 30.42s/it]
 97%|█████████▋| 5052/5198 [2:14:47<1:18:25, 32.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.39s/it][A100%|██████████| 1/1 [00:30<00:00, 30.39s/it]
 97%|█████████▋| 5052/5198 [2:14:45<1:18:27, 32.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.44s/it][A100%|██████████| 1/1 [00:30<00:00, 30.44s/it]
 97%|█████████▋| 5052/5198 [2:14:37<1:18:26, 32.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.51s/it][A100%|██████████| 1/1 [00:30<00:00, 30.51s/it]
 97%|█████████▋| 5052/5198 [2:14:39<1:18:28, 32.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.35s/it][A100%|██████████| 1/1 [00:30<00:00, 30.35s/it]
 97%|█████████▋| 5052/5198 [2:14:33<1:18:26, 32.23s/it]
100%|██████████| 1/1 [00:30<00:00, 30.14s/it][A100%|██████████| 1/1 [00:30<00:00, 30.14s/it]
 97%|█████████▋| 5052/5198 [2:14:18<1:18:22, 32.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.49s/it][A100%|██████████| 1/1 [00:30<00:00, 30.49s/it]
 97%|█████████▋| 5052/5198 [2:14:23<1:18:27, 32.24s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4737
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.80s/it][A100%|██████████| 1/1 [00:30<00:00, 30.80s/it]
 97%|█████████▋| 5053/5198 [2:15:06<1:17:01, 31.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:12:51,672] [INFO] [logging.py:96:log_dist] [Rank 0] step=5052, skipped=0, lr=[3.5252542622925865e-07], mom=[(0.9, 0.999)]
steps: 5052 loss: 1.4945 iter time (s): 30.030 samples/sec: 4.262

100%|██████████| 1/1 [00:30<00:00, 30.65s/it][A100%|██████████| 1/1 [00:30<00:00, 30.65s/it]
 97%|█████████▋| 5053/5198 [2:15:16<1:16:46, 31.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.88s/it][A100%|██████████| 1/1 [00:30<00:00, 30.88s/it]
 97%|█████████▋| 5053/5198 [2:15:18<1:16:55, 31.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.89s/it][A100%|██████████| 1/1 [00:30<00:00, 30.89s/it]
 97%|█████████▋| 5053/5198 [2:15:08<1:16:56, 31.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.95s/it][A100%|██████████| 1/1 [00:30<00:00, 30.95s/it]
 97%|█████████▋| 5053/5198 [2:15:10<1:16:59, 31.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.93s/it][A100%|██████████| 1/1 [00:30<00:00, 30.93s/it]
 97%|█████████▋| 5053/5198 [2:14:54<1:16:58, 31.85s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4738
Training on 128 of 128 sentences.

100%|██████████| 1/1 [00:30<00:00, 30.98s/it][A100%|██████████| 1/1 [00:30<00:00, 30.98s/it]
 97%|█████████▋| 5053/5198 [2:15:04<1:16:59, 31.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.09s/it][A100%|██████████| 1/1 [00:31<00:00, 31.09s/it]
 97%|█████████▋| 5053/5198 [2:14:49<1:17:01, 31.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.60s/it][A100%|██████████| 1/1 [00:31<00:00, 31.60s/it]
 97%|█████████▋| 5054/5198 [2:15:38<1:16:23, 31.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:13:23,678] [INFO] [logging.py:96:log_dist] [Rank 0] step=5053, skipped=0, lr=[3.514830881258882e-07], mom=[(0.9, 0.999)]
steps: 5053 loss: 1.3780 iter time (s): 31.083 samples/sec: 4.118

100%|██████████| 1/1 [00:31<00:00, 31.89s/it][A100%|██████████| 1/1 [00:31<00:00, 31.89s/it]
 97%|█████████▋| 5054/5198 [2:15:50<1:16:26, 31.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.05s/it][A100%|██████████| 1/1 [00:32<00:00, 32.05s/it]
 97%|█████████▋| 5054/5198 [2:15:48<1:16:27, 31.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.86s/it][A100%|██████████| 1/1 [00:31<00:00, 31.86s/it]
 97%|█████████▋| 5054/5198 [2:15:39<1:16:25, 31.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.81s/it][A100%|██████████| 1/1 [00:31<00:00, 31.81s/it]
 97%|█████████▋| 5054/5198 [2:15:42<1:16:26, 31.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.78s/it][A100%|██████████| 1/1 [00:31<00:00, 31.79s/it]
 97%|█████████▋| 5054/5198 [2:15:36<1:16:24, 31.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.70s/it][A100%|██████████| 1/1 [00:31<00:00, 31.70s/it]
 97%|█████████▋| 5054/5198 [2:15:21<1:16:22, 31.82s/it]
100%|██████████| 1/1 [00:31<00:00, 31.83s/it][A100%|██████████| 1/1 [00:31<00:00, 31.83s/it]
 97%|█████████▋| 5054/5198 [2:15:26<1:16:26, 31.85s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4739

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.73s/it][A100%|██████████| 1/1 [00:31<00:00, 31.73s/it]
 97%|█████████▋| 5055/5198 [2:16:10<1:15:54, 31.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:13:55,599] [INFO] [logging.py:96:log_dist] [Rank 0] step=5054, skipped=0, lr=[3.504422415425446e-07], mom=[(0.9, 0.999)]
steps: 5054 loss: 1.4611 iter time (s): 31.172 samples/sec: 4.106

100%|██████████| 1/1 [00:31<00:00, 31.87s/it][A100%|██████████| 1/1 [00:31<00:00, 31.87s/it]
 97%|█████████▋| 5055/5198 [2:16:21<1:15:55, 31.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.92s/it][A100%|██████████| 1/1 [00:31<00:00, 31.92s/it]
 97%|█████████▋| 5055/5198 [2:16:20<1:15:58, 31.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.96s/it][A100%|██████████| 1/1 [00:31<00:00, 31.96s/it]
 97%|█████████▋| 5055/5198 [2:16:11<1:15:59, 31.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.00s/it][A100%|██████████| 1/1 [00:32<00:00, 32.01s/it]
 97%|█████████▋| 5055/5198 [2:16:14<1:16:01, 31.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.98s/it][A100%|██████████| 1/1 [00:31<00:00, 31.98s/it]
 97%|█████████▋| 5055/5198 [2:16:08<1:15:59, 31.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.98s/it][A100%|██████████| 1/1 [00:31<00:00, 31.98s/it]
 97%|█████████▋| 5055/5198 [2:15:53<1:15:57, 31.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.99s/it][A100%|██████████| 1/1 [00:31<00:00, 31.99s/it]
 97%|█████████▋| 5055/5198 [2:15:58<1:16:00, 31.89s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_315
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:24<00:00, 24.66s/it][A100%|██████████| 1/1 [00:24<00:00, 24.66s/it]
 97%|█████████▋| 5056/5198 [2:16:34<1:10:21, 29.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:14:20,438] [INFO] [logging.py:96:log_dist] [Rank 0] step=5055, skipped=0, lr=[3.494028868131583e-07], mom=[(0.9, 0.999)]
steps: 5055 loss: 1.9472 iter time (s): 24.052 samples/sec: 5.322

100%|██████████| 1/1 [00:25<00:00, 25.03s/it][A100%|██████████| 1/1 [00:25<00:00, 25.03s/it]
 97%|█████████▋| 5056/5198 [2:16:46<1:10:33, 29.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:25<00:00, 25.19s/it][A100%|██████████| 1/1 [00:25<00:00, 25.19s/it]
 97%|█████████▋| 5056/5198 [2:16:45<1:10:41, 29.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:25<00:00, 25.10s/it][A100%|██████████| 1/1 [00:25<00:00, 25.10s/it]
 97%|█████████▋| 5056/5198 [2:16:37<1:10:38, 29.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:25<00:00, 25.07s/it][A100%|██████████| 1/1 [00:25<00:00, 25.07s/it]
 97%|█████████▋| 5056/5198 [2:16:39<1:10:39, 29.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:25<00:00, 25.09s/it][A100%|██████████| 1/1 [00:25<00:00, 25.09s/it]
 97%|█████████▋| 5056/5198 [2:16:33<1:10:38, 29.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:25<00:00, 25.09s/it][A100%|██████████| 1/1 [00:25<00:00, 25.09s/it]
 97%|█████████▋| 5056/5198 [2:16:18<1:10:37, 29.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:25<00:00, 25.11s/it][A100%|██████████| 1/1 [00:25<00:00, 25.11s/it]
 97%|█████████▋| 5056/5198 [2:16:23<1:10:39, 29.86s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4740
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.14s/it][A100%|██████████| 1/1 [00:34<00:00, 34.14s/it]
 97%|█████████▋| 5057/5198 [2:17:09<1:13:02, 31.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:14:54,661] [INFO] [logging.py:96:log_dist] [Rank 0] step=5056, skipped=0, lr=[3.4836502427117934e-07], mom=[(0.9, 0.999)]
steps: 5056 loss: 1.5418 iter time (s): 33.138 samples/sec: 3.863

100%|██████████| 1/1 [00:34<00:00, 34.07s/it][A100%|██████████| 1/1 [00:34<00:00, 34.07s/it]
 97%|█████████▋| 5057/5198 [2:17:21<1:13:04, 31.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.85s/it][A100%|██████████| 1/1 [00:33<00:00, 33.85s/it]
 97%|█████████▋| 5057/5198 [2:17:19<1:13:00, 31.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.89s/it][A100%|██████████| 1/1 [00:33<00:00, 33.89s/it]
 97%|█████████▋| 5057/5198 [2:17:13<1:13:00, 31.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.00s/it][A100%|██████████| 1/1 [00:34<00:00, 34.00s/it]
 97%|█████████▋| 5057/5198 [2:17:11<1:13:05, 31.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.89s/it][A100%|██████████| 1/1 [00:33<00:00, 33.89s/it]
 97%|█████████▋| 5057/5198 [2:17:07<1:13:00, 31.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.91s/it][A100%|██████████| 1/1 [00:33<00:00, 33.91s/it]
 97%|█████████▋| 5057/5198 [2:16:52<1:12:59, 31.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.90s/it][A100%|██████████| 1/1 [00:33<00:00, 33.90s/it]
 97%|█████████▋| 5057/5198 [2:16:57<1:13:01, 31.07s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4741
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.89s/it][A100%|██████████| 1/1 [00:29<00:00, 29.89s/it]
 97%|█████████▋| 5058/5198 [2:17:39<1:11:47, 30.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:15:24,560] [INFO] [logging.py:96:log_dist] [Rank 0] step=5057, skipped=0, lr=[3.473286542495801e-07], mom=[(0.9, 0.999)]
steps: 5057 loss: 1.5017 iter time (s): 29.119 samples/sec: 4.396

100%|██████████| 1/1 [00:29<00:00, 29.85s/it][A100%|██████████| 1/1 [00:29<00:00, 29.85s/it]
 97%|█████████▋| 5058/5198 [2:17:50<1:11:41, 30.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.90s/it][A100%|██████████| 1/1 [00:29<00:00, 29.90s/it]
 97%|█████████▋| 5058/5198 [2:17:49<1:11:40, 30.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.76s/it][A100%|██████████| 1/1 [00:29<00:00, 29.76s/it]
 97%|█████████▋| 5058/5198 [2:17:40<1:11:38, 30.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.81s/it][A100%|██████████| 1/1 [00:29<00:00, 29.81s/it]
 97%|█████████▋| 5058/5198 [2:17:43<1:11:37, 30.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.83s/it][A100%|██████████| 1/1 [00:29<00:00, 29.84s/it]
 97%|█████████▋| 5058/5198 [2:17:37<1:11:37, 30.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.83s/it][A100%|██████████| 1/1 [00:29<00:00, 29.83s/it]
 97%|█████████▋| 5058/5198 [2:17:22<1:11:37, 30.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.84s/it][A100%|██████████| 1/1 [00:29<00:00, 29.84s/it]
 97%|█████████▋| 5058/5198 [2:17:27<1:11:38, 30.70s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4742
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.69s/it][A100%|██████████| 1/1 [00:34<00:00, 34.69s/it]
 97%|█████████▋| 5059/5198 [2:18:14<1:14:07, 31.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:15:59,578] [INFO] [logging.py:96:log_dist] [Rank 0] step=5058, skipped=0, lr=[3.462937770808537e-07], mom=[(0.9, 0.999)]
steps: 5058 loss: 1.5041 iter time (s): 34.294 samples/sec: 3.732

100%|██████████| 1/1 [00:35<00:00, 35.01s/it][A100%|██████████| 1/1 [00:35<00:00, 35.01s/it]
 97%|█████████▋| 5059/5198 [2:18:25<1:14:09, 32.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.96s/it][A100%|██████████| 1/1 [00:34<00:00, 34.96s/it]
 97%|█████████▋| 5059/5198 [2:18:24<1:14:07, 31.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.99s/it][A100%|██████████| 1/1 [00:34<00:00, 35.00s/it]
 97%|█████████▋| 5059/5198 [2:18:15<1:14:06, 31.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.03s/it][A100%|██████████| 1/1 [00:35<00:00, 35.03s/it]
 97%|█████████▋| 5059/5198 [2:18:18<1:14:07, 32.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.02s/it][A100%|██████████| 1/1 [00:35<00:00, 35.02s/it]
 97%|█████████▋| 5059/5198 [2:17:57<1:14:07, 32.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.08s/it][A100%|██████████| 1/1 [00:35<00:00, 35.08s/it]
 97%|█████████▋| 5059/5198 [2:18:12<1:14:10, 32.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.04s/it][A100%|██████████| 1/1 [00:35<00:00, 35.04s/it]
 97%|█████████▋| 5059/5198 [2:18:02<1:14:09, 32.01s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4743
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.59s/it][A100%|██████████| 1/1 [00:32<00:00, 32.59s/it]
 97%|█████████▋| 5060/5198 [2:18:46<1:14:05, 32.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:16:32,194] [INFO] [logging.py:96:log_dist] [Rank 0] step=5059, skipped=0, lr=[3.452603930970146e-07], mom=[(0.9, 0.999)]
steps: 5059 loss: 1.4983 iter time (s): 31.863 samples/sec: 4.017

100%|██████████| 1/1 [00:32<00:00, 32.55s/it][A100%|██████████| 1/1 [00:32<00:00, 32.55s/it]
 97%|█████████▋| 5060/5198 [2:18:58<1:14:00, 32.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.68s/it][A100%|██████████| 1/1 [00:32<00:00, 32.68s/it]
 97%|█████████▋| 5060/5198 [2:18:56<1:14:04, 32.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.69s/it][A100%|██████████| 1/1 [00:32<00:00, 32.69s/it]
 97%|█████████▋| 5060/5198 [2:18:48<1:14:04, 32.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.65s/it][A100%|██████████| 1/1 [00:32<00:00, 32.65s/it]
 97%|█████████▋| 5060/5198 [2:18:51<1:14:03, 32.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.56s/it][A100%|██████████| 1/1 [00:32<00:00, 32.56s/it]
 97%|█████████▋| 5060/5198 [2:18:44<1:14:00, 32.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.57s/it][A100%|██████████| 1/1 [00:32<00:00, 32.57s/it]
 97%|█████████▋| 5060/5198 [2:18:34<1:14:00, 32.18s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4744
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.62s/it][A100%|██████████| 1/1 [00:32<00:00, 32.62s/it]
 97%|█████████▋| 5060/5198 [2:18:30<1:14:01, 32.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.37s/it][A100%|██████████| 1/1 [00:35<00:00, 35.37s/it]
 97%|█████████▋| 5061/5198 [2:19:22<1:15:49, 33.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:17:07,863] [INFO] [logging.py:96:log_dist] [Rank 0] step=5060, skipped=0, lr=[3.442285026295983e-07], mom=[(0.9, 0.999)]
steps: 5060 loss: 1.4566 iter time (s): 34.953 samples/sec: 3.662

100%|██████████| 1/1 [00:35<00:00, 35.72s/it][A100%|██████████| 1/1 [00:35<00:00, 35.72s/it]
 97%|█████████▋| 5061/5198 [2:19:34<1:15:54, 33.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.63s/it][A100%|██████████| 1/1 [00:35<00:00, 35.63s/it]
 97%|█████████▋| 5061/5198 [2:19:32<1:15:53, 33.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.68s/it][A100%|██████████| 1/1 [00:35<00:00, 35.68s/it]
 97%|█████████▋| 5061/5198 [2:19:24<1:15:55, 33.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.71s/it][A100%|██████████| 1/1 [00:35<00:00, 35.71s/it]
 97%|█████████▋| 5061/5198 [2:19:26<1:15:55, 33.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.72s/it][A100%|██████████| 1/1 [00:35<00:00, 35.72s/it]
 97%|█████████▋| 5061/5198 [2:19:20<1:15:54, 33.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.71s/it][A100%|██████████| 1/1 [00:35<00:00, 35.71s/it]
 97%|█████████▋| 5061/5198 [2:19:05<1:15:54, 33.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.75s/it][A100%|██████████| 1/1 [00:35<00:00, 35.75s/it]
 97%|█████████▋| 5061/5198 [2:19:10<1:15:55, 33.25s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4745
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.76s/it][A100%|██████████| 1/1 [00:29<00:00, 29.76s/it]
 97%|█████████▋| 5062/5198 [2:19:52<1:12:59, 32.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:17:37,545] [INFO] [logging.py:96:log_dist] [Rank 0] step=5061, skipped=0, lr=[3.431981060096602e-07], mom=[(0.9, 0.999)]
steps: 5061 loss: 1.4376 iter time (s): 28.882 samples/sec: 4.432

100%|██████████| 1/1 [00:29<00:00, 29.65s/it][A100%|██████████| 1/1 [00:29<00:00, 29.65s/it]
 97%|█████████▋| 5062/5198 [2:20:03<1:12:55, 32.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.68s/it][A100%|██████████| 1/1 [00:29<00:00, 29.68s/it]
 97%|█████████▋| 5062/5198 [2:20:02<1:12:55, 32.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.56s/it][A100%|██████████| 1/1 [00:29<00:00, 29.56s/it]
 97%|█████████▋| 5062/5198 [2:19:53<1:12:52, 32.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.63s/it][A100%|██████████| 1/1 [00:29<00:00, 29.63s/it]
 97%|█████████▋| 5062/5198 [2:19:56<1:12:54, 32.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.67s/it][A100%|██████████| 1/1 [00:29<00:00, 29.67s/it]
 97%|█████████▋| 5062/5198 [2:19:50<1:12:55, 32.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.64s/it][A100%|██████████| 1/1 [00:29<00:00, 29.64s/it]
 97%|█████████▋| 5062/5198 [2:19:40<1:12:54, 32.17s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4746

100%|██████████| 1/1 [00:29<00:00, 29.66s/it][A100%|██████████| 1/1 [00:29<00:00, 29.66s/it]
 97%|█████████▋| 5062/5198 [2:19:35<1:12:55, 32.17s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.76s/it][A100%|██████████| 1/1 [00:30<00:00, 30.76s/it]
 97%|█████████▋| 5063/5198 [2:20:23<1:11:35, 31.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:18:08,474] [INFO] [logging.py:96:log_dist] [Rank 0] step=5062, skipped=0, lr=[3.421692035677772e-07], mom=[(0.9, 0.999)]
steps: 5062 loss: 1.5378 iter time (s): 30.169 samples/sec: 4.243

100%|██████████| 1/1 [00:30<00:00, 30.87s/it][A100%|██████████| 1/1 [00:30<00:00, 30.88s/it]
 97%|█████████▋| 5063/5198 [2:20:34<1:11:30, 31.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.97s/it][A100%|██████████| 1/1 [00:30<00:00, 30.97s/it]
 97%|█████████▋| 5063/5198 [2:20:33<1:11:34, 31.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.94s/it][A100%|██████████| 1/1 [00:30<00:00, 30.94s/it]
 97%|█████████▋| 5063/5198 [2:20:24<1:11:31, 31.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.92s/it][A100%|██████████| 1/1 [00:30<00:00, 30.92s/it]
 97%|█████████▋| 5063/5198 [2:20:27<1:11:32, 31.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.88s/it][A100%|██████████| 1/1 [00:30<00:00, 30.88s/it]
 97%|█████████▋| 5063/5198 [2:20:21<1:11:31, 31.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.89s/it][A100%|██████████| 1/1 [00:30<00:00, 30.89s/it]
 97%|█████████▋| 5063/5198 [2:20:06<1:11:31, 31.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.91s/it][A100%|██████████| 1/1 [00:30<00:00, 30.91s/it]
 97%|█████████▋| 5063/5198 [2:20:11<1:11:32, 31.79s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4747
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.53s/it][A100%|██████████| 1/1 [00:30<00:00, 30.53s/it]
 97%|█████████▋| 5064/5198 [2:20:53<1:10:17, 31.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:18:39,128] [INFO] [logging.py:96:log_dist] [Rank 0] step=5063, skipped=0, lr=[3.4114179563404725e-07], mom=[(0.9, 0.999)]
steps: 5063 loss: 1.4434 iter time (s): 29.904 samples/sec: 4.280

100%|██████████| 1/1 [00:30<00:00, 30.72s/it][A100%|██████████| 1/1 [00:30<00:00, 30.72s/it]
 97%|█████████▋| 5064/5198 [2:21:05<1:10:16, 31.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.61s/it][A100%|██████████| 1/1 [00:30<00:00, 30.61s/it]
 97%|█████████▋| 5064/5198 [2:21:03<1:10:14, 31.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.80s/it][A100%|██████████| 1/1 [00:30<00:00, 30.80s/it]
 97%|█████████▋| 5064/5198 [2:20:55<1:10:20, 31.49s/it]
100%|██████████| 1/1 [00:30<00:00, 30.70s/it][A100%|██████████| 1/1 [00:30<00:00, 30.70s/it]
 97%|█████████▋| 5064/5198 [2:20:58<1:10:17, 31.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.70s/it][A100%|██████████| 1/1 [00:30<00:00, 30.70s/it]
 97%|█████████▋| 5064/5198 [2:20:37<1:10:16, 31.46s/it]
100%|██████████| 1/1 [00:30<00:00, 30.72s/it][A100%|██████████| 1/1 [00:30<00:00, 30.72s/it]
 97%|█████████▋| 5064/5198 [2:20:51<1:10:17, 31.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.70s/it][A100%|██████████| 1/1 [00:30<00:00, 30.70s/it]
 97%|█████████▋| 5064/5198 [2:20:41<1:10:16, 31.47s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4748
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.74s/it][A100%|██████████| 1/1 [00:31<00:00, 31.74s/it]
 97%|█████████▋| 5065/5198 [2:21:25<1:10:02, 31.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:19:11,045] [INFO] [logging.py:96:log_dist] [Rank 0] step=5064, skipped=0, lr=[3.401158825380875e-07], mom=[(0.9, 0.999)]
steps: 5064 loss: 1.4939 iter time (s): 31.113 samples/sec: 4.114

100%|██████████| 1/1 [00:31<00:00, 31.89s/it][A100%|██████████| 1/1 [00:31<00:00, 31.89s/it]
 97%|█████████▋| 5065/5198 [2:21:37<1:10:02, 31.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.93s/it][A100%|██████████| 1/1 [00:31<00:00, 31.93s/it]
 97%|█████████▋| 5065/5198 [2:21:35<1:10:03, 31.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.78s/it][A100%|██████████| 1/1 [00:31<00:00, 31.78s/it]
 97%|█████████▋| 5065/5198 [2:21:27<1:10:00, 31.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.88s/it][A100%|██████████| 1/1 [00:31<00:00, 31.88s/it]
 97%|█████████▋| 5065/5198 [2:21:29<1:10:02, 31.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.82s/it][A100%|██████████| 1/1 [00:31<00:00, 31.82s/it]
 97%|█████████▋| 5065/5198 [2:21:23<1:10:00, 31.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.87s/it][A100%|██████████| 1/1 [00:31<00:00, 31.87s/it]
 97%|█████████▋| 5065/5198 [2:21:09<1:10:01, 31.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.86s/it][A100%|██████████| 1/1 [00:31<00:00, 31.86s/it]
 97%|█████████▋| 5065/5198 [2:21:13<1:10:00, 31.59s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4749
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.04s/it][A100%|██████████| 1/1 [00:33<00:00, 33.04s/it]
 97%|█████████▋| 5066/5198 [2:21:58<1:10:34, 32.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:19:44,343] [INFO] [logging.py:96:log_dist] [Rank 0] step=5065, skipped=0, lr=[3.3909146460903735e-07], mom=[(0.9, 0.999)]
steps: 5065 loss: 1.4823 iter time (s): 32.549 samples/sec: 3.933

100%|██████████| 1/1 [00:33<00:00, 33.27s/it][A100%|██████████| 1/1 [00:33<00:00, 33.27s/it]
 97%|█████████▋| 5066/5198 [2:22:10<1:10:37, 32.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.27s/it][A100%|██████████| 1/1 [00:33<00:00, 33.27s/it]
 97%|█████████▋| 5066/5198 [2:22:08<1:10:37, 32.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.34s/it][A100%|██████████| 1/1 [00:33<00:00, 33.34s/it]
 97%|█████████▋| 5066/5198 [2:22:00<1:10:39, 32.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.28s/it][A100%|██████████| 1/1 [00:33<00:00, 33.28s/it]
 97%|█████████▋| 5066/5198 [2:22:03<1:10:38, 32.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.38s/it][A100%|██████████| 1/1 [00:33<00:00, 33.38s/it]
 97%|█████████▋| 5066/5198 [2:21:57<1:10:40, 32.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.35s/it][A100%|██████████| 1/1 [00:33<00:00, 33.35s/it]
 97%|█████████▋| 5066/5198 [2:21:42<1:10:39, 32.12s/it]
100%|██████████| 1/1 [00:33<00:00, 33.35s/it][A100%|██████████| 1/1 [00:33<00:00, 33.35s/it]
 97%|█████████▋| 5066/5198 [2:21:47<1:10:39, 32.12s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4750

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.90s/it][A100%|██████████| 1/1 [00:31<00:00, 31.90s/it]
 97%|█████████▋| 5067/5198 [2:22:30<1:10:01, 32.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:20:16,375] [INFO] [logging.py:96:log_dist] [Rank 0] step=5066, skipped=0, lr=[3.3806854217555495e-07], mom=[(0.9, 0.999)]
steps: 5066 loss: 1.5258 iter time (s): 31.229 samples/sec: 4.099

100%|██████████| 1/1 [00:32<00:00, 32.06s/it][A100%|██████████| 1/1 [00:32<00:00, 32.06s/it]
 97%|█████████▋| 5067/5198 [2:22:42<1:10:04, 32.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.95s/it][A100%|██████████| 1/1 [00:31<00:00, 31.95s/it]
 97%|█████████▋| 5067/5198 [2:22:40<1:10:00, 32.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.98s/it][A100%|██████████| 1/1 [00:31<00:00, 31.98s/it]
 97%|█████████▋| 5067/5198 [2:22:32<1:10:02, 32.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.05s/it][A100%|██████████| 1/1 [00:32<00:00, 32.05s/it]
 97%|█████████▋| 5067/5198 [2:22:35<1:10:04, 32.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.97s/it][A100%|██████████| 1/1 [00:31<00:00, 31.97s/it]
 97%|█████████▋| 5067/5198 [2:22:28<1:10:02, 32.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.98s/it][A100%|██████████| 1/1 [00:31<00:00, 31.98s/it]
 97%|█████████▋| 5067/5198 [2:22:14<1:10:02, 32.08s/it]
100%|██████████| 1/1 [00:31<00:00, 31.98s/it][A100%|██████████| 1/1 [00:31<00:00, 31.98s/it]
 97%|█████████▋| 5067/5198 [2:22:19<1:10:02, 32.08s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4751

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.38s/it][A100%|██████████| 1/1 [00:30<00:00, 30.38s/it]
 97%|█████████▋| 5068/5198 [2:23:01<1:08:27, 31.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:20:46,823] [INFO] [logging.py:96:log_dist] [Rank 0] step=5067, skipped=0, lr=[3.3704711556581974e-07], mom=[(0.9, 0.999)]
steps: 5067 loss: 1.3683 iter time (s): 29.689 samples/sec: 4.311

100%|██████████| 1/1 [00:30<00:00, 30.36s/it][A100%|██████████| 1/1 [00:30<00:00, 30.36s/it]
 97%|█████████▋| 5068/5198 [2:23:13<1:08:25, 31.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.44s/it][A100%|██████████| 1/1 [00:30<00:00, 30.44s/it]
 97%|█████████▋| 5068/5198 [2:23:11<1:08:24, 31.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.42s/it][A100%|██████████| 1/1 [00:30<00:00, 30.42s/it]
 97%|█████████▋| 5068/5198 [2:23:03<1:08:25, 31.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.35s/it][A100%|██████████| 1/1 [00:30<00:00, 30.35s/it]
 97%|█████████▋| 5068/5198 [2:23:05<1:08:24, 31.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.38s/it][A100%|██████████| 1/1 [00:30<00:00, 30.38s/it]
 97%|█████████▋| 5068/5198 [2:22:59<1:08:24, 31.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.40s/it][A100%|██████████| 1/1 [00:30<00:00, 30.40s/it]
 97%|█████████▋| 5068/5198 [2:22:44<1:08:25, 31.58s/it]
100%|██████████| 1/1 [00:30<00:00, 30.40s/it][A100%|██████████| 1/1 [00:30<00:00, 30.40s/it]
 97%|█████████▋| 5068/5198 [2:22:49<1:08:24, 31.58s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4752

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.57s/it][A100%|██████████| 1/1 [00:29<00:00, 29.57s/it]
 98%|█████████▊| 5069/5198 [2:23:31<1:06:44, 31.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:21:16,515] [INFO] [logging.py:96:log_dist] [Rank 0] step=5068, skipped=0, lr=[3.360271851075298e-07], mom=[(0.9, 0.999)]
steps: 5068 loss: 1.4043 iter time (s): 28.979 samples/sec: 4.417

100%|██████████| 1/1 [00:29<00:00, 29.71s/it][A100%|██████████| 1/1 [00:29<00:00, 29.71s/it]
 98%|█████████▊| 5069/5198 [2:23:42<1:06:41, 31.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.71s/it][A100%|██████████| 1/1 [00:29<00:00, 29.71s/it]
 98%|█████████▊| 5069/5198 [2:23:40<1:06:41, 31.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.70s/it][A100%|██████████| 1/1 [00:29<00:00, 29.70s/it]
 98%|█████████▊| 5069/5198 [2:23:32<1:06:41, 31.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.72s/it][A100%|██████████| 1/1 [00:29<00:00, 29.72s/it]
 98%|█████████▊| 5069/5198 [2:23:35<1:06:41, 31.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.71s/it][A100%|██████████| 1/1 [00:29<00:00, 29.71s/it]
 98%|█████████▊| 5069/5198 [2:23:29<1:06:40, 31.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.70s/it][A100%|██████████| 1/1 [00:29<00:00, 29.70s/it]
 98%|█████████▊| 5069/5198 [2:23:14<1:06:41, 31.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.72s/it][A100%|██████████| 1/1 [00:29<00:00, 29.72s/it]
 98%|█████████▊| 5069/5198 [2:23:19<1:06:41, 31.02s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4753
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.25s/it][A100%|██████████| 1/1 [00:32<00:00, 32.25s/it]
 98%|█████████▊| 5070/5198 [2:24:03<1:07:06, 31.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:21:49,069] [INFO] [logging.py:96:log_dist] [Rank 0] step=5069, skipped=0, lr=[3.350087511279043e-07], mom=[(0.9, 0.999)]
steps: 5069 loss: 1.4415 iter time (s): 31.802 samples/sec: 4.025

100%|██████████| 1/1 [00:32<00:00, 32.54s/it][A100%|██████████| 1/1 [00:32<00:00, 32.54s/it]
 98%|█████████▊| 5070/5198 [2:24:15<1:07:09, 31.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.53s/it][A100%|██████████| 1/1 [00:32<00:00, 32.53s/it]
 98%|█████████▊| 5070/5198 [2:24:13<1:07:08, 31.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.48s/it][A100%|██████████| 1/1 [00:32<00:00, 32.48s/it]
 98%|█████████▊| 5070/5198 [2:24:05<1:07:07, 31.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.48s/it][A100%|██████████| 1/1 [00:32<00:00, 32.48s/it]
 98%|█████████▊| 5070/5198 [2:24:07<1:07:06, 31.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.52s/it][A100%|██████████| 1/1 [00:32<00:00, 32.52s/it]
 98%|█████████▊| 5070/5198 [2:24:01<1:07:07, 31.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.54s/it][A100%|██████████| 1/1 [00:32<00:00, 32.54s/it]
 98%|█████████▊| 5070/5198 [2:23:47<1:07:09, 31.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.54s/it][A100%|██████████| 1/1 [00:32<00:00, 32.54s/it]
 98%|█████████▊| 5070/5198 [2:23:51<1:07:09, 31.48s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4754
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.13s/it][A100%|██████████| 1/1 [00:29<00:00, 29.13s/it]
 98%|█████████▊| 5071/5198 [2:24:32<1:05:13, 30.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:22:18,205] [INFO] [logging.py:96:log_dist] [Rank 0] step=5070, skipped=0, lr=[3.3399181395368324e-07], mom=[(0.9, 0.999)]
steps: 5070 loss: 1.4700 iter time (s): 28.400 samples/sec: 4.507

100%|██████████| 1/1 [00:29<00:00, 29.22s/it][A100%|██████████| 1/1 [00:29<00:00, 29.22s/it]
 98%|█████████▊| 5071/5198 [2:24:44<1:05:12, 30.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.13s/it][A100%|██████████| 1/1 [00:29<00:00, 29.13s/it]
 98%|█████████▊| 5071/5198 [2:24:42<1:05:08, 30.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.11s/it][A100%|██████████| 1/1 [00:29<00:00, 29.11s/it]
 98%|█████████▊| 5071/5198 [2:24:34<1:05:06, 30.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.11s/it][A100%|██████████| 1/1 [00:29<00:00, 29.11s/it]
 98%|█████████▊| 5071/5198 [2:24:30<1:05:06, 30.76s/it]
100%|██████████| 1/1 [00:29<00:00, 29.19s/it][A100%|██████████| 1/1 [00:29<00:00, 29.19s/it]
 98%|█████████▊| 5071/5198 [2:24:37<1:05:09, 30.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.07s/it][A100%|██████████| 1/1 [00:29<00:00, 29.07s/it]
 98%|█████████▊| 5071/5198 [2:24:16<1:05:06, 30.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.09s/it][A100%|██████████| 1/1 [00:29<00:00, 29.09s/it]
 98%|█████████▊| 5071/5198 [2:24:20<1:05:06, 30.76s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_316
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:25<00:00, 25.15s/it][A100%|██████████| 1/1 [00:25<00:00, 25.15s/it]
 98%|█████████▊| 5072/5198 [2:24:58<1:01:12, 29.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:22:43,661] [INFO] [logging.py:96:log_dist] [Rank 0] step=5071, skipped=0, lr=[3.32976373911124e-07], mom=[(0.9, 0.999)]
steps: 5071 loss: 1.8453 iter time (s): 24.796 samples/sec: 5.162

100%|██████████| 1/1 [00:25<00:00, 25.57s/it][A100%|██████████| 1/1 [00:25<00:00, 25.57s/it]
 98%|█████████▊| 5072/5198 [2:25:08<1:01:21, 29.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:25<00:00, 25.63s/it][A100%|██████████| 1/1 [00:25<00:00, 25.63s/it]
 98%|█████████▊| 5072/5198 [2:25:10<1:01:25, 29.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:25<00:00, 25.64s/it][A100%|██████████| 1/1 [00:25<00:00, 25.65s/it]
 98%|█████████▊| 5072/5198 [2:25:00<1:01:22, 29.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:25<00:00, 25.59s/it][A100%|██████████| 1/1 [00:25<00:00, 25.59s/it]
 98%|█████████▊| 5072/5198 [2:24:56<1:01:21, 29.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:25<00:00, 25.60s/it][A100%|██████████| 1/1 [00:25<00:00, 25.60s/it]
 98%|█████████▊| 5072/5198 [2:25:02<1:01:22, 29.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:25<00:00, 25.66s/it][A100%|██████████| 1/1 [00:25<00:00, 25.66s/it]
 98%|█████████▊| 5072/5198 [2:24:41<1:01:23, 29.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:25<00:00, 25.65s/it][A100%|██████████| 1/1 [00:25<00:00, 25.65s/it]
 98%|█████████▊| 5072/5198 [2:24:46<1:01:22, 29.23s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4755
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.39s/it][A100%|██████████| 1/1 [00:36<00:00, 36.39s/it]
 98%|█████████▊| 5073/5198 [2:25:34<1:05:21, 31.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:23:20,296] [INFO] [logging.py:96:log_dist] [Rank 0] step=5072, skipped=0, lr=[3.319624313260051e-07], mom=[(0.9, 0.999)]
steps: 5072 loss: 1.4516 iter time (s): 35.751 samples/sec: 3.580

100%|██████████| 1/1 [00:36<00:00, 36.52s/it][A100%|██████████| 1/1 [00:36<00:00, 36.53s/it]
 98%|█████████▊| 5073/5198 [2:25:44<1:05:26, 31.41s/it]
100%|██████████| 1/1 [00:36<00:00, 36.51s/it][A100%|██████████| 1/1 [00:36<00:00, 36.51s/it]
 98%|█████████▊| 5073/5198 [2:25:46<1:05:29, 31.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.49s/it][A100%|██████████| 1/1 [00:36<00:00, 36.49s/it]
 98%|█████████▊| 5073/5198 [2:25:36<1:05:26, 31.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.45s/it][A100%|██████████| 1/1 [00:36<00:00, 36.45s/it]
 98%|█████████▊| 5073/5198 [2:25:39<1:05:24, 31.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.55s/it][A100%|██████████| 1/1 [00:36<00:00, 36.55s/it]
 98%|█████████▊| 5073/5198 [2:25:32<1:05:27, 31.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.49s/it][A100%|██████████| 1/1 [00:36<00:00, 36.49s/it]
 98%|█████████▊| 5073/5198 [2:25:18<1:05:26, 31.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.53s/it][A100%|██████████| 1/1 [00:36<00:00, 36.53s/it]
 98%|█████████▊| 5073/5198 [2:25:23<1:05:27, 31.42s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4756
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.53s/it][A100%|██████████| 1/1 [00:31<00:00, 31.53s/it]
 98%|█████████▊| 5074/5198 [2:26:06<1:05:01, 31.47s/it][2024-09-02 01:23:51,535] [INFO] [logging.py:96:log_dist] [Rank 0] step=5073, skipped=0, lr=[3.309499865236254e-07], mom=[(0.9, 0.999)]
steps: 5073 loss: 1.4673 iter time (s): 30.448 samples/sec: 4.204

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.09s/it][A100%|██████████| 1/1 [00:31<00:00, 31.09s/it]
 98%|█████████▊| 5074/5198 [2:26:17<1:04:45, 31.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.37s/it][A100%|██████████| 1/1 [00:31<00:00, 31.37s/it]
 98%|█████████▊| 5074/5198 [2:26:07<1:04:53, 31.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.38s/it][A100%|██████████| 1/1 [00:31<00:00, 31.38s/it]
 98%|█████████▊| 5074/5198 [2:26:10<1:04:53, 31.40s/it]
100%|██████████| 1/1 [00:31<00:00, 31.56s/it][A100%|██████████| 1/1 [00:31<00:00, 31.56s/it]
 98%|█████████▊| 5074/5198 [2:26:16<1:05:00, 31.46s/it]
100%|██████████| 1/1 [00:31<00:00, 31.30s/it][A100%|██████████| 1/1 [00:31<00:00, 31.31s/it]
 98%|█████████▊| 5074/5198 [2:26:04<1:04:51, 31.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.78s/it][A100%|██████████| 1/1 [00:31<00:00, 31.78s/it]
 98%|█████████▊| 5074/5198 [2:25:50<1:05:08, 31.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.76s/it][A100%|██████████| 1/1 [00:31<00:00, 31.76s/it]
 98%|█████████▊| 5074/5198 [2:25:54<1:05:08, 31.52s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4757
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.12s/it][A100%|██████████| 1/1 [00:31<00:00, 31.12s/it]
 98%|█████████▊| 5075/5198 [2:26:37<1:04:23, 31.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:24:23,016] [INFO] [logging.py:96:log_dist] [Rank 0] step=5074, skipped=0, lr=[3.2993903982880195e-07], mom=[(0.9, 0.999)]
steps: 5074 loss: 1.5244 iter time (s): 30.170 samples/sec: 4.243

100%|██████████| 1/1 [00:31<00:00, 31.42s/it][A100%|██████████| 1/1 [00:31<00:00, 31.42s/it]
 98%|█████████▊| 5075/5198 [2:26:49<1:04:17, 31.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.11s/it][A100%|██████████| 1/1 [00:31<00:00, 31.11s/it]
 98%|█████████▊| 5075/5198 [2:26:47<1:04:17, 31.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.21s/it][A100%|██████████| 1/1 [00:31<00:00, 31.21s/it]
 98%|█████████▊| 5075/5198 [2:26:39<1:04:15, 31.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.24s/it][A100%|██████████| 1/1 [00:31<00:00, 31.24s/it]
 98%|█████████▊| 5075/5198 [2:26:41<1:04:16, 31.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.26s/it][A100%|██████████| 1/1 [00:31<00:00, 31.27s/it]
 98%|█████████▊| 5075/5198 [2:26:35<1:04:17, 31.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.82s/it][A100%|██████████| 1/1 [00:30<00:00, 30.82s/it]
 98%|█████████▊| 5075/5198 [2:26:20<1:04:11, 31.32s/it]
100%|██████████| 1/1 [00:30<00:00, 30.81s/it][A100%|██████████| 1/1 [00:30<00:00, 30.81s/it]
 98%|█████████▊| 5075/5198 [2:26:25<1:04:11, 31.31s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4758

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.07s/it][A100%|██████████| 1/1 [00:30<00:00, 30.07s/it]
 98%|█████████▊| 5076/5198 [2:27:07<1:03:08, 31.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:24:53,275] [INFO] [logging.py:96:log_dist] [Rank 0] step=5075, skipped=0, lr=[3.289295915658707e-07], mom=[(0.9, 0.999)]
steps: 5075 loss: 1.4493 iter time (s): 29.612 samples/sec: 4.323

100%|██████████| 1/1 [00:30<00:00, 30.27s/it][A100%|██████████| 1/1 [00:30<00:00, 30.27s/it]
 98%|█████████▊| 5076/5198 [2:27:19<1:03:06, 31.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.27s/it][A100%|██████████| 1/1 [00:30<00:00, 30.27s/it]
 98%|█████████▊| 5076/5198 [2:27:17<1:03:06, 31.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.34s/it][A100%|██████████| 1/1 [00:30<00:00, 30.34s/it]
 98%|█████████▊| 5076/5198 [2:27:09<1:03:07, 31.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.29s/it][A100%|██████████| 1/1 [00:30<00:00, 30.29s/it]
 98%|█████████▊| 5076/5198 [2:27:12<1:03:06, 31.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.29s/it][A100%|██████████| 1/1 [00:30<00:00, 30.29s/it]
 98%|█████████▊| 5076/5198 [2:27:05<1:03:06, 31.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.30s/it][A100%|██████████| 1/1 [00:30<00:00, 30.30s/it]
 98%|█████████▊| 5076/5198 [2:26:51<1:03:03, 31.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.31s/it][A100%|██████████| 1/1 [00:30<00:00, 30.31s/it]
 98%|█████████▊| 5076/5198 [2:26:55<1:03:03, 31.01s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4759
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.06s/it][A100%|██████████| 1/1 [00:31<00:00, 31.06s/it]
 98%|█████████▊| 5077/5198 [2:27:39<1:02:44, 31.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:25:24,478] [INFO] [logging.py:96:log_dist] [Rank 0] step=5076, skipped=0, lr=[3.2792164205868913e-07], mom=[(0.9, 0.999)]
steps: 5076 loss: 1.5171 iter time (s): 30.498 samples/sec: 4.197

100%|██████████| 1/1 [00:31<00:00, 31.17s/it][A100%|██████████| 1/1 [00:31<00:00, 31.17s/it]
 98%|█████████▊| 5077/5198 [2:27:50<1:02:41, 31.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.24s/it][A100%|██████████| 1/1 [00:31<00:00, 31.25s/it]
 98%|█████████▊| 5077/5198 [2:27:48<1:02:43, 31.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.24s/it][A100%|██████████| 1/1 [00:31<00:00, 31.24s/it]
 98%|█████████▊| 5077/5198 [2:27:40<1:02:43, 31.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.20s/it][A100%|██████████| 1/1 [00:31<00:00, 31.20s/it]
 98%|█████████▊| 5077/5198 [2:27:43<1:02:41, 31.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.24s/it][A
100%|██████████| 1/1 [00:31<00:00, 31.24s/it]
 98%|█████████▊| 5077/5198 [2:27:37<1:02:43, 31.10s/it]100%|██████████| 1/1 [00:31<00:00, 31.19s/it][A100%|██████████| 1/1 [00:31<00:00, 31.19s/it]
 98%|█████████▊| 5077/5198 [2:27:22<1:02:39, 31.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.21s/it][A100%|██████████| 1/1 [00:31<00:00, 31.21s/it]
 98%|█████████▊| 5077/5198 [2:27:27<1:02:39, 31.07s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4760
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.01s/it][A100%|██████████| 1/1 [00:34<00:00, 34.01s/it]
 98%|█████████▊| 5078/5198 [2:28:13<1:04:02, 32.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:25:58,754] [INFO] [logging.py:96:log_dist] [Rank 0] step=5077, skipped=0, lr=[3.269151916306321e-07], mom=[(0.9, 0.999)]
steps: 5077 loss: 1.5023 iter time (s): 33.558 samples/sec: 3.814

100%|██████████| 1/1 [00:34<00:00, 34.36s/it][A100%|██████████| 1/1 [00:34<00:00, 34.36s/it]
 98%|█████████▊| 5078/5198 [2:28:25<1:04:08, 32.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.22s/it][A100%|██████████| 1/1 [00:34<00:00, 34.22s/it]
 98%|█████████▊| 5078/5198 [2:28:14<1:04:05, 32.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.30s/it][A100%|██████████| 1/1 [00:34<00:00, 34.30s/it]
 98%|█████████▊| 5078/5198 [2:28:23<1:04:07, 32.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.33s/it][A100%|██████████| 1/1 [00:34<00:00, 34.33s/it]
 98%|█████████▊| 5078/5198 [2:28:17<1:04:07, 32.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.28s/it][A100%|██████████| 1/1 [00:34<00:00, 34.28s/it]
 98%|█████████▊| 5078/5198 [2:28:11<1:04:06, 32.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.31s/it][A100%|██████████| 1/1 [00:34<00:00, 34.31s/it]
 98%|█████████▊| 5078/5198 [2:27:56<1:04:05, 32.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.30s/it][A100%|██████████| 1/1 [00:34<00:00, 34.30s/it]
 98%|█████████▊| 5078/5198 [2:28:01<1:04:05, 32.04s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4761
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.64s/it][A100%|██████████| 1/1 [00:30<00:00, 30.64s/it]
 98%|█████████▊| 5079/5198 [2:28:44<1:02:47, 31.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:26:29,473] [INFO] [logging.py:96:log_dist] [Rank 0] step=5078, skipped=0, lr=[3.259102406045926e-07], mom=[(0.9, 0.999)]
steps: 5078 loss: 1.4016 iter time (s): 29.976 samples/sec: 4.270

100%|██████████| 1/1 [00:30<00:00, 30.63s/it][A100%|██████████| 1/1 [00:30<00:00, 30.63s/it]
 98%|█████████▊| 5079/5198 [2:28:55<1:02:45, 31.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.59s/it][A100%|██████████| 1/1 [00:30<00:00, 30.59s/it]
 98%|█████████▊| 5079/5198 [2:28:53<1:02:43, 31.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.75s/it][A100%|██████████| 1/1 [00:30<00:00, 30.75s/it]
 98%|█████████▊| 5079/5198 [2:28:45<1:02:47, 31.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.64s/it][A100%|██████████| 1/1 [00:30<00:00, 30.64s/it]
 98%|█████████▊| 5079/5198 [2:28:48<1:02:44, 31.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.69s/it][A100%|██████████| 1/1 [00:30<00:00, 30.69s/it]
 98%|█████████▊| 5079/5198 [2:28:42<1:02:46, 31.65s/it]
100%|██████████| 1/1 [00:30<00:00, 30.66s/it][A100%|██████████| 1/1 [00:30<00:00, 30.66s/it]
 98%|█████████▊| 5079/5198 [2:28:27<1:02:44, 31.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.67s/it][A100%|██████████| 1/1 [00:30<00:00, 30.68s/it]
 98%|█████████▊| 5079/5198 [2:28:32<1:02:44, 31.63s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4762
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.66s/it][A100%|██████████| 1/1 [00:31<00:00, 31.66s/it]
 98%|█████████▊| 5080/5198 [2:29:15<1:02:21, 31.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:27:01,335] [INFO] [logging.py:96:log_dist] [Rank 0] step=5079, skipped=0, lr=[3.2490678930298523e-07], mom=[(0.9, 0.999)]
steps: 5079 loss: 1.4869 iter time (s): 31.159 samples/sec: 4.108

100%|██████████| 1/1 [00:31<00:00, 31.90s/it][A100%|██████████| 1/1 [00:31<00:00, 31.90s/it]
 98%|█████████▊| 5080/5198 [2:29:27<1:02:23, 31.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.86s/it][A100%|██████████| 1/1 [00:31<00:00, 31.86s/it]
 98%|█████████▊| 5080/5198 [2:29:25<1:02:20, 31.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.91s/it][A100%|██████████| 1/1 [00:31<00:00, 31.91s/it]
 98%|█████████▊| 5080/5198 [2:29:17<1:02:24, 31.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.93s/it][A100%|██████████| 1/1 [00:31<00:00, 31.94s/it]
 98%|█████████▊| 5080/5198 [2:29:20<1:02:23, 31.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.93s/it][A100%|██████████| 1/1 [00:31<00:00, 31.93s/it]
 98%|█████████▊| 5080/5198 [2:28:59<1:02:23, 31.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.95s/it][A100%|██████████| 1/1 [00:31<00:00, 31.95s/it]
 98%|█████████▊| 5080/5198 [2:29:13<1:02:25, 31.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.94s/it][A100%|██████████| 1/1 [00:31<00:00, 31.94s/it]
 98%|█████████▊| 5080/5198 [2:29:04<1:02:23, 31.73s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4763
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.03s/it][A100%|██████████| 1/1 [00:30<00:00, 30.03s/it]
 98%|█████████▊| 5081/5198 [2:29:46<1:00:55, 31.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:27:31,441] [INFO] [logging.py:96:log_dist] [Rank 0] step=5080, skipped=0, lr=[3.239048380477415e-07], mom=[(0.9, 0.999)]
steps: 5080 loss: 1.4177 iter time (s): 29.313 samples/sec: 4.367

100%|██████████| 1/1 [00:30<00:00, 30.08s/it][A100%|██████████| 1/1 [00:30<00:00, 30.09s/it]
 98%|█████████▊| 5081/5198 [2:29:57<1:00:54, 31.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.08s/it][A100%|██████████| 1/1 [00:30<00:00, 30.08s/it]
 98%|█████████▊| 5081/5198 [2:29:55<1:00:52, 31.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.04s/it][A100%|██████████| 1/1 [00:30<00:00, 30.04s/it]
 98%|█████████▊| 5081/5198 [2:29:47<1:00:53, 31.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.02s/it][A100%|██████████| 1/1 [00:30<00:00, 30.02s/it]
 98%|█████████▊| 5081/5198 [2:29:50<1:00:52, 31.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.96s/it][A100%|██████████| 1/1 [00:29<00:00, 29.96s/it]
 98%|█████████▊| 5081/5198 [2:29:43<1:00:51, 31.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.01s/it][A100%|██████████| 1/1 [00:30<00:00, 30.01s/it]
 98%|█████████▊| 5081/5198 [2:29:29<1:00:51, 31.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 30.00s/it][A100%|██████████| 1/1 [00:30<00:00, 30.00s/it]
 98%|█████████▊| 5081/5198 [2:29:34<1:00:51, 31.21s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4764
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.99s/it][A100%|██████████| 1/1 [00:30<00:00, 30.99s/it]
 98%|█████████▊| 5082/5198 [2:30:17<1:00:21, 31.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:28:02,624] [INFO] [logging.py:96:log_dist] [Rank 0] step=5081, skipped=0, lr=[3.229043871603121e-07], mom=[(0.9, 0.999)]
steps: 5081 loss: 1.4769 iter time (s): 30.494 samples/sec: 4.198

100%|██████████| 1/1 [00:31<00:00, 31.13s/it][A100%|██████████| 1/1 [00:31<00:00, 31.13s/it]
 98%|█████████▊| 5082/5198 [2:30:28<1:00:19, 31.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.22s/it][A100%|██████████| 1/1 [00:31<00:00, 31.22s/it]
 98%|█████████▊| 5082/5198 [2:30:27<1:00:21, 31.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.14s/it][A100%|██████████| 1/1 [00:31<00:00, 31.14s/it]
 98%|█████████▊| 5082/5198 [2:30:18<1:00:20, 31.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.18s/it][A100%|██████████| 1/1 [00:31<00:00, 31.18s/it]
 98%|█████████▊| 5082/5198 [2:30:21<1:00:20, 31.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.20s/it][A100%|██████████| 1/1 [00:31<00:00, 31.20s/it]
 98%|█████████▊| 5082/5198 [2:30:15<1:00:20, 31.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.19s/it][A100%|██████████| 1/1 [00:31<00:00, 31.19s/it]
 98%|█████████▊| 5082/5198 [2:30:00<1:00:19, 31.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.18s/it][A100%|██████████| 1/1 [00:31<00:00, 31.18s/it]
 98%|█████████▊| 5082/5198 [2:30:05<1:00:19, 31.20s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4765
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.13s/it][A100%|██████████| 1/1 [00:30<00:00, 30.13s/it]
 98%|█████████▊| 5083/5198 [2:30:47<59:17, 30.94s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:28:32,902] [INFO] [logging.py:96:log_dist] [Rank 0] step=5082, skipped=0, lr=[3.219054369616674e-07], mom=[(0.9, 0.999)]
steps: 5082 loss: 1.4341 iter time (s): 29.588 samples/sec: 4.326

100%|██████████| 1/1 [00:30<00:00, 30.34s/it][A100%|██████████| 1/1 [00:30<00:00, 30.34s/it]
 98%|█████████▊| 5083/5198 [2:30:59<59:19, 30.95s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.27s/it][A100%|██████████| 1/1 [00:30<00:00, 30.27s/it]
 98%|█████████▊| 5083/5198 [2:30:57<59:17, 30.94s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.26s/it][A100%|██████████| 1/1 [00:30<00:00, 30.26s/it]
 98%|█████████▊| 5083/5198 [2:30:49<59:16, 30.93s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.29s/it][A100%|██████████| 1/1 [00:30<00:00, 30.29s/it]
 98%|█████████▊| 5083/5198 [2:30:51<59:17, 30.94s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.25s/it][A100%|██████████| 1/1 [00:30<00:00, 30.26s/it]
 98%|█████████▊| 5083/5198 [2:30:45<59:16, 30.92s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.29s/it][A100%|██████████| 1/1 [00:30<00:00, 30.29s/it]
 98%|█████████▊| 5083/5198 [2:30:30<59:17, 30.93s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.29s/it][A100%|██████████| 1/1 [00:30<00:00, 30.29s/it]
 98%|█████████▊| 5083/5198 [2:30:35<59:16, 30.93s/it]  Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4766
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.93s/it][A100%|██████████| 1/1 [00:30<00:00, 30.93s/it]
 98%|█████████▊| 5084/5198 [2:31:18<58:50, 30.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:29:03,939] [INFO] [logging.py:96:log_dist] [Rank 0] step=5083, skipped=0, lr=[3.209079877722948e-07], mom=[(0.9, 0.999)]
steps: 5083 loss: 1.4752 iter time (s): 30.331 samples/sec: 4.220

100%|██████████| 1/1 [00:30<00:00, 30.92s/it][A100%|██████████| 1/1 [00:30<00:00, 30.92s/it]
 98%|█████████▊| 5084/5198 [2:31:30<58:47, 30.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 31.00s/it][A100%|██████████| 1/1 [00:30<00:00, 31.00s/it]
 98%|█████████▊| 5084/5198 [2:31:28<58:49, 30.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.99s/it][A100%|██████████| 1/1 [00:30<00:00, 30.99s/it]
 98%|█████████▊| 5084/5198 [2:31:20<58:47, 30.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.99s/it][A100%|██████████| 1/1 [00:30<00:00, 30.99s/it]
 98%|█████████▊| 5084/5198 [2:31:22<58:48, 30.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.03s/it][A100%|██████████| 1/1 [00:31<00:00, 31.03s/it]
 98%|█████████▊| 5084/5198 [2:31:16<58:49, 30.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.01s/it][A100%|██████████| 1/1 [00:31<00:00, 31.01s/it]
 98%|█████████▊| 5084/5198 [2:31:01<58:49, 30.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.03s/it][A100%|██████████| 1/1 [00:31<00:00, 31.03s/it]
 98%|█████████▊| 5084/5198 [2:31:06<58:49, 30.96s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4767
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.49s/it][A100%|██████████| 1/1 [00:30<00:00, 30.49s/it]
 98%|█████████▊| 5085/5198 [2:31:49<58:10, 30.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:29:34,617] [INFO] [logging.py:96:log_dist] [Rank 0] step=5084, skipped=0, lr=[3.199120399122e-07], mom=[(0.9, 0.999)]
steps: 5084 loss: 1.4064 iter time (s): 29.976 samples/sec: 4.270

100%|██████████| 1/1 [00:30<00:00, 30.71s/it][A100%|██████████| 1/1 [00:30<00:00, 30.71s/it]
 98%|█████████▊| 5085/5198 [2:32:00<58:09, 30.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.66s/it][A100%|██████████| 1/1 [00:30<00:00, 30.66s/it]
 98%|█████████▊| 5085/5198 [2:31:59<58:08, 30.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.73s/it][A100%|██████████| 1/1 [00:30<00:00, 30.73s/it]
 98%|█████████▊| 5085/5198 [2:31:50<58:10, 30.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.73s/it][A100%|██████████| 1/1 [00:30<00:00, 30.73s/it]
 98%|█████████▊| 5085/5198 [2:31:53<58:10, 30.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.72s/it][A100%|██████████| 1/1 [00:30<00:00, 30.72s/it]
 98%|█████████▊| 5085/5198 [2:31:47<58:10, 30.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.70s/it][A100%|██████████| 1/1 [00:30<00:00, 30.70s/it]
 98%|█████████▊| 5085/5198 [2:31:32<58:09, 30.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.70s/it][A100%|██████████| 1/1 [00:30<00:00, 30.70s/it]
 98%|█████████▊| 5085/5198 [2:31:37<58:09, 30.88s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4768
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.43s/it][A100%|██████████| 1/1 [00:33<00:00, 33.43s/it]
 98%|█████████▊| 5086/5198 [2:32:22<59:08, 31.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:30:08,242] [INFO] [logging.py:96:log_dist] [Rank 0] step=5085, skipped=0, lr=[3.189175937009088e-07], mom=[(0.9, 0.999)]
steps: 5085 loss: 1.4287 iter time (s): 32.898 samples/sec: 3.891

100%|██████████| 1/1 [00:33<00:00, 33.59s/it][A100%|██████████| 1/1 [00:33<00:00, 33.59s/it]
 98%|█████████▊| 5086/5198 [2:32:34<59:09, 31.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.65s/it][A100%|██████████| 1/1 [00:33<00:00, 33.65s/it]
 98%|█████████▊| 5086/5198 [2:32:32<59:11, 31.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.66s/it][A100%|██████████| 1/1 [00:33<00:00, 33.66s/it]
 98%|█████████▊| 5086/5198 [2:32:24<59:12, 31.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.63s/it][A100%|██████████| 1/1 [00:33<00:00, 33.63s/it]
 98%|█████████▊| 5086/5198 [2:32:27<59:11, 31.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.64s/it][A100%|██████████| 1/1 [00:33<00:00, 33.64s/it]
 98%|█████████▊| 5086/5198 [2:32:20<59:12, 31.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.64s/it][A100%|██████████| 1/1 [00:33<00:00, 33.64s/it]
 98%|█████████▊| 5086/5198 [2:32:10<59:11, 31.71s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4769

Training on 128 of 128 sentences.
100%|██████████| 1/1 [00:33<00:00, 33.67s/it][A100%|██████████| 1/1 [00:33<00:00, 33.67s/it]
 98%|█████████▊| 5086/5198 [2:32:06<59:12, 31.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.24s/it][A100%|██████████| 1/1 [00:33<00:00, 33.24s/it]
 98%|█████████▊| 5087/5198 [2:32:56<59:33, 32.19s/it]
0it [00:00, ?it/s][A0it [00:00, ?it/s]

  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:30:41,648] [INFO] [logging.py:96:log_dist] [Rank 0] step=5086, skipped=0, lr=[3.179246494574646e-07], mom=[(0.9, 0.999)]
steps: 5086 loss: 1.4427 iter time (s): 32.655 samples/sec: 3.920

100%|██████████| 1/1 [00:33<00:00, 33.43s/it][A100%|██████████| 1/1 [00:33<00:00, 33.43s/it]
 98%|█████████▊| 5087/5198 [2:33:07<59:36, 32.22s/it]
0it [00:00, ?it/s][A0it [00:00, ?it/s]

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.41s/it][A100%|██████████| 1/1 [00:33<00:00, 33.41s/it]
 98%|█████████▊| 5087/5198 [2:33:06<59:36, 32.22s/it]
0it [00:00, ?it/s][A0it [00:00, ?it/s]

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.37s/it][A100%|██████████| 1/1 [00:33<00:00, 33.37s/it]
 98%|█████████▊| 5087/5198 [2:32:57<59:36, 32.22s/it]
0it [00:00, ?it/s][A0it [00:00, ?it/s]

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.40s/it][A100%|██████████| 1/1 [00:33<00:00, 33.40s/it]
 98%|█████████▊| 5087/5198 [2:33:00<59:36, 32.22s/it]
0it [00:00, ?it/s][A0it [00:00, ?it/s]

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.42s/it][A100%|██████████| 1/1 [00:33<00:00, 33.42s/it]
 98%|█████████▊| 5087/5198 [2:32:54<59:37, 32.23s/it]
100%|██████████| 1/1 [00:33<00:00, 33.38s/it][A100%|██████████| 1/1 [00:33<00:00, 33.38s/it]
 98%|█████████▊| 5087/5198 [2:32:39<59:36, 32.22s/it]
0it [00:00, ?it/s][A0it [00:00, ?it/s]

0it [00:00, ?it/s][A
0it [00:00, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.41s/it][A100%|██████████| 1/1 [00:33<00:00, 33.41s/it]
 98%|█████████▊| 5087/5198 [2:32:44<59:36, 32.22s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_317
Training on 0 of 112 sentences.

0it [00:00, ?it/s][A0it [00:00, ?it/s]
Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4770
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.16s/it][A100%|██████████| 1/1 [00:30<00:00, 30.16s/it]
 98%|█████████▊| 5089/5198 [2:33:26<44:14, 24.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:31:11,953] [INFO] [logging.py:96:log_dist] [Rank 0] step=5087, skipped=0, lr=[3.169332075004275e-07], mom=[(0.9, 0.999)]
steps: 5087 loss: 1.4933 iter time (s): 29.546 samples/sec: 4.332

100%|██████████| 1/1 [00:30<00:00, 30.28s/it][A100%|██████████| 1/1 [00:30<00:00, 30.28s/it]
 98%|█████████▊| 5089/5198 [2:33:38<44:13, 24.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.26s/it][A100%|██████████| 1/1 [00:30<00:00, 30.26s/it]
 98%|█████████▊| 5089/5198 [2:33:36<44:12, 24.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.30s/it][A100%|██████████| 1/1 [00:30<00:00, 30.30s/it]
 98%|█████████▊| 5089/5198 [2:33:28<44:13, 24.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.25s/it][A100%|██████████| 1/1 [00:30<00:00, 30.25s/it]
 98%|█████████▊| 5089/5198 [2:33:30<44:12, 24.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.22s/it][A100%|██████████| 1/1 [00:30<00:00, 30.22s/it]
 98%|█████████▊| 5089/5198 [2:33:24<44:11, 24.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.24s/it][A100%|██████████| 1/1 [00:30<00:00, 30.24s/it]
 98%|█████████▊| 5089/5198 [2:33:09<44:11, 24.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.25s/it][A100%|██████████| 1/1 [00:30<00:00, 30.25s/it]
 98%|█████████▊| 5089/5198 [2:33:14<44:12, 24.33s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4771
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.94s/it][A100%|██████████| 1/1 [00:32<00:00, 32.94s/it]
 98%|█████████▊| 5090/5198 [2:33:59<47:44, 26.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:31:45,174] [INFO] [logging.py:96:log_dist] [Rank 0] step=5088, skipped=0, lr=[3.1594326814787766e-07], mom=[(0.9, 0.999)]
steps: 5088 loss: 1.4398 iter time (s): 32.511 samples/sec: 3.937

100%|██████████| 1/1 [00:33<00:00, 33.21s/it][A100%|██████████| 1/1 [00:33<00:00, 33.21s/it]
 98%|█████████▊| 5090/5198 [2:34:11<47:46, 26.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.18s/it][A100%|██████████| 1/1 [00:33<00:00, 33.18s/it]
 98%|█████████▊| 5090/5198 [2:34:09<47:45, 26.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.21s/it][A100%|██████████| 1/1 [00:33<00:00, 33.21s/it]
 98%|█████████▊| 5090/5198 [2:34:01<47:46, 26.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.26s/it][A100%|██████████| 1/1 [00:33<00:00, 33.26s/it]
 98%|█████████▊| 5090/5198 [2:34:04<47:47, 26.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.25s/it][A100%|██████████| 1/1 [00:33<00:00, 33.25s/it]
 98%|█████████▊| 5090/5198 [2:33:57<47:46, 26.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.26s/it][A100%|██████████| 1/1 [00:33<00:00, 33.27s/it]
 98%|█████████▊| 5090/5198 [2:33:43<47:47, 26.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.25s/it][A100%|██████████| 1/1 [00:33<00:00, 33.26s/it]
 98%|█████████▊| 5090/5198 [2:33:47<47:47, 26.55s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4772
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.44s/it][A100%|██████████| 1/1 [00:31<00:00, 31.44s/it]
 98%|█████████▊| 5091/5198 [2:34:31<49:39, 27.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:32:16,701] [INFO] [logging.py:96:log_dist] [Rank 0] step=5089, skipped=0, lr=[3.1495483171741107e-07], mom=[(0.9, 0.999)]
steps: 5089 loss: 1.4384 iter time (s): 30.778 samples/sec: 4.159

100%|██████████| 1/1 [00:31<00:00, 31.55s/it][A100%|██████████| 1/1 [00:31<00:00, 31.55s/it]
 98%|█████████▊| 5091/5198 [2:34:43<49:40, 27.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.58s/it][A100%|██████████| 1/1 [00:31<00:00, 31.58s/it]
 98%|█████████▊| 5091/5198 [2:34:41<49:40, 27.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.58s/it][A100%|██████████| 1/1 [00:31<00:00, 31.58s/it]
 98%|█████████▊| 5091/5198 [2:34:33<49:41, 27.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.54s/it][A100%|██████████| 1/1 [00:31<00:00, 31.54s/it]
 98%|█████████▊| 5091/5198 [2:34:35<49:40, 27.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.57s/it][A100%|██████████| 1/1 [00:31<00:00, 31.57s/it]
 98%|█████████▊| 5091/5198 [2:34:29<49:41, 27.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.59s/it][A100%|██████████| 1/1 [00:31<00:00, 31.59s/it]
 98%|█████████▊| 5091/5198 [2:34:14<49:41, 27.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.58s/it][A100%|██████████| 1/1 [00:31<00:00, 31.58s/it]
 98%|█████████▊| 5091/5198 [2:34:19<49:41, 27.86s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4773
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.93s/it][A100%|██████████| 1/1 [00:29<00:00, 29.93s/it]
 98%|█████████▊| 5092/5198 [2:35:01<50:17, 28.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:32:46,780] [INFO] [logging.py:96:log_dist] [Rank 0] step=5090, skipped=0, lr=[3.1396789852614335e-07], mom=[(0.9, 0.999)]
steps: 5090 loss: 1.4296 iter time (s): 29.272 samples/sec: 4.373

100%|██████████| 1/1 [00:30<00:00, 30.07s/it][A100%|██████████| 1/1 [00:30<00:00, 30.07s/it]
 98%|█████████▊| 5092/5198 [2:35:13<50:16, 28.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.12s/it][A100%|██████████| 1/1 [00:30<00:00, 30.12s/it]
 98%|█████████▊| 5092/5198 [2:35:11<50:18, 28.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.99s/it][A100%|██████████| 1/1 [00:29<00:00, 29.99s/it]
 98%|█████████▊| 5092/5198 [2:35:03<50:14, 28.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.06s/it][A100%|██████████| 1/1 [00:30<00:00, 30.06s/it]
 98%|█████████▊| 5092/5198 [2:35:05<50:16, 28.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.98s/it][A100%|██████████| 1/1 [00:29<00:00, 29.98s/it]
 98%|█████████▊| 5092/5198 [2:34:44<50:15, 28.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.04s/it][A100%|██████████| 1/1 [00:30<00:00, 30.04s/it]
 98%|█████████▊| 5092/5198 [2:34:59<50:16, 28.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.02s/it][A100%|██████████| 1/1 [00:30<00:00, 30.02s/it]
 98%|█████████▊| 5092/5198 [2:34:49<50:15, 28.45s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4774
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.40s/it][A100%|██████████| 1/1 [00:28<00:00, 28.40s/it]
 98%|█████████▊| 5093/5198 [2:35:30<49:51, 28.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:33:15,290] [INFO] [logging.py:96:log_dist] [Rank 0] step=5091, skipped=0, lr=[3.1298246889070675e-07], mom=[(0.9, 0.999)]
steps: 5091 loss: 1.5031 iter time (s): 27.757 samples/sec: 4.611

100%|██████████| 1/1 [00:28<00:00, 28.44s/it][A100%|██████████| 1/1 [00:28<00:00, 28.44s/it]
 98%|█████████▊| 5093/5198 [2:35:41<49:48, 28.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.41s/it][A100%|██████████| 1/1 [00:28<00:00, 28.41s/it]
 98%|█████████▊| 5093/5198 [2:35:39<49:48, 28.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.45s/it][A100%|██████████| 1/1 [00:28<00:00, 28.45s/it]
 98%|█████████▊| 5093/5198 [2:35:31<49:46, 28.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.39s/it][A100%|██████████| 1/1 [00:28<00:00, 28.39s/it]
 98%|█████████▊| 5093/5198 [2:35:34<49:46, 28.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.42s/it][A100%|██████████| 1/1 [00:28<00:00, 28.42s/it]
 98%|█████████▊| 5093/5198 [2:35:27<49:47, 28.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:28<00:00, 28.46s/it][A100%|██████████| 1/1 [00:28<00:00, 28.46s/it]
 98%|█████████▊| 5093/5198 [2:35:13<49:47, 28.45s/it]
100%|██████████| 1/1 [00:28<00:00, 28.41s/it][A100%|██████████| 1/1 [00:28<00:00, 28.41s/it]
 98%|█████████▊| 5093/5198 [2:35:17<49:46, 28.44s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4775

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.73s/it][A100%|██████████| 1/1 [00:29<00:00, 29.73s/it]
 98%|█████████▊| 5094/5198 [2:35:59<50:05, 28.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:33:45,244] [INFO] [logging.py:96:log_dist] [Rank 0] step=5092, skipped=0, lr=[3.119985431272524e-07], mom=[(0.9, 0.999)]
steps: 5092 loss: 1.4560 iter time (s): 29.295 samples/sec: 4.369

100%|██████████| 1/1 [00:29<00:00, 29.91s/it][A100%|██████████| 1/1 [00:29<00:00, 29.91s/it]
 98%|█████████▊| 5094/5198 [2:36:11<50:03, 28.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.93s/it][A100%|██████████| 1/1 [00:29<00:00, 29.93s/it]
 98%|█████████▊| 5094/5198 [2:36:09<50:03, 28.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.98s/it][A100%|██████████| 1/1 [00:29<00:00, 29.98s/it]
 98%|█████████▊| 5094/5198 [2:36:01<50:04, 28.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.97s/it][A100%|██████████| 1/1 [00:29<00:00, 29.97s/it]
 98%|█████████▊| 5094/5198 [2:36:04<50:03, 28.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.97s/it][A100%|██████████| 1/1 [00:29<00:00, 29.97s/it]
 98%|█████████▊| 5094/5198 [2:35:57<50:03, 28.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.96s/it][A100%|██████████| 1/1 [00:29<00:00, 29.96s/it]
 98%|█████████▊| 5094/5198 [2:35:43<50:03, 28.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.97s/it][A100%|██████████| 1/1 [00:29<00:00, 29.97s/it]
 98%|█████████▊| 5094/5198 [2:35:47<50:03, 28.88s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4776
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.26s/it][A100%|██████████| 1/1 [00:31<00:00, 31.26s/it]
 98%|█████████▊| 5095/5198 [2:36:31<50:51, 29.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:34:16,658] [INFO] [logging.py:96:log_dist] [Rank 0] step=5093, skipped=0, lr=[3.1101612155144725e-07], mom=[(0.9, 0.999)]
steps: 5093 loss: 1.4139 iter time (s): 30.729 samples/sec: 4.165

100%|██████████| 1/1 [00:31<00:00, 31.48s/it][A100%|██████████| 1/1 [00:31<00:00, 31.48s/it]
 98%|█████████▊| 5095/5198 [2:36:42<50:52, 29.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.43s/it][A100%|██████████| 1/1 [00:31<00:00, 31.43s/it]
 98%|█████████▊| 5095/5198 [2:36:41<50:51, 29.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.47s/it][A100%|██████████| 1/1 [00:31<00:00, 31.47s/it]
 98%|█████████▊| 5095/5198 [2:36:32<50:52, 29.64s/it]
100%|██████████| 1/1 [00:31<00:00, 31.42s/it][A100%|██████████| 1/1 [00:31<00:00, 31.42s/it]
 98%|█████████▊| 5095/5198 [2:36:35<50:50, 29.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.45s/it][A100%|██████████| 1/1 [00:31<00:00, 31.45s/it]
 98%|█████████▊| 5095/5198 [2:36:29<50:51, 29.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.45s/it][A100%|██████████| 1/1 [00:31<00:00, 31.45s/it]
 98%|█████████▊| 5095/5198 [2:36:14<50:51, 29.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.46s/it][A100%|██████████| 1/1 [00:31<00:00, 31.47s/it]
 98%|█████████▊| 5095/5198 [2:36:19<50:52, 29.63s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4777
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.46s/it][A100%|██████████| 1/1 [00:34<00:00, 34.46s/it]
 98%|█████████▊| 5096/5198 [2:37:05<52:52, 31.10s/it][2024-09-02 01:34:51,065] [INFO] [logging.py:96:log_dist] [Rank 0] step=5094, skipped=0, lr=[3.1003520447847754e-07], mom=[(0.9, 0.999)]
steps: 5094 loss: 1.5021 iter time (s): 33.662 samples/sec: 3.803

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.55s/it][A100%|██████████| 1/1 [00:34<00:00, 34.55s/it]
 98%|█████████▊| 5096/5198 [2:37:17<52:49, 31.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.56s/it][A100%|██████████| 1/1 [00:34<00:00, 34.56s/it]
 98%|█████████▊| 5096/5198 [2:37:15<52:49, 31.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.65s/it][A100%|██████████| 1/1 [00:34<00:00, 34.65s/it]
 98%|█████████▊| 5096/5198 [2:37:10<52:51, 31.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.67s/it][A100%|██████████| 1/1 [00:34<00:00, 34.67s/it]
 98%|█████████▊| 5096/5198 [2:37:07<52:53, 31.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.61s/it][A100%|██████████| 1/1 [00:34<00:00, 34.61s/it]
 98%|█████████▊| 5096/5198 [2:36:49<52:51, 31.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.66s/it][A100%|██████████| 1/1 [00:34<00:00, 34.66s/it]
 98%|█████████▊| 5096/5198 [2:37:03<52:52, 31.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:35<00:00, 35.07s/it][A100%|██████████| 1/1 [00:35<00:00, 35.07s/it]
 98%|█████████▊| 5096/5198 [2:36:54<53:05, 31.23s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4778
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.02s/it][A100%|██████████| 1/1 [00:33<00:00, 33.02s/it]
 98%|█████████▊| 5097/5198 [2:37:39<53:22, 31.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:35:24,542] [INFO] [logging.py:96:log_dist] [Rank 0] step=5095, skipped=0, lr=[3.090557922230446e-07], mom=[(0.9, 0.999)]
steps: 5095 loss: 1.5370 iter time (s): 32.064 samples/sec: 3.992

100%|██████████| 1/1 [00:33<00:00, 33.27s/it][A100%|██████████| 1/1 [00:33<00:00, 33.27s/it]
 98%|█████████▊| 5097/5198 [2:37:50<53:24, 31.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.32s/it][A100%|██████████| 1/1 [00:33<00:00, 33.32s/it]
 98%|█████████▊| 5097/5198 [2:37:49<53:25, 31.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.15s/it][A100%|██████████| 1/1 [00:33<00:00, 33.15s/it]
 98%|█████████▊| 5097/5198 [2:37:40<53:23, 31.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.23s/it][A100%|██████████| 1/1 [00:33<00:00, 33.23s/it]
 98%|█████████▊| 5097/5198 [2:37:43<53:24, 31.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.20s/it][A100%|██████████| 1/1 [00:33<00:00, 33.20s/it]
 98%|█████████▊| 5097/5198 [2:37:37<53:24, 31.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:33<00:00, 33.24s/it][A100%|██████████| 1/1 [00:33<00:00, 33.24s/it]
 98%|█████████▊| 5097/5198 [2:37:22<53:24, 31.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.78s/it][A100%|██████████| 1/1 [00:32<00:00, 32.78s/it]
 98%|█████████▊| 5097/5198 [2:37:27<53:20, 31.68s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4779
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.70s/it][A100%|██████████| 1/1 [00:29<00:00, 29.70s/it]
 98%|█████████▊| 5098/5198 [2:38:08<51:55, 31.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:35:54,305] [INFO] [logging.py:96:log_dist] [Rank 0] step=5096, skipped=0, lr=[3.0807788509936887e-07], mom=[(0.9, 0.999)]
steps: 5096 loss: 1.4713 iter time (s): 29.046 samples/sec: 4.407

100%|██████████| 1/1 [00:29<00:00, 29.77s/it][A100%|██████████| 1/1 [00:29<00:00, 29.77s/it]
 98%|█████████▊| 5098/5198 [2:38:20<51:54, 31.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.76s/it][A100%|██████████| 1/1 [00:29<00:00, 29.76s/it]
 98%|█████████▊| 5098/5198 [2:38:18<51:55, 31.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.74s/it][A100%|██████████| 1/1 [00:29<00:00, 29.74s/it]
 98%|█████████▊| 5098/5198 [2:38:10<51:53, 31.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.79s/it][A100%|██████████| 1/1 [00:29<00:00, 29.79s/it]
 98%|█████████▊| 5098/5198 [2:38:13<51:55, 31.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.72s/it][A100%|██████████| 1/1 [00:29<00:00, 29.72s/it]
 98%|█████████▊| 5098/5198 [2:38:06<51:53, 31.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.74s/it][A100%|██████████| 1/1 [00:29<00:00, 29.74s/it]
 98%|█████████▊| 5098/5198 [2:37:52<51:53, 31.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.74s/it][A100%|██████████| 1/1 [00:29<00:00, 29.74s/it]
 98%|█████████▊| 5098/5198 [2:37:56<51:50, 31.11s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4780
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.13s/it][A100%|██████████| 1/1 [00:31<00:00, 31.13s/it]
 98%|█████████▊| 5099/5198 [2:38:40<51:29, 31.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:36:25,676] [INFO] [logging.py:96:log_dist] [Rank 0] step=5097, skipped=0, lr=[3.07101483421187e-07], mom=[(0.9, 0.999)]
steps: 5097 loss: 1.4932 iter time (s): 30.672 samples/sec: 4.173

100%|██████████| 1/1 [00:31<00:00, 31.40s/it][A100%|██████████| 1/1 [00:31<00:00, 31.40s/it]
 98%|█████████▊| 5099/5198 [2:38:52<51:31, 31.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.36s/it][A100%|██████████| 1/1 [00:31<00:00, 31.36s/it]
 98%|█████████▊| 5099/5198 [2:38:50<51:30, 31.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.36s/it][A100%|██████████| 1/1 [00:31<00:00, 31.36s/it]
 98%|█████████▊| 5099/5198 [2:38:41<51:28, 31.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.35s/it][A100%|██████████| 1/1 [00:31<00:00, 31.35s/it]
 98%|█████████▊| 5099/5198 [2:38:44<51:30, 31.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.38s/it][A100%|██████████| 1/1 [00:31<00:00, 31.38s/it]
 98%|█████████▊| 5099/5198 [2:38:38<51:29, 31.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.38s/it][A100%|██████████| 1/1 [00:31<00:00, 31.38s/it]
 98%|█████████▊| 5099/5198 [2:38:28<51:27, 31.19s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4781
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.40s/it][A100%|██████████| 1/1 [00:31<00:00, 31.40s/it]
 98%|█████████▊| 5099/5198 [2:38:23<51:30, 31.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.05s/it][A100%|██████████| 1/1 [00:30<00:00, 30.05s/it]
 98%|█████████▊| 5100/5198 [2:39:10<50:29, 30.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:36:55,831] [INFO] [logging.py:96:log_dist] [Rank 0] step=5098, skipped=0, lr=[3.0612658750175305e-07], mom=[(0.9, 0.999)]
steps: 5098 loss: 1.5151 iter time (s): 29.444 samples/sec: 4.347

100%|██████████| 1/1 [00:30<00:00, 30.09s/it][A100%|██████████| 1/1 [00:30<00:00, 30.09s/it]
 98%|█████████▊| 5100/5198 [2:39:22<50:27, 30.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.07s/it][A100%|██████████| 1/1 [00:30<00:00, 30.07s/it]
 98%|█████████▊| 5100/5198 [2:39:20<50:25, 30.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.09s/it][A100%|██████████| 1/1 [00:30<00:00, 30.09s/it]
 98%|█████████▊| 5100/5198 [2:39:11<50:25, 30.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.09s/it][A100%|██████████| 1/1 [00:30<00:00, 30.09s/it]
 98%|█████████▊| 5100/5198 [2:39:14<50:26, 30.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.09s/it][A100%|██████████| 1/1 [00:30<00:00, 30.09s/it]
 98%|█████████▊| 5100/5198 [2:39:08<50:26, 30.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.08s/it][A100%|██████████| 1/1 [00:30<00:00, 30.08s/it]
 98%|█████████▊| 5100/5198 [2:38:53<50:26, 30.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:30<00:00, 30.12s/it][A100%|██████████| 1/1 [00:30<00:00, 30.12s/it]
 98%|█████████▊| 5100/5198 [2:38:58<50:25, 30.87s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4782
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.13s/it][A100%|██████████| 1/1 [00:29<00:00, 29.13s/it]
 98%|█████████▊| 5101/5198 [2:39:39<49:12, 30.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:37:25,145] [INFO] [logging.py:96:log_dist] [Rank 0] step=5099, skipped=0, lr=[3.0515319765383887e-07], mom=[(0.9, 0.999)]
steps: 5099 loss: 1.5014 iter time (s): 28.637 samples/sec: 4.470

100%|██████████| 1/1 [00:29<00:00, 29.20s/it][A100%|██████████| 1/1 [00:29<00:00, 29.20s/it]
 98%|█████████▊| 5101/5198 [2:39:51<49:07, 30.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.33s/it][A100%|██████████| 1/1 [00:29<00:00, 29.33s/it]
 98%|█████████▊| 5101/5198 [2:39:49<49:10, 30.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.32s/it][A100%|██████████| 1/1 [00:29<00:00, 29.32s/it]
 98%|█████████▊| 5101/5198 [2:39:41<49:10, 30.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.26s/it][A100%|██████████| 1/1 [00:29<00:00, 29.26s/it]
 98%|█████████▊| 5101/5198 [2:39:43<49:08, 30.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.28s/it][A100%|██████████| 1/1 [00:29<00:00, 29.28s/it]
 98%|█████████▊| 5101/5198 [2:39:37<49:09, 30.40s/it]
100%|██████████| 1/1 [00:29<00:00, 29.25s/it][A100%|██████████| 1/1 [00:29<00:00, 29.25s/it]
 98%|█████████▊| 5101/5198 [2:39:23<49:08, 30.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.25s/it][A100%|██████████| 1/1 [00:29<00:00, 29.25s/it]
 98%|█████████▊| 5101/5198 [2:39:27<49:07, 30.39s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4783
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.32s/it][A100%|██████████| 1/1 [00:34<00:00, 34.32s/it]
 98%|█████████▊| 5102/5198 [2:40:14<50:38, 31.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:37:59,794] [INFO] [logging.py:96:log_dist] [Rank 0] step=5100, skipped=0, lr=[3.041813141897296e-07], mom=[(0.9, 0.999)]
steps: 5100 loss: 1.4248 iter time (s): 34.036 samples/sec: 3.761

100%|██████████| 1/1 [00:34<00:00, 34.80s/it][A100%|██████████| 1/1 [00:34<00:00, 34.80s/it]
 98%|█████████▊| 5102/5198 [2:40:26<50:44, 31.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.69s/it][A100%|██████████| 1/1 [00:34<00:00, 34.69s/it]
 98%|█████████▊| 5102/5198 [2:40:24<50:43, 31.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.74s/it][A100%|██████████| 1/1 [00:34<00:00, 34.74s/it]
 98%|█████████▊| 5102/5198 [2:40:16<50:44, 31.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.72s/it][A100%|██████████| 1/1 [00:34<00:00, 34.72s/it]
 98%|█████████▊| 5102/5198 [2:40:18<50:42, 31.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.75s/it][A100%|██████████| 1/1 [00:34<00:00, 34.75s/it]
 98%|█████████▊| 5102/5198 [2:40:12<50:43, 31.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.79s/it][A100%|██████████| 1/1 [00:34<00:00, 34.79s/it]
 98%|█████████▊| 5102/5198 [2:39:57<50:44, 31.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:34<00:00, 34.80s/it][A100%|██████████| 1/1 [00:34<00:00, 34.80s/it]
 98%|█████████▊| 5102/5198 [2:40:02<50:43, 31.71s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4784
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.90s/it][A100%|██████████| 1/1 [00:38<00:00, 38.90s/it]
 98%|█████████▊| 5103/5198 [2:40:53<53:37, 33.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:38:38,990] [INFO] [logging.py:96:log_dist] [Rank 0] step=5101, skipped=0, lr=[3.0321093742123175e-07], mom=[(0.9, 0.999)]
steps: 5101 loss: 1.4449 iter time (s): 38.427 samples/sec: 3.331

100%|██████████| 1/1 [00:39<00:00, 39.15s/it][A100%|██████████| 1/1 [00:39<00:00, 39.15s/it]
 98%|█████████▊| 5103/5198 [2:41:05<53:44, 33.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:39<00:00, 39.22s/it][A100%|██████████| 1/1 [00:39<00:00, 39.22s/it]
 98%|█████████▊| 5103/5198 [2:41:03<53:45, 33.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:39<00:00, 39.16s/it][A100%|██████████| 1/1 [00:39<00:00, 39.16s/it]
 98%|█████████▊| 5103/5198 [2:40:55<53:44, 33.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:39<00:00, 39.19s/it][A100%|██████████| 1/1 [00:39<00:00, 39.19s/it]
 98%|█████████▊| 5103/5198 [2:40:57<53:44, 33.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:39<00:00, 39.21s/it][A100%|██████████| 1/1 [00:39<00:00, 39.21s/it]
 98%|█████████▊| 5103/5198 [2:40:51<53:45, 33.96s/it]
100%|██████████| 1/1 [00:39<00:00, 39.18s/it][A100%|██████████| 1/1 [00:39<00:00, 39.18s/it]
 98%|█████████▊| 5103/5198 [2:40:36<53:45, 33.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:39<00:00, 39.18s/it][A100%|██████████| 1/1 [00:39<00:00, 39.18s/it]
 98%|█████████▊| 5103/5198 [2:40:41<53:44, 33.95s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4785
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.50s/it][A100%|██████████| 1/1 [00:32<00:00, 32.50s/it]
 98%|█████████▊| 5104/5198 [2:41:26<52:28, 33.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:39:11,374] [INFO] [logging.py:96:log_dist] [Rank 0] step=5102, skipped=0, lr=[3.022420676596651e-07], mom=[(0.9, 0.999)]
steps: 5102 loss: 1.4545 iter time (s): 31.629 samples/sec: 4.047

100%|██████████| 1/1 [00:32<00:00, 32.44s/it][A100%|██████████| 1/1 [00:32<00:00, 32.44s/it]
 98%|█████████▊| 5104/5198 [2:41:37<52:28, 33.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.40s/it][A100%|██████████| 1/1 [00:32<00:00, 32.40s/it]
 98%|█████████▊| 5104/5198 [2:41:35<52:28, 33.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.52s/it][A100%|██████████| 1/1 [00:32<00:00, 32.52s/it]
 98%|█████████▊| 5104/5198 [2:41:27<52:30, 33.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.49s/it][A100%|██████████| 1/1 [00:32<00:00, 32.50s/it]
 98%|█████████▊| 5104/5198 [2:41:30<52:30, 33.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.41s/it][A100%|██████████| 1/1 [00:32<00:00, 32.41s/it]
 98%|█████████▊| 5104/5198 [2:41:24<52:28, 33.50s/it]
100%|██████████| 1/1 [00:32<00:00, 32.41s/it][A100%|██████████| 1/1 [00:32<00:00, 32.41s/it]
 98%|█████████▊| 5104/5198 [2:41:09<52:28, 33.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.42s/it][A100%|██████████| 1/1 [00:32<00:00, 32.42s/it]
 98%|█████████▊| 5104/5198 [2:41:14<52:28, 33.49s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4786
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.34s/it][A100%|██████████| 1/1 [00:29<00:00, 29.34s/it]
 98%|█████████▊| 5105/5198 [2:41:55<50:03, 32.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:39:40,799] [INFO] [logging.py:96:log_dist] [Rank 0] step=5103, skipped=0, lr=[3.0127470521586726e-07], mom=[(0.9, 0.999)]
steps: 5103 loss: 1.4531 iter time (s): 28.628 samples/sec: 4.471

100%|██████████| 1/1 [00:29<00:00, 29.29s/it][A100%|██████████| 1/1 [00:29<00:00, 29.30s/it]
 98%|█████████▊| 5105/5198 [2:42:07<49:58, 32.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.31s/it][A100%|██████████| 1/1 [00:29<00:00, 29.31s/it]
 98%|█████████▊| 5105/5198 [2:42:05<49:58, 32.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.15s/it][A100%|██████████| 1/1 [00:29<00:00, 29.15s/it]
 98%|█████████▊| 5105/5198 [2:41:56<49:55, 32.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.22s/it][A100%|██████████| 1/1 [00:29<00:00, 29.22s/it]
 98%|█████████▊| 5105/5198 [2:41:59<49:56, 32.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.24s/it][A100%|██████████| 1/1 [00:29<00:00, 29.24s/it]
 98%|█████████▊| 5105/5198 [2:41:53<49:56, 32.22s/it]
100%|██████████| 1/1 [00:29<00:00, 29.24s/it][A100%|██████████| 1/1 [00:29<00:00, 29.24s/it]
 98%|█████████▊| 5105/5198 [2:41:38<49:56, 32.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.24s/it][A100%|██████████| 1/1 [00:29<00:00, 29.24s/it]
 98%|█████████▊| 5105/5198 [2:41:43<49:56, 32.22s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4787
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.70s/it][A100%|██████████| 1/1 [00:29<00:00, 29.70s/it]
 98%|█████████▊| 5106/5198 [2:42:25<48:23, 31.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:40:10,676] [INFO] [logging.py:96:log_dist] [Rank 0] step=5104, skipped=0, lr=[3.0030885040019377e-07], mom=[(0.9, 0.999)]
steps: 5104 loss: 1.4488 iter time (s): 29.264 samples/sec: 4.374

100%|██████████| 1/1 [00:29<00:00, 29.92s/it][A100%|██████████| 1/1 [00:29<00:00, 29.92s/it]
 98%|█████████▊| 5106/5198 [2:42:36<48:22, 31.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.95s/it][A100%|██████████| 1/1 [00:29<00:00, 29.95s/it]
 98%|█████████▊| 5106/5198 [2:42:35<48:23, 31.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.94s/it][A100%|██████████| 1/1 [00:29<00:00, 29.94s/it]
 98%|█████████▊| 5106/5198 [2:42:26<48:20, 31.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.93s/it][A100%|██████████| 1/1 [00:29<00:00, 29.93s/it]
 98%|█████████▊| 5106/5198 [2:42:29<48:21, 31.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.92s/it][A100%|██████████| 1/1 [00:29<00:00, 29.92s/it]
 98%|█████████▊| 5106/5198 [2:42:23<48:21, 31.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.98s/it][A100%|██████████| 1/1 [00:29<00:00, 29.98s/it]
 98%|█████████▊| 5106/5198 [2:42:08<48:22, 31.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.97s/it][A100%|██████████| 1/1 [00:29<00:00, 29.97s/it]
 98%|█████████▊| 5106/5198 [2:42:13<48:22, 31.54s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4788
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.17s/it][A100%|██████████| 1/1 [00:29<00:00, 29.17s/it]
 98%|█████████▊| 5107/5198 [2:42:54<46:51, 30.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:40:39,984] [INFO] [logging.py:96:log_dist] [Rank 0] step=5105, skipped=0, lr=[2.9934450352251245e-07], mom=[(0.9, 0.999)]
steps: 5105 loss: 1.4440 iter time (s): 28.599 samples/sec: 4.476

100%|██████████| 1/1 [00:29<00:00, 29.29s/it][A100%|██████████| 1/1 [00:29<00:00, 29.29s/it]
 98%|█████████▊| 5107/5198 [2:43:06<46:49, 30.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.19s/it][A100%|██████████| 1/1 [00:29<00:00, 29.19s/it]
 98%|█████████▊| 5107/5198 [2:43:04<46:47, 30.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.29s/it][A100%|██████████| 1/1 [00:29<00:00, 29.29s/it]
 98%|█████████▊| 5107/5198 [2:42:56<46:48, 30.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.21s/it][A100%|██████████| 1/1 [00:29<00:00, 29.21s/it]
 98%|█████████▊| 5107/5198 [2:42:58<46:46, 30.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.22s/it][A100%|██████████| 1/1 [00:29<00:00, 29.22s/it]
 98%|█████████▊| 5107/5198 [2:42:52<46:46, 30.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.19s/it][A100%|██████████| 1/1 [00:29<00:00, 29.19s/it]
 98%|█████████▊| 5107/5198 [2:42:37<46:46, 30.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:29<00:00, 29.21s/it][A100%|██████████| 1/1 [00:29<00:00, 29.21s/it]
 98%|█████████▊| 5107/5198 [2:42:42<46:46, 30.84s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4789
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.34s/it][A100%|██████████| 1/1 [00:31<00:00, 31.34s/it]
 98%|█████████▊| 5108/5198 [2:43:26<46:35, 31.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:41:11,517] [INFO] [logging.py:96:log_dist] [Rank 0] step=5106, skipped=0, lr=[2.9838166489221046e-07], mom=[(0.9, 0.999)]
steps: 5106 loss: 1.5256 iter time (s): 30.916 samples/sec: 4.140

100%|██████████| 1/1 [00:31<00:00, 31.45s/it][A100%|██████████| 1/1 [00:31<00:00, 31.45s/it]
 98%|█████████▊| 5108/5198 [2:43:37<46:34, 31.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.63s/it][A100%|██████████| 1/1 [00:31<00:00, 31.63s/it]
 98%|█████████▊| 5108/5198 [2:43:36<46:37, 31.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.65s/it][A100%|██████████| 1/1 [00:31<00:00, 31.65s/it]
 98%|█████████▊| 5108/5198 [2:43:30<46:37, 31.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.66s/it][A100%|██████████| 1/1 [00:31<00:00, 31.66s/it]
 98%|█████████▊| 5108/5198 [2:43:27<46:39, 31.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.66s/it][A100%|██████████| 1/1 [00:31<00:00, 31.67s/it]
 98%|█████████▊| 5108/5198 [2:43:24<46:38, 31.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.68s/it][A100%|██████████| 1/1 [00:31<00:00, 31.68s/it]
 98%|█████████▊| 5108/5198 [2:43:09<46:38, 31.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:31<00:00, 31.66s/it][A100%|██████████| 1/1 [00:31<00:00, 31.66s/it]
 98%|█████████▊| 5108/5198 [2:43:14<46:38, 31.09s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4790
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.40s/it][A100%|██████████| 1/1 [00:32<00:00, 32.40s/it]
 98%|█████████▊| 5109/5198 [2:43:58<46:44, 31.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:41:44,105] [INFO] [logging.py:96:log_dist] [Rank 0] step=5107, skipped=0, lr=[2.9742033481819075e-07], mom=[(0.9, 0.999)]
steps: 5107 loss: 1.5311 iter time (s): 31.835 samples/sec: 4.021

100%|██████████| 1/1 [00:32<00:00, 32.74s/it][A100%|██████████| 1/1 [00:32<00:00, 32.74s/it]
 98%|█████████▊| 5109/5198 [2:44:10<46:48, 31.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.55s/it][A100%|██████████| 1/1 [00:32<00:00, 32.55s/it]
 98%|█████████▊| 5109/5198 [2:44:08<46:46, 31.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.55s/it][A100%|██████████| 1/1 [00:32<00:00, 32.55s/it]
 98%|█████████▊| 5109/5198 [2:44:00<46:47, 31.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.59s/it][A100%|██████████| 1/1 [00:32<00:00, 32.59s/it]
 98%|█████████▊| 5109/5198 [2:44:03<46:47, 31.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.56s/it][A100%|██████████| 1/1 [00:32<00:00, 32.56s/it]
 98%|█████████▊| 5109/5198 [2:43:42<46:46, 31.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.60s/it][A100%|██████████| 1/1 [00:32<00:00, 32.60s/it]
 98%|█████████▊| 5109/5198 [2:43:56<46:47, 31.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:32<00:00, 32.57s/it][A100%|██████████| 1/1 [00:32<00:00, 32.57s/it]
 98%|█████████▊| 5109/5198 [2:43:46<46:46, 31.54s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4791
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.01s/it][A100%|██████████| 1/1 [00:36<00:00, 36.01s/it]
 98%|█████████▊| 5110/5198 [2:44:34<48:14, 32.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-09-02 01:42:20,398] [INFO] [logging.py:96:log_dist] [Rank 0] step=5108, skipped=0, lr=[2.9646051360887206e-07], mom=[(0.9, 0.999)]
steps: 5108 loss: 1.4135 iter time (s): 35.548 samples/sec: 3.601

100%|██████████| 1/1 [00:36<00:00, 36.33s/it][A100%|██████████| 1/1 [00:36<00:00, 36.33s/it]
 98%|█████████▊| 5110/5198 [2:44:46<48:23, 32.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.39s/it][A100%|██████████| 1/1 [00:36<00:00, 36.39s/it]
 98%|█████████▊| 5110/5198 [2:44:44<48:23, 32.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.34s/it][A100%|██████████| 1/1 [00:36<00:00, 36.34s/it]
 98%|█████████▊| 5110/5198 [2:44:36<48:22, 32.99s/it]
100%|██████████| 1/1 [00:36<00:00, 36.32s/it][A100%|██████████| 1/1 [00:36<00:00, 36.32s/it]
 98%|█████████▊| 5110/5198 [2:44:39<48:21, 32.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.33s/it][A100%|██████████| 1/1 [00:36<00:00, 36.33s/it]
 98%|█████████▊| 5110/5198 [2:44:33<48:22, 32.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.38s/it][A100%|██████████| 1/1 [00:36<00:00, 36.38s/it]
 98%|█████████▊| 5110/5198 [2:44:18<48:23, 32.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.36s/it][A100%|██████████| 1/1 [00:36<00:00, 36.36s/it]
 98%|█████████▊| 5110/5198 [2:44:23<48:22, 32.99s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4792
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A