[2024-05-29 21:50:40,335] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-29 21:50:44,462] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2024-05-29 21:50:44,462] [INFO] [runner.py:568:main] cmd = /home/hpc/b207dd/b207dd11/miniconda3/envs/py38/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None llava/train_parallel_deepspeed_mixtral_lora.py --num_stages=8 --lora_r=128 --lora_alpha=256 --save_model_shard=5 --skip_shard=40 --checkpoint_dir=/home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint
[2024-05-29 21:50:48,230] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-29 21:50:50,002] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]}
[2024-05-29 21:50:50,002] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=8, node_rank=0
[2024-05-29 21:50:50,002] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]})
[2024-05-29 21:50:50,002] [INFO] [launch.py:163:main] dist_world_size=8
[2024-05-29 21:50:50,002] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
[2024-05-29 21:50:50,017] [INFO] [launch.py:253:main] process 746893 spawned with command: ['/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/bin/python', '-u', 'llava/train_parallel_deepspeed_mixtral_lora.py', '--local_rank=0', '--num_stages=8', '--lora_r=128', '--lora_alpha=256', '--save_model_shard=5', '--skip_shard=40', '--checkpoint_dir=/home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint']
[2024-05-29 21:50:50,028] [INFO] [launch.py:253:main] process 746894 spawned with command: ['/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/bin/python', '-u', 'llava/train_parallel_deepspeed_mixtral_lora.py', '--local_rank=1', '--num_stages=8', '--lora_r=128', '--lora_alpha=256', '--save_model_shard=5', '--skip_shard=40', '--checkpoint_dir=/home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint']
[2024-05-29 21:50:50,039] [INFO] [launch.py:253:main] process 746895 spawned with command: ['/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/bin/python', '-u', 'llava/train_parallel_deepspeed_mixtral_lora.py', '--local_rank=2', '--num_stages=8', '--lora_r=128', '--lora_alpha=256', '--save_model_shard=5', '--skip_shard=40', '--checkpoint_dir=/home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint']
[2024-05-29 21:50:50,051] [INFO] [launch.py:253:main] process 746896 spawned with command: ['/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/bin/python', '-u', 'llava/train_parallel_deepspeed_mixtral_lora.py', '--local_rank=3', '--num_stages=8', '--lora_r=128', '--lora_alpha=256', '--save_model_shard=5', '--skip_shard=40', '--checkpoint_dir=/home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint']
[2024-05-29 21:50:50,069] [INFO] [launch.py:253:main] process 746897 spawned with command: ['/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/bin/python', '-u', 'llava/train_parallel_deepspeed_mixtral_lora.py', '--local_rank=4', '--num_stages=8', '--lora_r=128', '--lora_alpha=256', '--save_model_shard=5', '--skip_shard=40', '--checkpoint_dir=/home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint']
[2024-05-29 21:50:50,085] [INFO] [launch.py:253:main] process 746898 spawned with command: ['/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/bin/python', '-u', 'llava/train_parallel_deepspeed_mixtral_lora.py', '--local_rank=5', '--num_stages=8', '--lora_r=128', '--lora_alpha=256', '--save_model_shard=5', '--skip_shard=40', '--checkpoint_dir=/home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint']
[2024-05-29 21:50:50,102] [INFO] [launch.py:253:main] process 746899 spawned with command: ['/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/bin/python', '-u', 'llava/train_parallel_deepspeed_mixtral_lora.py', '--local_rank=6', '--num_stages=8', '--lora_r=128', '--lora_alpha=256', '--save_model_shard=5', '--skip_shard=40', '--checkpoint_dir=/home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint']
[2024-05-29 21:50:50,119] [INFO] [launch.py:253:main] process 746900 spawned with command: ['/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/bin/python', '-u', 'llava/train_parallel_deepspeed_mixtral_lora.py', '--local_rank=7', '--num_stages=8', '--lora_r=128', '--lora_alpha=256', '--save_model_shard=5', '--skip_shard=40', '--checkpoint_dir=/home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint']
[2024-05-29 21:50:55,943] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-29 21:50:56,026] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-29 21:50:56,615] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-05-29 21:50:56,697] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-05-29 21:51:00,472] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-29 21:51:01,194] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-05-29 21:51:05,987] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-29 21:51:06,283] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-29 21:51:06,818] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-05-29 21:51:07,012] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-05-29 21:51:07,012] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
Loading checkpoint shards:   0%|          | 0/20 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/20 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/20 [00:00<?, ?it/s]Loading checkpoint shards:   5%|▌         | 1/20 [00:00<00:10,  1.83it/s]Loading checkpoint shards:   0%|          | 0/20 [00:00<?, ?it/s]Loading checkpoint shards:   5%|▌         | 1/20 [00:00<00:16,  1.18it/s]Loading checkpoint shards:   5%|▌         | 1/20 [00:01<00:19,  1.00s/it]Loading checkpoint shards:   5%|▌         | 1/20 [00:00<00:15,  1.24it/s]Loading checkpoint shards:  10%|█         | 2/20 [00:01<00:17,  1.05it/s]Loading checkpoint shards:  10%|█         | 2/20 [00:02<00:18,  1.03s/it]Loading checkpoint shards:  10%|█         | 2/20 [00:02<00:19,  1.11s/it]Loading checkpoint shards:  15%|█▌        | 3/20 [00:02<00:15,  1.12it/s]Loading checkpoint shards:  10%|█         | 2/20 [00:02<00:20,  1.11s/it]Loading checkpoint shards:  15%|█▌        | 3/20 [00:03<00:19,  1.13s/it]Loading checkpoint shards:  15%|█▌        | 3/20 [00:03<00:18,  1.08s/it]Loading checkpoint shards:  20%|██        | 4/20 [00:03<00:15,  1.05it/s]Loading checkpoint shards:  15%|█▌        | 3/20 [00:03<00:17,  1.02s/it]Loading checkpoint shards:  20%|██        | 4/20 [00:05<00:22,  1.41s/it]Loading checkpoint shards:  25%|██▌       | 5/20 [00:05<00:18,  1.25s/it]Loading checkpoint shards:  20%|██        | 4/20 [00:05<00:23,  1.45s/it]Loading checkpoint shards:  20%|██        | 4/20 [00:04<00:22,  1.39s/it]Loading checkpoint shards:  25%|██▌       | 5/20 [00:06<00:18,  1.25s/it]Loading checkpoint shards:  30%|███       | 6/20 [00:06<00:17,  1.22s/it]Loading checkpoint shards:  25%|██▌       | 5/20 [00:06<00:19,  1.29s/it]Loading checkpoint shards:  25%|██▌       | 5/20 [00:06<00:21,  1.41s/it]Loading checkpoint shards:  30%|███       | 6/20 [00:07<00:16,  1.19s/it]Loading checkpoint shards:  30%|███       | 6/20 [00:07<00:16,  1.19s/it]Loading checkpoint shards:  35%|███▌      | 7/20 [00:07<00:15,  1.16s/it]Loading checkpoint shards:  30%|███       | 6/20 [00:07<00:17,  1.25s/it]Loading checkpoint shards:  35%|███▌      | 7/20 [00:08<00:15,  1.16s/it]Loading checkpoint shards:  35%|███▌      | 7/20 [00:08<00:14,  1.11s/it]Loading checkpoint shards:  40%|████      | 8/20 [00:08<00:13,  1.15s/it]Loading checkpoint shards:  35%|███▌      | 7/20 [00:08<00:15,  1.21s/it]Loading checkpoint shards:  40%|████      | 8/20 [00:09<00:12,  1.07s/it]Loading checkpoint shards:  40%|████      | 8/20 [00:09<00:13,  1.14s/it]Loading checkpoint shards:  45%|████▌     | 9/20 [00:09<00:12,  1.10s/it]Loading checkpoint shards:  40%|████      | 8/20 [00:09<00:14,  1.22s/it]Loading checkpoint shards:  45%|████▌     | 9/20 [00:10<00:11,  1.08s/it]Loading checkpoint shards:  45%|████▌     | 9/20 [00:10<00:12,  1.11s/it]Loading checkpoint shards:  50%|█████     | 10/20 [00:10<00:10,  1.06s/it]Loading checkpoint shards:  45%|████▌     | 9/20 [00:10<00:12,  1.18s/it]Loading checkpoint shards:  50%|█████     | 10/20 [00:11<00:10,  1.07s/it]Loading checkpoint shards:  50%|█████     | 10/20 [00:11<00:11,  1.15s/it]Loading checkpoint shards:  55%|█████▌    | 11/20 [00:12<00:10,  1.15s/it][2024-05-29 21:51:22,587] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Loading checkpoint shards:  50%|█████     | 10/20 [00:11<00:11,  1.15s/it]Loading checkpoint shards:  55%|█████▌    | 11/20 [00:12<00:09,  1.04s/it]Loading checkpoint shards:  55%|█████▌    | 11/20 [00:13<00:11,  1.23s/it]Loading checkpoint shards:  60%|██████    | 12/20 [00:13<00:09,  1.21s/it]Loading checkpoint shards:  60%|██████    | 12/20 [00:13<00:08,  1.01s/it]Loading checkpoint shards:  55%|█████▌    | 11/20 [00:12<00:10,  1.12s/it][2024-05-29 21:51:24,387] [INFO] [comm.py:637:init_distributed] cdb=None
Loading checkpoint shards:  60%|██████    | 12/20 [00:14<00:09,  1.22s/it]Loading checkpoint shards:  65%|██████▌   | 13/20 [00:14<00:08,  1.21s/it]Loading checkpoint shards:  60%|██████    | 12/20 [00:14<00:08,  1.10s/it][2024-05-29 21:51:24,811] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Loading checkpoint shards:  65%|██████▌   | 13/20 [00:14<00:07,  1.04s/it][2024-05-29 21:51:25,574] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Loading checkpoint shards:  70%|███████   | 14/20 [00:15<00:07,  1.25s/it]Loading checkpoint shards:  65%|██████▌   | 13/20 [00:15<00:08,  1.16s/it]Loading checkpoint shards:  70%|███████   | 14/20 [00:15<00:06,  1.14s/it]Loading checkpoint shards:  65%|██████▌   | 13/20 [00:15<00:09,  1.34s/it][2024-05-29 21:51:27,157] [INFO] [comm.py:637:init_distributed] cdb=None
Loading checkpoint shards:  75%|███████▌  | 15/20 [00:17<00:06,  1.27s/it]Loading checkpoint shards:  70%|███████   | 14/20 [00:16<00:07,  1.22s/it][2024-05-29 21:51:27,587] [INFO] [comm.py:637:init_distributed] cdb=None
Loading checkpoint shards:  70%|███████   | 14/20 [00:17<00:08,  1.34s/it]Loading checkpoint shards:  75%|███████▌  | 15/20 [00:17<00:06,  1.29s/it]Loading checkpoint shards:  75%|███████▌  | 15/20 [00:18<00:06,  1.31s/it]Loading checkpoint shards:  80%|████████  | 16/20 [00:18<00:05,  1.36s/it]Loading checkpoint shards:   0%|          | 0/20 [00:00<?, ?it/s]Loading checkpoint shards:  75%|███████▌  | 15/20 [00:19<00:07,  1.50s/it]Loading checkpoint shards:  80%|████████  | 16/20 [00:19<00:06,  1.57s/it]Loading checkpoint shards:  80%|████████  | 16/20 [00:20<00:06,  1.51s/it]Loading checkpoint shards:   5%|▌         | 1/20 [00:01<00:31,  1.68s/it]Loading checkpoint shards:  85%|████████▌ | 17/20 [00:21<00:04,  1.60s/it]Loading checkpoint shards:  85%|████████▌ | 17/20 [00:21<00:04,  1.64s/it]Loading checkpoint shards:   0%|          | 0/20 [00:00<?, ?it/s]Loading checkpoint shards:  80%|████████  | 16/20 [00:21<00:07,  1.79s/it]Loading checkpoint shards:  85%|████████▌ | 17/20 [00:21<00:04,  1.50s/it]Loading checkpoint shards:  10%|█         | 2/20 [00:03<00:28,  1.58s/it]Loading checkpoint shards:   0%|          | 0/20 [00:00<?, ?it/s]Loading checkpoint shards:  90%|█████████ | 18/20 [00:22<00:03,  1.62s/it]Loading checkpoint shards:   0%|          | 0/20 [00:00<?, ?it/s]Loading checkpoint shards:   5%|▌         | 1/20 [00:01<00:29,  1.54s/it]Loading checkpoint shards:  90%|█████████ | 18/20 [00:23<00:03,  1.66s/it]Loading checkpoint shards:  85%|████████▌ | 17/20 [00:23<00:05,  1.92s/it]Loading checkpoint shards:  95%|█████████▌| 19/20 [00:24<00:01,  1.64s/it]Loading checkpoint shards:  90%|█████████ | 18/20 [00:23<00:03,  1.71s/it]Loading checkpoint shards:   5%|▌         | 1/20 [00:01<00:32,  1.70s/it]Loading checkpoint shards:   5%|▌         | 1/20 [00:02<00:46,  2.42s/it]Loading checkpoint shards:  15%|█▌        | 3/20 [00:05<00:34,  2.00s/it]Loading checkpoint shards:  95%|█████████▌| 19/20 [00:24<00:01,  1.68s/it]Loading checkpoint shards:  10%|█         | 2/20 [00:03<00:31,  1.74s/it]Loading checkpoint shards: 100%|██████████| 20/20 [00:25<00:00,  1.45s/it]Loading checkpoint shards: 100%|██████████| 20/20 [00:25<00:00,  1.27s/it]
Loading checkpoint shards:  90%|█████████ | 18/20 [00:25<00:04,  2.01s/it]Loading checkpoint shards:  95%|█████████▌| 19/20 [00:25<00:01,  1.75s/it]Loading checkpoint shards: 100%|██████████| 20/20 [00:26<00:00,  1.61s/it]Loading checkpoint shards: 100%|██████████| 20/20 [00:26<00:00,  1.31s/it]
Loading checkpoint shards: 100%|██████████| 20/20 [00:26<00:00,  1.34s/it]Loading checkpoint shards: 100%|██████████| 20/20 [00:26<00:00,  1.30s/it]
Loading checkpoint shards:  10%|█         | 2/20 [00:04<00:37,  2.10s/it]Loading checkpoint shards:  10%|█         | 2/20 [00:04<00:40,  2.25s/it]Loading checkpoint shards:  15%|█▌        | 3/20 [00:05<00:30,  1.79s/it]Loading checkpoint shards:  20%|██        | 4/20 [00:08<00:33,  2.12s/it]Loading checkpoint shards:  95%|█████████▌| 19/20 [00:28<00:02,  2.08s/it]Loading checkpoint shards: 100%|██████████| 20/20 [00:28<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 20/20 [00:28<00:00,  1.43s/it]
Loading checkpoint shards:  20%|██        | 4/20 [00:07<00:29,  1.83s/it]Loading checkpoint shards:  25%|██▌       | 5/20 [00:09<00:30,  2.00s/it]Loading checkpoint shards:  15%|█▌        | 3/20 [00:06<00:38,  2.25s/it]Loading checkpoint shards:  15%|█▌        | 3/20 [00:06<00:39,  2.30s/it]Loading checkpoint shards:  30%|███       | 6/20 [00:11<00:27,  1.99s/it]Loading checkpoint shards:  20%|██        | 4/20 [00:08<00:34,  2.15s/it]Loading checkpoint shards:  25%|██▌       | 5/20 [00:09<00:31,  2.11s/it]Print trainable params: 96485376 || all params: 47115384832 || trainable%: 0.20
Loading checkpoint shards:  20%|██        | 4/20 [00:09<00:40,  2.50s/it]Print trainable params: 96485376 || all params: 47115384832 || trainable%: 0.20
Print trainable params: 96485376 || all params: 47115384832 || trainable%: 0.20
Loading checkpoint shards:  35%|███▌      | 7/20 [00:13<00:26,  2.02s/it]Print trainable params: 96485376 || all params: 47115384832 || trainable%: 0.20
Loading checkpoint shards:  30%|███       | 6/20 [00:11<00:29,  2.11s/it]Loading checkpoint shards:  25%|██▌       | 5/20 [00:10<00:33,  2.23s/it]Loading checkpoint shards:  25%|██▌       | 5/20 [00:11<00:35,  2.34s/it]Loading checkpoint shards:  40%|████      | 8/20 [00:15<00:23,  1.93s/it]Loading checkpoint shards:  35%|███▌      | 7/20 [00:13<00:24,  1.86s/it]Loading checkpoint shards:  30%|███       | 6/20 [00:12<00:26,  1.92s/it]Loading checkpoint shards:  30%|███       | 6/20 [00:13<00:28,  2.07s/it]Loading checkpoint shards:  45%|████▌     | 9/20 [00:16<00:18,  1.72s/it]Loading checkpoint shards:  40%|████      | 8/20 [00:14<00:20,  1.69s/it]Loading checkpoint shards:  35%|███▌      | 7/20 [00:13<00:23,  1.78s/it]Loading checkpoint shards:  35%|███▌      | 7/20 [00:14<00:23,  1.81s/it]Loading checkpoint shards:  50%|█████     | 10/20 [00:17<00:15,  1.54s/it]Loading checkpoint shards:  45%|████▌     | 9/20 [00:15<00:17,  1.56s/it]Loading checkpoint shards:  40%|████      | 8/20 [00:14<00:19,  1.61s/it]Loading checkpoint shards:  55%|█████▌    | 11/20 [00:19<00:12,  1.43s/it]Loading checkpoint shards:  40%|████      | 8/20 [00:15<00:19,  1.67s/it]Loading checkpoint shards:  50%|█████     | 10/20 [00:16<00:14,  1.43s/it]Loading checkpoint shards:  45%|████▌     | 9/20 [00:15<00:15,  1.42s/it]Loading checkpoint shards:  45%|████▌     | 9/20 [00:17<00:16,  1.51s/it]Loading checkpoint shards:  60%|██████    | 12/20 [00:20<00:10,  1.37s/it]Loading checkpoint shards:  50%|█████     | 10/20 [00:16<00:12,  1.30s/it]Loading checkpoint shards:  55%|█████▌    | 11/20 [00:18<00:12,  1.40s/it]Loading checkpoint shards:  65%|██████▌   | 13/20 [00:21<00:09,  1.30s/it]Loading checkpoint shards:  50%|█████     | 10/20 [00:18<00:14,  1.44s/it]Rank 4 initialized with CUDA_MEM (60744794112, 84974239744)
Deepspeed engine initializing at --- RANK 4 --- ...
Loading checkpoint shards:  55%|█████▌    | 11/20 [00:18<00:11,  1.25s/it]Loading checkpoint shards:  60%|██████    | 12/20 [00:19<00:11,  1.39s/it]Loading checkpoint shards:  70%|███████   | 14/20 [00:22<00:07,  1.22s/it]Loading checkpoint shards:  60%|██████    | 12/20 [00:19<00:09,  1.17s/it]Loading checkpoint shards:  55%|█████▌    | 11/20 [00:19<00:12,  1.44s/it]Rank 7 initialized with CUDA_MEM (60218408960, 84974239744)
Deepspeed engine initializing at --- RANK 7 --- ...
Loading checkpoint shards:  65%|██████▌   | 13/20 [00:20<00:09,  1.31s/it]Loading checkpoint shards:  75%|███████▌  | 15/20 [00:23<00:05,  1.19s/it]Rank 5 initialized with CUDA_MEM (60744794112, 84974239744)
Deepspeed engine initializing at --- RANK 5 --- ...
Loading checkpoint shards:  65%|██████▌   | 13/20 [00:20<00:08,  1.20s/it]Loading checkpoint shards:  60%|██████    | 12/20 [00:21<00:11,  1.40s/it]Using /home/hpc/b207dd/b207dd11/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Loading checkpoint shards:  80%|████████  | 16/20 [00:24<00:04,  1.17s/it]Loading checkpoint shards:  70%|███████   | 14/20 [00:22<00:08,  1.38s/it]Loading checkpoint shards:  70%|███████   | 14/20 [00:21<00:07,  1.22s/it]Rank 1 initialized with CUDA_MEM (60744794112, 84974239744)
Deepspeed engine initializing at --- RANK 1 --- ...
Loading checkpoint shards:  65%|██████▌   | 13/20 [00:22<00:09,  1.42s/it]Loading checkpoint shards:  85%|████████▌ | 17/20 [00:25<00:03,  1.17s/it]Using /home/hpc/b207dd/b207dd11/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Loading checkpoint shards:  75%|███████▌  | 15/20 [00:23<00:07,  1.45s/it]Using /home/hpc/b207dd/b207dd11/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Loading checkpoint shards:  75%|███████▌  | 15/20 [00:23<00:06,  1.30s/it]Detected CUDA files, patching ldflags
Emitting ninja build file /home/hpc/b207dd/b207dd11/.cache/torch_extensions/py38_cu121/fused_adam/build.ninja...
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading checkpoint shards:  90%|█████████ | 18/20 [00:27<00:02,  1.21s/it]Loading checkpoint shards:  70%|███████   | 14/20 [00:24<00:08,  1.45s/it]Using /home/hpc/b207dd/b207dd11/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Loading checkpoint shards:  80%|████████  | 16/20 [00:24<00:05,  1.29s/it]Loading checkpoint shards:  80%|████████  | 16/20 [00:25<00:05,  1.50s/it]Loading checkpoint shards:  95%|█████████▌| 19/20 [00:28<00:01,  1.23s/it]Loading checkpoint shards:  75%|███████▌  | 15/20 [00:25<00:07,  1.41s/it]ninja: no work to do.
Loading extension module fused_adam...
Time to load fused_adam op: 4.406257629394531 seconds
Loading extension module fused_adam...
[2024-05-29 21:51:58,185] [INFO] [engine.py:141:__init__] is_pipe_partitioned= False is_grad_partitioned= False
Time to load fused_adam op: 0.8114399909973145 seconds
[2024-05-29 21:51:58,189] [INFO] [engine.py:141:__init__] is_pipe_partitioned= False is_grad_partitioned= False
Loading extension module fused_adam...
Time to load fused_adam op: 2.1126997470855713 seconds
[2024-05-29 21:51:58,211] [INFO] [engine.py:141:__init__] is_pipe_partitioned= False is_grad_partitioned= False
Loading extension module fused_adam...
Time to load fused_adam op: 2.8138558864593506 seconds
[2024-05-29 21:51:58,231] [INFO] [engine.py:141:__init__] is_pipe_partitioned= False is_grad_partitioned= False
Loading checkpoint shards: 100%|██████████| 20/20 [00:29<00:00,  1.02s/it]Loading checkpoint shards: 100%|██████████| 20/20 [00:29<00:00,  1.45s/it]
Loading checkpoint shards:  85%|████████▌ | 17/20 [00:25<00:03,  1.27s/it]Loading checkpoint shards:  85%|████████▌ | 17/20 [00:27<00:04,  1.50s/it]Loading checkpoint shards:  80%|████████  | 16/20 [00:27<00:05,  1.49s/it]Loading checkpoint shards:  90%|█████████ | 18/20 [00:26<00:02,  1.25s/it]Loading checkpoint shards:  90%|█████████ | 18/20 [00:28<00:02,  1.49s/it]Loading checkpoint shards:  95%|█████████▌| 19/20 [00:28<00:01,  1.26s/it]Loading checkpoint shards:  85%|████████▌ | 17/20 [00:28<00:04,  1.53s/it]Print trainable params: 96485376 || all params: 47115384832 || trainable%: 0.20
Loading checkpoint shards: 100%|██████████| 20/20 [00:28<00:00,  1.12s/it]Loading checkpoint shards: 100%|██████████| 20/20 [00:28<00:00,  1.45s/it]
Loading checkpoint shards:  95%|█████████▌| 19/20 [00:30<00:01,  1.52s/it]Loading checkpoint shards: 100%|██████████| 20/20 [00:30<00:00,  1.18s/it]Loading checkpoint shards: 100%|██████████| 20/20 [00:30<00:00,  1.52s/it]
Loading checkpoint shards:  90%|█████████ | 18/20 [00:29<00:02,  1.44s/it]Loading checkpoint shards:  95%|█████████▌| 19/20 [00:31<00:01,  1.36s/it]Loading checkpoint shards: 100%|██████████| 20/20 [00:31<00:00,  1.06s/it]Loading checkpoint shards: 100%|██████████| 20/20 [00:31<00:00,  1.57s/it]
Print trainable params: 96485376 || all params: 47115384832 || trainable%: 0.20
Print trainable params: 96485376 || all params: 47115384832 || trainable%: 0.20
SEED_LAYERS=False BASE_SEED=1234 SEED_FN=None
Using topology: {ProcessCoord(pipe=0, data=0): 0, ProcessCoord(pipe=1, data=0): 1, ProcessCoord(pipe=2, data=0): 2, ProcessCoord(pipe=3, data=0): 3, ProcessCoord(pipe=4, data=0): 4, ProcessCoord(pipe=5, data=0): 5, ProcessCoord(pipe=6, data=0): 6, ProcessCoord(pipe=7, data=0): 7}
[2024-05-29 21:52:04,268] [INFO] [module.py:375:_partition_layers] Partitioning pipeline stages with method type:LanguageModelLayerWrapper
stage=0 layers=2
     0: LlavaMultiModalModuleWrapper
     1: LanguageModelLayerWrapper
stage=1 layers=1
     2: LanguageModelLayerWrapper
stage=2 layers=1
     3: LanguageModelLayerWrapper
stage=3 layers=1
     4: LanguageModelLayerWrapper
stage=4 layers=1
     5: LanguageModelLayerWrapper
stage=5 layers=1
     6: LanguageModelLayerWrapper
stage=6 layers=1
     7: LanguageModelLayerWrapper
stage=7 layers=2
     8: LanguageModelLayerWrapper
     9: LanguageModelFinalWrapper
  loss: loss_fn
Rank 3 initialized with CUDA_MEM (60744794112, 84974239744)
Deepspeed engine initializing at --- RANK 3 --- ...
Print trainable params: 96485376 || all params: 47115384832 || trainable%: 0.20
Using /home/hpc/b207dd/b207dd11/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Rank 6 initialized with CUDA_MEM (60744794112, 84974239744)
Deepspeed engine initializing at --- RANK 6 --- ...
Rank 2 initialized with CUDA_MEM (60744794112, 84974239744)
Deepspeed engine initializing at --- RANK 2 --- ...
Rank 0 initialized with CUDA_MEM (58783956992, 84974239744)
Deepspeed engine initializing at --- RANK 0 --- ...
[2024-05-29 21:52:09,138] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown
Using /home/hpc/b207dd/b207dd11/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/hpc/b207dd/b207dd11/.cache/torch_extensions/py38_cu121/fused_adam/build.ninja...
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[2024-05-29 21:52:09,454] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
Using /home/hpc/b207dd/b207dd11/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
ninja: no work to do.
Loading extension module fused_adam...
Time to load fused_adam op: 4.227689027786255 seconds
[2024-05-29 21:52:10,327] [INFO] [engine.py:141:__init__] is_pipe_partitioned= False is_grad_partitioned= False
Loading extension module fused_adam...
Time to load fused_adam op: 1.2067921161651611 seconds
[2024-05-29 21:52:10,359] [INFO] [engine.py:141:__init__] is_pipe_partitioned= False is_grad_partitioned= False
Loading extension module fused_adam...
Time to load fused_adam op: 0.6048793792724609 seconds
[2024-05-29 21:52:10,418] [INFO] [engine.py:141:__init__] is_pipe_partitioned= False is_grad_partitioned= False
Using /home/hpc/b207dd/b207dd11/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/hpc/b207dd/b207dd11/.cache/torch_extensions/py38_cu121/fused_adam/build.ninja...
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module fused_adam...
Time to load fused_adam op: 7.004414081573486 seconds
[2024-05-29 21:52:17,814] [INFO] [logging.py:96:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adam as basic optimizer
[2024-05-29 21:52:17,814] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-05-29 21:52:17,824] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
[2024-05-29 21:52:17,824] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = adam
[2024-05-29 21:52:17,824] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = WarmupCosineLR
[2024-05-29 21:52:17,824] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupCosineLR object at 0x1495980b9d90>
[2024-05-29 21:52:17,824] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2024-05-29 21:52:17,825] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-05-29 21:52:17,825] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-05-29 21:52:17,825] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-05-29 21:52:17,825] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-05-29 21:52:17,825] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-05-29 21:52:17,826] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-05-29 21:52:17,826] [INFO] [config.py:1000:print]   bfloat16_enabled ............. False
[2024-05-29 21:52:17,826] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-05-29 21:52:17,826] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-05-29 21:52:17,826] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-05-29 21:52:17,826] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-05-29 21:52:17,826] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1495980b98e0>
[2024-05-29 21:52:17,826] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-05-29 21:52:17,826] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-05-29 21:52:17,826] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-05-29 21:52:17,826] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-05-29 21:52:17,826] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-05-29 21:52:17,826] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-05-29 21:52:17,826] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-05-29 21:52:17,826] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-05-29 21:52:17,826] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-05-29 21:52:17,826] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-05-29 21:52:17,826] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-05-29 21:52:17,826] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-05-29 21:52:17,826] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-05-29 21:52:17,826] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-05-29 21:52:17,826] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-05-29 21:52:17,826] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-05-29 21:52:17,826] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-05-29 21:52:17,826] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-05-29 21:52:17,826] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-05-29 21:52:17,826] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-05-29 21:52:17,826] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-05-29 21:52:17,826] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-05-29 21:52:17,826] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-05-29 21:52:17,826] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-05-29 21:52:17,826] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-05-29 21:52:17,826] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-05-29 21:52:17,826] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 128
[2024-05-29 21:52:17,826] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2024-05-29 21:52:17,827] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-05-29 21:52:17,827] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-05-29 21:52:17,827] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-05-29 21:52:17,827] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 65536
[2024-05-29 21:52:17,827] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-05-29 21:52:17,827] [INFO] [config.py:1000:print]   loss_scale ................... 0
[2024-05-29 21:52:17,827] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-05-29 21:52:17,827] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-05-29 21:52:17,827] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-05-29 21:52:17,827] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=True, output_path='/home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint', job_name='deepspeed_monitor_logs') enabled=True
[2024-05-29 21:52:17,827] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-05-29 21:52:17,827] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-05-29 21:52:17,827] [INFO] [config.py:1000:print]   optimizer_name ............... adam
[2024-05-29 21:52:17,827] [INFO] [config.py:1000:print]   optimizer_params ............. {'lr': 2e-05}
[2024-05-29 21:52:17,827] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True, 'use_reentrant': False}
[2024-05-29 21:52:17,827] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-05-29 21:52:17,827] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-05-29 21:52:17,827] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-05-29 21:52:17,827] [INFO] [config.py:1000:print]   scheduler_name ............... WarmupCosineLR
[2024-05-29 21:52:17,827] [INFO] [config.py:1000:print]   scheduler_params ............. {'total_num_steps': 5718, 'warmup_min_ratio': 0.1, 'warmup_num_steps': 171.54}
[2024-05-29 21:52:17,827] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-05-29 21:52:17,827] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-05-29 21:52:17,827] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-05-29 21:52:17,827] [INFO] [config.py:1000:print]   steps_per_print .............. 1
[2024-05-29 21:52:17,827] [INFO] [config.py:1000:print]   train_batch_size ............. 128
[2024-05-29 21:52:17,827] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  1
[2024-05-29 21:52:17,827] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-05-29 21:52:17,827] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-05-29 21:52:17,827] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2024-05-29 21:52:17,827] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-05-29 21:52:17,827] [INFO] [config.py:1000:print]   world_size ................... 1
[2024-05-29 21:52:17,827] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  False
[2024-05-29 21:52:17,827] [INFO] [config.py:1000:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-05-29 21:52:17,827] [INFO] [config.py:1000:print]   zero_enabled ................. False
[2024-05-29 21:52:17,827] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2024-05-29 21:52:17,827] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 0
[2024-05-29 21:52:17,827] [INFO] [config.py:986:print_user_config]   json = {
    "train_batch_size": 128, 
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 128, 
    "steps_per_print": 1, 
    "optimizer": {
        "type": "Adam", 
        "params": {
            "lr": 2e-05
        }
    }, 
    "scheduler": {
        "type": "WarmupCosineLR", 
        "params": {
            "total_num_steps": 5.718000e+03, 
            "warmup_min_ratio": 0.1, 
            "warmup_num_steps": 171.54
        }
    }, 
    "pipeline": {
        "use_reentrant": false
    }, 
    "csv_monitor": {
        "enabled": true, 
        "output_path": "/home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint", 
        "job_name": "deepspeed_monitor_logs"
    }
}
[2024-05-29 21:52:17,827] [INFO] [engine.py:101:__init__] CONFIG: micro_batches=128 micro_batch_size=1
[2024-05-29 21:52:17,827] [INFO] [engine.py:141:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[2024-05-29 21:52:22,523] [INFO] [engine.py:160:__init__] RANK=6 STAGE=6 LAYERS=1 [7, 8) STAGE_PARAMS=6815744 (6.816M) TOTAL_PARAMS=96485376 (96.485M) UNIQUE_PARAMS=96485376 (96.485M)
[2024-05-29 21:52:22,523] [INFO] [engine.py:160:__init__] RANK=4 STAGE=4 LAYERS=1 [5, 6) STAGE_PARAMS=6815744 (6.816M) TOTAL_PARAMS=96485376 (96.485M) UNIQUE_PARAMS=96485376 (96.485M)
[2024-05-29 21:52:22,523] [INFO] [engine.py:160:__init__] RANK=0 STAGE=0 LAYERS=2 [0, 2) STAGE_PARAMS=48775168 (48.775M) TOTAL_PARAMS=96485376 (96.485M) UNIQUE_PARAMS=96485376 (96.485M)
[2024-05-29 21:52:22,523] [INFO] [engine.py:160:__init__] RANK=5 STAGE=5 LAYERS=1 [6, 7) STAGE_PARAMS=6815744 (6.816M) TOTAL_PARAMS=96485376 (96.485M) UNIQUE_PARAMS=96485376 (96.485M)
[2024-05-29 21:52:22,523] [INFO] [engine.py:160:__init__] RANK=1 STAGE=1 LAYERS=1 [2, 3) STAGE_PARAMS=6815744 (6.816M) TOTAL_PARAMS=96485376 (96.485M) UNIQUE_PARAMS=96485376 (96.485M)
[2024-05-29 21:52:22,523] [INFO] [engine.py:160:__init__] RANK=3 STAGE=3 LAYERS=1 [4, 5) STAGE_PARAMS=6815744 (6.816M) TOTAL_PARAMS=96485376 (96.485M) UNIQUE_PARAMS=96485376 (96.485M)
[2024-05-29 21:52:22,523] [INFO] [engine.py:160:__init__] RANK=7 STAGE=7 LAYERS=2 [8, 10) STAGE_PARAMS=6815744 (6.816M) TOTAL_PARAMS=96485376 (96.485M) UNIQUE_PARAMS=96485376 (96.485M)
[2024-05-29 21:52:22,523] [INFO] [engine.py:160:__init__] RANK=2 STAGE=2 LAYERS=1 [3, 4) STAGE_PARAMS=6815744 (6.816M) TOTAL_PARAMS=96485376 (96.485M) UNIQUE_PARAMS=96485376 (96.485M)
Deepspeed engine successfully initialized at --- RANK 0 --- hosting 24 of 136 trainable parameters
Loading latest model checkpoint at shard 40
[2024-05-29 21:52:25,184] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/mp_rank_00_model_states.pt...
[2024-05-29 21:52:25,301] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/mp_rank_00_model_states.pt.
[2024-05-29 21:52:25,302] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/mp_rank_00_model_states.pt...
[2024-05-29 21:52:25,390] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/mp_rank_00_model_states.pt.
[2024-05-29 21:52:25,391] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/layer_00-model_states.pt...
Deepspeed engine successfully initialized at --- RANK 7 --- hosting 16 of 136 trainable parameters
[2024-05-29 21:52:25,791] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/mp_rank_00_model_states.pt...
[2024-05-29 21:52:25,823] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/layer_00-model_states.pt.
[2024-05-29 21:52:25,825] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/layer_00-model_states.pt...
[2024-05-29 21:52:25,927] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/mp_rank_00_model_states.pt.
[2024-05-29 21:52:25,927] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/mp_rank_07_model_states.pt...
[2024-05-29 21:52:25,938] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/mp_rank_07_model_states.pt.
[2024-05-29 21:52:25,939] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/layer_08-model_states.pt...
[2024-05-29 21:52:26,064] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/layer_00-model_states.pt.
[2024-05-29 21:52:26,276] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/layer_01-model_states.pt...
Deepspeed engine successfully initialized at --- RANK 1 --- hosting 16 of 136 trainable parameters
Deepspeed engine successfully initialized at --- RANK 2 --- hosting 16 of 136 trainable parameters
[2024-05-29 21:52:27,266] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/mp_rank_00_model_states.pt...
[2024-05-29 21:52:27,267] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/mp_rank_00_model_states.pt...
Deepspeed engine successfully initialized at --- RANK 4 --- hosting 16 of 136 trainable parameters
Deepspeed engine successfully initialized at --- RANK 3 --- hosting 16 of 136 trainable parameters
[2024-05-29 21:52:27,373] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/mp_rank_00_model_states.pt...
[2024-05-29 21:52:27,373] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/mp_rank_00_model_states.pt...
[2024-05-29 21:52:27,386] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/mp_rank_00_model_states.pt.
[2024-05-29 21:52:27,387] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/mp_rank_02_model_states.pt...
[2024-05-29 21:52:27,403] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/mp_rank_02_model_states.pt.
[2024-05-29 21:52:27,404] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/layer_03-model_states.pt...
[2024-05-29 21:52:27,404] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/mp_rank_00_model_states.pt.
[2024-05-29 21:52:27,405] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/mp_rank_01_model_states.pt...
[2024-05-29 21:52:27,419] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/mp_rank_01_model_states.pt.
[2024-05-29 21:52:27,419] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/layer_02-model_states.pt...
[2024-05-29 21:52:27,469] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/mp_rank_00_model_states.pt.
[2024-05-29 21:52:27,469] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/mp_rank_04_model_states.pt...
[2024-05-29 21:52:27,481] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/mp_rank_04_model_states.pt.
[2024-05-29 21:52:27,481] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/layer_05-model_states.pt...
[2024-05-29 21:52:27,494] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/mp_rank_00_model_states.pt.
[2024-05-29 21:52:27,495] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/mp_rank_03_model_states.pt...
[2024-05-29 21:52:27,510] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/mp_rank_03_model_states.pt.
[2024-05-29 21:52:27,511] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/layer_04-model_states.pt...
Deepspeed engine successfully initialized at --- RANK 5 --- hosting 16 of 136 trainable parameters
Deepspeed engine successfully initialized at --- RANK 6 --- hosting 16 of 136 trainable parameters
[2024-05-29 21:52:27,523] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/mp_rank_00_model_states.pt...
[2024-05-29 21:52:27,523] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/mp_rank_00_model_states.pt...
[2024-05-29 21:52:27,640] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/mp_rank_00_model_states.pt.
[2024-05-29 21:52:27,641] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/mp_rank_06_model_states.pt...
[2024-05-29 21:52:27,643] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/mp_rank_00_model_states.pt.
[2024-05-29 21:52:27,643] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/mp_rank_05_model_states.pt...
[2024-05-29 21:52:27,654] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/mp_rank_05_model_states.pt.
[2024-05-29 21:52:27,655] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/layer_06-model_states.pt...
[2024-05-29 21:52:27,656] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/mp_rank_06_model_states.pt.
[2024-05-29 21:52:27,656] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/layer_07-model_states.pt...
[2024-05-29 21:52:35,543] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/layer_02-model_states.pt.
[2024-05-29 21:52:36,041] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/layer_02-model_states.pt...
[2024-05-29 21:52:36,925] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/layer_06-model_states.pt.
[2024-05-29 21:52:37,223] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/layer_06-model_states.pt...
[2024-05-29 21:52:37,562] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/layer_05-model_states.pt.
[2024-05-29 21:52:38,242] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/layer_05-model_states.pt...
[2024-05-29 21:52:43,056] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/layer_02-model_states.pt.
[2024-05-29 21:52:44,193] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/layer_06-model_states.pt.
  0%|          | 0/520 [00:00<?, ?it/s]
  0%|          | 0/10 [00:00<?, ?it/s][A[2024-05-29 21:52:46,119] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/layer_05-model_states.pt.
[2024-05-29 21:52:46,242] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/layer_08-model_states.pt.
[2024-05-29 21:52:46,928] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/layer_08-model_states.pt...
  0%|          | 0/520 [00:00<?, ?it/s]
  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/520 [00:00<?, ?it/s]
  0%|          | 0/10 [00:00<?, ?it/s][A[2024-05-29 21:52:52,736] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/layer_08-model_states.pt.
[2024-05-29 21:52:54,104] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/layer_09-model_states.pt...
[2024-05-29 21:52:54,279] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/layer_09-model_states.pt.
[2024-05-29 21:52:54,292] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/layer_09-model_states.pt...
[2024-05-29 21:52:54,465] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/layer_09-model_states.pt.
  0%|          | 0/520 [00:00<?, ?it/s]
  0%|          | 0/10 [00:00<?, ?it/s][A[2024-05-29 21:53:12,530] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/layer_07-model_states.pt.
[2024-05-29 21:53:13,350] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/layer_07-model_states.pt...
[2024-05-29 21:53:19,036] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/layer_03-model_states.pt.
[2024-05-29 21:53:19,608] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/layer_03-model_states.pt...
[2024-05-29 21:53:21,627] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/layer_07-model_states.pt.
  0%|          | 0/520 [00:00<?, ?it/s]
  0%|          | 0/10 [00:00<?, ?it/s][A[2024-05-29 21:53:26,606] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/layer_03-model_states.pt.
  0%|          | 0/520 [00:00<?, ?it/s]
  0%|          | 0/10 [00:00<?, ?it/s][A[2024-05-29 21:53:46,523] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/layer_04-model_states.pt.
[2024-05-29 21:53:46,968] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/layer_04-model_states.pt...
[2024-05-29 21:53:53,197] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/layer_04-model_states.pt.
  0%|          | 0/520 [00:00<?, ?it/s]
  0%|          | 0/10 [00:00<?, ?it/s][A[2024-05-29 21:54:51,202] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/layer_01-model_states.pt.
[2024-05-29 21:54:51,677] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/layer_01-model_states.pt...
[2024-05-29 21:54:58,832] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step400/layer_01-model_states.pt.
  0%|          | 0/520 [00:00<?, ?it/s]Shard 0 / 40 skipped
Shard 1 / 40 skipped
Shard 2 / 40 skipped
Shard 3 / 40 skipped
Shard 4 / 40 skipped
Shard 5 / 40 skipped
Shard 6 / 40 skipped
Shard 7 / 40 skipped
Shard 8 / 40 skipped
Shard 9 / 40 skipped
Shard 10 / 40 skipped
Shard 11 / 40 skipped
Shard 12 / 40 skipped
Shard 13 / 40 skipped
Shard 14 / 40 skipped
Shard 15 / 40 skipped
Shard 16 / 40 skipped
Shard 17 / 40 skipped
Shard 18 / 40 skipped
Shard 19 / 40 skipped
Shard 20 / 40 skipped
Shard 21 / 40 skipped
Shard 22 / 40 skipped
Shard 23 / 40 skipped
Shard 24 / 40 skipped
Shard 25 / 40 skipped
Shard 26 / 40 skipped
Shard 27 / 40 skipped
Shard 28 / 40 skipped
Shard 29 / 40 skipped
Shard 30 / 40 skipped
Shard 31 / 40 skipped
Shard 32 / 40 skipped
Shard 33 / 40 skipped
Shard 34 / 40 skipped
Shard 35 / 40 skipped
Shard 36 / 40 skipped
Shard 37 / 40 skipped
Shard 38 / 40 skipped
Shard 39 / 40 skipped
Shard 40 in [40]: file /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_184 skipped to avoid exceeding cuda memory
Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_218
Training on 1280 of 1280 sentences.

  0%|          | 0/10 [00:00<?, ?it/s][A[2024-05-29 21:56:00,149] [INFO] [logging.py:96:log_dist] [Rank 0] step=401, skipped=0, lr=[1.9915667087971767e-05], mom=[(0.9, 0.999)]
steps: 401 loss: 0.7874 iter time (s): 64.503 samples/sec: 1.984

 10%|█         | 1/10 [03:10<28:33, 190.42s/it][A
 10%|█         | 1/10 [02:40<24:08, 160.92s/it][A
 10%|█         | 1/10 [03:18<29:43, 198.12s/it][A
 10%|█         | 1/10 [03:17<29:36, 197.43s/it][A
 10%|█         | 1/10 [02:09<19:28, 129.80s/it][A
 10%|█         | 1/10 [02:36<23:27, 156.42s/it][A
 10%|█         | 1/10 [03:20<30:01, 200.13s/it][A
 10%|█         | 1/10 [01:05<09:45, 65.09s/it][A
 20%|██        | 2/10 [04:06<14:51, 111.38s/it][A[2024-05-29 21:57:02,394] [INFO] [logging.py:96:log_dist] [Rank 0] step=402, skipped=0, lr=[1.9914931477129762e-05], mom=[(0.9, 0.999)]
steps: 402 loss: 0.7585 iter time (s): 56.788 samples/sec: 2.254

 20%|██        | 2/10 [03:38<13:20, 100.02s/it][A
 20%|██        | 2/10 [04:15<15:22, 115.32s/it][A
 20%|██        | 2/10 [04:14<15:20, 115.01s/it][A
 20%|██        | 2/10 [03:07<11:37, 87.16s/it] [A
 20%|██        | 2/10 [03:33<13:05, 98.16s/it] [A
 20%|██        | 2/10 [04:17<15:29, 116.15s/it][A
 20%|██        | 2/10 [02:02<08:04, 60.55s/it][A
 30%|███       | 3/10 [05:03<10:05, 86.50s/it] [A[2024-05-29 21:57:59,279] [INFO] [logging.py:96:log_dist] [Rank 0] step=403, skipped=0, lr=[1.991419268565245e-05], mom=[(0.9, 0.999)]
steps: 403 loss: 0.7158 iter time (s): 56.257 samples/sec: 2.275

 30%|███       | 3/10 [04:35<09:21, 80.27s/it] [A
 30%|███       | 3/10 [05:12<10:20, 88.63s/it] [A
 30%|███       | 3/10 [05:11<10:19, 88.44s/it] [A
 30%|███       | 3/10 [04:04<08:33, 73.34s/it][A
 30%|███       | 3/10 [04:30<09:14, 79.28s/it][A
 30%|███       | 3/10 [05:14<10:23, 89.06s/it] [A
 30%|███       | 3/10 [02:59<06:51, 58.85s/it][A
 40%|████      | 4/10 [06:00<07:29, 74.84s/it][A[2024-05-29 21:58:56,260] [INFO] [logging.py:96:log_dist] [Rank 0] step=404, skipped=0, lr=[1.9913450713776848e-05], mom=[(0.9, 0.999)]
steps: 404 loss: 0.6341 iter time (s): 56.418 samples/sec: 2.269

 40%|████      | 4/10 [05:32<07:06, 71.09s/it][A
 40%|████      | 4/10 [06:09<07:36, 76.12s/it][A
 40%|████      | 4/10 [06:08<07:36, 76.03s/it][A
 40%|████      | 4/10 [05:27<07:02, 70.49s/it][A
 40%|████      | 4/10 [05:01<06:41, 66.91s/it][A
 40%|████      | 4/10 [03:56<05:48, 58.12s/it][A
 40%|████      | 4/10 [06:11<07:38, 76.41s/it][A
 50%|█████     | 5/10 [06:57<05:42, 68.46s/it][A[2024-05-29 21:59:53,404] [INFO] [logging.py:96:log_dist] [Rank 0] step=405, skipped=0, lr=[1.9912705561741002e-05], mom=[(0.9, 0.999)]
steps: 405 loss: 0.7337 iter time (s): 56.583 samples/sec: 2.262

 50%|█████     | 5/10 [06:29<05:30, 66.08s/it][A
 50%|█████     | 5/10 [07:06<05:46, 69.28s/it][A
 50%|█████     | 5/10 [07:05<05:46, 69.25s/it][A
 50%|█████     | 5/10 [05:58<05:16, 63.38s/it][A
 50%|█████     | 5/10 [06:24<05:28, 65.68s/it][A
 50%|█████     | 5/10 [07:08<05:47, 69.47s/it][A
 50%|█████     | 5/10 [04:53<04:48, 57.78s/it][A
 60%|██████    | 6/10 [07:53<04:16, 64.19s/it][A[2024-05-29 22:00:49,303] [INFO] [logging.py:96:log_dist] [Rank 0] step=406, skipped=0, lr=[1.9911957229783973e-05], mom=[(0.9, 0.999)]
steps: 406 loss: 0.6832 iter time (s): 55.283 samples/sec: 2.315

 60%|██████    | 6/10 [07:25<04:10, 62.62s/it][A
 60%|██████    | 6/10 [08:02<04:18, 64.74s/it][A
 60%|██████    | 6/10 [08:01<04:18, 64.68s/it][A
 60%|██████    | 6/10 [06:54<04:03, 60.85s/it][A
 60%|██████    | 6/10 [08:04<04:19, 64.85s/it][A
 60%|██████    | 6/10 [07:20<04:09, 62.37s/it][A
 60%|██████    | 6/10 [05:49<03:48, 57.14s/it][A
 70%|███████   | 7/10 [08:49<03:04, 61.55s/it][A[2024-05-29 22:01:45,421] [INFO] [logging.py:96:log_dist] [Rank 0] step=407, skipped=0, lr=[1.9911205718145846e-05], mom=[(0.9, 0.999)]
steps: 407 loss: 0.6146 iter time (s): 55.502 samples/sec: 2.306

 70%|███████   | 7/10 [08:58<03:05, 61.96s/it][A
 70%|███████   | 7/10 [08:21<03:01, 60.57s/it][A
 70%|███████   | 7/10 [08:57<03:05, 61.94s/it][A
 70%|███████   | 7/10 [07:50<02:57, 59.31s/it][A
 70%|███████   | 7/10 [09:00<03:06, 62.02s/it][A
 70%|███████   | 7/10 [06:45<02:50, 56.96s/it][A
 70%|███████   | 7/10 [08:17<03:01, 60.52s/it][A
 80%|████████  | 8/10 [09:46<02:00, 60.11s/it][A[2024-05-29 22:02:42,439] [INFO] [logging.py:96:log_dist] [Rank 0] step=408, skipped=0, lr=[1.991045102706772e-05], mom=[(0.9, 0.999)]
steps: 408 loss: 0.6385 iter time (s): 55.919 samples/sec: 2.289

 80%|████████  | 8/10 [09:18<01:58, 59.38s/it][A
 80%|████████  | 8/10 [09:55<02:00, 60.36s/it][A
 80%|████████  | 8/10 [09:54<02:00, 60.32s/it][A
 80%|████████  | 8/10 [09:13<01:58, 59.19s/it][A
 80%|████████  | 8/10 [08:47<01:57, 58.56s/it][A
 80%|████████  | 8/10 [09:57<02:00, 60.40s/it][A
 80%|████████  | 8/10 [07:42<01:53, 56.83s/it][A
 90%|█████████ | 9/10 [10:43<00:59, 59.04s/it][A[2024-05-29 22:03:39,132] [INFO] [logging.py:96:log_dist] [Rank 0] step=409, skipped=0, lr=[1.9909693156791736e-05], mom=[(0.9, 0.999)]
steps: 409 loss: 0.6417 iter time (s): 56.087 samples/sec: 2.282

 90%|█████████ | 9/10 [10:15<00:58, 58.53s/it][A
 90%|█████████ | 9/10 [10:52<00:59, 59.22s/it][A
 90%|█████████ | 9/10 [10:51<00:59, 59.18s/it][A
 90%|█████████ | 9/10 [09:43<00:57, 57.97s/it][A
 90%|█████████ | 9/10 [10:54<00:59, 59.25s/it][A
 90%|█████████ | 9/10 [10:10<00:58, 58.43s/it][A
 90%|█████████ | 9/10 [08:39<00:56, 56.78s/it][A
100%|██████████| 10/10 [11:39<00:00, 58.24s/it][A100%|██████████| 10/10 [11:39<00:00, 69.97s/it]
  8%|▊         | 42/520 [11:39<2:12:42, 16.66s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A[2024-05-29 22:04:35,582] [INFO] [logging.py:96:log_dist] [Rank 0] step=410, skipped=0, lr=[1.9908932107561017e-05], mom=[(0.9, 0.999)]
steps: 410 loss: 0.6866 iter time (s): 55.839 samples/sec: 2.292

100%|██████████| 10/10 [11:11<00:00, 57.87s/it][A100%|██████████| 10/10 [11:11<00:00, 67.14s/it]
  8%|▊         | 42/520 [11:11<2:07:21, 15.99s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [11:48<00:00, 58.35s/it][A100%|██████████| 10/10 [11:48<00:00, 70.87s/it]
  8%|▊         | 42/520 [11:48<2:14:25, 16.87s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [11:47<00:00, 58.35s/it][A100%|██████████| 10/10 [11:47<00:00, 70.79s/it]
  8%|▊         | 42/520 [11:47<2:14:16, 16.86s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [10:40<00:00, 57.50s/it][A100%|██████████| 10/10 [10:40<00:00, 64.03s/it]
  8%|▊         | 42/520 [10:40<2:01:27, 15.25s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [11:50<00:00, 58.38s/it][A100%|██████████| 10/10 [11:50<00:00, 71.07s/it]
  8%|▊         | 42/520 [11:50<2:14:48, 16.92s/it]
100%|██████████| 10/10 [11:07<00:00, 57.82s/it][A100%|██████████| 10/10 [11:07<00:00, 66.70s/it]
  8%|▊         | 42/520 [11:07<2:06:31, 15.88s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [09:35<00:00, 56.69s/it][A100%|██████████| 10/10 [09:35<00:00, 57.57s/it]
  8%|▊         | 42/520 [09:35<1:49:11, 13.71s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_267
Training on 1280 of 1280 sentences.

  0%|          | 0/10 [00:00<?, ?it/s][A
 10%|█         | 1/10 [01:20<12:08, 80.91s/it][A[2024-05-29 22:05:57,179] [INFO] [logging.py:96:log_dist] [Rank 0] step=411, skipped=0, lr=[1.9908167879619734e-05], mom=[(0.9, 0.999)]
steps: 411 loss: 0.4934 iter time (s): 80.921 samples/sec: 1.582

 10%|█         | 1/10 [01:21<12:15, 81.68s/it][A
 10%|█         | 1/10 [01:21<12:15, 81.73s/it][A
 10%|█         | 1/10 [01:21<12:15, 81.70s/it][A
 10%|█         | 1/10 [01:21<12:15, 81.73s/it][A
 10%|█         | 1/10 [01:21<12:15, 81.71s/it][A
 10%|█         | 1/10 [01:21<12:15, 81.76s/it][A
 10%|█         | 1/10 [01:21<12:15, 81.74s/it][A
 20%|██        | 2/10 [02:43<10:56, 82.00s/it][A[2024-05-29 22:07:19,954] [INFO] [logging.py:96:log_dist] [Rank 0] step=412, skipped=0, lr=[1.990740047321307e-05], mom=[(0.9, 0.999)]
steps: 412 loss: 0.5241 iter time (s): 82.016 samples/sec: 1.561

 20%|██        | 2/10 [02:44<10:58, 82.36s/it][A
 20%|██        | 2/10 [02:44<10:58, 82.32s/it][A
 20%|██        | 2/10 [02:44<10:58, 82.33s/it][A
 20%|██        | 2/10 [02:44<10:58, 82.35s/it][A
 20%|██        | 2/10 [02:44<10:58, 82.34s/it][A
 20%|██        | 2/10 [02:44<10:58, 82.37s/it][A
 20%|██        | 2/10 [02:44<10:58, 82.35s/it][A
 30%|███       | 3/10 [04:05<09:33, 81.89s/it][A[2024-05-29 22:08:41,712] [INFO] [logging.py:96:log_dist] [Rank 0] step=413, skipped=0, lr=[1.990662988858723e-05], mom=[(0.9, 0.999)]
steps: 413 loss: 0.4839 iter time (s): 80.996 samples/sec: 1.580

 30%|███       | 3/10 [04:06<09:34, 82.11s/it][A
 30%|███       | 3/10 [04:06<09:34, 82.11s/it][A
 30%|███       | 3/10 [04:06<09:34, 82.11s/it][A
 30%|███       | 3/10 [04:06<09:34, 82.13s/it][A
 30%|███       | 3/10 [04:06<09:34, 82.12s/it][A
 30%|███       | 3/10 [04:06<09:34, 82.14s/it][A
 30%|███       | 3/10 [04:06<09:34, 82.13s/it][A
 40%|████      | 4/10 [05:27<08:10, 81.81s/it][A[2024-05-29 22:10:03,414] [INFO] [logging.py:96:log_dist] [Rank 0] step=414, skipped=0, lr=[1.9905856125989437e-05], mom=[(0.9, 0.999)]
steps: 414 loss: 0.4979 iter time (s): 80.810 samples/sec: 1.584

 40%|████      | 4/10 [05:27<08:11, 81.92s/it][A
 40%|████      | 4/10 [05:27<08:11, 81.89s/it][A
 40%|████      | 4/10 [05:27<08:11, 81.92s/it][A
 40%|████      | 4/10 [05:27<08:11, 81.92s/it][A
 40%|████      | 4/10 [05:28<08:11, 81.94s/it][A
 40%|████      | 4/10 [05:28<08:11, 81.93s/it][A
 40%|████      | 4/10 [05:28<08:11, 81.93s/it][A
 50%|█████     | 5/10 [06:49<06:50, 82.02s/it][A[2024-05-29 22:11:25,786] [INFO] [logging.py:96:log_dist] [Rank 0] step=415, skipped=0, lr=[1.990507918566793e-05], mom=[(0.9, 0.999)]
steps: 415 loss: 0.4959 iter time (s): 81.577 samples/sec: 1.569

 50%|█████     | 5/10 [06:50<06:50, 82.10s/it][A
 50%|█████     | 5/10 [06:50<06:50, 82.10s/it][A
 50%|█████     | 5/10 [06:50<06:50, 82.10s/it][A
 50%|█████     | 5/10 [06:50<06:50, 82.11s/it][A
 50%|█████     | 5/10 [06:50<06:50, 82.11s/it][A
 50%|█████     | 5/10 [06:50<06:50, 82.11s/it][A
 50%|█████     | 5/10 [06:50<06:50, 82.11s/it][A
 60%|██████    | 6/10 [08:10<05:27, 81.81s/it][A[2024-05-29 22:12:47,214] [INFO] [logging.py:96:log_dist] [Rank 0] step=416, skipped=0, lr=[1.990429906787197e-05], mom=[(0.9, 0.999)]
steps: 416 loss: 0.5035 iter time (s): 80.582 samples/sec: 1.588

 60%|██████    | 6/10 [08:11<05:27, 81.87s/it][A
 60%|██████    | 6/10 [08:11<05:27, 81.85s/it][A
 60%|██████    | 6/10 [08:11<05:27, 81.87s/it][A
 60%|██████    | 6/10 [08:11<05:27, 81.87s/it][A
 60%|██████    | 6/10 [08:11<05:27, 81.85s/it][A
 60%|██████    | 6/10 [08:11<05:27, 81.85s/it][A
 60%|██████    | 6/10 [08:11<05:27, 81.86s/it][A
 70%|███████   | 7/10 [09:33<04:05, 81.92s/it][A[2024-05-29 22:14:09,334] [INFO] [logging.py:96:log_dist] [Rank 0] step=417, skipped=0, lr=[1.9903515772851843e-05], mom=[(0.9, 0.999)]
steps: 417 loss: 0.4995 iter time (s): 81.326 samples/sec: 1.574

 70%|███████   | 7/10 [09:33<04:05, 81.94s/it][A
 70%|███████   | 7/10 [09:33<04:05, 81.95s/it][A
 70%|███████   | 7/10 [09:33<04:05, 81.93s/it][A
 70%|███████   | 7/10 [09:33<04:05, 81.94s/it][A
 70%|███████   | 7/10 [09:33<04:05, 81.94s/it][A
 70%|███████   | 7/10 [09:33<04:05, 81.94s/it][A
 70%|███████   | 7/10 [09:33<04:05, 81.94s/it][A
 80%|████████  | 8/10 [10:53<02:42, 81.41s/it][A[2024-05-29 22:15:29,647] [INFO] [logging.py:96:log_dist] [Rank 0] step=418, skipped=0, lr=[1.9902729300858847e-05], mom=[(0.9, 0.999)]
steps: 418 loss: 0.4899 iter time (s): 79.561 samples/sec: 1.609

 80%|████████  | 8/10 [10:54<02:42, 81.42s/it][A
 80%|████████  | 8/10 [10:54<02:42, 81.44s/it][A
 80%|████████  | 8/10 [10:54<02:42, 81.42s/it][A
 80%|████████  | 8/10 [10:54<02:42, 81.45s/it][A
 80%|████████  | 8/10 [10:54<02:42, 81.45s/it][A
 80%|████████  | 8/10 [10:54<02:42, 81.45s/it][A
 80%|████████  | 8/10 [10:54<02:42, 81.45s/it][A
 90%|█████████ | 9/10 [12:13<01:20, 80.96s/it][A[2024-05-29 22:16:49,626] [INFO] [logging.py:96:log_dist] [Rank 0] step=419, skipped=0, lr=[1.9901939652145303e-05], mom=[(0.9, 0.999)]
steps: 419 loss: 0.4778 iter time (s): 79.106 samples/sec: 1.618

 90%|█████████ | 9/10 [12:14<01:20, 80.98s/it][A
 90%|█████████ | 9/10 [12:14<01:20, 80.96s/it][A
 90%|█████████ | 9/10 [12:14<01:20, 80.98s/it][A
 90%|█████████ | 9/10 [12:14<01:20, 80.96s/it][A
 90%|█████████ | 9/10 [12:14<01:20, 80.99s/it][A
 90%|█████████ | 9/10 [12:14<01:20, 80.98s/it][A
 90%|█████████ | 9/10 [12:14<01:20, 80.98s/it][A
100%|██████████| 10/10 [13:32<00:00, 80.39s/it][A100%|██████████| 10/10 [13:32<00:00, 81.25s/it]
  8%|▊         | 43/520 [25:12<5:40:32, 42.84s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A[2024-05-29 22:18:08,736] [INFO] [logging.py:96:log_dist] [Rank 0] step=420, skipped=0, lr=[1.9901146826964545e-05], mom=[(0.9, 0.999)]
steps: 420 loss: 0.5035 iter time (s): 78.269 samples/sec: 1.635

100%|██████████| 10/10 [13:33<00:00, 80.40s/it][A100%|██████████| 10/10 [13:33<00:00, 81.33s/it]
  8%|▊         | 43/520 [24:44<5:35:36, 42.21s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:33<00:00, 80.38s/it][A100%|██████████| 10/10 [13:33<00:00, 81.32s/it]
  8%|▊         | 43/520 [25:21<5:42:15, 43.05s/it]
100%|██████████| 10/10 [13:33<00:00, 80.41s/it][A100%|██████████| 10/10 [13:33<00:00, 81.33s/it]
  8%|▊         | 43/520 [25:22<5:42:25, 43.07s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:33<00:00, 80.37s/it][A100%|██████████| 10/10 [13:33<00:00, 81.33s/it]
  8%|▊         | 43/520 [24:13<5:29:54, 41.50s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:33<00:00, 80.38s/it][A100%|██████████| 10/10 [13:33<00:00, 81.33s/it]
  8%|▊         | 43/520 [24:40<5:34:47, 42.11s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:33<00:00, 80.40s/it][A100%|██████████| 10/10 [13:33<00:00, 81.34s/it]
  8%|▊         | 43/520 [25:24<5:42:48, 43.12s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:33<00:00, 80.39s/it][A100%|██████████| 10/10 [13:33<00:00, 81.33s/it]
  8%|▊         | 43/520 [23:09<5:18:04, 40.01s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_213
Training on 1280 of 1280 sentences.

  0%|          | 0/10 [00:00<?, ?it/s][A
 10%|█         | 1/10 [00:57<08:36, 57.37s/it][A[2024-05-29 22:19:05,279] [INFO] [logging.py:96:log_dist] [Rank 0] step=421, skipped=0, lr=[1.9900350825570938e-05], mom=[(0.9, 0.999)]
steps: 421 loss: 0.6328 iter time (s): 55.625 samples/sec: 2.301

 10%|█         | 1/10 [00:56<08:27, 56.34s/it][A
 10%|█         | 1/10 [00:56<08:26, 56.27s/it][A
 10%|█         | 1/10 [00:56<08:27, 56.35s/it][A
 10%|█         | 1/10 [00:56<08:26, 56.31s/it][A
 10%|█         | 1/10 [00:56<08:25, 56.22s/it][A
 10%|█         | 1/10 [00:56<08:26, 56.32s/it][A
 10%|█         | 1/10 [00:56<08:25, 56.22s/it][A
 20%|██        | 2/10 [01:53<07:31, 56.43s/it][A[2024-05-29 22:20:01,217] [INFO] [logging.py:96:log_dist] [Rank 0] step=422, skipped=0, lr=[1.989955164821985e-05], mom=[(0.9, 0.999)]
steps: 422 loss: 0.6042 iter time (s): 55.411 samples/sec: 2.310

 20%|██        | 2/10 [01:52<07:28, 56.12s/it][A
 20%|██        | 2/10 [01:52<07:28, 56.12s/it][A
 20%|██        | 2/10 [01:52<07:29, 56.14s/it][A
 20%|██        | 2/10 [01:52<07:28, 56.11s/it][A
 20%|██        | 2/10 [01:52<07:29, 56.16s/it][A
 20%|██        | 2/10 [01:52<07:28, 56.11s/it][A
 20%|██        | 2/10 [01:52<07:28, 56.10s/it][A
 30%|███       | 3/10 [02:48<06:30, 55.82s/it][A[2024-05-29 22:20:56,315] [INFO] [logging.py:96:log_dist] [Rank 0] step=423, skipped=0, lr=[1.989874929516769e-05], mom=[(0.9, 0.999)]
steps: 423 loss: 0.6175 iter time (s): 54.506 samples/sec: 2.348

 30%|███       | 3/10 [02:47<06:29, 55.67s/it][A
 30%|███       | 3/10 [02:47<06:29, 55.66s/it][A
 30%|███       | 3/10 [02:47<06:29, 55.69s/it][A
 30%|███       | 3/10 [02:47<06:29, 55.66s/it][A
 30%|███       | 3/10 [02:47<06:29, 55.66s/it][A
 30%|███       | 3/10 [02:47<06:29, 55.64s/it][A
 30%|███       | 3/10 [02:47<06:29, 55.64s/it][A
 40%|████      | 4/10 [03:42<05:31, 55.25s/it][A[2024-05-29 22:21:50,690] [INFO] [logging.py:96:log_dist] [Rank 0] step=424, skipped=0, lr=[1.9897943766671857e-05], mom=[(0.9, 0.999)]
steps: 424 loss: 0.6522 iter time (s): 53.768 samples/sec: 2.381

 40%|████      | 4/10 [03:41<05:30, 55.15s/it][A
 40%|████      | 4/10 [03:41<05:30, 55.14s/it][A
 40%|████      | 4/10 [03:41<05:30, 55.15s/it][A
 40%|████      | 4/10 [03:41<05:30, 55.14s/it][A
 40%|████      | 4/10 [03:41<05:30, 55.16s/it][A
 40%|████      | 4/10 [03:41<05:30, 55.14s/it][A
 40%|████      | 4/10 [03:41<05:30, 55.15s/it][A
 50%|█████     | 5/10 [04:37<04:35, 55.15s/it][A[2024-05-29 22:22:45,681] [INFO] [logging.py:96:log_dist] [Rank 0] step=425, skipped=0, lr=[1.9897135062990803e-05], mom=[(0.9, 0.999)]
steps: 425 loss: 0.6162 iter time (s): 54.417 samples/sec: 2.352

 50%|█████     | 5/10 [04:36<04:35, 55.12s/it][A
 50%|█████     | 5/10 [04:36<04:35, 55.14s/it][A
 50%|█████     | 5/10 [04:36<04:35, 55.10s/it][A
 50%|█████     | 5/10 [04:36<04:35, 55.15s/it][A
 50%|█████     | 5/10 [04:36<04:35, 55.15s/it][A
 50%|█████     | 5/10 [04:36<04:35, 55.16s/it][A
 50%|█████     | 5/10 [04:37<04:36, 55.23s/it][A
 60%|██████    | 6/10 [05:34<03:42, 55.65s/it][A[2024-05-29 22:23:42,271] [INFO] [logging.py:96:log_dist] [Rank 0] step=426, skipped=0, lr=[1.9896323184383962e-05], mom=[(0.9, 0.999)]
steps: 426 loss: 0.6277 iter time (s): 55.813 samples/sec: 2.293

 60%|██████    | 6/10 [05:33<03:42, 55.60s/it][A
 60%|██████    | 6/10 [05:33<03:42, 55.60s/it][A
 60%|██████    | 6/10 [05:33<03:42, 55.59s/it][A
 60%|██████    | 6/10 [05:33<03:42, 55.60s/it][A
 60%|██████    | 6/10 [05:33<03:42, 55.57s/it][A
 60%|██████    | 6/10 [05:33<03:42, 55.59s/it][A
 60%|██████    | 6/10 [05:33<03:42, 55.59s/it][A
 70%|███████   | 7/10 [06:29<02:46, 55.44s/it][A[2024-05-29 22:24:37,307] [INFO] [logging.py:96:log_dist] [Rank 0] step=427, skipped=0, lr=[1.9895508131111815e-05], mom=[(0.9, 0.999)]
steps: 427 loss: 0.6070 iter time (s): 54.404 samples/sec: 2.353

 70%|███████   | 7/10 [06:28<02:46, 55.39s/it][A
 70%|███████   | 7/10 [06:28<02:46, 55.40s/it][A
 70%|███████   | 7/10 [06:28<02:46, 55.42s/it][A
 70%|███████   | 7/10 [06:28<02:46, 55.40s/it][A
 70%|███████   | 7/10 [06:28<02:46, 55.39s/it][A
 70%|███████   | 7/10 [06:28<02:46, 55.39s/it][A
 70%|███████   | 7/10 [06:28<02:46, 55.39s/it][A
 80%|████████  | 8/10 [07:23<01:50, 55.11s/it][A[2024-05-29 22:25:31,709] [INFO] [logging.py:96:log_dist] [Rank 0] step=428, skipped=0, lr=[1.9894689903435852e-05], mom=[(0.9, 0.999)]
steps: 428 loss: 0.6522 iter time (s): 53.835 samples/sec: 2.378

 80%|████████  | 8/10 [07:22<01:50, 55.10s/it][A
 80%|████████  | 8/10 [07:22<01:50, 55.09s/it][A
 80%|████████  | 8/10 [07:22<01:50, 55.08s/it][A
 80%|████████  | 8/10 [07:22<01:50, 55.10s/it][A
 80%|████████  | 8/10 [07:22<01:50, 55.08s/it][A
 80%|████████  | 8/10 [07:22<01:50, 55.09s/it][A
 80%|████████  | 8/10 [07:22<01:50, 55.09s/it][A
 90%|█████████ | 9/10 [08:18<00:55, 55.13s/it][A[2024-05-29 22:26:26,885] [INFO] [logging.py:96:log_dist] [Rank 0] step=429, skipped=0, lr=[1.9893868501618575e-05], mom=[(0.9, 0.999)]
steps: 429 loss: 0.6390 iter time (s): 54.563 samples/sec: 2.346

 90%|█████████ | 9/10 [08:17<00:55, 55.12s/it][A
 90%|█████████ | 9/10 [08:17<00:55, 55.09s/it][A
 90%|█████████ | 9/10 [08:18<00:55, 55.11s/it][A
 90%|█████████ | 9/10 [08:17<00:55, 55.11s/it][A
 90%|█████████ | 9/10 [08:17<00:55, 55.10s/it][A
 90%|█████████ | 9/10 [08:17<00:55, 55.11s/it][A
 90%|█████████ | 9/10 [08:17<00:55, 55.10s/it][A
100%|██████████| 10/10 [09:13<00:00, 55.06s/it][A100%|██████████| 10/10 [09:13<00:00, 55.37s/it]
  8%|▊         | 44/520 [34:25<8:41:44, 65.77s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A[2024-05-29 22:27:21,755] [INFO] [logging.py:96:log_dist] [Rank 0] step=430, skipped=0, lr=[1.989304392592351e-05], mom=[(0.9, 0.999)]
steps: 430 loss: 0.6498 iter time (s): 54.301 samples/sec: 2.357

100%|██████████| 10/10 [09:12<00:00, 55.03s/it][A100%|██████████| 10/10 [09:12<00:00, 55.28s/it]
  8%|▊         | 44/520 [33:57<8:36:43, 65.13s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [09:12<00:00, 55.04s/it][A100%|██████████| 10/10 [09:12<00:00, 55.28s/it]
  8%|▊         | 44/520 [34:34<8:43:12, 65.95s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [09:12<00:00, 55.04s/it][A100%|██████████| 10/10 [09:12<00:00, 55.29s/it]
  8%|▊         | 44/520 [34:34<8:43:05, 65.94s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [09:12<00:00, 55.03s/it][A100%|██████████| 10/10 [09:12<00:00, 55.28s/it]
  8%|▊         | 44/520 [33:53<8:35:56, 65.04s/it]
100%|██████████| 10/10 [09:12<00:00, 55.06s/it][A100%|██████████| 10/10 [09:12<00:00, 55.29s/it]
  8%|▊         | 44/520 [33:26<8:31:19, 64.45s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [09:12<00:00, 55.04s/it][A100%|██████████| 10/10 [09:12<00:00, 55.28s/it]
  8%|▊         | 44/520 [34:36<8:43:34, 66.00s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [09:12<00:00, 55.05s/it][A100%|██████████| 10/10 [09:12<00:00, 55.28s/it]
  8%|▊         | 44/520 [32:21<8:20:00, 63.03s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_164
Training on 1280 of 1280 sentences.

  0%|          | 0/10 [00:00<?, ?it/s][A
 10%|█         | 1/10 [02:08<19:17, 128.66s/it][A[2024-05-29 22:29:32,515] [INFO] [logging.py:96:log_dist] [Rank 0] step=431, skipped=0, lr=[1.989221617661521e-05], mom=[(0.9, 0.999)]
steps: 431 loss: 0.6310 iter time (s): 130.072 samples/sec: 0.984

 10%|█         | 1/10 [02:10<19:37, 130.81s/it][A
 10%|█         | 1/10 [02:10<19:37, 130.80s/it][A
 10%|█         | 1/10 [02:10<19:37, 130.78s/it][A
 10%|█         | 1/10 [02:10<19:38, 130.91s/it][A
 10%|█         | 1/10 [02:10<19:37, 130.88s/it][A
 10%|█         | 1/10 [02:10<19:37, 130.85s/it][A
 10%|█         | 1/10 [02:10<19:37, 130.85s/it][A
 20%|██        | 2/10 [04:19<17:19, 129.95s/it][A[2024-05-29 22:31:43,374] [INFO] [logging.py:96:log_dist] [Rank 0] step=432, skipped=0, lr=[1.989138525395923e-05], mom=[(0.9, 0.999)]
steps: 432 loss: 0.6184 iter time (s): 130.159 samples/sec: 0.983

 20%|██        | 2/10 [04:21<17:26, 130.83s/it][A
 20%|██        | 2/10 [04:21<17:26, 130.85s/it][A
 20%|██        | 2/10 [04:21<17:26, 130.84s/it][A
 20%|██        | 2/10 [04:21<17:27, 130.90s/it][A
 20%|██        | 2/10 [04:21<17:26, 130.86s/it][A
 20%|██        | 2/10 [04:21<17:27, 130.88s/it][A
 20%|██        | 2/10 [04:21<17:26, 130.87s/it][A
 30%|███       | 3/10 [06:30<15:13, 130.45s/it][A[2024-05-29 22:33:54,422] [INFO] [logging.py:96:log_dist] [Rank 0] step=433, skipped=0, lr=[1.989055115822215e-05], mom=[(0.9, 0.999)]
steps: 433 loss: 0.6166 iter time (s): 130.377 samples/sec: 0.982

 30%|███       | 3/10 [06:32<15:16, 130.97s/it][A
 30%|███       | 3/10 [06:32<15:16, 130.96s/it][A
 30%|███       | 3/10 [06:32<15:16, 130.92s/it][A
 30%|███       | 3/10 [06:32<15:16, 130.95s/it][A
 30%|███       | 3/10 [06:32<15:16, 130.95s/it][A
 30%|███       | 3/10 [06:32<15:16, 130.96s/it][A
 30%|███       | 3/10 [06:32<15:16, 130.95s/it][A
 40%|████      | 4/10 [08:41<13:03, 130.53s/it][A[2024-05-29 22:36:05,070] [INFO] [logging.py:96:log_dist] [Rank 0] step=434, skipped=0, lr=[1.9889713889671575e-05], mom=[(0.9, 0.999)]
steps: 434 loss: 0.6053 iter time (s): 129.937 samples/sec: 0.985

 40%|████      | 4/10 [08:43<13:04, 130.81s/it][A
 40%|████      | 4/10 [08:43<13:04, 130.82s/it][A
 40%|████      | 4/10 [08:43<13:04, 130.81s/it][A
 40%|████      | 4/10 [08:43<13:04, 130.81s/it][A
 40%|████      | 4/10 [08:43<13:04, 130.81s/it][A
 40%|████      | 4/10 [08:43<13:04, 130.81s/it][A
 40%|████      | 4/10 [08:43<13:04, 130.81s/it][A
 50%|█████     | 5/10 [10:51<10:52, 130.56s/it][A[2024-05-29 22:38:15,687] [INFO] [logging.py:96:log_dist] [Rank 0] step=435, skipped=0, lr=[1.9888873448576114e-05], mom=[(0.9, 0.999)]
steps: 435 loss: 0.6002 iter time (s): 129.943 samples/sec: 0.985

 50%|█████     | 5/10 [10:53<10:53, 130.74s/it][A
 50%|█████     | 5/10 [10:54<10:53, 130.75s/it][A
 50%|█████     | 5/10 [10:54<10:53, 130.73s/it][A
 50%|█████     | 5/10 [10:53<10:53, 130.74s/it][A
 50%|█████     | 5/10 [10:53<10:53, 130.73s/it][A
 50%|█████     | 5/10 [10:53<10:53, 130.74s/it][A
 50%|█████     | 5/10 [10:53<10:53, 130.74s/it][A
 60%|██████    | 6/10 [13:02<08:42, 130.64s/it][A[2024-05-29 22:40:26,497] [INFO] [logging.py:96:log_dist] [Rank 0] step=436, skipped=0, lr=[1.988802983520541e-05], mom=[(0.9, 0.999)]
steps: 436 loss: 0.5899 iter time (s): 130.169 samples/sec: 0.983

 60%|██████    | 6/10 [13:05<08:43, 130.84s/it][A
 60%|██████    | 6/10 [13:04<08:43, 130.82s/it][A
 60%|██████    | 6/10 [13:04<08:43, 130.80s/it][A
 60%|██████    | 6/10 [13:04<08:43, 130.80s/it][A
 60%|██████    | 6/10 [13:04<08:43, 130.81s/it][A
 60%|██████    | 6/10 [13:04<08:43, 130.80s/it][A
 60%|██████    | 6/10 [13:04<08:43, 130.81s/it][A
 70%|███████   | 7/10 [15:13<06:32, 130.68s/it][A[2024-05-29 22:42:37,229] [INFO] [logging.py:96:log_dist] [Rank 0] step=437, skipped=0, lr=[1.9887183049830106e-05], mom=[(0.9, 0.999)]
steps: 437 loss: 0.5828 iter time (s): 129.936 samples/sec: 0.985

 70%|███████   | 7/10 [15:15<06:32, 130.74s/it][A
 70%|███████   | 7/10 [15:15<06:32, 130.71s/it][A
 70%|███████   | 7/10 [15:15<06:32, 130.73s/it][A
 70%|███████   | 7/10 [15:15<06:32, 130.75s/it][A
 70%|███████   | 7/10 [15:15<06:32, 130.74s/it][A
 70%|███████   | 7/10 [15:15<06:32, 130.73s/it][A
 70%|███████   | 7/10 [15:15<06:32, 130.73s/it][A
 80%|████████  | 8/10 [17:23<04:21, 130.65s/it][A[2024-05-29 22:44:47,824] [INFO] [logging.py:96:log_dist] [Rank 0] step=438, skipped=0, lr=[1.9886333092721878e-05], mom=[(0.9, 0.999)]
steps: 438 loss: 0.5666 iter time (s): 129.939 samples/sec: 0.985

 80%|████████  | 8/10 [17:26<04:21, 130.68s/it][A
 80%|████████  | 8/10 [17:26<04:21, 130.68s/it][A
 80%|████████  | 8/10 [17:26<04:21, 130.68s/it][A
 80%|████████  | 8/10 [17:26<04:21, 130.69s/it][A
 80%|████████  | 8/10 [17:26<04:21, 130.69s/it][A
 80%|████████  | 8/10 [17:26<04:21, 130.69s/it][A
 80%|████████  | 8/10 [17:26<04:21, 130.69s/it][A
 90%|█████████ | 9/10 [19:34<02:10, 130.67s/it][A[2024-05-29 22:46:58,536] [INFO] [logging.py:96:log_dist] [Rank 0] step=439, skipped=0, lr=[1.988547996415341e-05], mom=[(0.9, 0.999)]
steps: 439 loss: 0.6012 iter time (s): 130.052 samples/sec: 0.984

 90%|█████████ | 9/10 [19:36<02:10, 130.69s/it][A
 90%|█████████ | 9/10 [19:36<02:10, 130.70s/it][A
 90%|█████████ | 9/10 [19:36<02:10, 130.69s/it][A
 90%|█████████ | 9/10 [19:36<02:10, 130.69s/it][A
 90%|█████████ | 9/10 [19:36<02:10, 130.70s/it][A
 90%|█████████ | 9/10 [19:36<02:10, 130.70s/it][A
 90%|█████████ | 9/10 [19:36<02:10, 130.70s/it][A
100%|██████████| 10/10 [21:45<00:00, 130.75s/it][A100%|██████████| 10/10 [21:45<00:00, 130.56s/it]
[2024-05-29 22:49:09,457] [INFO] [logging.py:96:log_dist] [Rank 0] step=440, skipped=0, lr=[1.9884623664398406e-05], mom=[(0.9, 0.999)]
steps: 440 loss: 0.5940 iter time (s): 130.268 samples/sec: 0.983

100%|██████████| 10/10 [21:47<00:00, 130.77s/it][A100%|██████████| 10/10 [21:47<00:00, 130.78s/it]

100%|██████████| 10/10 [21:47<00:00, 130.77s/it][A100%|██████████| 10/10 [21:47<00:00, 130.77s/it]

100%|██████████| 10/10 [21:47<00:00, 130.78s/it][A100%|██████████| 10/10 [21:47<00:00, 130.78s/it]

100%|██████████| 10/10 [21:47<00:00, 130.78s/it][A100%|██████████| 10/10 [21:47<00:00, 130.77s/it]

100%|██████████| 10/10 [21:47<00:00, 130.77s/it][A100%|██████████| 10/10 [21:47<00:00, 130.78s/it]

100%|██████████| 10/10 [21:47<00:00, 130.78s/it][A100%|██████████| 10/10 [21:47<00:00, 130.78s/it]

100%|██████████| 10/10 [21:47<00:00, 130.78s/it][A100%|██████████| 10/10 [21:47<00:00, 130.78s/it]
Checkpointing at shard 45
[2024-05-29 22:49:15,054] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step440 is about to be saved!
[2024-05-29 22:49:16,742] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step440/layer_00-model_states.pt...
[2024-05-29 22:49:19,251] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step440/layer_00-model_states.pt.
[2024-05-29 22:49:24,553] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step440/layer_05-model_states.pt...
[2024-05-29 22:49:25,370] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step440/layer_04-model_states.pt...
[2024-05-29 22:49:27,722] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step440/layer_03-model_states.pt...
[2024-05-29 22:49:28,876] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step440/layer_06-model_states.pt...
[2024-05-29 22:49:29,440] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step440/layer_02-model_states.pt...
[2024-05-29 22:49:30,719] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step440/layer_07-model_states.pt...
[2024-05-29 22:49:30,804] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step440/layer_08-model_states.pt...
[2024-05-29 22:49:32,993] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step440/layer_01-model_states.pt...
[2024-05-29 22:51:39,142] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step440/layer_01-model_states.pt.
[2024-05-29 22:51:39,752] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step440/mp_rank_00_model_states.pt
[2024-05-29 22:51:39,752] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step440/mp_rank_00_model_states.pt...
[2024-05-29 22:51:40,847] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step440/mp_rank_00_model_states.pt.
[2024-05-29 22:51:40,847] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step440 is ready now!
[2024-05-29 22:52:00,054] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step440/layer_05-model_states.pt.
[2024-05-29 22:52:00,696] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step440/mp_rank_04_model_states.pt...
[2024-05-29 22:52:00,857] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step440/mp_rank_04_model_states.pt.
[2024-05-29 22:52:00,857] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step440 is ready now!
[2024-05-29 22:52:32,512] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step440/layer_06-model_states.pt.
[2024-05-29 22:52:33,229] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step440/mp_rank_05_model_states.pt...
[2024-05-29 22:52:33,379] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step440/mp_rank_05_model_states.pt.
[2024-05-29 22:52:33,379] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step440 is ready now!
[2024-05-29 22:52:35,175] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step440/layer_03-model_states.pt.
[2024-05-29 22:52:35,916] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step440/mp_rank_02_model_states.pt...
[2024-05-29 22:52:36,078] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step440/mp_rank_02_model_states.pt.
[2024-05-29 22:52:36,078] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step440 is ready now!
[2024-05-29 22:52:43,257] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step440/layer_07-model_states.pt.
[2024-05-29 22:52:43,261] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step440/layer_08-model_states.pt.
[2024-05-29 22:52:43,264] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step440/layer_04-model_states.pt.
[2024-05-29 22:52:44,370] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step440/mp_rank_06_model_states.pt...
[2024-05-29 22:52:44,508] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step440/mp_rank_03_model_states.pt...
[2024-05-29 22:52:44,843] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step440/mp_rank_06_model_states.pt.
[2024-05-29 22:52:44,843] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step440 is ready now!
[2024-05-29 22:52:44,900] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step440/mp_rank_03_model_states.pt.
[2024-05-29 22:52:44,900] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step440 is ready now!
[2024-05-29 22:52:44,931] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step440/layer_09-model_states.pt...
[2024-05-29 22:52:46,217] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step440/layer_09-model_states.pt.
[2024-05-29 22:52:46,220] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step440/mp_rank_07_model_states.pt...
[2024-05-29 22:52:46,374] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step440/mp_rank_07_model_states.pt.
[2024-05-29 22:52:46,374] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step440 is ready now!
[2024-05-29 22:52:50,699] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step440/layer_02-model_states.pt.
[2024-05-29 22:52:51,469] [INFO] [logging.py:96:log_dist] [Rank 1] Saving model checkpoint: /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step440/mp_rank_01_model_states.pt
[2024-05-29 22:52:51,470] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step440/mp_rank_01_model_states.pt...
[2024-05-29 22:52:51,555] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step440/mp_rank_01_model_states.pt.
[2024-05-29 22:52:51,555] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step440 is ready now!
Checkpoint saved using --- 221.3948540687561 seconds ---  9%|▊         | 45/520 [1:00:06<20:20:26, 154.16s/it]
  9%|▊         | 45/520 [59:56<20:19:33, 154.05s/it]  9%|▊         | 45/520 [58:55<20:08:58, 152.71s/it]  9%|▊         | 45/520 [59:27<20:14:12, 153.37s/it]  9%|▊         | 45/520 [59:22<20:13:19, 153.26s/it]  9%|▊         | 45/520 [57:50<19:58:20, 151.37s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_312
  9%|▊         | 45/520 [1:00:03<20:20:04, 154.12s/it]  9%|▊         | 45/520 [1:00:04<20:20:14, 154.13s/it]Training on 1280 of 1280 sentences.

  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
 10%|█         | 1/10 [01:17<11:34, 77.17s/it][A[2024-05-29 22:54:10,524] [INFO] [logging.py:96:log_dist] [Rank 0] step=441, skipped=0, lr=[1.9883764193731593e-05], mom=[(0.9, 0.999)]
steps: 441 loss: 0.6218 iter time (s): 78.923 samples/sec: 1.622

 10%|█         | 1/10 [01:19<11:53, 79.29s/it][A
 10%|█         | 1/10 [01:19<11:54, 79.41s/it][A
 10%|█         | 1/10 [01:19<11:55, 79.53s/it][A
 10%|█         | 1/10 [01:19<11:56, 79.64s/it][A
 10%|█         | 1/10 [01:19<11:57, 79.69s/it][A
 10%|█         | 1/10 [01:19<11:57, 79.76s/it][A
 10%|█         | 1/10 [01:19<11:57, 79.77s/it][A
 20%|██        | 2/10 [02:39<10:40, 80.07s/it][A[2024-05-29 22:55:32,627] [INFO] [logging.py:96:log_dist] [Rank 0] step=442, skipped=0, lr=[1.988290155242871e-05], mom=[(0.9, 0.999)]
steps: 442 loss: 0.6224 iter time (s): 81.288 samples/sec: 1.575

 20%|██        | 2/10 [02:41<10:48, 81.05s/it][A
 20%|██        | 2/10 [02:41<10:49, 81.19s/it][A
 20%|██        | 2/10 [02:41<10:49, 81.19s/it][A
 20%|██        | 2/10 [02:41<10:49, 81.22s/it][A
 20%|██        | 2/10 [02:42<10:49, 81.24s/it][A
 20%|██        | 2/10 [02:42<10:50, 81.26s/it][A
 20%|██        | 2/10 [02:42<10:50, 81.27s/it][A
 30%|███       | 3/10 [03:59<09:20, 80.01s/it][A[2024-05-29 22:56:52,566] [INFO] [logging.py:96:log_dist] [Rank 0] step=443, skipped=0, lr=[1.9882035740766504e-05], mom=[(0.9, 0.999)]
steps: 443 loss: 0.6296 iter time (s): 78.912 samples/sec: 1.622

 30%|███       | 3/10 [04:01<09:23, 80.45s/it][A
 30%|███       | 3/10 [04:01<09:23, 80.45s/it][A
 30%|███       | 3/10 [04:01<09:23, 80.51s/it][A
 30%|███       | 3/10 [04:01<09:23, 80.56s/it][A
 30%|███       | 3/10 [04:01<09:24, 80.61s/it][A
 30%|███       | 3/10 [04:01<09:24, 80.62s/it][A
 30%|███       | 3/10 [04:01<09:24, 80.63s/it][A
 40%|████      | 4/10 [05:20<08:02, 80.36s/it][A[2024-05-29 22:58:13,457] [INFO] [logging.py:96:log_dist] [Rank 0] step=444, skipped=0, lr=[1.9881166759022764e-05], mom=[(0.9, 0.999)]
steps: 444 loss: 0.6213 iter time (s): 79.954 samples/sec: 1.601

 40%|████      | 4/10 [05:22<08:03, 80.63s/it][A
 40%|████      | 4/10 [05:22<08:04, 80.67s/it][A
 40%|████      | 4/10 [05:22<08:04, 80.67s/it][A
 40%|████      | 4/10 [05:22<08:04, 80.68s/it][A
 40%|████      | 4/10 [05:22<08:04, 80.76s/it][A
 40%|████      | 4/10 [05:22<08:04, 80.72s/it][A
 40%|████      | 4/10 [05:22<08:04, 80.72s/it][A
 50%|█████     | 5/10 [06:40<06:41, 80.30s/it][A[2024-05-29 22:59:33,656] [INFO] [logging.py:96:log_dist] [Rank 0] step=445, skipped=0, lr=[1.988029460747627e-05], mom=[(0.9, 0.999)]
steps: 445 loss: 0.6140 iter time (s): 79.270 samples/sec: 1.615

 50%|█████     | 5/10 [06:42<06:42, 80.50s/it][A
 50%|█████     | 5/10 [06:42<06:42, 80.47s/it][A
 50%|█████     | 5/10 [06:42<06:42, 80.52s/it][A
 50%|█████     | 5/10 [06:42<06:42, 80.50s/it][A
 50%|█████     | 5/10 [06:43<06:42, 80.54s/it][A
 50%|█████     | 5/10 [06:43<06:42, 80.55s/it][A
 50%|█████     | 5/10 [06:43<06:42, 80.57s/it][A
 60%|██████    | 6/10 [08:00<05:21, 80.39s/it][A[2024-05-29 23:00:54,218] [INFO] [logging.py:96:log_dist] [Rank 0] step=446, skipped=0, lr=[1.9879419286406834e-05], mom=[(0.9, 0.999)]
steps: 446 loss: 0.6019 iter time (s): 79.605 samples/sec: 1.608

 60%|██████    | 6/10 [08:03<05:22, 80.52s/it][A
 60%|██████    | 6/10 [08:03<05:22, 80.60s/it][A
 60%|██████    | 6/10 [08:03<05:22, 80.63s/it][A
 60%|██████    | 6/10 [08:03<05:22, 80.57s/it][A
 60%|██████    | 6/10 [08:03<05:22, 80.59s/it][A
 60%|██████    | 6/10 [08:03<05:22, 80.57s/it][A
 60%|██████    | 6/10 [08:03<05:22, 80.58s/it][A
 70%|███████   | 7/10 [09:22<04:02, 80.68s/it][A[2024-05-29 23:02:15,492] [INFO] [logging.py:96:log_dist] [Rank 0] step=447, skipped=0, lr=[1.9878540796095278e-05], mom=[(0.9, 0.999)]
steps: 447 loss: 0.5960 iter time (s): 80.230 samples/sec: 1.595

 70%|███████   | 7/10 [09:24<04:02, 80.73s/it][A
 70%|███████   | 7/10 [09:24<04:02, 80.73s/it][A
 70%|███████   | 7/10 [09:24<04:02, 80.72s/it][A
 70%|███████   | 7/10 [09:24<04:02, 80.73s/it][A
 70%|███████   | 7/10 [09:24<04:02, 80.72s/it][A
 70%|███████   | 7/10 [09:24<04:02, 80.72s/it][A
 70%|███████   | 7/10 [09:24<04:02, 80.72s/it][A
 80%|████████  | 8/10 [10:43<02:41, 80.79s/it][A[2024-05-29 23:03:36,518] [INFO] [logging.py:96:log_dist] [Rank 0] step=448, skipped=0, lr=[1.9877659136823447e-05], mom=[(0.9, 0.999)]
steps: 448 loss: 0.6002 iter time (s): 80.254 samples/sec: 1.595

 80%|████████  | 8/10 [10:45<02:41, 80.85s/it][A
 80%|████████  | 8/10 [10:45<02:41, 80.84s/it][A
 80%|████████  | 8/10 [10:45<02:41, 80.81s/it][A
 80%|████████  | 8/10 [10:45<02:41, 80.83s/it][A
 80%|████████  | 8/10 [10:45<02:41, 80.83s/it][A
 80%|████████  | 8/10 [10:45<02:41, 80.83s/it][A
 80%|████████  | 8/10 [10:45<02:41, 80.83s/it][A
 90%|█████████ | 9/10 [12:05<01:21, 81.26s/it][A[2024-05-29 23:04:58,795] [INFO] [logging.py:96:log_dist] [Rank 0] step=449, skipped=0, lr=[1.9876774308874198e-05], mom=[(0.9, 0.999)]
steps: 449 loss: 0.6092 iter time (s): 81.451 samples/sec: 1.572

 90%|█████████ | 9/10 [12:07<01:21, 81.29s/it][A
 90%|█████████ | 9/10 [12:07<01:21, 81.27s/it][A
 90%|█████████ | 9/10 [12:07<01:21, 81.28s/it][A
 90%|█████████ | 9/10 [12:07<01:21, 81.25s/it][A
 90%|█████████ | 9/10 [12:07<01:21, 81.26s/it][A
 90%|█████████ | 9/10 [12:07<01:21, 81.26s/it][A
 90%|█████████ | 9/10 [12:07<01:21, 81.26s/it][A
100%|██████████| 10/10 [13:26<00:00, 81.17s/it][A100%|██████████| 10/10 [13:26<00:00, 80.64s/it]
  9%|▉         | 46/520 [1:13:23<27:05:27, 205.75s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A[2024-05-29 23:06:19,773] [INFO] [logging.py:96:log_dist] [Rank 0] step=450, skipped=0, lr=[1.9875886312531406e-05], mom=[(0.9, 0.999)]
steps: 450 loss: 0.6119 iter time (s): 80.231 samples/sec: 1.595

100%|██████████| 10/10 [13:28<00:00, 81.22s/it][A100%|██████████| 10/10 [13:28<00:00, 80.86s/it]
  9%|▉         | 46/520 [1:12:55<27:01:56, 205.31s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:28<00:00, 81.19s/it][A100%|██████████| 10/10 [13:28<00:00, 80.87s/it]
  9%|▉         | 46/520 [1:13:32<27:07:31, 206.01s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:28<00:00, 81.17s/it][A100%|██████████| 10/10 [13:28<00:00, 80.87s/it]
  9%|▉         | 46/520 [1:13:32<27:07:23, 206.00s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:28<00:00, 81.18s/it][A100%|██████████| 10/10 [13:28<00:00, 80.89s/it]
  9%|▉         | 46/520 [1:12:24<26:57:17, 204.72s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:28<00:00, 81.19s/it][A100%|██████████| 10/10 [13:28<00:00, 80.89s/it]
  9%|▉         | 46/520 [1:12:51<27:01:18, 205.23s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:28<00:00, 81.19s/it][A100%|██████████| 10/10 [13:28<00:00, 80.90s/it]
  9%|▉         | 46/520 [1:13:35<27:07:53, 206.06s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:29<00:00, 81.19s/it][A100%|██████████| 10/10 [13:29<00:00, 80.90s/it]
  9%|▉         | 46/520 [1:11:20<26:47:35, 203.49s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_428
Training on 1280 of 1280 sentences.

  0%|          | 0/10 [00:00<?, ?it/s][A
 10%|█         | 1/10 [01:00<09:08, 60.99s/it][A[2024-05-29 23:07:20,217] [INFO] [logging.py:96:log_dist] [Rank 0] step=451, skipped=0, lr=[1.9874995148079958e-05], mom=[(0.9, 0.999)]
steps: 451 loss: 0.3961 iter time (s): 59.569 samples/sec: 2.149

 10%|█         | 1/10 [01:00<09:02, 60.27s/it][A
 10%|█         | 1/10 [01:00<09:02, 60.27s/it][A
 10%|█         | 1/10 [01:00<09:03, 60.35s/it][A
 10%|█         | 1/10 [01:00<09:02, 60.31s/it][A
 10%|█         | 1/10 [01:00<09:02, 60.31s/it][A
 10%|█         | 1/10 [01:00<09:02, 60.28s/it][A
 10%|█         | 1/10 [01:00<09:02, 60.27s/it][A
 20%|██        | 2/10 [02:01<08:07, 60.91s/it][A[2024-05-29 23:08:21,068] [INFO] [logging.py:96:log_dist] [Rank 0] step=452, skipped=0, lr=[1.9874100815805766e-05], mom=[(0.9, 0.999)]
steps: 452 loss: 0.3623 iter time (s): 60.208 samples/sec: 2.126

 20%|██        | 2/10 [02:01<08:04, 60.60s/it][A
 20%|██        | 2/10 [02:01<08:05, 60.65s/it][A
 20%|██        | 2/10 [02:01<08:05, 60.65s/it][A
 20%|██        | 2/10 [02:01<08:04, 60.61s/it][A
 20%|██        | 2/10 [02:01<08:04, 60.60s/it][A
 20%|██        | 2/10 [02:01<08:04, 60.60s/it][A
 20%|██        | 2/10 [02:01<08:04, 60.60s/it][A
 30%|███       | 3/10 [03:02<07:04, 60.69s/it][A[2024-05-29 23:09:21,489] [INFO] [logging.py:96:log_dist] [Rank 0] step=453, skipped=0, lr=[1.9873203315995758e-05], mom=[(0.9, 0.999)]
steps: 453 loss: 0.3416 iter time (s): 59.807 samples/sec: 2.140

 30%|███       | 3/10 [03:01<07:03, 60.54s/it][A
 30%|███       | 3/10 [03:01<07:03, 60.52s/it][A
 30%|███       | 3/10 [03:01<07:03, 60.53s/it][A
 30%|███       | 3/10 [03:01<07:03, 60.54s/it][A
 30%|███       | 3/10 [03:01<07:03, 60.54s/it][A
 30%|███       | 3/10 [03:01<07:03, 60.53s/it][A
 30%|███       | 3/10 [03:01<07:03, 60.53s/it][A
 40%|████      | 4/10 [04:03<06:04, 60.83s/it][A[2024-05-29 23:10:22,545] [INFO] [logging.py:96:log_dist] [Rank 0] step=454, skipped=0, lr=[1.9872302648937865e-05], mom=[(0.9, 0.999)]
steps: 454 loss: 0.3383 iter time (s): 60.404 samples/sec: 2.119

 40%|████      | 4/10 [04:02<06:04, 60.74s/it][A
 40%|████      | 4/10 [04:02<06:04, 60.73s/it][A
 40%|████      | 4/10 [04:02<06:04, 60.77s/it][A
 40%|████      | 4/10 [04:02<06:04, 60.74s/it][A
 40%|████      | 4/10 [04:02<06:04, 60.73s/it][A
 40%|████      | 4/10 [04:02<06:04, 60.74s/it][A
 40%|████      | 4/10 [04:02<06:04, 60.74s/it][A
 50%|█████     | 5/10 [05:03<05:03, 60.60s/it][A[2024-05-29 23:11:22,736] [INFO] [logging.py:96:log_dist] [Rank 0] step=455, skipped=0, lr=[1.987139881492105e-05], mom=[(0.9, 0.999)]
steps: 455 loss: 0.3452 iter time (s): 59.545 samples/sec: 2.150

 50%|█████     | 5/10 [05:02<05:02, 60.54s/it][A
 50%|█████     | 5/10 [05:02<05:02, 60.55s/it][A
 50%|█████     | 5/10 [05:02<05:02, 60.54s/it][A
 50%|█████     | 5/10 [05:02<05:02, 60.53s/it][A
 50%|█████     | 5/10 [05:02<05:02, 60.53s/it][A
 50%|█████     | 5/10 [05:02<05:02, 60.54s/it][A
 50%|█████     | 5/10 [05:02<05:02, 60.54s/it][A
 60%|██████    | 6/10 [06:03<04:02, 60.53s/it][A[2024-05-29 23:12:23,124] [INFO] [logging.py:96:log_dist] [Rank 0] step=456, skipped=0, lr=[1.9870491814235284e-05], mom=[(0.9, 0.999)]
steps: 456 loss: 0.3295 iter time (s): 59.755 samples/sec: 2.142

 60%|██████    | 6/10 [06:03<04:01, 60.50s/it][A
 60%|██████    | 6/10 [06:03<04:01, 60.50s/it][A
 60%|██████    | 6/10 [06:03<04:01, 60.50s/it][A
 60%|██████    | 6/10 [06:03<04:01, 60.49s/it][A
 60%|██████    | 6/10 [06:03<04:01, 60.48s/it][A
 60%|██████    | 6/10 [06:03<04:01, 60.49s/it][A
 60%|██████    | 6/10 [06:03<04:01, 60.49s/it][A
 70%|███████   | 7/10 [07:04<03:01, 60.54s/it][A[2024-05-29 23:13:23,686] [INFO] [logging.py:96:log_dist] [Rank 0] step=457, skipped=0, lr=[1.9869581647171554e-05], mom=[(0.9, 0.999)]
steps: 457 loss: 0.3074 iter time (s): 59.926 samples/sec: 2.136

 70%|███████   | 7/10 [07:03<03:01, 60.50s/it][A
 70%|███████   | 7/10 [07:03<03:01, 60.51s/it][A
 70%|███████   | 7/10 [07:03<03:01, 60.52s/it][A
 70%|███████   | 7/10 [07:03<03:01, 60.52s/it][A
 70%|███████   | 7/10 [07:03<03:01, 60.52s/it][A
 70%|███████   | 7/10 [07:03<03:01, 60.51s/it][A
 70%|███████   | 7/10 [07:03<03:01, 60.52s/it][A
 80%|████████  | 8/10 [08:05<02:01, 60.77s/it][A[2024-05-29 23:14:24,947] [INFO] [logging.py:96:log_dist] [Rank 0] step=458, skipped=0, lr=[1.986866831402186e-05], mom=[(0.9, 0.999)]
steps: 458 loss: 0.3285 iter time (s): 60.603 samples/sec: 2.112

 80%|████████  | 8/10 [08:04<02:01, 60.73s/it][A
 80%|████████  | 8/10 [08:05<02:01, 60.75s/it][A
 80%|████████  | 8/10 [08:05<02:01, 60.75s/it][A
 80%|████████  | 8/10 [08:04<02:01, 60.74s/it][A
 80%|████████  | 8/10 [08:04<02:01, 60.73s/it][A
 80%|████████  | 8/10 [08:04<02:01, 60.73s/it][A
 80%|████████  | 8/10 [08:04<02:01, 60.74s/it][A
 90%|█████████ | 9/10 [09:05<01:00, 60.41s/it][A[2024-05-29 23:15:24,560] [INFO] [logging.py:96:log_dist] [Rank 0] step=459, skipped=0, lr=[1.986775181507923e-05], mom=[(0.9, 0.999)]
steps: 459 loss: 0.3456 iter time (s): 59.034 samples/sec: 2.168

 90%|█████████ | 9/10 [09:04<01:00, 60.39s/it][A
 90%|█████████ | 9/10 [09:04<01:00, 60.39s/it][A
 90%|█████████ | 9/10 [09:04<01:00, 60.40s/it][A
 90%|█████████ | 9/10 [09:04<01:00, 60.41s/it][A
 90%|█████████ | 9/10 [09:04<01:00, 60.41s/it][A
 90%|█████████ | 9/10 [09:04<01:00, 60.41s/it][A
 90%|█████████ | 9/10 [09:04<01:00, 60.41s/it][A
100%|██████████| 10/10 [10:04<00:00, 60.11s/it][A100%|██████████| 10/10 [10:04<00:00, 60.48s/it]
  9%|▉         | 47/520 [1:23:27<32:21:57, 246.34s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A[2024-05-29 23:16:23,987] [INFO] [logging.py:96:log_dist] [Rank 0] step=460, skipped=0, lr=[1.98668321506377e-05], mom=[(0.9, 0.999)]
steps: 460 loss: 0.3099 iter time (s): 58.758 samples/sec: 2.178

100%|██████████| 10/10 [10:04<00:00, 60.11s/it][A100%|██████████| 10/10 [10:04<00:00, 60.41s/it]
  9%|▉         | 47/520 [1:22:59<32:18:14, 245.87s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [10:04<00:00, 60.11s/it][A100%|██████████| 10/10 [10:04<00:00, 60.41s/it]
  9%|▉         | 47/520 [1:23:37<32:23:16, 246.50s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [10:04<00:00, 60.08s/it][A100%|██████████| 10/10 [10:04<00:00, 60.40s/it]
  9%|▉         | 47/520 [1:22:28<32:14:02, 245.33s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [10:04<00:00, 60.11s/it][A100%|██████████| 10/10 [10:04<00:00, 60.42s/it]
  9%|▉         | 47/520 [1:23:36<32:23:13, 246.50s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [10:04<00:00, 60.09s/it][A100%|██████████| 10/10 [10:04<00:00, 60.40s/it]
  9%|▉         | 47/520 [1:23:39<32:23:32, 246.54s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [10:04<00:00, 60.10s/it][A100%|██████████| 10/10 [10:04<00:00, 60.41s/it]
  9%|▉         | 47/520 [1:22:55<32:17:42, 245.80s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [10:04<00:00, 60.09s/it][A100%|██████████| 10/10 [10:04<00:00, 60.40s/it]
  9%|▉         | 47/520 [1:21:24<32:05:21, 244.23s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_23
Training on 1280 of 1280 sentences.

  0%|          | 0/10 [00:00<?, ?it/s][A
 10%|█         | 1/10 [02:04<18:40, 124.55s/it][A[2024-05-29 23:18:30,096] [INFO] [logging.py:96:log_dist] [Rank 0] step=461, skipped=0, lr=[1.9865909320992317e-05], mom=[(0.9, 0.999)]
steps: 461 loss: 0.9069 iter time (s): 125.711 samples/sec: 1.018

 10%|█         | 1/10 [02:06<18:59, 126.59s/it][A
 10%|█         | 1/10 [02:06<18:59, 126.61s/it][A
 10%|█         | 1/10 [02:06<18:59, 126.56s/it][A
 10%|█         | 1/10 [02:06<19:00, 126.73s/it][A
 10%|█         | 1/10 [02:06<18:59, 126.66s/it][A
 10%|█         | 1/10 [02:06<19:00, 126.67s/it][A
 10%|█         | 1/10 [02:06<19:00, 126.71s/it][A
 20%|██        | 2/10 [04:11<16:46, 125.77s/it][A[2024-05-29 23:20:36,688] [INFO] [logging.py:96:log_dist] [Rank 0] step=462, skipped=0, lr=[1.9864983326439143e-05], mom=[(0.9, 0.999)]
steps: 462 loss: 0.8850 iter time (s): 125.672 samples/sec: 1.019

 20%|██        | 2/10 [04:13<16:52, 126.56s/it][A
 20%|██        | 2/10 [04:13<16:52, 126.51s/it][A
 20%|██        | 2/10 [04:12<16:51, 126.48s/it][A
 20%|██        | 2/10 [04:13<16:51, 126.49s/it][A
 20%|██        | 2/10 [04:13<16:51, 126.49s/it][A
 20%|██        | 2/10 [04:13<16:52, 126.51s/it][A
 20%|██        | 2/10 [04:13<16:51, 126.50s/it][A
 30%|███       | 3/10 [06:17<14:41, 125.97s/it][A[2024-05-29 23:22:43,321] [INFO] [logging.py:96:log_dist] [Rank 0] step=463, skipped=0, lr=[1.986405416727527e-05], mom=[(0.9, 0.999)]
steps: 463 loss: 0.8746 iter time (s): 125.645 samples/sec: 1.019

 30%|███       | 3/10 [06:18<14:42, 126.12s/it][A
 30%|███       | 3/10 [06:19<14:44, 126.39s/it][A
 30%|███       | 3/10 [06:19<14:44, 126.43s/it][A
 30%|███       | 3/10 [06:19<14:45, 126.46s/it][A
 30%|███       | 3/10 [06:19<14:45, 126.48s/it][A
 30%|███       | 3/10 [06:19<14:45, 126.45s/it][A
 30%|███       | 3/10 [06:19<14:45, 126.45s/it][A
 40%|████      | 4/10 [08:23<12:37, 126.20s/it][A[2024-05-29 23:24:49,116] [INFO] [logging.py:96:log_dist] [Rank 0] step=464, skipped=0, lr=[1.9863121843798786e-05], mom=[(0.9, 0.999)]
steps: 464 loss: 0.8701 iter time (s): 126.025 samples/sec: 1.016

 40%|████      | 4/10 [08:25<12:37, 126.28s/it][A
 40%|████      | 4/10 [08:25<12:37, 126.33s/it][A
 40%|████      | 4/10 [08:25<12:38, 126.43s/it][A
 40%|████      | 4/10 [08:25<12:38, 126.43s/it][A
 40%|████      | 4/10 [08:25<12:38, 126.41s/it][A
 40%|████      | 4/10 [08:25<12:39, 126.50s/it][A
 40%|████      | 4/10 [08:25<12:38, 126.44s/it][A
 50%|█████     | 5/10 [10:30<10:31, 126.28s/it][A[2024-05-29 23:26:55,889] [INFO] [logging.py:96:log_dist] [Rank 0] step=465, skipped=0, lr=[1.9862186356308813e-05], mom=[(0.9, 0.999)]
steps: 465 loss: 0.9097 iter time (s): 125.742 samples/sec: 1.018

 50%|█████     | 5/10 [10:32<10:32, 126.50s/it][A
 50%|█████     | 5/10 [10:32<10:32, 126.49s/it][A
 50%|█████     | 5/10 [10:32<10:32, 126.48s/it][A
 50%|█████     | 5/10 [10:32<10:32, 126.52s/it][A
 50%|█████     | 5/10 [10:32<10:32, 126.50s/it][A
 50%|█████     | 5/10 [10:32<10:32, 126.48s/it][A
 50%|█████     | 5/10 [10:32<10:32, 126.49s/it][A
 60%|██████    | 6/10 [12:36<08:25, 126.35s/it][A[2024-05-29 23:29:02,379] [INFO] [logging.py:96:log_dist] [Rank 0] step=466, skipped=0, lr=[1.986124770510547e-05], mom=[(0.9, 0.999)]
steps: 466 loss: 0.8485 iter time (s): 125.659 samples/sec: 1.019

 60%|██████    | 6/10 [12:38<08:26, 126.51s/it][A
 60%|██████    | 6/10 [12:38<08:26, 126.52s/it][A
 60%|██████    | 6/10 [12:38<08:25, 126.47s/it][A
 60%|██████    | 6/10 [12:39<08:26, 126.52s/it][A
 60%|██████    | 6/10 [12:38<08:25, 126.49s/it][A
 60%|██████    | 6/10 [12:38<08:26, 126.51s/it][A
 60%|██████    | 6/10 [12:38<08:26, 126.54s/it][A
 70%|███████   | 7/10 [14:43<06:19, 126.44s/it][A[2024-05-29 23:31:08,993] [INFO] [logging.py:96:log_dist] [Rank 0] step=467, skipped=0, lr=[1.9860305890489905e-05], mom=[(0.9, 0.999)]
steps: 467 loss: 0.8586 iter time (s): 125.706 samples/sec: 1.018

 70%|███████   | 7/10 [14:45<06:19, 126.45s/it][A
 70%|███████   | 7/10 [14:45<06:19, 126.51s/it][A
 70%|███████   | 7/10 [14:45<06:19, 126.45s/it][A
 70%|███████   | 7/10 [14:45<06:19, 126.46s/it][A
 70%|███████   | 7/10 [14:45<06:19, 126.45s/it][A
 70%|███████   | 7/10 [14:45<06:19, 126.50s/it][A
 70%|███████   | 7/10 [14:45<06:19, 126.48s/it][A
 80%|████████  | 8/10 [16:49<04:12, 126.34s/it][A[2024-05-29 23:33:15,142] [INFO] [logging.py:96:log_dist] [Rank 0] step=468, skipped=0, lr=[1.985936091276427e-05], mom=[(0.9, 0.999)]
steps: 468 loss: 0.8171 iter time (s): 125.429 samples/sec: 1.020

 80%|████████  | 8/10 [16:51<04:12, 126.39s/it][A
 80%|████████  | 8/10 [16:51<04:12, 126.43s/it][A
 80%|████████  | 8/10 [16:51<04:12, 126.41s/it][A
 80%|████████  | 8/10 [16:51<04:12, 126.38s/it][A
 80%|████████  | 8/10 [16:51<04:12, 126.40s/it][A
 80%|████████  | 8/10 [16:51<04:12, 126.41s/it][A
 80%|████████  | 8/10 [16:51<04:12, 126.40s/it][A
 90%|█████████ | 9/10 [18:56<02:06, 126.38s/it][A[2024-05-29 23:35:21,610] [INFO] [logging.py:96:log_dist] [Rank 0] step=469, skipped=0, lr=[1.9858412772231748e-05], mom=[(0.9, 0.999)]
steps: 469 loss: 0.9309 iter time (s): 125.704 samples/sec: 1.018

 90%|█████████ | 9/10 [18:58<02:06, 126.45s/it][A
 90%|█████████ | 9/10 [18:58<02:06, 126.44s/it][A
 90%|█████████ | 9/10 [18:58<02:06, 126.47s/it][A
 90%|█████████ | 9/10 [18:58<02:06, 126.47s/it][A
 90%|█████████ | 9/10 [18:58<02:06, 126.45s/it][A
 90%|█████████ | 9/10 [18:58<02:06, 126.47s/it][A
 90%|█████████ | 9/10 [18:58<02:06, 126.50s/it][A
100%|██████████| 10/10 [21:02<00:00, 126.46s/it][A100%|██████████| 10/10 [21:02<00:00, 126.27s/it]
  9%|▉         | 48/520 [1:44:30<49:12:11, 375.28s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A[2024-05-29 23:37:28,242] [INFO] [logging.py:96:log_dist] [Rank 0] step=470, skipped=0, lr=[1.9857461469196517e-05], mom=[(0.9, 0.999)]
steps: 470 loss: 0.8641 iter time (s): 125.749 samples/sec: 1.018

100%|██████████| 10/10 [21:04<00:00, 126.47s/it][A100%|██████████| 10/10 [21:04<00:00, 126.46s/it]
  9%|▉         | 48/520 [1:44:04<49:10:51, 375.11s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [21:04<00:00, 126.49s/it][A100%|██████████| 10/10 [21:04<00:00, 126.47s/it]
  9%|▉         | 48/520 [1:44:41<49:15:17, 375.67s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [21:04<00:00, 126.51s/it][A100%|██████████| 10/10 [21:04<00:00, 126.48s/it]
  9%|▉         | 48/520 [1:44:41<49:15:21, 375.68s/it]

  0%|          | 0/10 [00:00<?, ?it/s][A100%|██████████| 10/10 [21:04<00:00, 126.48s/it][A100%|██████████| 10/10 [21:04<00:00, 126.48s/it]
  9%|▉         | 48/520 [1:43:33<49:07:22, 374.67s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [21:04<00:00, 126.48s/it][A100%|██████████| 10/10 [21:04<00:00, 126.47s/it]
  9%|▉         | 48/520 [1:44:00<49:10:30, 375.07s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [21:04<00:00, 126.50s/it][A100%|██████████| 10/10 [21:04<00:00, 126.48s/it]
  9%|▉         | 48/520 [1:42:28<48:59:46, 373.70s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_170
Training on 1280 of 1280 sentences.

  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [21:04<00:00, 126.50s/it][A100%|██████████| 10/10 [21:04<00:00, 126.48s/it]
  9%|▉         | 48/520 [1:44:43<49:15:40, 375.72s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
 10%|█         | 1/10 [02:06<18:58, 126.49s/it][A[2024-05-29 23:39:35,023] [INFO] [logging.py:96:log_dist] [Rank 0] step=471, skipped=0, lr=[1.9856507003963777e-05], mom=[(0.9, 0.999)]
steps: 471 loss: 0.5812 iter time (s): 125.632 samples/sec: 1.019

 10%|█         | 1/10 [02:06<18:57, 126.36s/it][A
 10%|█         | 1/10 [02:06<18:57, 126.36s/it][A
 10%|█         | 1/10 [02:06<18:56, 126.33s/it][A
 10%|█         | 1/10 [02:06<18:57, 126.38s/it][A
 10%|█         | 1/10 [02:06<18:56, 126.32s/it][A
 10%|█         | 1/10 [02:06<18:56, 126.33s/it][A
 10%|█         | 1/10 [02:06<18:57, 126.37s/it][A
 20%|██        | 2/10 [04:12<16:50, 126.34s/it][A[2024-05-29 23:41:41,254] [INFO] [logging.py:96:log_dist] [Rank 0] step=472, skipped=0, lr=[1.9855549376839748e-05], mom=[(0.9, 0.999)]
steps: 472 loss: 0.5727 iter time (s): 125.497 samples/sec: 1.020

 20%|██        | 2/10 [04:12<16:50, 126.29s/it][A
 20%|██        | 2/10 [04:12<16:49, 126.23s/it][A
 20%|██        | 2/10 [04:12<16:50, 126.29s/it][A
 20%|██        | 2/10 [04:12<16:50, 126.28s/it][A
 20%|██        | 2/10 [04:12<16:50, 126.28s/it][A
 20%|██        | 2/10 [04:12<16:50, 126.27s/it][A
 20%|██        | 2/10 [04:12<16:50, 126.27s/it][A
 30%|███       | 3/10 [06:18<14:44, 126.31s/it][A[2024-05-29 23:43:47,518] [INFO] [logging.py:96:log_dist] [Rank 0] step=473, skipped=0, lr=[1.9854588588131664e-05], mom=[(0.9, 0.999)]
steps: 473 loss: 0.5725 iter time (s): 125.552 samples/sec: 1.019

 30%|███       | 3/10 [06:18<14:44, 126.31s/it][A
 30%|███       | 3/10 [06:18<14:44, 126.31s/it][A
 30%|███       | 3/10 [06:18<14:43, 126.25s/it][A
 30%|███       | 3/10 [06:18<14:43, 126.27s/it][A
 30%|███       | 3/10 [06:18<14:43, 126.26s/it][A
 30%|███       | 3/10 [06:18<14:43, 126.26s/it][A
 30%|███       | 3/10 [06:18<14:43, 126.27s/it][A
 40%|████      | 4/10 [08:25<12:37, 126.25s/it][A[2024-05-29 23:45:53,696] [INFO] [logging.py:96:log_dist] [Rank 0] step=474, skipped=0, lr=[1.9853624638147766e-05], mom=[(0.9, 0.999)]
steps: 474 loss: 0.5929 iter time (s): 125.463 samples/sec: 1.020

 40%|████      | 4/10 [08:25<12:37, 126.22s/it][A
 40%|████      | 4/10 [08:25<12:37, 126.23s/it][A
 40%|████      | 4/10 [08:24<12:37, 126.21s/it][A
 40%|████      | 4/10 [08:25<12:37, 126.24s/it][A
 40%|████      | 4/10 [08:24<12:37, 126.23s/it][A
 40%|████      | 4/10 [08:24<12:37, 126.23s/it][A
 40%|████      | 4/10 [08:25<12:37, 126.23s/it][A
 50%|█████     | 5/10 [10:31<10:31, 126.30s/it][A[2024-05-29 23:48:00,074] [INFO] [logging.py:96:log_dist] [Rank 0] step=475, skipped=0, lr=[1.985265752719731e-05], mom=[(0.9, 0.999)]
steps: 475 loss: 0.5915 iter time (s): 125.675 samples/sec: 1.019

 50%|█████     | 5/10 [10:31<10:31, 126.32s/it][A
 50%|█████     | 5/10 [10:31<10:31, 126.30s/it][A
 50%|█████     | 5/10 [10:31<10:31, 126.28s/it][A
 50%|█████     | 5/10 [10:31<10:31, 126.30s/it][A
 50%|█████     | 5/10 [10:31<10:31, 126.29s/it][A
 50%|█████     | 5/10 [10:31<10:31, 126.29s/it][A
 50%|█████     | 5/10 [10:31<10:31, 126.29s/it][A
 60%|██████    | 6/10 [12:37<08:24, 126.23s/it][A[2024-05-29 23:50:06,172] [INFO] [logging.py:96:log_dist] [Rank 0] step=476, skipped=0, lr=[1.985168725559058e-05], mom=[(0.9, 0.999)]
steps: 476 loss: 0.5827 iter time (s): 125.364 samples/sec: 1.021

 60%|██████    | 6/10 [12:37<08:24, 126.22s/it][A
 60%|██████    | 6/10 [12:37<08:24, 126.23s/it][A
 60%|██████    | 6/10 [12:37<08:24, 126.22s/it][A
 60%|██████    | 6/10 [12:37<08:24, 126.22s/it][A
 60%|██████    | 6/10 [12:37<08:24, 126.22s/it][A
 60%|██████    | 6/10 [12:37<08:24, 126.21s/it][A
 60%|██████    | 6/10 [12:37<08:24, 126.22s/it][A
 70%|███████   | 7/10 [14:43<06:18, 126.17s/it][A[2024-05-29 23:52:12,224] [INFO] [logging.py:96:log_dist] [Rank 0] step=477, skipped=0, lr=[1.985071382363885e-05], mom=[(0.9, 0.999)]
steps: 477 loss: 0.5676 iter time (s): 125.351 samples/sec: 1.021

 70%|███████   | 7/10 [14:43<06:18, 126.16s/it][A
 70%|███████   | 7/10 [14:43<06:18, 126.17s/it][A
 70%|███████   | 7/10 [14:43<06:18, 126.13s/it][A
 70%|███████   | 7/10 [14:43<06:18, 126.14s/it][A
 70%|███████   | 7/10 [14:43<06:18, 126.15s/it][A
 70%|███████   | 7/10 [14:43<06:18, 126.15s/it][A
 70%|███████   | 7/10 [14:43<06:18, 126.15s/it][A
 80%|████████  | 8/10 [16:49<04:12, 126.17s/it][A[2024-05-29 23:54:18,380] [INFO] [logging.py:96:log_dist] [Rank 0] step=478, skipped=0, lr=[1.9849737231654426e-05], mom=[(0.9, 0.999)]
steps: 478 loss: 0.5879 iter time (s): 125.480 samples/sec: 1.020

 80%|████████  | 8/10 [16:49<04:12, 126.16s/it][A
 80%|████████  | 8/10 [16:49<04:12, 126.17s/it][A
 80%|████████  | 8/10 [16:49<04:12, 126.18s/it][A
 80%|████████  | 8/10 [16:49<04:12, 126.17s/it][A
 80%|████████  | 8/10 [16:49<04:12, 126.16s/it][A
 80%|████████  | 8/10 [16:49<04:12, 126.16s/it][A
 80%|████████  | 8/10 [16:49<04:12, 126.16s/it][A
 90%|█████████ | 9/10 [18:56<02:06, 126.32s/it][A[2024-05-29 23:56:25,034] [INFO] [logging.py:96:log_dist] [Rank 0] step=479, skipped=0, lr=[1.9848757479950624e-05], mom=[(0.9, 0.999)]
steps: 479 loss: 0.5525 iter time (s): 125.949 samples/sec: 1.016

 90%|█████████ | 9/10 [18:56<02:06, 126.32s/it][A
 90%|█████████ | 9/10 [18:56<02:06, 126.32s/it][A
 90%|█████████ | 9/10 [18:56<02:06, 126.31s/it][A
 90%|█████████ | 9/10 [18:56<02:06, 126.31s/it][A
 90%|█████████ | 9/10 [18:56<02:06, 126.32s/it][A
 90%|█████████ | 9/10 [18:56<02:06, 126.32s/it][A
 90%|█████████ | 9/10 [18:56<02:06, 126.32s/it][A
100%|██████████| 10/10 [21:02<00:00, 126.37s/it][A100%|██████████| 10/10 [21:02<00:00, 126.30s/it]
  9%|▉         | 49/520 [2:05:33<66:55:06, 511.48s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A[2024-05-29 23:58:31,229] [INFO] [logging.py:96:log_dist] [Rank 0] step=480, skipped=0, lr=[1.9847774568841773e-05], mom=[(0.9, 0.999)]
steps: 480 loss: 0.5906 iter time (s): 125.484 samples/sec: 1.020

100%|██████████| 10/10 [21:02<00:00, 126.28s/it][A100%|██████████| 10/10 [21:02<00:00, 126.26s/it]
  9%|▉         | 49/520 [2:05:07<66:53:30, 511.28s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [21:02<00:00, 126.26s/it][A100%|██████████| 10/10 [21:02<00:00, 126.25s/it]
  9%|▉         | 49/520 [2:05:44<66:57:10, 511.74s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [21:02<00:00, 126.29s/it][A100%|██████████| 10/10 [21:02<00:00, 126.25s/it]
  9%|▉         | 49/520 [2:05:43<66:57:14, 511.75s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [21:02<00:00, 126.29s/it][A100%|██████████| 10/10 [21:02<00:00, 126.26s/it]
  9%|▉         | 49/520 [2:04:36<66:50:31, 510.90s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [21:02<00:00, 126.28s/it][A100%|██████████| 10/10 [21:02<00:00, 126.25s/it]
  9%|▉         | 49/520 [2:05:02<66:53:08, 511.23s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [21:02<00:00, 126.28s/it][A100%|██████████| 10/10 [21:02<00:00, 126.25s/it]
  9%|▉         | 49/520 [2:05:46<66:57:28, 511.78s/it]
100%|██████████| 10/10 [21:02<00:00, 126.27s/it][A100%|██████████| 10/10 [21:02<00:00, 126.25s/it]
  9%|▉         | 49/520 [2:03:31<66:44:04, 510.07s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_139

  0%|          | 0/10 [00:00<?, ?it/s][ATraining on 1280 of 1280 sentences.

  0%|          | 0/10 [00:00<?, ?it/s][A
 10%|█         | 1/10 [01:42<15:18, 102.01s/it][A[2024-05-30 00:00:12,818] [INFO] [logging.py:96:log_dist] [Rank 0] step=481, skipped=0, lr=[1.9846788498643216e-05], mom=[(0.9, 0.999)]
steps: 481 loss: 0.5584 iter time (s): 100.811 samples/sec: 1.270

 10%|█         | 1/10 [01:41<15:14, 101.58s/it][A
 10%|█         | 1/10 [01:41<15:15, 101.69s/it][A
 10%|█         | 1/10 [01:41<15:14, 101.62s/it][A
 10%|█         | 1/10 [01:41<15:14, 101.62s/it][A
 10%|█         | 1/10 [01:41<15:14, 101.62s/it][A
 10%|█         | 1/10 [01:41<15:14, 101.62s/it][A
 10%|█         | 1/10 [01:41<15:14, 101.65s/it][A
 20%|██        | 2/10 [03:23<13:32, 101.59s/it][A[2024-05-30 00:01:54,106] [INFO] [logging.py:96:log_dist] [Rank 0] step=482, skipped=0, lr=[1.984579926967131e-05], mom=[(0.9, 0.999)]
steps: 482 loss: 0.5721 iter time (s): 100.537 samples/sec: 1.273

 20%|██        | 2/10 [03:22<13:31, 101.46s/it][A
 20%|██        | 2/10 [03:22<13:31, 101.40s/it][A
 20%|██        | 2/10 [03:22<13:30, 101.37s/it][A
 20%|██        | 2/10 [03:22<13:31, 101.44s/it][A
 20%|██        | 2/10 [03:22<13:31, 101.41s/it][A
 20%|██        | 2/10 [03:22<13:31, 101.42s/it][A
 20%|██        | 2/10 [03:22<13:31, 101.43s/it][A
 30%|███       | 3/10 [05:03<11:45, 100.83s/it][A[2024-05-30 00:03:34,029] [INFO] [logging.py:96:log_dist] [Rank 0] step=483, skipped=0, lr=[1.984480688224342e-05], mom=[(0.9, 0.999)]
steps: 483 loss: 0.5464 iter time (s): 99.190 samples/sec: 1.290

 30%|███       | 3/10 [05:02<11:45, 100.73s/it][A
 30%|███       | 3/10 [05:02<11:45, 100.76s/it][A
 30%|███       | 3/10 [05:02<11:44, 100.71s/it][A
 30%|███       | 3/10 [05:02<11:45, 100.74s/it][A
 30%|███       | 3/10 [05:02<11:45, 100.76s/it][A

 30%|███       | 3/10 [05:02<11:45, 100.75s/it][A 30%|███       | 3/10 [05:02<11:45, 100.75s/it][A
 40%|████      | 4/10 [06:43<10:04, 100.69s/it][A[2024-05-30 00:05:14,521] [INFO] [logging.py:96:log_dist] [Rank 0] step=484, skipped=0, lr=[1.984381133667793e-05], mom=[(0.9, 0.999)]
steps: 484 loss: 0.5702 iter time (s): 99.740 samples/sec: 1.283

 40%|████      | 4/10 [06:43<10:03, 100.60s/it][A
 40%|████      | 4/10 [06:43<10:03, 100.65s/it][A
 40%|████      | 4/10 [06:43<10:03, 100.62s/it][A
 40%|████      | 4/10 [06:43<10:03, 100.64s/it][A
 40%|████      | 4/10 [06:43<10:03, 100.63s/it][A
 40%|████      | 4/10 [06:43<10:03, 100.64s/it][A
 40%|████      | 4/10 [06:43<10:03, 100.64s/it][A
 50%|█████     | 5/10 [08:24<08:23, 100.68s/it][A[2024-05-30 00:06:55,181] [INFO] [logging.py:96:log_dist] [Rank 0] step=485, skipped=0, lr=[1.9842812633294234e-05], mom=[(0.9, 0.999)]
steps: 485 loss: 0.5791 iter time (s): 99.919 samples/sec: 1.281

 50%|█████     | 5/10 [08:23<08:23, 100.66s/it][A
 50%|█████     | 5/10 [08:24<08:23, 100.64s/it][A
 50%|█████     | 5/10 [08:23<08:23, 100.62s/it][A
 50%|█████     | 5/10 [08:23<08:23, 100.65s/it][A
 50%|█████     | 5/10 [08:24<08:23, 100.67s/it][A
 50%|█████     | 5/10 [08:24<08:23, 100.66s/it][A
 50%|█████     | 5/10 [08:24<08:23, 100.66s/it][A
 60%|██████    | 6/10 [10:05<06:43, 100.82s/it][A[2024-05-30 00:08:36,278] [INFO] [logging.py:96:log_dist] [Rank 0] step=486, skipped=0, lr=[1.984181077241274e-05], mom=[(0.9, 0.999)]
steps: 486 loss: 0.5623 iter time (s): 100.335 samples/sec: 1.276

 60%|██████    | 6/10 [10:05<06:43, 100.82s/it][A
 60%|██████    | 6/10 [10:05<06:43, 100.85s/it][A
 60%|██████    | 6/10 [10:05<06:43, 100.83s/it][A
 60%|██████    | 6/10 [10:05<06:43, 100.82s/it][A
 60%|██████    | 6/10 [10:05<06:43, 100.81s/it][A
 60%|██████    | 6/10 [10:05<06:43, 100.82s/it][A
 60%|██████    | 6/10 [10:05<06:43, 100.82s/it][A
 70%|███████   | 7/10 [11:45<05:01, 100.64s/it][A[2024-05-30 00:10:16,536] [INFO] [logging.py:96:log_dist] [Rank 0] step=487, skipped=0, lr=[1.984080575435488e-05], mom=[(0.9, 0.999)]
steps: 487 loss: 0.5477 iter time (s): 99.464 samples/sec: 1.287

 70%|███████   | 7/10 [11:45<05:01, 100.61s/it][A
 70%|███████   | 7/10 [11:45<05:01, 100.62s/it][A
 70%|███████   | 7/10 [11:45<05:01, 100.62s/it][A
 70%|███████   | 7/10 [11:45<05:01, 100.61s/it][A
 70%|███████   | 7/10 [11:45<05:01, 100.62s/it][A
 70%|███████   | 7/10 [11:45<05:01, 100.62s/it][A
 70%|███████   | 7/10 [11:45<05:01, 100.62s/it][A
 80%|████████  | 8/10 [13:26<03:21, 100.66s/it][A[2024-05-30 00:11:57,243] [INFO] [logging.py:96:log_dist] [Rank 0] step=488, skipped=0, lr=[1.9839797579443077e-05], mom=[(0.9, 0.999)]
steps: 488 loss: 0.5611 iter time (s): 99.955 samples/sec: 1.281

 80%|████████  | 8/10 [13:26<03:21, 100.66s/it][A
 80%|████████  | 8/10 [13:26<03:21, 100.64s/it][A
 80%|████████  | 8/10 [13:26<03:21, 100.65s/it][A
 80%|████████  | 8/10 [13:26<03:21, 100.66s/it][A
 80%|████████  | 8/10 [13:26<03:21, 100.66s/it][A
 80%|████████  | 8/10 [13:26<03:21, 100.65s/it][A
 80%|████████  | 8/10 [13:26<03:21, 100.65s/it][A
 90%|█████████ | 9/10 [15:07<01:40, 100.82s/it][A[2024-05-30 00:13:38,437] [INFO] [logging.py:96:log_dist] [Rank 0] step=489, skipped=0, lr=[1.9838786248000787e-05], mom=[(0.9, 0.999)]
steps: 489 loss: 0.5757 iter time (s): 100.431 samples/sec: 1.275

 90%|█████████ | 9/10 [15:07<01:40, 100.83s/it][A
 90%|█████████ | 9/10 [15:07<01:40, 100.80s/it][A
 90%|█████████ | 9/10 [15:07<01:40, 100.83s/it][A
 90%|█████████ | 9/10 [15:07<01:40, 100.82s/it][A
 90%|█████████ | 9/10 [15:07<01:40, 100.81s/it][A
 90%|█████████ | 9/10 [15:07<01:40, 100.82s/it][A
 90%|█████████ | 9/10 [15:07<01:40, 100.82s/it][A
100%|██████████| 10/10 [16:48<00:00, 100.90s/it][A100%|██████████| 10/10 [16:48<00:00, 100.87s/it]
[2024-05-30 00:15:19,508] [INFO] [logging.py:96:log_dist] [Rank 0] step=490, skipped=0, lr=[1.9837771760352463e-05], mom=[(0.9, 0.999)]
steps: 490 loss: 0.5535 iter time (s): 100.323 samples/sec: 1.276

100%|██████████| 10/10 [16:48<00:00, 100.89s/it][A100%|██████████| 10/10 [16:48<00:00, 100.83s/it]

100%|██████████| 10/10 [16:48<00:00, 100.88s/it][A100%|██████████| 10/10 [16:48<00:00, 100.83s/it]

100%|██████████| 10/10 [16:48<00:00, 100.88s/it][A100%|██████████| 10/10 [16:48<00:00, 100.82s/it]

100%|██████████| 10/10 [16:48<00:00, 100.90s/it][A100%|██████████| 10/10 [16:48<00:00, 100.83s/it]

100%|██████████| 10/10 [16:48<00:00, 100.88s/it][A100%|██████████| 10/10 [16:48<00:00, 100.83s/it]

100%|██████████| 10/10 [16:48<00:00, 100.90s/it][A100%|██████████| 10/10 [16:48<00:00, 100.83s/it]

100%|██████████| 10/10 [16:48<00:00, 100.89s/it][A100%|██████████| 10/10 [16:48<00:00, 100.83s/it]
Checkpointing at shard 50
[2024-05-30 00:15:20,240] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step490 is about to be saved!
[2024-05-30 00:15:21,888] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step490/layer_00-model_states.pt...
[2024-05-30 00:15:24,678] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step490/layer_00-model_states.pt.
[2024-05-30 00:15:29,947] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step490/layer_04-model_states.pt...
[2024-05-30 00:15:30,704] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step490/layer_05-model_states.pt...
[2024-05-30 00:15:31,773] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step490/layer_03-model_states.pt...
[2024-05-30 00:15:32,107] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step490/layer_02-model_states.pt...
[2024-05-30 00:15:33,559] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step490/layer_06-model_states.pt...
[2024-05-30 00:15:34,260] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step490/layer_08-model_states.pt...
[2024-05-30 00:15:34,615] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step490/layer_07-model_states.pt...
[2024-05-30 00:15:36,740] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step490/layer_01-model_states.pt...
[2024-05-30 00:21:31,305] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step490/layer_03-model_states.pt.
[2024-05-30 00:21:32,099] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step490/mp_rank_02_model_states.pt...
[2024-05-30 00:21:32,255] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step490/mp_rank_02_model_states.pt.
[2024-05-30 00:21:32,255] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step490 is ready now!
[2024-05-30 00:21:32,508] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step490/layer_04-model_states.pt.
[2024-05-30 00:21:32,535] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step490/layer_01-model_states.pt.
[2024-05-30 00:21:32,560] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step490/layer_06-model_states.pt.
[2024-05-30 00:21:32,571] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step490/layer_05-model_states.pt.
[2024-05-30 00:21:32,601] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step490/layer_08-model_states.pt.
[2024-05-30 00:21:32,626] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step490/layer_07-model_states.pt.
[2024-05-30 00:21:33,351] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step490/mp_rank_04_model_states.pt...
[2024-05-30 00:21:33,435] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step490/mp_rank_04_model_states.pt.
[2024-05-30 00:21:33,435] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step490 is ready now!
[2024-05-30 00:21:33,488] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step490/mp_rank_00_model_states.pt
[2024-05-30 00:21:33,488] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step490/mp_rank_00_model_states.pt...
[2024-05-30 00:21:34,000] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step490/mp_rank_00_model_states.pt.
[2024-05-30 00:21:34,000] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step490 is ready now!
[2024-05-30 00:21:34,093] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step490/mp_rank_03_model_states.pt...
[2024-05-30 00:21:34,359] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step490/mp_rank_03_model_states.pt.
[2024-05-30 00:21:34,359] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step490 is ready now!
[2024-05-30 00:21:34,766] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step490/layer_09-model_states.pt...
[2024-05-30 00:21:34,949] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step490/mp_rank_05_model_states.pt...
[2024-05-30 00:21:35,064] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step490/mp_rank_06_model_states.pt...
[2024-05-30 00:21:35,084] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step490/mp_rank_05_model_states.pt.
[2024-05-30 00:21:35,085] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step490 is ready now!
[2024-05-30 00:21:35,236] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step490/mp_rank_06_model_states.pt.
[2024-05-30 00:21:35,237] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step490 is ready now!
[2024-05-30 00:21:36,027] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step490/layer_09-model_states.pt.
[2024-05-30 00:21:36,036] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step490/mp_rank_07_model_states.pt...
[2024-05-30 00:21:36,140] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step490/mp_rank_07_model_states.pt.
[2024-05-30 00:21:36,141] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step490 is ready now!
[2024-05-30 00:21:36,299] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step490/layer_02-model_states.pt.
[2024-05-30 00:21:37,408] [INFO] [logging.py:96:log_dist] [Rank 1] Saving model checkpoint: /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step490/mp_rank_01_model_states.pt
[2024-05-30 00:21:37,409] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step490/mp_rank_01_model_states.pt...
[2024-05-30 00:21:37,516] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step490/mp_rank_01_model_states.pt.
[2024-05-30 00:21:37,516] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step490 is ready now!
Checkpoint saved using --- 377.27717113494873 seconds ---
 10%|▉         | 50/520 [2:28:42<87:22:27, 669.25s/it] 10%|▉         | 50/520 [2:28:49<87:19:29, 668.87s/it] 10%|▉         | 50/520 [2:26:36<87:08:33, 667.47s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_89
 10%|▉         | 50/520 [2:27:41<87:13:56, 668.16s/it] 10%|▉         | 50/520 [2:28:13<87:16:52, 668.54s/it] 10%|▉         | 50/520 [2:28:08<87:16:01, 668.43s/it] 10%|▉         | 50/520 [2:28:52<87:19:31, 668.88s/it] 10%|▉         | 50/520 [2:28:50<87:19:44, 668.90s/it]Training on 1280 of 1280 sentences.

  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
 10%|█         | 1/10 [01:11<10:40, 71.12s/it][A[2024-05-30 00:22:50,256] [INFO] [logging.py:96:log_dist] [Rank 0] step=491, skipped=0, lr=[1.983675411682358e-05], mom=[(0.9, 0.999)]
steps: 491 loss: 1.2018 iter time (s): 72.687 samples/sec: 1.761

 10%|█         | 1/10 [01:13<10:57, 73.09s/it][A
 10%|█         | 1/10 [01:13<10:58, 73.19s/it][A
 10%|█         | 1/10 [01:13<10:59, 73.33s/it][A
 10%|█         | 1/10 [01:13<11:00, 73.42s/it][A
 10%|█         | 1/10 [01:13<11:00, 73.43s/it][A
 10%|█         | 1/10 [01:13<11:01, 73.50s/it][A
 10%|█         | 1/10 [01:13<11:01, 73.51s/it][A
 20%|██        | 2/10 [02:26<09:47, 73.38s/it][A[2024-05-30 00:24:05,213] [INFO] [logging.py:96:log_dist] [Rank 0] step=492, skipped=0, lr=[1.9835733317740626e-05], mom=[(0.9, 0.999)]
steps: 492 loss: 1.1835 iter time (s): 74.168 samples/sec: 1.726

 20%|██        | 2/10 [02:28<09:53, 74.20s/it][A
 20%|██        | 2/10 [02:28<09:53, 74.21s/it][A
 20%|██        | 2/10 [02:28<09:54, 74.29s/it][A
 20%|██        | 2/10 [02:28<09:54, 74.31s/it][A
 20%|██        | 2/10 [02:28<09:54, 74.33s/it][A
 20%|██        | 2/10 [02:28<09:54, 74.34s/it][A
 20%|██        | 2/10 [02:28<09:54, 74.35s/it][A
 30%|███       | 3/10 [03:41<08:39, 74.23s/it][A[2024-05-30 00:25:20,482] [INFO] [logging.py:96:log_dist] [Rank 0] step=493, skipped=0, lr=[1.98347093634311e-05], mom=[(0.9, 0.999)]
steps: 493 loss: 1.1648 iter time (s): 74.503 samples/sec: 1.718

 30%|███       | 3/10 [03:43<08:42, 74.66s/it][A
 30%|███       | 3/10 [03:43<08:42, 74.70s/it][A
 30%|███       | 3/10 [03:43<08:42, 74.70s/it][A
 30%|███       | 3/10 [03:43<08:42, 74.70s/it][A
 30%|███       | 3/10 [03:43<08:43, 74.73s/it][A
 30%|███       | 3/10 [03:43<08:43, 74.73s/it][A
 30%|███       | 3/10 [03:43<08:43, 74.74s/it][A
 40%|████      | 4/10 [04:55<07:26, 74.39s/it][A[2024-05-30 00:26:35,118] [INFO] [logging.py:96:log_dist] [Rank 0] step=494, skipped=0, lr=[1.983368225422351e-05], mom=[(0.9, 0.999)]
steps: 494 loss: 1.1755 iter time (s): 73.962 samples/sec: 1.731

 40%|████      | 4/10 [04:57<07:27, 74.63s/it][A
 40%|████      | 4/10 [04:58<07:28, 74.67s/it][A
 40%|████      | 4/10 [04:58<07:28, 74.69s/it][A
 40%|████      | 4/10 [04:58<07:28, 74.68s/it][A
 40%|████      | 4/10 [04:58<07:28, 74.71s/it][A
 40%|████      | 4/10 [04:58<07:28, 74.71s/it][A
 40%|████      | 4/10 [04:58<07:28, 74.70s/it][A
 50%|█████     | 5/10 [06:09<06:10, 74.12s/it][A[2024-05-30 00:27:48,548] [INFO] [logging.py:96:log_dist] [Rank 0] step=495, skipped=0, lr=[1.9832651990447372e-05], mom=[(0.9, 0.999)]
steps: 495 loss: 1.1881 iter time (s): 72.748 samples/sec: 1.759

 50%|█████     | 5/10 [06:11<06:11, 74.22s/it][A
 50%|█████     | 5/10 [06:11<06:11, 74.22s/it][A
 50%|█████     | 5/10 [06:11<06:11, 74.23s/it][A
 50%|█████     | 5/10 [06:11<06:11, 74.24s/it][A
 50%|█████     | 5/10 [06:11<06:11, 74.26s/it][A
 50%|█████     | 5/10 [06:11<06:11, 74.25s/it][A
 50%|█████     | 5/10 [06:11<06:11, 74.26s/it][A
 60%|██████    | 6/10 [07:24<04:56, 74.22s/it][A[2024-05-30 00:29:03,153] [INFO] [logging.py:96:log_dist] [Rank 0] step=496, skipped=0, lr=[1.9831618572433225e-05], mom=[(0.9, 0.999)]
steps: 496 loss: 1.1615 iter time (s): 73.874 samples/sec: 1.733

 60%|██████    | 6/10 [07:25<04:57, 74.36s/it][A
 60%|██████    | 6/10 [07:26<04:57, 74.34s/it][A
 60%|██████    | 6/10 [07:26<04:57, 74.38s/it][A
 60%|██████    | 6/10 [07:26<04:57, 74.38s/it][A
 60%|██████    | 6/10 [07:26<04:57, 74.38s/it][A
 60%|██████    | 6/10 [07:26<04:57, 74.37s/it][A
 60%|██████    | 6/10 [07:26<04:57, 74.38s/it][A
 70%|███████   | 7/10 [08:40<03:44, 74.81s/it][A[2024-05-30 00:30:19,167] [INFO] [logging.py:96:log_dist] [Rank 0] step=497, skipped=0, lr=[1.9830582000512618e-05], mom=[(0.9, 0.999)]
steps: 497 loss: 1.1233 iter time (s): 75.512 samples/sec: 1.695

 70%|███████   | 7/10 [08:42<03:44, 74.95s/it][A
 70%|███████   | 7/10 [08:42<03:44, 74.97s/it][A
 70%|███████   | 7/10 [08:42<03:44, 74.97s/it][A
 70%|███████   | 7/10 [08:42<03:44, 74.97s/it][A
 70%|███████   | 7/10 [08:42<03:44, 74.97s/it][A
 70%|███████   | 7/10 [08:42<03:44, 74.98s/it][A
 70%|███████   | 7/10 [08:42<03:44, 74.98s/it][A
 80%|████████  | 8/10 [09:54<02:29, 74.78s/it][A[2024-05-30 00:31:33,874] [INFO] [logging.py:96:log_dist] [Rank 0] step=498, skipped=0, lr=[1.9829542275018105e-05], mom=[(0.9, 0.999)]
steps: 498 loss: 1.1444 iter time (s): 73.804 samples/sec: 1.734

 80%|████████  | 8/10 [09:56<02:29, 74.81s/it][A
 80%|████████  | 8/10 [09:56<02:29, 74.82s/it][A
 80%|████████  | 8/10 [09:56<02:29, 74.81s/it][A
 80%|████████  | 8/10 [09:56<02:29, 74.82s/it][A
 80%|████████  | 8/10 [09:57<02:29, 74.82s/it][A
 80%|████████  | 8/10 [09:57<02:29, 74.83s/it][A
 80%|████████  | 8/10 [09:57<02:29, 74.82s/it][A
 90%|█████████ | 9/10 [11:09<01:14, 74.81s/it][A[2024-05-30 00:32:48,308] [INFO] [logging.py:96:log_dist] [Rank 0] step=499, skipped=0, lr=[1.9828499396283262e-05], mom=[(0.9, 0.999)]
steps: 499 loss: 1.1186 iter time (s): 73.728 samples/sec: 1.736

 90%|█████████ | 9/10 [11:11<01:14, 74.71s/it][A
 90%|█████████ | 9/10 [11:11<01:14, 74.69s/it][A
 90%|█████████ | 9/10 [11:11<01:14, 74.71s/it][A
 90%|█████████ | 9/10 [11:11<01:14, 74.70s/it][A
 90%|█████████ | 9/10 [11:11<01:14, 74.72s/it][A
 90%|█████████ | 9/10 [11:11<01:14, 74.71s/it][A
 90%|█████████ | 9/10 [11:11<01:14, 74.71s/it][A
100%|██████████| 10/10 [12:23<00:00, 74.49s/it][A100%|██████████| 10/10 [12:23<00:00, 74.34s/it]
 10%|▉         | 51/520 [2:41:06<89:09:45, 684.40s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A[2024-05-30 00:34:02,528] [INFO] [logging.py:96:log_dist] [Rank 0] step=500, skipped=0, lr=[1.982745336464266e-05], mom=[(0.9, 0.999)]
steps: 500 loss: 1.1071 iter time (s): 73.471 samples/sec: 1.742

100%|██████████| 10/10 [12:25<00:00, 74.54s/it][A100%|██████████| 10/10 [12:25<00:00, 74.53s/it]
 10%|▉         | 51/520 [2:40:38<89:08:21, 684.22s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [12:25<00:00, 74.54s/it][A100%|██████████| 10/10 [12:25<00:00, 74.54s/it]
 10%|▉         | 51/520 [2:41:15<89:10:48, 684.54s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [12:25<00:00, 74.53s/it][A100%|██████████| 10/10 [12:25<00:00, 74.55s/it]
 10%|▉         | 51/520 [2:41:14<89:10:47, 684.54s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [12:25<00:00, 74.54s/it][A100%|██████████| 10/10 [12:25<00:00, 74.56s/it]
 10%|▉         | 51/520 [2:40:07<89:06:31, 683.99s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [12:25<00:00, 74.53s/it][A100%|██████████| 10/10 [12:25<00:00, 74.56s/it]
 10%|▉         | 51/520 [2:40:34<89:08:14, 684.21s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [12:25<00:00, 74.54s/it][A100%|██████████| 10/10 [12:25<00:00, 74.57s/it]
 10%|▉         | 51/520 [2:41:17<89:11:04, 684.57s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [12:25<00:00, 74.54s/it][A100%|██████████| 10/10 [12:25<00:00, 74.57s/it]
 10%|▉         | 51/520 [2:39:02<89:02:23, 683.46s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_322
Training on 1280 of 1280 sentences.

  0%|          | 0/10 [00:00<?, ?it/s][A
 10%|█         | 1/10 [01:20<12:07, 80.79s/it][A[2024-05-30 00:35:23,508] [INFO] [logging.py:96:log_dist] [Rank 0] step=501, skipped=0, lr=[1.9826404180431897e-05], mom=[(0.9, 0.999)]
steps: 501 loss: 0.6058 iter time (s): 80.198 samples/sec: 1.596

 10%|█         | 1/10 [01:20<12:08, 80.97s/it][A
 10%|█         | 1/10 [01:20<12:08, 80.98s/it][A
 10%|█         | 1/10 [01:20<12:08, 81.00s/it][A
 10%|█         | 1/10 [01:21<12:09, 81.04s/it][A
 10%|█         | 1/10 [01:21<12:09, 81.00s/it][A
 10%|█         | 1/10 [01:21<12:09, 81.02s/it][A
 10%|█         | 1/10 [01:21<12:09, 81.02s/it][A
 20%|██        | 2/10 [02:41<10:45, 80.72s/it][A[2024-05-30 00:36:44,172] [INFO] [logging.py:96:log_dist] [Rank 0] step=502, skipped=0, lr=[1.9825351843987584e-05], mom=[(0.9, 0.999)]
steps: 502 loss: 0.5979 iter time (s): 79.930 samples/sec: 1.601

 20%|██        | 2/10 [02:41<10:46, 80.81s/it][A
 20%|██        | 2/10 [02:41<10:46, 80.85s/it][A
 20%|██        | 2/10 [02:41<10:46, 80.80s/it][A
 20%|██        | 2/10 [02:41<10:46, 80.85s/it][A
 20%|██        | 2/10 [02:41<10:46, 80.86s/it][A
 20%|██        | 2/10 [02:41<10:46, 80.86s/it][A
 20%|██        | 2/10 [02:41<10:46, 80.86s/it][A
 30%|███       | 3/10 [04:04<09:33, 81.90s/it][A[2024-05-30 00:38:07,489] [INFO] [logging.py:96:log_dist] [Rank 0] step=503, skipped=0, lr=[1.9824296355647327e-05], mom=[(0.9, 0.999)]
steps: 503 loss: 0.5994 iter time (s): 82.525 samples/sec: 1.551

 30%|███       | 3/10 [04:04<09:33, 81.96s/it][A
 30%|███       | 3/10 [04:05<09:34, 82.05s/it][A
 30%|███       | 3/10 [04:05<09:34, 82.06s/it][A
 30%|███       | 3/10 [04:05<09:34, 82.04s/it][A
 30%|███       | 3/10 [04:05<09:34, 82.07s/it][A
 30%|███       | 3/10 [04:05<09:34, 82.06s/it][A
 30%|███       | 3/10 [04:05<09:34, 82.07s/it][A
 40%|████      | 4/10 [05:25<08:08, 81.42s/it][A[2024-05-30 00:39:28,160] [INFO] [logging.py:96:log_dist] [Rank 0] step=504, skipped=0, lr=[1.9823237715749754e-05], mom=[(0.9, 0.999)]
steps: 504 loss: 0.5956 iter time (s): 79.675 samples/sec: 1.607

 40%|████      | 4/10 [05:25<08:08, 81.50s/it][A
 40%|████      | 4/10 [05:26<08:09, 81.59s/it][A
 40%|████      | 4/10 [05:26<08:09, 81.62s/it][A
 40%|████      | 4/10 [05:26<08:09, 81.59s/it][A
 40%|████      | 4/10 [05:26<08:09, 81.58s/it][A
 40%|████      | 4/10 [05:26<08:09, 81.60s/it][A
 40%|████      | 4/10 [05:26<08:09, 81.60s/it][A
 50%|█████     | 5/10 [06:48<06:49, 82.00s/it][A[2024-05-30 00:40:51,186] [INFO] [logging.py:96:log_dist] [Rank 0] step=505, skipped=0, lr=[1.9822175924634507e-05], mom=[(0.9, 0.999)]
steps: 505 loss: 0.5955 iter time (s): 81.884 samples/sec: 1.563

 50%|█████     | 5/10 [06:48<06:50, 82.04s/it][A
 50%|█████     | 5/10 [06:48<06:49, 81.95s/it][A
 50%|█████     | 5/10 [06:48<06:49, 81.96s/it][A
 50%|█████     | 5/10 [06:48<06:49, 81.98s/it][A
 50%|█████     | 5/10 [06:48<06:49, 81.97s/it][A
 50%|█████     | 5/10 [06:48<06:49, 81.98s/it][A
 50%|█████     | 5/10 [06:48<06:49, 81.97s/it][A
 60%|██████    | 6/10 [08:09<05:26, 81.68s/it][A[2024-05-30 00:42:12,251] [INFO] [logging.py:96:log_dist] [Rank 0] step=506, skipped=0, lr=[1.9821110982642234e-05], mom=[(0.9, 0.999)]
steps: 506 loss: 0.5970 iter time (s): 80.254 samples/sec: 1.595

 60%|██████    | 6/10 [08:09<05:26, 81.66s/it][A
 60%|██████    | 6/10 [08:09<05:26, 81.67s/it][A
 60%|██████    | 6/10 [08:09<05:26, 81.66s/it][A
 60%|██████    | 6/10 [08:09<05:26, 81.65s/it][A
 60%|██████    | 6/10 [08:09<05:26, 81.65s/it][A
 60%|██████    | 6/10 [08:09<05:26, 81.65s/it][A
 60%|██████    | 6/10 [08:09<05:26, 81.65s/it][A
 70%|███████   | 7/10 [09:29<04:03, 81.12s/it][A[2024-05-30 00:43:32,198] [INFO] [logging.py:96:log_dist] [Rank 0] step=507, skipped=0, lr=[1.9820042890114596e-05], mom=[(0.9, 0.999)]
steps: 507 loss: 0.5908 iter time (s): 79.191 samples/sec: 1.616

 70%|███████   | 7/10 [09:29<04:03, 81.12s/it][A
 70%|███████   | 7/10 [09:29<04:03, 81.13s/it][A
 70%|███████   | 7/10 [09:29<04:03, 81.10s/it][A
 70%|███████   | 7/10 [09:29<04:03, 81.11s/it][A
 70%|███████   | 7/10 [09:29<04:03, 81.11s/it][A
 70%|███████   | 7/10 [09:29<04:03, 81.12s/it][A
 70%|███████   | 7/10 [09:29<04:03, 81.11s/it][A
 80%|████████  | 8/10 [10:50<02:41, 80.96s/it][A[2024-05-30 00:44:52,363] [INFO] [logging.py:96:log_dist] [Rank 0] step=508, skipped=0, lr=[1.981897164739426e-05], mom=[(0.9, 0.999)]
steps: 508 loss: 0.6021 iter time (s): 79.327 samples/sec: 1.614

 80%|████████  | 8/10 [10:49<02:41, 80.80s/it][A
 80%|████████  | 8/10 [10:49<02:41, 80.82s/it][A
 80%|████████  | 8/10 [10:49<02:41, 80.79s/it][A
 80%|████████  | 8/10 [10:49<02:41, 80.79s/it][A
 80%|████████  | 8/10 [10:49<02:41, 80.79s/it][A
 80%|████████  | 8/10 [10:49<02:41, 80.80s/it][A
 80%|████████  | 8/10 [10:49<02:41, 80.79s/it][A
 90%|█████████ | 9/10 [12:10<01:20, 80.73s/it][A[2024-05-30 00:46:13,032] [INFO] [logging.py:96:log_dist] [Rank 0] step=509, skipped=0, lr=[1.981789725482491e-05], mom=[(0.9, 0.999)]
steps: 509 loss: 0.6061 iter time (s): 79.919 samples/sec: 1.602

 90%|█████████ | 9/10 [12:10<01:20, 80.79s/it][A
 90%|█████████ | 9/10 [12:10<01:20, 80.74s/it][A
 90%|█████████ | 9/10 [12:10<01:20, 80.77s/it][A
 90%|█████████ | 9/10 [12:10<01:20, 80.77s/it][A
 90%|█████████ | 9/10 [12:10<01:20, 80.76s/it][A
 90%|█████████ | 9/10 [12:10<01:20, 80.77s/it][A
 90%|█████████ | 9/10 [12:10<01:20, 80.77s/it][A
100%|██████████| 10/10 [13:30<00:00, 80.64s/it][A100%|██████████| 10/10 [13:30<00:00, 81.08s/it]
 10%|█         | 52/520 [2:54:36<92:41:04, 712.96s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A[2024-05-30 00:47:33,484] [INFO] [logging.py:96:log_dist] [Rank 0] step=510, skipped=0, lr=[1.9816819712751234e-05], mom=[(0.9, 0.999)]
steps: 510 loss: 0.6001 iter time (s): 79.622 samples/sec: 1.608

100%|██████████| 10/10 [13:30<00:00, 80.66s/it][A100%|██████████| 10/10 [13:30<00:00, 81.10s/it]
 10%|█         | 52/520 [2:54:09<92:40:21, 712.87s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:31<00:00, 80.67s/it][A100%|██████████| 10/10 [13:31<00:00, 81.11s/it]
 10%|█         | 52/520 [2:54:46<92:42:24, 713.13s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:31<00:00, 80.66s/it][A100%|██████████| 10/10 [13:31<00:00, 81.10s/it]
 10%|█         | 52/520 [2:54:45<92:42:18, 713.12s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:30<00:00, 80.65s/it][A100%|██████████| 10/10 [13:30<00:00, 81.10s/it]
 10%|█         | 52/520 [2:53:38<92:38:58, 712.69s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:31<00:00, 80.65s/it][A100%|██████████| 10/10 [13:31<00:00, 81.10s/it]
 10%|█         | 52/520 [2:54:05<92:40:20, 712.86s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:30<00:00, 80.65s/it][A100%|██████████| 10/10 [13:30<00:00, 81.10s/it]
 10%|█         | 52/520 [2:54:48<92:42:30, 713.14s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:31<00:00, 80.65s/it][A100%|██████████| 10/10 [13:31<00:00, 81.10s/it]
 10%|█         | 52/520 [2:52:33<92:35:51, 712.29s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_266
Training on 1280 of 1280 sentences.

  0%|          | 0/10 [00:00<?, ?it/s][A
 10%|█         | 1/10 [01:21<12:10, 81.19s/it][A[2024-05-30 00:48:54,546] [INFO] [logging.py:96:log_dist] [Rank 0] step=511, skipped=0, lr=[1.981573902151894e-05], mom=[(0.9, 0.999)]
steps: 511 loss: 0.5027 iter time (s): 80.228 samples/sec: 1.595

 10%|█         | 1/10 [01:21<12:09, 81.10s/it][A
 10%|█         | 1/10 [01:20<12:08, 80.96s/it][A
 10%|█         | 1/10 [01:21<12:09, 81.07s/it][A
 10%|█         | 1/10 [01:21<12:09, 81.11s/it][A
 10%|█         | 1/10 [01:21<12:09, 81.09s/it][A
 10%|█         | 1/10 [01:21<12:10, 81.13s/it][A
 10%|█         | 1/10 [01:21<12:09, 81.09s/it][A
 20%|██        | 2/10 [02:42<10:47, 80.99s/it][A[2024-05-30 00:50:15,534] [INFO] [logging.py:96:log_dist] [Rank 0] step=512, skipped=0, lr=[1.9814655181474738e-05], mom=[(0.9, 0.999)]
steps: 512 loss: 0.5086 iter time (s): 80.175 samples/sec: 1.597

 20%|██        | 2/10 [02:42<10:47, 80.99s/it][A
 20%|██        | 2/10 [02:41<10:48, 81.01s/it][A
 20%|██        | 2/10 [02:42<10:48, 81.06s/it][A
 20%|██        | 2/10 [02:42<10:48, 81.04s/it][A
 20%|██        | 2/10 [02:42<10:48, 81.03s/it][A
 20%|██        | 2/10 [02:42<10:48, 81.05s/it][A
 20%|██        | 2/10 [02:42<10:48, 81.03s/it][A
 30%|███       | 3/10 [04:03<09:28, 81.24s/it][A[2024-05-30 00:51:37,230] [INFO] [logging.py:96:log_dist] [Rank 0] step=513, skipped=0, lr=[1.981356819296635e-05], mom=[(0.9, 0.999)]
steps: 513 loss: 0.4783 iter time (s): 80.911 samples/sec: 1.582

 30%|███       | 3/10 [04:03<09:29, 81.37s/it][A
 30%|███       | 3/10 [04:03<09:29, 81.36s/it][A
 30%|███       | 3/10 [04:03<09:29, 81.36s/it][A
 30%|███       | 3/10 [04:03<09:29, 81.38s/it][A
 30%|███       | 3/10 [04:03<09:29, 81.37s/it][A
 30%|███       | 3/10 [04:03<09:29, 81.37s/it][A
 30%|███       | 3/10 [04:03<09:29, 81.36s/it][A
 40%|████      | 4/10 [05:25<08:07, 81.31s/it][A[2024-05-30 00:52:58,648] [INFO] [logging.py:96:log_dist] [Rank 0] step=514, skipped=0, lr=[1.9812478056342504e-05], mom=[(0.9, 0.999)]
steps: 514 loss: 0.5054 iter time (s): 80.570 samples/sec: 1.589

 40%|████      | 4/10 [05:25<08:08, 81.36s/it][A
 40%|████      | 4/10 [05:25<08:08, 81.35s/it][A
 40%|████      | 4/10 [05:25<08:08, 81.36s/it][A
 40%|████      | 4/10 [05:25<08:08, 81.36s/it][A
 40%|████      | 4/10 [05:25<08:08, 81.37s/it][A
 40%|████      | 4/10 [05:25<08:08, 81.36s/it][A
 40%|████      | 4/10 [05:25<08:08, 81.36s/it][A
 50%|█████     | 5/10 [06:46<06:47, 81.46s/it][A[2024-05-30 00:54:20,365] [INFO] [logging.py:96:log_dist] [Rank 0] step=515, skipped=0, lr=[1.9811384771952954e-05], mom=[(0.9, 0.999)]
steps: 515 loss: 0.4882 iter time (s): 80.912 samples/sec: 1.582

 50%|█████     | 5/10 [06:46<06:47, 81.49s/it][A
 50%|█████     | 5/10 [06:46<06:47, 81.50s/it][A
 50%|█████     | 5/10 [06:46<06:47, 81.49s/it][A
 50%|█████     | 5/10 [06:46<06:47, 81.47s/it][A
 50%|█████     | 5/10 [06:46<06:47, 81.48s/it][A
 50%|█████     | 5/10 [06:46<06:47, 81.48s/it][A
 50%|█████     | 5/10 [06:46<06:47, 81.50s/it][A
 60%|██████    | 6/10 [08:08<05:26, 81.69s/it][A[2024-05-30 00:55:42,484] [INFO] [logging.py:96:log_dist] [Rank 0] step=516, skipped=0, lr=[1.9810288340148445e-05], mom=[(0.9, 0.999)]
steps: 516 loss: 0.4950 iter time (s): 81.356 samples/sec: 1.573

 60%|██████    | 6/10 [08:09<05:27, 81.75s/it][A
 60%|██████    | 6/10 [08:08<05:26, 81.70s/it][A
 60%|██████    | 6/10 [08:09<05:26, 81.71s/it][A
 60%|██████    | 6/10 [08:09<05:26, 81.72s/it][A
 60%|██████    | 6/10 [08:09<05:26, 81.71s/it][A
 60%|██████    | 6/10 [08:09<05:26, 81.71s/it][A
 60%|██████    | 6/10 [08:09<05:26, 81.71s/it][A
 70%|███████   | 7/10 [09:31<04:06, 82.16s/it][A[2024-05-30 00:57:05,624] [INFO] [logging.py:96:log_dist] [Rank 0] step=517, skipped=0, lr=[1.9809188761280738e-05], mom=[(0.9, 0.999)]
steps: 517 loss: 0.4868 iter time (s): 82.337 samples/sec: 1.555

 70%|███████   | 7/10 [09:32<04:06, 82.15s/it][A
 70%|███████   | 7/10 [09:32<04:06, 82.17s/it][A
 70%|███████   | 7/10 [09:32<04:06, 82.18s/it][A
 70%|███████   | 7/10 [09:32<04:06, 82.15s/it][A
 70%|███████   | 7/10 [09:32<04:06, 82.18s/it][A
 70%|███████   | 7/10 [09:32<04:06, 82.16s/it][A
 70%|███████   | 7/10 [09:32<04:06, 82.16s/it][A
 80%|████████  | 8/10 [10:54<02:44, 82.28s/it][A[2024-05-30 00:58:28,174] [INFO] [logging.py:96:log_dist] [Rank 0] step=518, skipped=0, lr=[1.9808086035702618e-05], mom=[(0.9, 0.999)]
steps: 518 loss: 0.4929 iter time (s): 81.767 samples/sec: 1.565

 80%|████████  | 8/10 [10:54<02:44, 82.29s/it][A
 80%|████████  | 8/10 [10:54<02:44, 82.29s/it][A
 80%|████████  | 8/10 [10:54<02:44, 82.31s/it][A
 80%|████████  | 8/10 [10:54<02:44, 82.31s/it][A
 80%|████████  | 8/10 [10:54<02:44, 82.32s/it][A
 80%|████████  | 8/10 [10:54<02:44, 82.31s/it][A
 80%|████████  | 8/10 [10:54<02:44, 82.31s/it][A
 90%|█████████ | 9/10 [12:18<01:22, 82.75s/it][A[2024-05-30 00:59:51,977] [INFO] [logging.py:96:log_dist] [Rank 0] step=519, skipped=0, lr=[1.9806980163767848e-05], mom=[(0.9, 0.999)]
steps: 519 loss: 0.4784 iter time (s): 82.993 samples/sec: 1.542

 90%|█████████ | 9/10 [12:18<01:22, 82.78s/it][A
 90%|█████████ | 9/10 [12:18<01:22, 82.78s/it][A
 90%|█████████ | 9/10 [12:18<01:22, 82.78s/it][A
 90%|█████████ | 9/10 [12:18<01:22, 82.78s/it][A
 90%|█████████ | 9/10 [12:18<01:22, 82.78s/it][A
 90%|█████████ | 9/10 [12:18<01:22, 82.78s/it][A
 90%|█████████ | 9/10 [12:18<01:22, 82.77s/it][A
100%|██████████| 10/10 [13:41<00:00, 82.89s/it][A100%|██████████| 10/10 [13:41<00:00, 82.15s/it]
 10%|█         | 53/520 [3:08:18<95:55:44, 739.50s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A[2024-05-30 01:01:15,153] [INFO] [logging.py:96:log_dist] [Rank 0] step=520, skipped=0, lr=[1.9805871145831233e-05], mom=[(0.9, 0.999)]
steps: 520 loss: 0.4749 iter time (s): 82.364 samples/sec: 1.554

100%|██████████| 10/10 [13:41<00:00, 82.91s/it][A100%|██████████| 10/10 [13:41<00:00, 82.18s/it]
 10%|█         | 53/520 [3:07:51<95:55:24, 739.45s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:41<00:00, 82.92s/it][A100%|██████████| 10/10 [13:41<00:00, 82.18s/it]
 10%|█         | 53/520 [3:08:28<95:56:51, 739.64s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:41<00:00, 82.90s/it][A100%|██████████| 10/10 [13:41<00:00, 82.18s/it]
 10%|█         | 53/520 [3:08:27<95:56:47, 739.63s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:41<00:00, 82.91s/it][A100%|██████████| 10/10 [13:41<00:00, 82.18s/it]
 10%|█         | 53/520 [3:07:20<95:54:21, 739.32s/it]
100%|██████████| 10/10 [13:41<00:00, 82.90s/it][A100%|██████████| 10/10 [13:41<00:00, 82.17s/it]
 10%|█         | 53/520 [3:07:46<95:55:17, 739.44s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:41<00:00, 82.90s/it][A100%|██████████| 10/10 [13:41<00:00, 82.18s/it]
 10%|█         | 53/520 [3:08:30<95:56:59, 739.66s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:41<00:00, 82.90s/it][A100%|██████████| 10/10 [13:41<00:00, 82.17s/it]
 10%|█         | 53/520 [3:06:15<95:51:54, 739.00s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_426
Training on 1280 of 1280 sentences.

  0%|          | 0/10 [00:00<?, ?it/s][A
 10%|█         | 1/10 [01:07<10:11, 67.92s/it][A[2024-05-30 01:02:22,797] [INFO] [logging.py:96:log_dist] [Rank 0] step=521, skipped=0, lr=[1.980475898224857e-05], mom=[(0.9, 0.999)]
steps: 521 loss: 0.3567 iter time (s): 66.649 samples/sec: 1.921

 10%|█         | 1/10 [01:07<10:06, 67.41s/it][A
 10%|█         | 1/10 [01:07<10:07, 67.49s/it][A
 10%|█         | 1/10 [01:07<10:06, 67.44s/it][A
 10%|█         | 1/10 [01:07<10:07, 67.47s/it][A
 10%|█         | 1/10 [01:07<10:07, 67.47s/it][A
 10%|█         | 1/10 [01:07<10:07, 67.53s/it][A
 10%|█         | 1/10 [01:07<10:07, 67.48s/it][A
 20%|██        | 2/10 [02:17<09:11, 68.99s/it][A[2024-05-30 01:03:32,501] [INFO] [logging.py:96:log_dist] [Rank 0] step=522, skipped=0, lr=[1.9803643673376667e-05], mom=[(0.9, 0.999)]
steps: 522 loss: 0.3272 iter time (s): 69.004 samples/sec: 1.855

 20%|██        | 2/10 [02:17<09:10, 68.80s/it][A
 20%|██        | 2/10 [02:17<09:10, 68.78s/it][A
 20%|██        | 2/10 [02:17<09:10, 68.79s/it][A
 20%|██        | 2/10 [02:17<09:10, 68.76s/it][A
 20%|██        | 2/10 [02:17<09:10, 68.79s/it][A
 20%|██        | 2/10 [02:17<09:10, 68.80s/it][A
 20%|██        | 2/10 [02:17<09:10, 68.79s/it][A
 30%|███       | 3/10 [03:21<07:47, 66.83s/it][A[2024-05-30 01:04:36,785] [INFO] [logging.py:96:log_dist] [Rank 0] step=523, skipped=0, lr=[1.9802525219573343e-05], mom=[(0.9, 0.999)]
steps: 523 loss: 0.3152 iter time (s): 63.577 samples/sec: 2.013

 30%|███       | 3/10 [03:21<07:47, 66.72s/it][A
 30%|███       | 3/10 [03:21<07:46, 66.71s/it][A
 30%|███       | 3/10 [03:21<07:46, 66.71s/it][A
 30%|███       | 3/10 [03:21<07:46, 66.70s/it][A
 30%|███       | 3/10 [03:21<07:46, 66.70s/it][A
 30%|███       | 3/10 [03:21<07:46, 66.70s/it][A
 30%|███       | 3/10 [03:21<07:46, 66.71s/it][A
 40%|████      | 4/10 [04:26<06:34, 65.83s/it][A[2024-05-30 01:05:41,096] [INFO] [logging.py:96:log_dist] [Rank 0] step=524, skipped=0, lr=[1.9801403621197427e-05], mom=[(0.9, 0.999)]
steps: 524 loss: 0.3156 iter time (s): 63.673 samples/sec: 2.010

 40%|████      | 4/10 [04:25<06:34, 65.79s/it][A
 40%|████      | 4/10 [04:25<06:34, 65.76s/it][A
 40%|████      | 4/10 [04:25<06:34, 65.78s/it][A
 40%|████      | 4/10 [04:25<06:34, 65.76s/it][A

 40%|████      | 4/10 [04:25<06:34, 65.78s/it][A 40%|████      | 4/10 [04:25<06:34, 65.76s/it][A
 40%|████      | 4/10 [04:25<06:34, 65.76s/it][A
 50%|█████     | 5/10 [05:35<05:34, 66.95s/it][A[2024-05-30 01:06:50,039] [INFO] [logging.py:96:log_dist] [Rank 0] step=525, skipped=0, lr=[1.980027887860875e-05], mom=[(0.9, 0.999)]
steps: 525 loss: 0.3171 iter time (s): 68.300 samples/sec: 1.874

 50%|█████     | 5/10 [05:34<05:34, 66.93s/it][A
 50%|█████     | 5/10 [05:34<05:34, 66.89s/it][A
 50%|█████     | 5/10 [05:34<05:34, 66.93s/it][A
 50%|█████     | 5/10 [05:34<05:34, 66.91s/it][A
 50%|█████     | 5/10 [05:34<05:34, 66.91s/it][A
 50%|█████     | 5/10 [05:34<05:34, 66.91s/it][A
 50%|█████     | 5/10 [05:34<05:34, 66.91s/it][A
 60%|██████    | 6/10 [06:44<04:30, 67.71s/it][A[2024-05-30 01:07:59,209] [INFO] [logging.py:96:log_dist] [Rank 0] step=526, skipped=0, lr=[1.979915099216817e-05], mom=[(0.9, 0.999)]
steps: 526 loss: 0.3111 iter time (s): 68.541 samples/sec: 1.868

 60%|██████    | 6/10 [06:43<04:30, 67.69s/it][A
 60%|██████    | 6/10 [06:43<04:30, 67.69s/it][A
 60%|██████    | 6/10 [06:43<04:30, 67.68s/it][A
 60%|██████    | 6/10 [06:43<04:30, 67.69s/it][A
 60%|██████    | 6/10 [06:43<04:30, 67.71s/it][A
 60%|██████    | 6/10 [06:43<04:30, 67.71s/it][A
 60%|██████    | 6/10 [06:43<04:30, 67.70s/it][A
 70%|███████   | 7/10 [07:49<03:20, 66.90s/it][A[2024-05-30 01:09:04,442] [INFO] [logging.py:96:log_dist] [Rank 0] step=527, skipped=0, lr=[1.9798019962237527e-05], mom=[(0.9, 0.999)]
steps: 527 loss: 0.3076 iter time (s): 64.545 samples/sec: 1.983

 70%|███████   | 7/10 [07:49<03:20, 66.91s/it][A
 70%|███████   | 7/10 [07:49<03:20, 66.89s/it][A
 70%|███████   | 7/10 [07:49<03:20, 66.90s/it][A
 70%|███████   | 7/10 [07:49<03:20, 66.88s/it][A
 70%|███████   | 7/10 [07:49<03:20, 66.87s/it][A
 70%|███████   | 7/10 [07:49<03:20, 66.88s/it][A
 70%|███████   | 7/10 [07:49<03:20, 66.88s/it][A
 80%|████████  | 8/10 [08:55<02:13, 66.68s/it][A[2024-05-30 01:10:10,652] [INFO] [logging.py:96:log_dist] [Rank 0] step=528, skipped=0, lr=[1.979688578917969e-05], mom=[(0.9, 0.999)]
steps: 528 loss: 0.3126 iter time (s): 65.568 samples/sec: 1.952

 80%|████████  | 8/10 [08:55<02:13, 66.67s/it][A
 80%|████████  | 8/10 [08:55<02:13, 66.68s/it][A
 80%|████████  | 8/10 [08:55<02:13, 66.70s/it][A
 80%|████████  | 8/10 [08:55<02:13, 66.70s/it][A
 80%|████████  | 8/10 [08:55<02:13, 66.69s/it][A
 80%|████████  | 8/10 [08:55<02:13, 66.69s/it][A
 80%|████████  | 8/10 [08:55<02:13, 66.69s/it][A
 90%|█████████ | 9/10 [10:01<01:06, 66.53s/it][A[2024-05-30 01:11:16,849] [INFO] [logging.py:96:log_dist] [Rank 0] step=529, skipped=0, lr=[1.9795748473358537e-05], mom=[(0.9, 0.999)]
steps: 529 loss: 0.3214 iter time (s): 65.488 samples/sec: 1.955

 90%|█████████ | 9/10 [10:01<01:06, 66.51s/it][A
 90%|█████████ | 9/10 [10:01<01:06, 66.52s/it][A
 90%|█████████ | 9/10 [10:01<01:06, 66.53s/it][A
 90%|█████████ | 9/10 [10:01<01:06, 66.53s/it][A
 90%|█████████ | 9/10 [10:01<01:06, 66.53s/it][A
 90%|█████████ | 9/10 [10:01<01:06, 66.53s/it][A
 90%|█████████ | 9/10 [10:01<01:06, 66.53s/it][A
100%|██████████| 10/10 [11:07<00:00, 66.09s/it][A100%|██████████| 10/10 [11:07<00:00, 66.71s/it]
 10%|█         | 54/520 [3:19:25<93:18:16, 720.81s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A[2024-05-30 01:12:21,939] [INFO] [logging.py:96:log_dist] [Rank 0] step=530, skipped=0, lr=[1.9794608015138936e-05], mom=[(0.9, 0.999)]
steps: 530 loss: 0.2905 iter time (s): 64.386 samples/sec: 1.988

100%|██████████| 10/10 [11:06<00:00, 66.07s/it][A100%|██████████| 10/10 [11:06<00:00, 66.66s/it]
 10%|█         | 54/520 [3:18:57<93:16:53, 720.63s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [11:06<00:00, 66.09s/it][A100%|██████████| 10/10 [11:06<00:00, 66.66s/it]
 10%|█         | 54/520 [3:19:35<93:17:57, 720.77s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [11:06<00:00, 66.07s/it][A100%|██████████| 10/10 [11:06<00:00, 66.66s/it]
 10%|█         | 54/520 [3:19:34<93:17:56, 720.77s/it]
100%|██████████| 10/10 [11:06<00:00, 66.06s/it][A100%|██████████| 10/10 [11:06<00:00, 66.65s/it]
 10%|█         | 54/520 [3:18:26<93:15:56, 720.51s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [11:06<00:00, 66.08s/it][A100%|██████████| 10/10 [11:06<00:00, 66.67s/it]
 10%|█         | 54/520 [3:18:53<93:16:52, 720.63s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [11:06<00:00, 66.08s/it][A100%|██████████| 10/10 [11:06<00:00, 66.66s/it]
 10%|█         | 54/520 [3:19:37<93:18:04, 720.78s/it]
100%|██████████| 10/10 [11:06<00:00, 66.08s/it][A100%|██████████| 10/10 [11:06<00:00, 66.66s/it]
 10%|█         | 54/520 [3:17:22<93:14:17, 720.29s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_324

  0%|          | 0/10 [00:00<?, ?it/s][ATraining on 1280 of 1280 sentences.

  0%|          | 0/10 [00:00<?, ?it/s][A
 10%|█         | 1/10 [01:27<13:03, 87.11s/it][A[2024-05-30 01:13:49,822] [INFO] [logging.py:96:log_dist] [Rank 0] step=531, skipped=0, lr=[1.9793464414886774e-05], mom=[(0.9, 0.999)]
steps: 531 loss: 0.5885 iter time (s): 87.125 samples/sec: 1.469

 10%|█         | 1/10 [01:27<13:11, 87.92s/it][A
 10%|█         | 1/10 [01:27<13:11, 87.93s/it][A
 10%|█         | 1/10 [01:27<13:11, 87.99s/it][A
 10%|█         | 1/10 [01:28<13:12, 88.05s/it][A
 10%|█         | 1/10 [01:27<13:11, 87.98s/it][A
 10%|█         | 1/10 [01:28<13:12, 88.00s/it][A
 10%|█         | 1/10 [01:28<13:12, 88.05s/it][A
 20%|██        | 2/10 [02:50<11:17, 84.71s/it][A[2024-05-30 01:15:12,856] [INFO] [logging.py:96:log_dist] [Rank 0] step=532, skipped=0, lr=[1.9792317672968954e-05], mom=[(0.9, 0.999)]
steps: 532 loss: 0.5920 iter time (s): 82.180 samples/sec: 1.558

 20%|██        | 2/10 [02:50<11:20, 85.01s/it][A
 20%|██        | 2/10 [02:50<11:20, 85.03s/it][A
 20%|██        | 2/10 [02:50<11:20, 85.06s/it][A
 20%|██        | 2/10 [02:51<11:20, 85.06s/it][A
 20%|██        | 2/10 [02:50<11:20, 85.05s/it][A
 20%|██        | 2/10 [02:50<11:20, 85.05s/it][A
 20%|██        | 2/10 [02:51<11:20, 85.06s/it][A
 30%|███       | 3/10 [04:14<09:52, 84.62s/it][A[2024-05-30 01:16:37,376] [INFO] [logging.py:96:log_dist] [Rank 0] step=533, skipped=0, lr=[1.9791167789753372e-05], mom=[(0.9, 0.999)]
steps: 533 loss: 0.5998 iter time (s): 83.713 samples/sec: 1.529

 30%|███       | 3/10 [04:15<09:53, 84.81s/it][A
 30%|███       | 3/10 [04:15<09:53, 84.76s/it][A
 30%|███       | 3/10 [04:15<09:53, 84.82s/it][A
 30%|███       | 3/10 [04:15<09:53, 84.82s/it][A
 30%|███       | 3/10 [04:15<09:53, 84.79s/it][A
 30%|███       | 3/10 [04:15<09:53, 84.80s/it][A
 30%|███       | 3/10 [04:15<09:53, 84.80s/it][A
 40%|████      | 4/10 [05:44<08:40, 86.73s/it][A[2024-05-30 01:18:07,322] [INFO] [logging.py:96:log_dist] [Rank 0] step=534, skipped=0, lr=[1.9790014765608948e-05], mom=[(0.9, 0.999)]
steps: 534 loss: 0.6045 iter time (s): 89.168 samples/sec: 1.435

 40%|████      | 4/10 [05:45<08:40, 86.82s/it][A
 40%|████      | 4/10 [05:45<08:40, 86.81s/it][A
 40%|████      | 4/10 [05:45<08:41, 86.85s/it][A
 40%|████      | 4/10 [05:45<08:41, 86.85s/it][A
 40%|████      | 4/10 [05:45<08:41, 86.91s/it][A
 40%|████      | 4/10 [05:45<08:41, 86.90s/it][A
 40%|████      | 4/10 [05:45<08:41, 86.89s/it][A
 50%|█████     | 5/10 [07:08<07:08, 85.69s/it][A[2024-05-30 01:19:31,184] [INFO] [logging.py:96:log_dist] [Rank 0] step=535, skipped=0, lr=[1.978885860090559e-05], mom=[(0.9, 0.999)]
steps: 535 loss: 0.6024 iter time (s): 82.924 samples/sec: 1.544

 50%|█████     | 5/10 [07:09<07:08, 85.77s/it][A
 50%|█████     | 5/10 [07:09<07:08, 85.76s/it][A
 50%|█████     | 5/10 [07:09<07:08, 85.77s/it][A
 50%|█████     | 5/10 [07:09<07:08, 85.75s/it][A
 50%|█████     | 5/10 [07:09<07:08, 85.75s/it][A
 50%|█████     | 5/10 [07:09<07:08, 85.75s/it][A
 50%|█████     | 5/10 [07:09<07:08, 85.77s/it][A
 60%|██████    | 6/10 [08:30<05:38, 84.57s/it][A[2024-05-30 01:20:53,567] [INFO] [logging.py:96:log_dist] [Rank 0] step=536, skipped=0, lr=[1.9787699296014235e-05], mom=[(0.9, 0.999)]
steps: 536 loss: 0.5945 iter time (s): 81.571 samples/sec: 1.569

 60%|██████    | 6/10 [08:31<05:38, 84.60s/it][A
 60%|██████    | 6/10 [08:31<05:38, 84.65s/it][A
 60%|██████    | 6/10 [08:31<05:38, 84.62s/it][A
 60%|██████    | 6/10 [08:31<05:38, 84.63s/it][A
 60%|██████    | 6/10 [08:31<05:38, 84.60s/it][A
 60%|██████    | 6/10 [08:31<05:38, 84.62s/it][A
 60%|██████    | 6/10 [08:31<05:38, 84.61s/it][A
 70%|███████   | 7/10 [09:51<04:10, 83.42s/it][A[2024-05-30 01:22:14,617] [INFO] [logging.py:96:log_dist] [Rank 0] step=537, skipped=0, lr=[1.9786536851306807e-05], mom=[(0.9, 0.999)]
steps: 537 loss: 0.5960 iter time (s): 80.239 samples/sec: 1.595

 70%|███████   | 7/10 [09:52<04:10, 83.46s/it][A
 70%|███████   | 7/10 [09:52<04:10, 83.44s/it][A
 70%|███████   | 7/10 [09:52<04:10, 83.44s/it][A
 70%|███████   | 7/10 [09:52<04:10, 83.44s/it][A
 70%|███████   | 7/10 [09:52<04:10, 83.44s/it][A
 70%|███████   | 7/10 [09:52<04:10, 83.44s/it][A
 70%|███████   | 7/10 [09:52<04:10, 83.44s/it][A
 80%|████████  | 8/10 [11:13<02:45, 82.88s/it][A[2024-05-30 01:23:36,342] [INFO] [logging.py:96:log_dist] [Rank 0] step=538, skipped=0, lr=[1.978537126715625e-05], mom=[(0.9, 0.999)]
steps: 538 loss: 0.5982 iter time (s): 80.950 samples/sec: 1.581

 80%|████████  | 8/10 [11:14<02:45, 82.92s/it][A
 80%|████████  | 8/10 [11:14<02:45, 82.91s/it][A
 80%|████████  | 8/10 [11:14<02:45, 82.91s/it][A
 80%|████████  | 8/10 [11:14<02:45, 82.90s/it][A
 80%|████████  | 8/10 [11:14<02:45, 82.89s/it][A
 80%|████████  | 8/10 [11:14<02:45, 82.91s/it][A
 80%|████████  | 8/10 [11:14<02:45, 82.90s/it][A
 90%|█████████ | 9/10 [12:37<01:23, 83.08s/it][A[2024-05-30 01:24:59,856] [INFO] [logging.py:96:log_dist] [Rank 0] step=539, skipped=0, lr=[1.978420254393652e-05], mom=[(0.9, 0.999)]
steps: 539 loss: 0.5868 iter time (s): 82.691 samples/sec: 1.548

 90%|█████████ | 9/10 [12:37<01:23, 83.08s/it][A
 90%|█████████ | 9/10 [12:37<01:23, 83.09s/it][A
 90%|█████████ | 9/10 [12:37<01:23, 83.08s/it][A
 90%|█████████ | 9/10 [12:38<01:23, 83.08s/it][A
 90%|█████████ | 9/10 [12:37<01:23, 83.09s/it][A
 90%|█████████ | 9/10 [12:37<01:23, 83.09s/it][A
 90%|█████████ | 9/10 [12:38<01:23, 83.09s/it][A
100%|██████████| 10/10 [13:59<00:00, 82.73s/it][A100%|██████████| 10/10 [13:59<00:00, 83.91s/it]
[2024-05-30 01:26:21,828] [INFO] [logging.py:96:log_dist] [Rank 0] step=540, skipped=0, lr=[1.9783030682022566e-05], mom=[(0.9, 0.999)]
steps: 540 loss: 0.5786 iter time (s): 81.190 samples/sec: 1.577

100%|██████████| 10/10 [13:59<00:00, 82.74s/it][A100%|██████████| 10/10 [13:59<00:00, 83.99s/it]

100%|██████████| 10/10 [13:59<00:00, 82.74s/it][A100%|██████████| 10/10 [13:59<00:00, 83.99s/it]

100%|██████████| 10/10 [13:59<00:00, 82.74s/it][A100%|██████████| 10/10 [13:59<00:00, 83.99s/it]

100%|██████████| 10/10 [14:00<00:00, 82.76s/it][A100%|██████████| 10/10 [14:00<00:00, 84.01s/it]

100%|██████████| 10/10 [13:59<00:00, 82.75s/it][A100%|██████████| 10/10 [13:59<00:00, 83.99s/it]

100%|██████████| 10/10 [13:59<00:00, 82.74s/it][A100%|██████████| 10/10 [13:59<00:00, 84.00s/it]

100%|██████████| 10/10 [13:59<00:00, 82.75s/it][A100%|██████████| 10/10 [13:59<00:00, 84.00s/it]
Checkpointing at shard 55
[2024-05-30 01:26:22,660] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step540 is about to be saved!
[2024-05-30 01:26:24,164] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step540/layer_00-model_states.pt...
[2024-05-30 01:26:26,907] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step540/layer_00-model_states.pt.
[2024-05-30 01:26:31,338] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step540/layer_04-model_states.pt...
[2024-05-30 01:26:32,238] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step540/layer_03-model_states.pt...
[2024-05-30 01:26:33,129] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step540/layer_02-model_states.pt...
[2024-05-30 01:26:35,340] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step540/layer_06-model_states.pt...
[2024-05-30 01:26:35,357] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step540/layer_05-model_states.pt...
[2024-05-30 01:26:38,336] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step540/layer_01-model_states.pt...
[2024-05-30 01:26:41,725] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step540/layer_07-model_states.pt...
[2024-05-30 01:26:41,860] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step540/layer_08-model_states.pt...
[2024-05-30 01:30:09,736] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step540/layer_06-model_states.pt.
[2024-05-30 01:30:10,349] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step540/mp_rank_05_model_states.pt...
[2024-05-30 01:30:10,612] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step540/mp_rank_05_model_states.pt.
[2024-05-30 01:30:10,612] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step540 is ready now!
[2024-05-30 01:30:13,428] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step540/layer_05-model_states.pt.
[2024-05-30 01:30:14,048] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step540/mp_rank_04_model_states.pt...
[2024-05-30 01:30:14,246] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step540/mp_rank_04_model_states.pt.
[2024-05-30 01:30:14,247] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step540 is ready now!
[2024-05-30 01:30:14,409] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step540/layer_01-model_states.pt.
[2024-05-30 01:30:14,433] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step540/layer_04-model_states.pt.
[2024-05-30 01:30:14,450] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step540/layer_08-model_states.pt.
[2024-05-30 01:30:14,473] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step540/layer_07-model_states.pt.
[2024-05-30 01:30:14,535] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step540/layer_02-model_states.pt.
[2024-05-30 01:30:14,544] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step540/layer_03-model_states.pt.
[2024-05-30 01:30:15,085] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step540/mp_rank_03_model_states.pt...
[2024-05-30 01:30:15,165] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step540/mp_rank_00_model_states.pt
[2024-05-30 01:30:15,165] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step540/mp_rank_00_model_states.pt...
[2024-05-30 01:30:15,233] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step540/mp_rank_03_model_states.pt.
[2024-05-30 01:30:15,234] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step540 is ready now!
[2024-05-30 01:30:15,435] [INFO] [logging.py:96:log_dist] [Rank 1] Saving model checkpoint: /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step540/mp_rank_01_model_states.pt
[2024-05-30 01:30:15,435] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step540/mp_rank_01_model_states.pt...
[2024-05-30 01:30:15,578] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step540/mp_rank_01_model_states.pt.
[2024-05-30 01:30:15,579] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step540 is ready now!
[2024-05-30 01:30:15,581] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step540/mp_rank_06_model_states.pt...
[2024-05-30 01:30:15,620] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step540/mp_rank_02_model_states.pt...
[2024-05-30 01:30:15,641] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step540/layer_09-model_states.pt...
[2024-05-30 01:30:15,731] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step540/mp_rank_06_model_states.pt.
[2024-05-30 01:30:15,732] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step540 is ready now!
[2024-05-30 01:30:15,771] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step540/mp_rank_02_model_states.pt.
[2024-05-30 01:30:15,771] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step540 is ready now!
[2024-05-30 01:30:15,801] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step540/mp_rank_00_model_states.pt.
[2024-05-30 01:30:15,802] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step540 is ready now!
[2024-05-30 01:30:16,390] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step540/layer_09-model_states.pt.
[2024-05-30 01:30:16,400] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step540/mp_rank_07_model_states.pt...
[2024-05-30 01:30:16,514] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step540/mp_rank_07_model_states.pt.
[2024-05-30 01:30:16,514] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step540 is ready now!
Checkpoint saved using --- 233.85586738586426 seconds ---
 11%|█         | 55/520 [3:36:47<105:23:12, 815.90s/it] 11%|█         | 55/520 [3:37:30<105:24:01, 816.00s/it] 11%|█         | 55/520 [3:36:20<105:22:48, 815.85s/it] 11%|█         | 55/520 [3:36:52<105:23:59, 816.00s/it] 11%|█         | 55/520 [3:35:15<105:21:15, 815.65s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_74
 11%|█         | 55/520 [3:37:21<105:28:27, 816.58s/it] 11%|█         | 55/520 [3:37:28<105:24:17, 816.04s/it] 11%|█         | 55/520 [3:37:29<105:24:29, 816.06s/it]

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s][ATraining on 1280 of 1280 sentences.

  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
 10%|█         | 1/10 [01:15<11:18, 75.40s/it][A[2024-05-30 01:31:33,830] [INFO] [logging.py:96:log_dist] [Rank 0] step=541, skipped=0, lr=[1.9781855681790346e-05], mom=[(0.9, 0.999)]
steps: 541 loss: 1.1572 iter time (s): 76.943 samples/sec: 1.664

 10%|█         | 1/10 [01:17<11:36, 77.38s/it][A
 10%|█         | 1/10 [01:17<11:37, 77.48s/it][A
 10%|█         | 1/10 [01:17<11:38, 77.63s/it][A
 10%|█         | 1/10 [01:17<11:38, 77.65s/it][A
 10%|█         | 1/10 [01:17<11:39, 77.71s/it][A
 10%|█         | 1/10 [01:17<11:39, 77.76s/it][A
 10%|█         | 1/10 [01:17<11:40, 77.78s/it][A
 20%|██        | 2/10 [02:31<10:07, 75.94s/it][A[2024-05-30 01:32:50,136] [INFO] [logging.py:96:log_dist] [Rank 0] step=542, skipped=0, lr=[1.9780677543616837e-05], mom=[(0.9, 0.999)]
steps: 542 loss: 1.1457 iter time (s): 75.667 samples/sec: 1.692

 20%|██        | 2/10 [02:33<10:13, 76.75s/it][A
 20%|██        | 2/10 [02:33<10:14, 76.82s/it][A
 20%|██        | 2/10 [02:34<10:15, 76.89s/it][A
 20%|██        | 2/10 [02:34<10:15, 76.93s/it][A
 20%|██        | 2/10 [02:34<10:15, 76.95s/it][A
 20%|██        | 2/10 [02:34<10:15, 76.95s/it][A
 20%|██        | 2/10 [02:34<10:15, 76.97s/it][A
 30%|███       | 3/10 [03:47<08:51, 75.97s/it][A[2024-05-30 01:34:06,152] [INFO] [logging.py:96:log_dist] [Rank 0] step=543, skipped=0, lr=[1.9779496267880012e-05], mom=[(0.9, 0.999)]
steps: 543 loss: 1.1272 iter time (s): 75.186 samples/sec: 1.702

 30%|███       | 3/10 [03:49<08:54, 76.40s/it][A
 30%|███       | 3/10 [03:49<08:54, 76.42s/it][A
 30%|███       | 3/10 [03:49<08:55, 76.45s/it][A
 30%|███       | 3/10 [03:49<08:55, 76.47s/it][A
 30%|███       | 3/10 [03:50<08:55, 76.50s/it][A
 30%|███       | 3/10 [03:50<08:55, 76.51s/it][A
 30%|███       | 3/10 [03:50<08:55, 76.50s/it][A
 40%|████      | 4/10 [05:01<07:31, 75.21s/it][A[2024-05-30 01:35:20,188] [INFO] [logging.py:96:log_dist] [Rank 0] step=544, skipped=0, lr=[1.9778311854958855e-05], mom=[(0.9, 0.999)]
steps: 544 loss: 1.1315 iter time (s): 73.254 samples/sec: 1.747

 40%|████      | 4/10 [05:03<07:32, 75.48s/it][A
 40%|████      | 4/10 [05:03<07:32, 75.47s/it][A
 40%|████      | 4/10 [05:03<07:32, 75.50s/it][A
 40%|████      | 4/10 [05:03<07:32, 75.49s/it][A
 40%|████      | 4/10 [05:04<07:33, 75.51s/it][A
 40%|████      | 4/10 [05:04<07:33, 75.52s/it][A
 40%|████      | 4/10 [05:04<07:33, 75.51s/it][A
 50%|█████     | 5/10 [06:15<06:14, 74.80s/it][A[2024-05-30 01:36:34,277] [INFO] [logging.py:96:log_dist] [Rank 0] step=545, skipped=0, lr=[1.9777124305233354e-05], mom=[(0.9, 0.999)]
steps: 545 loss: 1.1378 iter time (s): 73.343 samples/sec: 1.745

 50%|█████     | 5/10 [06:17<06:14, 74.97s/it][A
 50%|█████     | 5/10 [06:17<06:14, 74.97s/it][A
 50%|█████     | 5/10 [06:17<06:14, 74.97s/it][A
 50%|█████     | 5/10 [06:18<06:15, 75.00s/it][A
 50%|█████     | 5/10 [06:18<06:14, 74.99s/it][A
 50%|█████     | 5/10 [06:18<06:14, 75.00s/it][A
 50%|█████     | 5/10 [06:18<06:14, 75.00s/it][A
 60%|██████    | 6/10 [07:31<04:59, 74.99s/it][A[2024-05-30 01:37:49,629] [INFO] [logging.py:96:log_dist] [Rank 0] step=546, skipped=0, lr=[1.97759336190845e-05], mom=[(0.9, 0.999)]
steps: 546 loss: 1.1373 iter time (s): 74.608 samples/sec: 1.716

 60%|██████    | 6/10 [07:33<05:00, 75.07s/it][A
 60%|██████    | 6/10 [07:33<05:00, 75.09s/it][A
 60%|██████    | 6/10 [07:33<05:00, 75.12s/it][A
 60%|██████    | 6/10 [07:33<05:00, 75.10s/it][A
 60%|██████    | 6/10 [07:33<05:00, 75.12s/it][A
 60%|██████    | 6/10 [07:33<05:00, 75.12s/it][A
 60%|██████    | 6/10 [07:33<05:00, 75.12s/it][A
 70%|███████   | 7/10 [08:46<03:45, 75.06s/it][A[2024-05-30 01:39:04,821] [INFO] [logging.py:96:log_dist] [Rank 0] step=547, skipped=0, lr=[1.97747397968943e-05], mom=[(0.9, 0.999)]
steps: 547 loss: 1.1214 iter time (s): 74.447 samples/sec: 1.719

 70%|███████   | 7/10 [08:48<03:45, 75.13s/it][A
 70%|███████   | 7/10 [08:48<03:45, 75.13s/it][A
 70%|███████   | 7/10 [08:48<03:45, 75.09s/it][A
 70%|███████   | 7/10 [08:48<03:45, 75.12s/it][A
 70%|███████   | 7/10 [08:48<03:45, 75.14s/it][A
 70%|███████   | 7/10 [08:48<03:45, 75.13s/it][A
 70%|███████   | 7/10 [08:48<03:45, 75.13s/it][A
 80%|████████  | 8/10 [10:03<02:31, 75.64s/it][A[2024-05-30 01:40:21,715] [INFO] [logging.py:96:log_dist] [Rank 0] step=548, skipped=0, lr=[1.9773542839045763e-05], mom=[(0.9, 0.999)]
steps: 548 loss: 1.1133 iter time (s): 76.206 samples/sec: 1.680

 80%|████████  | 8/10 [10:05<02:31, 75.69s/it][A
 80%|████████  | 8/10 [10:05<02:31, 75.69s/it][A
 80%|████████  | 8/10 [10:05<02:31, 75.68s/it][A
 80%|████████  | 8/10 [10:05<02:31, 75.70s/it][A
 80%|████████  | 8/10 [10:05<02:31, 75.71s/it][A
 80%|████████  | 8/10 [10:05<02:31, 75.70s/it][A
 80%|████████  | 8/10 [10:05<02:31, 75.70s/it][A
 90%|█████████ | 9/10 [11:20<01:16, 76.22s/it][A[2024-05-30 01:41:39,213] [INFO] [logging.py:96:log_dist] [Rank 0] step=549, skipped=0, lr=[1.97723427459229e-05], mom=[(0.9, 0.999)]
steps: 549 loss: 1.1088 iter time (s): 76.790 samples/sec: 1.667

 90%|█████████ | 9/10 [11:22<01:16, 76.25s/it][A
 90%|█████████ | 9/10 [11:22<01:16, 76.26s/it][A
 90%|█████████ | 9/10 [11:22<01:16, 76.28s/it][A
 90%|█████████ | 9/10 [11:23<01:16, 76.27s/it][A
 90%|█████████ | 9/10 [11:23<01:16, 76.27s/it][A
 90%|█████████ | 9/10 [11:23<01:16, 76.28s/it][A
 90%|█████████ | 9/10 [11:23<01:16, 76.28s/it][A
100%|██████████| 10/10 [12:37<00:00, 76.28s/it][A100%|██████████| 10/10 [12:37<00:00, 75.72s/it]
 11%|█         | 56/520 [3:49:59<103:07:49, 800.15s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A[2024-05-30 01:42:55,633] [INFO] [logging.py:96:log_dist] [Rank 0] step=550, skipped=0, lr=[1.977113951791073e-05], mom=[(0.9, 0.999)]
steps: 550 loss: 1.1034 iter time (s): 75.638 samples/sec: 1.692

100%|██████████| 10/10 [12:39<00:00, 76.30s/it][A100%|██████████| 10/10 [12:39<00:00, 75.91s/it]
 11%|█         | 56/520 [3:49:31<103:08:40, 800.26s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [12:39<00:00, 76.32s/it][A100%|██████████| 10/10 [12:39<00:00, 75.93s/it]
 11%|█         | 56/520 [3:50:08<103:09:23, 800.35s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [12:39<00:00, 76.32s/it][A100%|██████████| 10/10 [12:39<00:00, 75.94s/it]
 11%|█         | 56/520 [3:50:08<103:09:31, 800.37s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [12:39<00:00, 76.32s/it][A100%|██████████| 10/10 [12:39<00:00, 75.95s/it]
 11%|█         | 56/520 [3:49:00<103:08:41, 800.26s/it]
100%|██████████| 10/10 [12:39<00:00, 76.31s/it][A100%|██████████| 10/10 [12:39<00:00, 75.95s/it]
 11%|█         | 56/520 [3:49:27<103:09:00, 800.30s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [12:39<00:00, 76.31s/it][A100%|██████████| 10/10 [12:39<00:00, 75.95s/it]
 11%|█         | 56/520 [3:50:10<103:09:40, 800.39s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [12:39<00:00, 76.31s/it][A100%|██████████| 10/10 [12:39<00:00, 75.96s/it]
 11%|█         | 56/520 [3:47:55<103:07:43, 800.14s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_37
Training on 1280 of 1280 sentences.

  0%|          | 0/10 [00:00<?, ?it/s][A
 10%|█         | 1/10 [01:34<14:06, 94.11s/it][A[2024-05-30 01:44:30,430] [INFO] [logging.py:96:log_dist] [Rank 0] step=551, skipped=0, lr=[1.976993315539528e-05], mom=[(0.9, 0.999)]
steps: 551 loss: 0.8648 iter time (s): 93.959 samples/sec: 1.362

 10%|█         | 1/10 [01:34<14:14, 94.93s/it][A
 10%|█         | 1/10 [01:34<14:14, 94.98s/it][A
 10%|█         | 1/10 [01:34<14:14, 94.95s/it][A
 10%|█         | 1/10 [01:34<14:14, 94.93s/it][A
 10%|█         | 1/10 [01:34<14:14, 94.95s/it][A
 10%|█         | 1/10 [01:34<14:14, 94.97s/it][A
 10%|█         | 1/10 [01:34<14:14, 94.97s/it][A
 20%|██        | 2/10 [03:07<12:31, 93.95s/it][A[2024-05-30 01:46:04,270] [INFO] [logging.py:96:log_dist] [Rank 0] step=552, skipped=0, lr=[1.976872365876358e-05], mom=[(0.9, 0.999)]
steps: 552 loss: 0.8510 iter time (s): 92.964 samples/sec: 1.377

 20%|██        | 2/10 [03:08<12:34, 94.25s/it][A
 20%|██        | 2/10 [03:08<12:34, 94.26s/it][A
 20%|██        | 2/10 [03:08<12:34, 94.30s/it][A
 20%|██        | 2/10 [03:08<12:34, 94.29s/it][A
 20%|██        | 2/10 [03:08<12:34, 94.30s/it][A
 20%|██        | 2/10 [03:08<12:34, 94.29s/it][A
 20%|██        | 2/10 [03:08<12:34, 94.31s/it][A
 30%|███       | 3/10 [04:42<10:59, 94.24s/it][A[2024-05-30 01:47:38,840] [INFO] [logging.py:96:log_dist] [Rank 0] step=553, skipped=0, lr=[1.9767511028403668e-05], mom=[(0.9, 0.999)]
steps: 553 loss: 0.8944 iter time (s): 93.735 samples/sec: 1.366

 30%|███       | 3/10 [04:43<11:01, 94.44s/it][A
 30%|███       | 3/10 [04:43<11:01, 94.44s/it][A
 30%|███       | 3/10 [04:43<11:01, 94.45s/it][A

 30%|███       | 3/10 [04:43<11:01, 94.45s/it][A 30%|███       | 3/10 [04:43<11:01, 94.44s/it][A
 30%|███       | 3/10 [04:43<11:01, 94.45s/it][A
 30%|███       | 3/10 [04:43<11:01, 94.45s/it][A
 40%|████      | 4/10 [06:16<09:24, 94.04s/it][A[2024-05-30 01:49:12,573] [INFO] [logging.py:96:log_dist] [Rank 0] step=554, skipped=0, lr=[1.9766295264704586e-05], mom=[(0.9, 0.999)]
steps: 554 loss: 0.8693 iter time (s): 92.751 samples/sec: 1.380

 40%|████      | 4/10 [06:16<09:24, 94.11s/it][A
 40%|████      | 4/10 [06:17<09:24, 94.15s/it][A
 40%|████      | 4/10 [06:17<09:24, 94.13s/it][A
 40%|████      | 4/10 [06:17<09:24, 94.12s/it][A
 40%|████      | 4/10 [06:17<09:24, 94.13s/it][A
 40%|████      | 4/10 [06:17<09:24, 94.13s/it][A
 40%|████      | 4/10 [06:17<09:24, 94.13s/it][A
 50%|█████     | 5/10 [07:50<07:50, 94.10s/it][A[2024-05-30 01:50:46,783] [INFO] [logging.py:96:log_dist] [Rank 0] step=555, skipped=0, lr=[1.9765076368056377e-05], mom=[(0.9, 0.999)]
steps: 555 loss: 0.8845 iter time (s): 93.353 samples/sec: 1.371

 50%|█████     | 5/10 [07:51<07:50, 94.15s/it][A
 50%|█████     | 5/10 [07:51<07:50, 94.13s/it][A
 50%|█████     | 5/10 [07:51<07:50, 94.16s/it][A
 50%|█████     | 5/10 [07:51<07:50, 94.17s/it][A
 50%|█████     | 5/10 [07:51<07:50, 94.17s/it][A
 50%|█████     | 5/10 [07:51<07:50, 94.16s/it][A
 50%|█████     | 5/10 [07:51<07:50, 94.17s/it][A
 60%|██████    | 6/10 [09:23<06:15, 93.87s/it][A[2024-05-30 01:52:20,212] [INFO] [logging.py:96:log_dist] [Rank 0] step=556, skipped=0, lr=[1.9763854338850096e-05], mom=[(0.9, 0.999)]
steps: 556 loss: 0.8700 iter time (s): 92.547 samples/sec: 1.383

 60%|██████    | 6/10 [09:24<06:15, 93.92s/it][A
 60%|██████    | 6/10 [09:24<06:15, 93.91s/it][A
 60%|██████    | 6/10 [09:24<06:15, 93.92s/it][A
 60%|██████    | 6/10 [09:24<06:15, 93.93s/it][A
 60%|██████    | 6/10 [09:24<06:15, 93.94s/it][A
 60%|██████    | 6/10 [09:24<06:15, 93.93s/it][A
 60%|██████    | 6/10 [09:24<06:15, 93.93s/it][A
 70%|███████   | 7/10 [10:57<04:41, 93.69s/it][A[2024-05-30 01:53:53,560] [INFO] [logging.py:96:log_dist] [Rank 0] step=557, skipped=0, lr=[1.9762629177477806e-05], mom=[(0.9, 0.999)]
steps: 557 loss: 0.8453 iter time (s): 92.407 samples/sec: 1.385

 70%|███████   | 7/10 [10:57<04:41, 93.71s/it][A
 70%|███████   | 7/10 [10:57<04:41, 93.68s/it][A
 70%|███████   | 7/10 [10:57<04:41, 93.69s/it][A
 70%|███████   | 7/10 [10:57<04:41, 93.70s/it][A
 70%|███████   | 7/10 [10:58<04:41, 93.71s/it][A
 70%|███████   | 7/10 [10:58<04:41, 93.71s/it][A
 70%|███████   | 7/10 [10:58<04:41, 93.71s/it][A
 80%|████████  | 8/10 [12:32<03:08, 94.12s/it][A[2024-05-30 01:55:28,552] [INFO] [logging.py:96:log_dist] [Rank 0] step=558, skipped=0, lr=[1.976140088433256e-05], mom=[(0.9, 0.999)]
steps: 558 loss: 0.8503 iter time (s): 94.177 samples/sec: 1.359

 80%|████████  | 8/10 [12:32<03:08, 94.14s/it][A
 80%|████████  | 8/10 [12:32<03:08, 94.12s/it][A
 80%|████████  | 8/10 [12:33<03:08, 94.15s/it][A
 80%|████████  | 8/10 [12:33<03:08, 94.12s/it][A
 80%|████████  | 8/10 [12:33<03:08, 94.13s/it][A
 80%|████████  | 8/10 [12:33<03:08, 94.13s/it][A
 80%|████████  | 8/10 [12:33<03:08, 94.13s/it][A
 90%|█████████ | 9/10 [14:07<01:34, 94.59s/it][A[2024-05-30 01:57:04,203] [INFO] [logging.py:96:log_dist] [Rank 0] step=559, skipped=0, lr=[1.976016945980843e-05], mom=[(0.9, 0.999)]
steps: 559 loss: 0.8562 iter time (s): 94.752 samples/sec: 1.351

 90%|█████████ | 9/10 [14:08<01:34, 94.62s/it][A
 90%|█████████ | 9/10 [14:08<01:34, 94.60s/it][A
 90%|█████████ | 9/10 [14:08<01:34, 94.58s/it][A
 90%|█████████ | 9/10 [14:08<01:34, 94.60s/it][A
 90%|█████████ | 9/10 [14:08<01:34, 94.60s/it][A
 90%|█████████ | 9/10 [14:08<01:34, 94.60s/it][A
 90%|█████████ | 9/10 [14:08<01:34, 94.60s/it][A
100%|██████████| 10/10 [15:42<00:00, 94.55s/it][A100%|██████████| 10/10 [15:42<00:00, 94.23s/it]
 11%|█         | 57/520 [4:05:41<108:06:47, 840.62s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A[2024-05-30 01:58:38,647] [INFO] [logging.py:96:log_dist] [Rank 0] step=560, skipped=0, lr=[1.9758934904300483e-05], mom=[(0.9, 0.999)]
steps: 560 loss: 0.8690 iter time (s): 93.570 samples/sec: 1.368

100%|██████████| 10/10 [15:43<00:00, 94.55s/it][A100%|██████████| 10/10 [15:43<00:00, 94.31s/it]
 11%|█         | 57/520 [4:05:14<108:08:44, 840.87s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [15:43<00:00, 94.55s/it][A100%|██████████| 10/10 [15:43<00:00, 94.31s/it]
 11%|█         | 57/520 [4:05:51<108:09:11, 840.93s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [15:43<00:00, 94.57s/it][A100%|██████████| 10/10 [15:43<00:00, 94.31s/it]
 11%|█         | 57/520 [4:05:51<108:09:27, 840.97s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [15:43<00:00, 94.54s/it][A100%|██████████| 10/10 [15:43<00:00, 94.31s/it]
 11%|█         | 57/520 [4:04:43<108:08:42, 840.87s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [15:43<00:00, 94.55s/it][A100%|██████████| 10/10 [15:43<00:00, 94.31s/it]
 11%|█         | 57/520 [4:05:10<108:09:05, 840.92s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [15:43<00:00, 94.56s/it][A100%|██████████| 10/10 [15:43<00:00, 94.32s/it]
 11%|█         | 57/520 [4:05:54<108:09:37, 840.99s/it]
100%|██████████| 10/10 [15:43<00:00, 94.56s/it][A100%|██████████| 10/10 [15:43<00:00, 94.32s/it]
 11%|█         | 57/520 [4:03:38<108:08:13, 840.81s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_286

  0%|          | 0/10 [00:00<?, ?it/s][ATraining on 1280 of 1280 sentences.

  0%|          | 0/10 [00:00<?, ?it/s][A
 10%|█         | 1/10 [01:20<12:05, 80.62s/it][A[2024-05-30 01:59:59,052] [INFO] [logging.py:96:log_dist] [Rank 0] step=561, skipped=0, lr=[1.9757697218204802e-05], mom=[(0.9, 0.999)]
steps: 561 loss: 0.5812 iter time (s): 79.404 samples/sec: 1.612

 10%|█         | 1/10 [01:20<12:03, 80.38s/it][A
 10%|█         | 1/10 [01:20<12:03, 80.40s/it][A
 10%|█         | 1/10 [01:20<12:02, 80.33s/it][A
 10%|█         | 1/10 [01:20<12:03, 80.37s/it][A
 10%|█         | 1/10 [01:20<12:03, 80.33s/it][A
 10%|█         | 1/10 [01:20<12:03, 80.41s/it][A
 10%|█         | 1/10 [01:20<12:03, 80.35s/it][A
 20%|██        | 2/10 [02:41<10:46, 80.77s/it][A[2024-05-30 02:01:19,914] [INFO] [logging.py:96:log_dist] [Rank 0] step=562, skipped=0, lr=[1.9756456401918464e-05], mom=[(0.9, 0.999)]
steps: 562 loss: 0.5724 iter time (s): 80.012 samples/sec: 1.600

 20%|██        | 2/10 [02:41<10:45, 80.66s/it][A
 20%|██        | 2/10 [02:41<10:44, 80.61s/it][A
 20%|██        | 2/10 [02:41<10:44, 80.60s/it][A
 20%|██        | 2/10 [02:41<10:45, 80.63s/it][A
 20%|██        | 2/10 [02:41<10:44, 80.61s/it][A
 20%|██        | 2/10 [02:41<10:44, 80.60s/it][A
 20%|██        | 2/10 [02:41<10:44, 80.61s/it][A
 30%|███       | 3/10 [04:01<09:24, 80.63s/it][A[2024-05-30 02:02:40,386] [INFO] [logging.py:96:log_dist] [Rank 0] step=563, skipped=0, lr=[1.9755212455839552e-05], mom=[(0.9, 0.999)]
steps: 563 loss: 0.5720 iter time (s): 79.693 samples/sec: 1.606

 30%|███       | 3/10 [04:01<09:24, 80.58s/it][A
 30%|███       | 3/10 [04:01<09:24, 80.58s/it][A
 30%|███       | 3/10 [04:01<09:23, 80.56s/it][A
 30%|███       | 3/10 [04:01<09:23, 80.57s/it][A
 30%|███       | 3/10 [04:01<09:23, 80.56s/it][A
 30%|███       | 3/10 [04:01<09:23, 80.57s/it][A
 30%|███       | 3/10 [04:01<09:23, 80.57s/it][A
 40%|████      | 4/10 [05:21<08:02, 80.37s/it][A[2024-05-30 02:04:00,354] [INFO] [logging.py:96:log_dist] [Rank 0] step=564, skipped=0, lr=[1.9753965380367157e-05], mom=[(0.9, 0.999)]
steps: 564 loss: 0.5512 iter time (s): 79.132 samples/sec: 1.618

 40%|████      | 4/10 [05:21<08:01, 80.33s/it][A
 40%|████      | 4/10 [05:21<08:02, 80.35s/it][A
 40%|████      | 4/10 [05:21<08:02, 80.34s/it][A
 40%|████      | 4/10 [05:21<08:02, 80.35s/it][A
 40%|████      | 4/10 [05:21<08:02, 80.35s/it][A
 40%|████      | 4/10 [05:21<08:02, 80.34s/it][A
 40%|████      | 4/10 [05:21<08:02, 80.35s/it][A
 50%|█████     | 5/10 [06:41<06:40, 80.19s/it][A[2024-05-30 02:05:20,245] [INFO] [logging.py:96:log_dist] [Rank 0] step=565, skipped=0, lr=[1.9752715175901373e-05], mom=[(0.9, 0.999)]
steps: 565 loss: 0.5444 iter time (s): 79.078 samples/sec: 1.619

 50%|█████     | 5/10 [06:41<06:40, 80.19s/it][A
 50%|█████     | 5/10 [06:41<06:40, 80.18s/it][A
 50%|█████     | 5/10 [06:41<06:40, 80.19s/it][A
 50%|█████     | 5/10 [06:41<06:40, 80.18s/it][A
 50%|█████     | 5/10 [06:41<06:40, 80.17s/it][A
 50%|█████     | 5/10 [06:41<06:40, 80.18s/it][A
 50%|█████     | 5/10 [06:41<06:40, 80.18s/it][A
 60%|██████    | 6/10 [08:03<05:22, 80.59s/it][A[2024-05-30 02:06:41,603] [INFO] [logging.py:96:log_dist] [Rank 0] step=566, skipped=0, lr=[1.975146184284329e-05], mom=[(0.9, 0.999)]
steps: 566 loss: 0.5619 iter time (s): 80.539 samples/sec: 1.589

 60%|██████    | 6/10 [08:02<05:22, 80.57s/it][A
 60%|██████    | 6/10 [08:02<05:22, 80.58s/it][A
 60%|██████    | 6/10 [08:02<05:22, 80.58s/it][A
 60%|██████    | 6/10 [08:02<05:22, 80.59s/it][A
 60%|██████    | 6/10 [08:02<05:22, 80.60s/it][A
 60%|██████    | 6/10 [08:02<05:22, 80.58s/it][A
 60%|██████    | 6/10 [08:02<05:22, 80.58s/it][A
 70%|███████   | 7/10 [09:24<04:02, 80.72s/it][A[2024-05-30 02:08:02,574] [INFO] [logging.py:96:log_dist] [Rank 0] step=567, skipped=0, lr=[1.9750205381595017e-05], mom=[(0.9, 0.999)]
steps: 567 loss: 0.5567 iter time (s): 80.125 samples/sec: 1.597

 70%|███████   | 7/10 [09:23<04:02, 80.73s/it][A
 70%|███████   | 7/10 [09:23<04:02, 80.73s/it][A
 70%|███████   | 7/10 [09:23<04:02, 80.71s/it][A
 70%|███████   | 7/10 [09:23<04:02, 80.72s/it][A
 70%|███████   | 7/10 [09:23<04:02, 80.70s/it][A
 70%|███████   | 7/10 [09:23<04:02, 80.70s/it][A
 70%|███████   | 7/10 [09:23<04:02, 80.71s/it][A
 80%|████████  | 8/10 [10:44<02:41, 80.75s/it][A[2024-05-30 02:09:23,396] [INFO] [logging.py:96:log_dist] [Rank 0] step=568, skipped=0, lr=[1.974894579255965e-05], mom=[(0.9, 0.999)]
steps: 568 loss: 0.5492 iter time (s): 79.984 samples/sec: 1.600

 80%|████████  | 8/10 [10:44<02:41, 80.71s/it][A
 80%|████████  | 8/10 [10:44<02:41, 80.75s/it][A
 80%|████████  | 8/10 [10:44<02:41, 80.74s/it][A
 80%|████████  | 8/10 [10:44<02:41, 80.74s/it][A
 80%|████████  | 8/10 [10:44<02:41, 80.76s/it][A
 80%|████████  | 8/10 [10:44<02:41, 80.76s/it][A
 80%|████████  | 8/10 [10:44<02:41, 80.76s/it][A
 90%|█████████ | 9/10 [12:06<01:20, 80.88s/it][A[2024-05-30 02:10:44,555] [INFO] [logging.py:96:log_dist] [Rank 0] step=569, skipped=0, lr=[1.9747683076141307e-05], mom=[(0.9, 0.999)]
steps: 569 loss: 0.5215 iter time (s): 80.314 samples/sec: 1.594

 90%|█████████ | 9/10 [12:05<01:20, 80.88s/it][A
 90%|█████████ | 9/10 [12:05<01:20, 80.90s/it][A
 90%|█████████ | 9/10 [12:05<01:20, 80.88s/it][A
 90%|█████████ | 9/10 [12:05<01:20, 80.90s/it][A
 90%|█████████ | 9/10 [12:06<01:20, 80.95s/it][A
 90%|█████████ | 9/10 [12:06<01:20, 80.98s/it][A
 90%|█████████ | 9/10 [12:06<01:21, 81.02s/it][A
100%|██████████| 10/10 [13:27<00:00, 81.09s/it][A100%|██████████| 10/10 [13:27<00:00, 80.77s/it]
 11%|█         | 58/520 [4:19:09<106:39:53, 831.15s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A[2024-05-30 02:12:06,139] [INFO] [logging.py:96:log_dist] [Rank 0] step=570, skipped=0, lr=[1.974641723274509e-05], mom=[(0.9, 0.999)]
steps: 570 loss: 0.5349 iter time (s): 80.235 samples/sec: 1.595

100%|██████████| 10/10 [13:27<00:00, 81.11s/it][A100%|██████████| 10/10 [13:27<00:00, 80.75s/it]
 11%|█         | 58/520 [4:18:42<106:40:34, 831.24s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:27<00:00, 81.06s/it][A100%|██████████| 10/10 [13:27<00:00, 80.74s/it]
 11%|█         | 58/520 [4:19:19<106:40:38, 831.25s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:27<00:00, 81.06s/it][A100%|██████████| 10/10 [13:27<00:00, 80.73s/it]
 11%|█         | 58/520 [4:19:18<106:40:40, 831.26s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:27<00:00, 81.04s/it][A100%|██████████| 10/10 [13:27<00:00, 80.74s/it]
 11%|█         | 58/520 [4:18:11<106:40:14, 831.20s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:27<00:00, 81.06s/it][A100%|██████████| 10/10 [13:27<00:00, 80.74s/it]
 11%|█         | 58/520 [4:18:37<106:40:31, 831.24s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:27<00:00, 81.03s/it][A100%|██████████| 10/10 [13:27<00:00, 80.74s/it]
 11%|█         | 58/520 [4:19:21<106:40:49, 831.28s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:27<00:00, 81.03s/it][A100%|██████████| 10/10 [13:27<00:00, 80.74s/it]
 11%|█         | 58/520 [4:17:06<106:39:53, 831.16s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_53
Training on 1280 of 1280 sentences.

  0%|          | 0/10 [00:00<?, ?it/s][A
 10%|█         | 1/10 [01:03<09:32, 63.62s/it][A[2024-05-30 02:13:09,497] [INFO] [logging.py:96:log_dist] [Rank 0] step=571, skipped=0, lr=[1.974514826277711e-05], mom=[(0.9, 0.999)]
steps: 571 loss: 1.2669 iter time (s): 62.421 samples/sec: 2.051

 10%|█         | 1/10 [01:03<09:29, 63.25s/it][A
 10%|█         | 1/10 [01:03<09:30, 63.37s/it][A
 10%|█         | 1/10 [01:03<09:29, 63.29s/it][A
 10%|█         | 1/10 [01:03<09:29, 63.32s/it][A
 10%|█         | 1/10 [01:03<09:29, 63.24s/it][A
 10%|█         | 1/10 [01:03<09:29, 63.28s/it][A
 10%|█         | 1/10 [01:03<09:29, 63.23s/it][A
 20%|██        | 2/10 [02:07<08:30, 63.87s/it][A[2024-05-30 02:14:13,537] [INFO] [logging.py:96:log_dist] [Rank 0] step=572, skipped=0, lr=[1.9743876166644496e-05], mom=[(0.9, 0.999)]
steps: 572 loss: 1.2681 iter time (s): 63.361 samples/sec: 2.020

 20%|██        | 2/10 [02:07<08:29, 63.68s/it][A
 20%|██        | 2/10 [02:07<08:29, 63.71s/it][A
 20%|██        | 2/10 [02:07<08:29, 63.67s/it][A
 20%|██        | 2/10 [02:07<08:29, 63.71s/it][A
 20%|██        | 2/10 [02:07<08:29, 63.68s/it][A
 20%|██        | 2/10 [02:07<08:29, 63.68s/it][A
 20%|██        | 2/10 [02:07<08:29, 63.68s/it][A
 30%|███       | 3/10 [03:11<07:27, 63.86s/it][A[2024-05-30 02:15:17,396] [INFO] [logging.py:96:log_dist] [Rank 0] step=573, skipped=0, lr=[1.9742600944755358e-05], mom=[(0.9, 0.999)]
steps: 573 loss: 1.2761 iter time (s): 63.216 samples/sec: 2.025

 30%|███       | 3/10 [03:11<07:26, 63.76s/it][A
 30%|███       | 3/10 [03:11<07:26, 63.79s/it][A
 30%|███       | 3/10 [03:11<07:26, 63.78s/it][A
 30%|███       | 3/10 [03:11<07:26, 63.75s/it][A
 30%|███       | 3/10 [03:11<07:26, 63.77s/it][A
 30%|███       | 3/10 [03:11<07:26, 63.77s/it][A
 30%|███       | 3/10 [03:11<07:26, 63.76s/it][A
 40%|████      | 4/10 [04:14<06:21, 63.63s/it][A[2024-05-30 02:16:20,676] [INFO] [logging.py:96:log_dist] [Rank 0] step=574, skipped=0, lr=[1.9741322597518824e-05], mom=[(0.9, 0.999)]
steps: 574 loss: 1.2825 iter time (s): 62.642 samples/sec: 2.043

 40%|████      | 4/10 [04:14<06:21, 63.58s/it][A
 40%|████      | 4/10 [04:14<06:21, 63.58s/it][A
 40%|████      | 4/10 [04:14<06:21, 63.59s/it][A
 40%|████      | 4/10 [04:14<06:21, 63.59s/it][A
 40%|████      | 4/10 [04:14<06:21, 63.59s/it][A
 40%|████      | 4/10 [04:14<06:21, 63.59s/it][A
 40%|████      | 4/10 [04:14<06:21, 63.58s/it][A
 50%|█████     | 5/10 [05:17<05:15, 63.16s/it][A[2024-05-30 02:17:23,012] [INFO] [logging.py:96:log_dist] [Rank 0] step=575, skipped=0, lr=[1.9740041125345016e-05], mom=[(0.9, 0.999)]
steps: 575 loss: 1.2586 iter time (s): 61.675 samples/sec: 2.075

 50%|█████     | 5/10 [05:16<05:15, 63.15s/it][A
 50%|█████     | 5/10 [05:16<05:15, 63.15s/it][A
 50%|█████     | 5/10 [05:16<05:15, 63.14s/it][A
 50%|█████     | 5/10 [05:16<05:15, 63.14s/it][A
 50%|█████     | 5/10 [05:16<05:15, 63.14s/it][A
 50%|█████     | 5/10 [05:16<05:15, 63.15s/it][A
 50%|█████     | 5/10 [05:16<05:15, 63.14s/it][A
 60%|██████    | 6/10 [06:20<04:12, 63.17s/it][A[2024-05-30 02:18:26,191] [INFO] [logging.py:96:log_dist] [Rank 0] step=576, skipped=0, lr=[1.973875652864506e-05], mom=[(0.9, 0.999)]
steps: 576 loss: 1.2666 iter time (s): 62.489 samples/sec: 2.048

 60%|██████    | 6/10 [06:19<04:12, 63.13s/it][A
 60%|██████    | 6/10 [06:20<04:12, 63.15s/it][A
 60%|██████    | 6/10 [06:19<04:12, 63.13s/it][A
 60%|██████    | 6/10 [06:19<04:12, 63.17s/it][A
 60%|██████    | 6/10 [06:20<04:12, 63.20s/it][A
 60%|██████    | 6/10 [06:20<04:12, 63.19s/it][A
 60%|██████    | 6/10 [06:20<04:12, 63.20s/it][A
 70%|███████   | 7/10 [07:23<03:09, 63.31s/it][A[2024-05-30 02:19:29,802] [INFO] [logging.py:96:log_dist] [Rank 0] step=577, skipped=0, lr=[1.9737468807831098e-05], mom=[(0.9, 0.999)]
steps: 577 loss: 1.2686 iter time (s): 62.801 samples/sec: 2.038

 70%|███████   | 7/10 [07:23<03:09, 63.32s/it][A
 70%|███████   | 7/10 [07:23<03:09, 63.31s/it][A
 70%|███████   | 7/10 [07:23<03:09, 63.30s/it][A
 70%|███████   | 7/10 [07:23<03:09, 63.31s/it][A
 70%|███████   | 7/10 [07:23<03:09, 63.28s/it][A
 70%|███████   | 7/10 [07:23<03:09, 63.28s/it][A
 70%|███████   | 7/10 [07:23<03:09, 63.28s/it][A
 80%|████████  | 8/10 [08:27<02:06, 63.31s/it][A[2024-05-30 02:20:33,102] [INFO] [logging.py:96:log_dist] [Rank 0] step=578, skipped=0, lr=[1.9736177963316252e-05], mom=[(0.9, 0.999)]
steps: 578 loss: 1.2467 iter time (s): 62.652 samples/sec: 2.043

 80%|████████  | 8/10 [08:26<02:06, 63.31s/it][A
 80%|████████  | 8/10 [08:26<02:06, 63.30s/it][A
 80%|████████  | 8/10 [08:26<02:06, 63.30s/it][A
 80%|████████  | 8/10 [08:26<02:06, 63.31s/it][A
 80%|████████  | 8/10 [08:26<02:06, 63.29s/it][A
 80%|████████  | 8/10 [08:26<02:06, 63.30s/it][A
 80%|████████  | 8/10 [08:26<02:06, 63.29s/it][A
 90%|█████████ | 9/10 [09:29<01:03, 63.11s/it][A[2024-05-30 02:21:35,783] [INFO] [logging.py:96:log_dist] [Rank 0] step=579, skipped=0, lr=[1.9734883995514658e-05], mom=[(0.9, 0.999)]
steps: 579 loss: 1.2597 iter time (s): 61.997 samples/sec: 2.065

 90%|█████████ | 9/10 [09:29<01:03, 63.09s/it][A
 90%|█████████ | 9/10 [09:29<01:03, 63.08s/it][A
 90%|█████████ | 9/10 [09:29<01:03, 63.09s/it][A
 90%|█████████ | 9/10 [09:29<01:03, 63.09s/it][A
 90%|█████████ | 9/10 [09:29<01:03, 63.08s/it][A
 90%|█████████ | 9/10 [09:29<01:03, 63.09s/it][A
 90%|█████████ | 9/10 [09:29<01:03, 63.08s/it][A
100%|██████████| 10/10 [10:35<00:00, 63.93s/it][A100%|██████████| 10/10 [10:35<00:00, 63.57s/it]
 11%|█▏        | 59/520 [4:29:45<99:07:47, 774.12s/it] 
  0%|          | 0/10 [00:00<?, ?it/s][A[2024-05-30 02:22:41,550] [INFO] [logging.py:96:log_dist] [Rank 0] step=580, skipped=0, lr=[1.9733586904841457e-05], mom=[(0.9, 0.999)]
steps: 580 loss: 1.2521 iter time (s): 65.146 samples/sec: 1.965

100%|██████████| 10/10 [10:35<00:00, 63.92s/it][A100%|██████████| 10/10 [10:35<00:00, 63.53s/it]
 11%|█▏        | 59/520 [4:29:17<99:06:53, 774.00s/it] 
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [10:35<00:00, 63.93s/it][A100%|██████████| 10/10 [10:35<00:00, 63.53s/it]
 11%|█▏        | 59/520 [4:29:54<99:07:06, 774.03s/it] 
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [10:35<00:00, 63.92s/it][A100%|██████████| 10/10 [10:35<00:00, 63.53s/it]
 11%|█▏        | 59/520 [4:29:53<99:07:00, 774.01s/it] 
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [10:35<00:00, 63.91s/it][A100%|██████████| 10/10 [10:35<00:00, 63.52s/it]
 11%|█▏        | 59/520 [4:28:46<99:06:36, 773.96s/it] 
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [10:35<00:00, 63.92s/it][A100%|██████████| 10/10 [10:35<00:00, 63.53s/it]
 11%|█▏        | 59/520 [4:29:12<99:06:52, 774.00s/it] 
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [10:35<00:00, 63.92s/it][A100%|██████████| 10/10 [10:35<00:00, 63.53s/it]
 11%|█▏        | 59/520 [4:29:56<99:07:02, 774.02s/it] 
100%|██████████| 10/10 [10:35<00:00, 63.91s/it][A100%|██████████| 10/10 [10:35<00:00, 63.52s/it]
 11%|█▏        | 59/520 [4:27:41<99:06:18, 773.92s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_158
Training on 1280 of 1280 sentences.

  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
 10%|█         | 1/10 [02:09<19:25, 129.45s/it][A[2024-05-30 02:24:52,989] [INFO] [logging.py:96:log_dist] [Rank 0] step=581, skipped=0, lr=[1.9732286691712786e-05], mom=[(0.9, 0.999)]
steps: 581 loss: 0.5963 iter time (s): 130.677 samples/sec: 0.980

 10%|█         | 1/10 [02:11<19:42, 131.41s/it][A
 10%|█         | 1/10 [02:11<19:42, 131.41s/it][A
 10%|█         | 1/10 [02:11<19:43, 131.46s/it][A
 10%|█         | 1/10 [02:11<19:43, 131.49s/it][A
 10%|█         | 1/10 [02:11<19:43, 131.45s/it][A
 10%|█         | 1/10 [02:11<19:43, 131.48s/it][A
 10%|█         | 1/10 [02:11<19:43, 131.49s/it][A
 20%|██        | 2/10 [04:19<17:19, 129.98s/it][A[2024-05-30 02:27:03,376] [INFO] [logging.py:96:log_dist] [Rank 0] step=582, skipped=0, lr=[1.9730983356545785e-05], mom=[(0.9, 0.999)]
steps: 582 loss: 0.5783 iter time (s): 129.700 samples/sec: 0.987

 20%|██        | 2/10 [04:21<17:26, 130.83s/it][A
 20%|██        | 2/10 [04:21<17:26, 130.86s/it][A
 20%|██        | 2/10 [04:21<17:27, 130.89s/it][A
 20%|██        | 2/10 [04:21<17:27, 130.91s/it][A
 20%|██        | 2/10 [04:21<17:26, 130.86s/it][A
 20%|██        | 2/10 [04:21<17:26, 130.87s/it][A
 20%|██        | 2/10 [04:21<17:27, 130.88s/it][A
 30%|███       | 3/10 [06:30<15:11, 130.23s/it][A[2024-05-30 02:29:13,882] [INFO] [logging.py:96:log_dist] [Rank 0] step=583, skipped=0, lr=[1.9729676899758596e-05], mom=[(0.9, 0.999)]
steps: 583 loss: 0.6014 iter time (s): 129.773 samples/sec: 0.986

 30%|███       | 3/10 [06:32<15:14, 130.70s/it][A
 30%|███       | 3/10 [06:32<15:14, 130.68s/it][A
 30%|███       | 3/10 [06:32<15:14, 130.71s/it][A
 30%|███       | 3/10 [06:32<15:14, 130.71s/it][A
 30%|███       | 3/10 [06:32<15:14, 130.70s/it][A
 30%|███       | 3/10 [06:32<15:14, 130.70s/it][A
 30%|███       | 3/10 [06:32<15:14, 130.71s/it][A
 40%|████      | 4/10 [08:40<13:01, 130.32s/it][A[2024-05-30 02:31:24,325] [INFO] [logging.py:96:log_dist] [Rank 0] step=584, skipped=0, lr=[1.9728367321770367e-05], mom=[(0.9, 0.999)]
steps: 584 loss: 0.5933 iter time (s): 129.716 samples/sec: 0.987

 40%|████      | 4/10 [08:42<13:03, 130.59s/it][A
 40%|████      | 4/10 [08:42<13:03, 130.59s/it][A
 40%|████      | 4/10 [08:42<13:03, 130.57s/it][A
 40%|████      | 4/10 [08:42<13:03, 130.57s/it][A
 40%|████      | 4/10 [08:42<13:03, 130.57s/it][A
 40%|████      | 4/10 [08:42<13:03, 130.57s/it][A
 40%|████      | 4/10 [08:42<13:03, 130.58s/it][A
 50%|█████     | 5/10 [10:51<10:51, 130.35s/it][A[2024-05-30 02:33:34,750] [INFO] [logging.py:96:log_dist] [Rank 0] step=585, skipped=0, lr=[1.9727054623001234e-05], mom=[(0.9, 0.999)]
steps: 585 loss: 0.5945 iter time (s): 129.751 samples/sec: 0.987

 50%|█████     | 5/10 [10:53<10:52, 130.50s/it][A
 50%|█████     | 5/10 [10:53<10:52, 130.54s/it][A
 50%|█████     | 5/10 [10:53<10:52, 130.51s/it][A
 50%|█████     | 5/10 [10:53<10:52, 130.53s/it][A
 50%|█████     | 5/10 [10:53<10:52, 130.52s/it][A
 50%|█████     | 5/10 [10:53<10:52, 130.52s/it][A
 50%|█████     | 5/10 [10:53<10:52, 130.53s/it][A
 60%|██████    | 6/10 [13:01<08:41, 130.36s/it][A[2024-05-30 02:35:45,125] [INFO] [logging.py:96:log_dist] [Rank 0] step=586, skipped=0, lr=[1.9725738803872353e-05], mom=[(0.9, 0.999)]
steps: 586 loss: 0.5708 iter time (s): 129.685 samples/sec: 0.987

 60%|██████    | 6/10 [13:03<08:41, 130.47s/it][A
 60%|██████    | 6/10 [13:03<08:41, 130.47s/it][A
 60%|██████    | 6/10 [13:03<08:42, 130.52s/it][A
 60%|██████    | 6/10 [13:03<08:42, 130.57s/it][A
 60%|██████    | 6/10 [13:03<08:42, 130.54s/it][A
 60%|██████    | 6/10 [13:04<08:42, 130.63s/it][A
 60%|██████    | 6/10 [13:04<08:43, 130.80s/it][A
 70%|███████   | 7/10 [15:13<06:32, 130.81s/it][A[2024-05-30 02:37:56,864] [INFO] [logging.py:96:log_dist] [Rank 0] step=587, skipped=0, lr=[1.9724419864805866e-05], mom=[(0.9, 0.999)]
steps: 587 loss: 0.5845 iter time (s): 130.097 samples/sec: 0.984

 70%|███████   | 7/10 [15:15<06:32, 130.88s/it][A
 70%|███████   | 7/10 [15:15<06:32, 130.88s/it][A
 70%|███████   | 7/10 [15:15<06:32, 130.87s/it][A
 70%|███████   | 7/10 [15:15<06:32, 130.86s/it][A
 70%|███████   | 7/10 [15:15<06:32, 130.87s/it][A
 70%|███████   | 7/10 [15:15<06:32, 130.85s/it][A
 70%|███████   | 7/10 [15:15<06:32, 130.80s/it][A
 80%|████████  | 8/10 [17:23<04:21, 130.74s/it][A[2024-05-30 02:40:07,437] [INFO] [logging.py:96:log_dist] [Rank 0] step=588, skipped=0, lr=[1.9723097806224922e-05], mom=[(0.9, 0.999)]
steps: 588 loss: 0.5812 iter time (s): 129.867 samples/sec: 0.986

 80%|████████  | 8/10 [17:25<04:21, 130.80s/it][A
 80%|████████  | 8/10 [17:25<04:21, 130.78s/it][A
 80%|████████  | 8/10 [17:25<04:21, 130.79s/it][A
 80%|████████  | 8/10 [17:26<04:21, 130.79s/it][A
 80%|████████  | 8/10 [17:25<04:21, 130.78s/it][A
 80%|████████  | 8/10 [17:25<04:21, 130.76s/it][A
 80%|████████  | 8/10 [17:25<04:21, 130.72s/it][A
 90%|█████████ | 9/10 [19:34<02:10, 130.64s/it][A[2024-05-30 02:42:17,860] [INFO] [logging.py:96:log_dist] [Rank 0] step=589, skipped=0, lr=[1.9721772628553675e-05], mom=[(0.9, 0.999)]
steps: 589 loss: 0.5590 iter time (s): 129.732 samples/sec: 0.987

 90%|█████████ | 9/10 [19:36<02:10, 130.68s/it][A
 90%|█████████ | 9/10 [19:36<02:10, 130.69s/it][A
 90%|█████████ | 9/10 [19:36<02:10, 130.66s/it][A
 90%|█████████ | 9/10 [19:36<02:10, 130.65s/it][A
 90%|█████████ | 9/10 [19:36<02:10, 130.68s/it][A

 90%|█████████ | 9/10 [19:36<02:10, 130.64s/it][A 90%|█████████ | 9/10 [19:36<02:10, 130.62s/it][A
100%|██████████| 10/10 [21:45<00:00, 130.83s/it][A100%|██████████| 10/10 [21:45<00:00, 130.56s/it]
[2024-05-30 02:44:29,145] [INFO] [logging.py:96:log_dist] [Rank 0] step=590, skipped=0, lr=[1.9720444332217268e-05], mom=[(0.9, 0.999)]
steps: 590 loss: 0.5719 iter time (s): 130.653 samples/sec: 0.980

100%|██████████| 10/10 [21:47<00:00, 130.88s/it][A100%|██████████| 10/10 [21:47<00:00, 130.77s/it]

100%|██████████| 10/10 [21:47<00:00, 130.86s/it][A100%|██████████| 10/10 [21:47<00:00, 130.76s/it]

100%|██████████| 10/10 [21:47<00:00, 130.82s/it][A100%|██████████| 10/10 [21:47<00:00, 130.76s/it]

100%|██████████| 10/10 [21:47<00:00, 130.88s/it][A100%|██████████| 10/10 [21:47<00:00, 130.77s/it]


100%|██████████| 10/10 [21:47<00:00, 130.86s/it][A100%|██████████| 10/10 [21:47<00:00, 130.76s/it]
100%|██████████| 10/10 [21:47<00:00, 130.84s/it][A100%|██████████| 10/10 [21:47<00:00, 130.76s/it]

100%|██████████| 10/10 [21:47<00:00, 130.83s/it][A100%|██████████| 10/10 [21:47<00:00, 130.76s/it]
Checkpointing at shard 60
[2024-05-30 02:44:29,829] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step590 is about to be saved!
[2024-05-30 02:44:31,690] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step590/layer_00-model_states.pt...
[2024-05-30 02:44:38,789] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step590/layer_00-model_states.pt.
[2024-05-30 02:44:38,862] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step590/layer_02-model_states.pt...
[2024-05-30 02:44:39,442] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step590/layer_03-model_states.pt...
[2024-05-30 02:44:39,694] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step590/layer_04-model_states.pt...
[2024-05-30 02:44:43,434] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step590/layer_06-model_states.pt...
[2024-05-30 02:44:43,661] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step590/layer_05-model_states.pt...
[2024-05-30 02:44:45,722] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step590/layer_07-model_states.pt...
[2024-05-30 02:44:45,925] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step590/layer_08-model_states.pt...
[2024-05-30 02:44:47,148] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step590/layer_01-model_states.pt...
[2024-05-30 02:48:53,536] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step590/layer_06-model_states.pt.
[2024-05-30 02:48:54,170] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step590/mp_rank_05_model_states.pt...
[2024-05-30 02:48:54,716] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step590/mp_rank_05_model_states.pt.
[2024-05-30 02:48:54,716] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step590 is ready now!
[2024-05-30 02:49:27,218] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step590/layer_02-model_states.pt.
[2024-05-30 02:49:27,849] [INFO] [logging.py:96:log_dist] [Rank 1] Saving model checkpoint: /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step590/mp_rank_01_model_states.pt
[2024-05-30 02:49:27,849] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step590/mp_rank_01_model_states.pt...
[2024-05-30 02:49:28,475] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step590/mp_rank_01_model_states.pt.
[2024-05-30 02:49:28,475] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step590 is ready now!
[2024-05-30 02:49:41,973] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step590/layer_04-model_states.pt.
[2024-05-30 02:49:42,546] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step590/mp_rank_03_model_states.pt...
[2024-05-30 02:49:42,918] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step590/mp_rank_03_model_states.pt.
[2024-05-30 02:49:42,918] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step590 is ready now!
[2024-05-30 02:49:43,736] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step590/layer_03-model_states.pt.
[2024-05-30 02:49:43,919] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step590/mp_rank_02_model_states.pt...
[2024-05-30 02:49:45,287] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step590/mp_rank_02_model_states.pt.
[2024-05-30 02:49:45,287] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step590 is ready now!
[2024-05-30 02:50:00,536] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step590/layer_08-model_states.pt.
[2024-05-30 02:50:00,649] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step590/layer_07-model_states.pt.
[2024-05-30 02:50:01,366] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step590/mp_rank_06_model_states.pt...
[2024-05-30 02:50:01,367] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step590/layer_09-model_states.pt...
[2024-05-30 02:50:02,496] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step590/mp_rank_06_model_states.pt.
[2024-05-30 02:50:02,496] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step590 is ready now!
[2024-05-30 02:50:04,337] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step590/layer_09-model_states.pt.
[2024-05-30 02:50:04,368] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step590/mp_rank_07_model_states.pt...
[2024-05-30 02:50:04,584] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step590/mp_rank_07_model_states.pt.
[2024-05-30 02:50:04,584] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step590 is ready now!
[2024-05-30 02:50:04,653] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step590/layer_05-model_states.pt.
[2024-05-30 02:50:05,420] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step590/mp_rank_04_model_states.pt...
[2024-05-30 02:50:05,654] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step590/mp_rank_04_model_states.pt.
[2024-05-30 02:50:05,654] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step590 is ready now!
[2024-05-30 02:50:15,908] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step590/layer_01-model_states.pt.
[2024-05-30 02:50:16,751] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step590/mp_rank_00_model_states.pt
[2024-05-30 02:50:16,751] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step590/mp_rank_00_model_states.pt...
[2024-05-30 02:50:17,303] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step590/mp_rank_00_model_states.pt.
[2024-05-30 02:50:17,303] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step590 is ready now!
Checkpoint saved using --- 347.5395665168762 seconds ---
 12%|█▏        | 60/520 [4:55:16<132:02:43, 1033.40s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_88
 12%|█▏        | 60/520 [4:57:22<132:08:07, 1034.10s/it] 12%|█▏        | 60/520 [4:56:48<132:03:09, 1033.46s/it] 12%|█▏        | 60/520 [4:56:21<132:03:14, 1033.47s/it] 12%|█▏        | 60/520 [4:57:29<132:03:36, 1033.51s/it] 12%|█▏        | 60/520 [4:57:31<132:03:15, 1033.47s/it] 12%|█▏        | 60/520 [4:57:30<132:03:51, 1033.55s/it] 12%|█▏        | 60/520 [4:56:52<132:03:56, 1033.56s/it]Training on 1280 of 1280 sentences.

  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
 10%|█         | 1/10 [01:10<10:35, 70.57s/it][A[2024-05-30 02:51:29,764] [INFO] [logging.py:96:log_dist] [Rank 0] step=591, skipped=0, lr=[1.9719112917641853e-05], mom=[(0.9, 0.999)]
steps: 591 loss: 1.0952 iter time (s): 72.113 samples/sec: 1.775

 10%|█         | 1/10 [01:12<10:52, 72.49s/it][A
 10%|█         | 1/10 [01:12<10:53, 72.57s/it][A
 10%|█         | 1/10 [01:12<10:54, 72.68s/it][A
 10%|█         | 1/10 [01:12<10:55, 72.78s/it][A
 10%|█         | 1/10 [01:12<10:55, 72.81s/it][A
 10%|█         | 1/10 [01:12<10:55, 72.88s/it][A
 10%|█         | 1/10 [01:12<10:56, 72.90s/it][A
 20%|██        | 2/10 [02:23<09:34, 71.76s/it][A[2024-05-30 02:52:42,360] [INFO] [logging.py:96:log_dist] [Rank 0] step=592, skipped=0, lr=[1.9717778385254585e-05], mom=[(0.9, 0.999)]
steps: 592 loss: 1.1125 iter time (s): 71.830 samples/sec: 1.782

 20%|██        | 2/10 [02:25<09:40, 72.50s/it][A
 20%|██        | 2/10 [02:25<09:40, 72.61s/it][A
 20%|██        | 2/10 [02:25<09:41, 72.68s/it][A
 20%|██        | 2/10 [02:25<09:41, 72.68s/it][A
 20%|██        | 2/10 [02:25<09:41, 72.71s/it][A
 20%|██        | 2/10 [02:25<09:41, 72.71s/it][A
 20%|██        | 2/10 [02:25<09:41, 72.71s/it][A
 30%|███       | 3/10 [03:36<08:26, 72.41s/it][A[2024-05-30 02:53:55,539] [INFO] [logging.py:96:log_dist] [Rank 0] step=593, skipped=0, lr=[1.971644073548361e-05], mom=[(0.9, 0.999)]
steps: 593 loss: 1.1202 iter time (s): 72.424 samples/sec: 1.767

 30%|███       | 3/10 [03:38<08:29, 72.82s/it][A
 30%|███       | 3/10 [03:38<08:30, 72.86s/it][A
 30%|███       | 3/10 [03:38<08:30, 72.87s/it][A
 30%|███       | 3/10 [03:38<08:30, 72.89s/it][A
 30%|███       | 3/10 [03:38<08:30, 72.89s/it][A
 30%|███       | 3/10 [03:38<08:30, 72.91s/it][A
 30%|███       | 3/10 [03:38<08:30, 72.91s/it][A
 40%|████      | 4/10 [04:50<07:17, 72.99s/it][A[2024-05-30 02:55:09,396] [INFO] [logging.py:96:log_dist] [Rank 0] step=594, skipped=0, lr=[1.9715099968758085e-05], mom=[(0.9, 0.999)]
steps: 594 loss: 1.1171 iter time (s): 73.145 samples/sec: 1.750

 40%|████      | 4/10 [04:52<07:19, 73.23s/it][A
 40%|████      | 4/10 [04:52<07:19, 73.22s/it][A
 40%|████      | 4/10 [04:52<07:19, 73.28s/it][A
 40%|████      | 4/10 [04:52<07:19, 73.29s/it][A
 40%|████      | 4/10 [04:52<07:19, 73.33s/it][A
 40%|████      | 4/10 [04:52<07:20, 73.35s/it][A
 40%|████      | 4/10 [04:52<07:20, 73.36s/it][A
 50%|█████     | 5/10 [06:03<06:05, 73.11s/it][A[2024-05-30 02:56:22,738] [INFO] [logging.py:96:log_dist] [Rank 0] step=595, skipped=0, lr=[1.9713756085508156e-05], mom=[(0.9, 0.999)]
steps: 595 loss: 1.1014 iter time (s): 72.458 samples/sec: 1.767

 50%|█████     | 5/10 [06:05<06:06, 73.28s/it][A
 50%|█████     | 5/10 [06:05<06:06, 73.29s/it][A
 50%|█████     | 5/10 [06:05<06:06, 73.29s/it][A
 50%|█████     | 5/10 [06:05<06:06, 73.30s/it][A
 50%|█████     | 5/10 [06:05<06:06, 73.28s/it][A
 50%|█████     | 5/10 [06:05<06:06, 73.29s/it][A
 50%|█████     | 5/10 [06:05<06:06, 73.29s/it][A
 60%|██████    | 6/10 [07:16<04:52, 73.16s/it][A[2024-05-30 02:57:35,993] [INFO] [logging.py:96:log_dist] [Rank 0] step=596, skipped=0, lr=[1.9712409086164978e-05], mom=[(0.9, 0.999)]
steps: 596 loss: 1.1160 iter time (s): 72.558 samples/sec: 1.764

 60%|██████    | 6/10 [07:18<04:53, 73.26s/it][A
 60%|██████    | 6/10 [07:18<04:53, 73.29s/it][A
 60%|██████    | 6/10 [07:18<04:53, 73.28s/it][A
 60%|██████    | 6/10 [07:19<04:53, 73.30s/it][A
 60%|██████    | 6/10 [07:19<04:53, 73.29s/it][A
 60%|██████    | 6/10 [07:19<04:53, 73.29s/it][A
 60%|██████    | 6/10 [07:19<04:53, 73.29s/it][A
 70%|███████   | 7/10 [08:30<03:39, 73.26s/it][A[2024-05-30 02:58:49,477] [INFO] [logging.py:96:log_dist] [Rank 0] step=597, skipped=0, lr=[1.9711058971160696e-05], mom=[(0.9, 0.999)]
steps: 597 loss: 1.0862 iter time (s): 72.750 samples/sec: 1.759

 70%|███████   | 7/10 [08:32<03:40, 73.36s/it][A
 70%|███████   | 7/10 [08:32<03:39, 73.33s/it][A
 70%|███████   | 7/10 [08:32<03:40, 73.34s/it][A
 70%|███████   | 7/10 [08:32<03:39, 73.33s/it][A
 70%|███████   | 7/10 [08:32<03:40, 73.35s/it][A
 70%|███████   | 7/10 [08:32<03:40, 73.35s/it][A
 70%|███████   | 7/10 [08:32<03:40, 73.36s/it][A
 80%|████████  | 8/10 [09:44<02:27, 73.51s/it][A[2024-05-30 03:00:03,423] [INFO] [logging.py:96:log_dist] [Rank 0] step=598, skipped=0, lr=[1.9709705740928466e-05], mom=[(0.9, 0.999)]
steps: 598 loss: 1.0925 iter time (s): 73.177 samples/sec: 1.749

 80%|████████  | 8/10 [09:46<02:27, 73.52s/it][A
 80%|████████  | 8/10 [09:46<02:27, 73.54s/it][A
 80%|████████  | 8/10 [09:46<02:27, 73.52s/it][A
 80%|████████  | 8/10 [09:46<02:27, 73.55s/it][A
 80%|████████  | 8/10 [09:46<02:27, 73.53s/it][A
 80%|████████  | 8/10 [09:46<02:27, 73.55s/it][A
 80%|████████  | 8/10 [09:46<02:27, 73.53s/it][A
 90%|█████████ | 9/10 [10:57<01:13, 73.56s/it][A[2024-05-30 03:01:17,192] [INFO] [logging.py:96:log_dist] [Rank 0] step=599, skipped=0, lr=[1.9708349395902437e-05], mom=[(0.9, 0.999)]
steps: 599 loss: 1.0972 iter time (s): 73.056 samples/sec: 1.752

 90%|█████████ | 9/10 [10:59<01:13, 73.61s/it][A
 90%|█████████ | 9/10 [11:00<01:13, 73.61s/it][A
 90%|█████████ | 9/10 [11:00<01:13, 73.61s/it][A
 90%|█████████ | 9/10 [11:00<01:13, 73.61s/it][A
 90%|█████████ | 9/10 [11:00<01:13, 73.61s/it][A
 90%|█████████ | 9/10 [11:00<01:13, 73.61s/it][A
 90%|█████████ | 9/10 [11:00<01:13, 73.61s/it][A
100%|██████████| 10/10 [12:11<00:00, 73.65s/it][A100%|██████████| 10/10 [12:11<00:00, 73.18s/it]
 12%|█▏        | 61/520 [5:09:34<120:26:52, 944.69s/it] 
  0%|          | 0/10 [00:00<?, ?it/s][A[2024-05-30 03:02:31,044] [INFO] [logging.py:96:log_dist] [Rank 0] step=600, skipped=0, lr=[1.9706989936517756e-05], mom=[(0.9, 0.999)]
steps: 600 loss: 1.0981 iter time (s): 73.121 samples/sec: 1.751

100%|██████████| 10/10 [12:13<00:00, 73.68s/it][A100%|██████████| 10/10 [12:13<00:00, 73.37s/it]
 12%|█▏        | 61/520 [5:09:06<120:28:12, 944.86s/it] 
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [12:13<00:00, 73.68s/it][A100%|██████████| 10/10 [12:13<00:00, 73.38s/it]
 12%|█▏        | 61/520 [5:09:44<120:28:23, 944.89s/it] 
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [12:13<00:00, 73.68s/it][A100%|██████████| 10/10 [12:13<00:00, 73.40s/it]
 12%|█▏        | 61/520 [5:09:43<120:28:27, 944.90s/it] 
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [12:14<00:00, 73.68s/it][A100%|██████████| 10/10 [12:14<00:00, 73.41s/it]
 12%|█▏        | 61/520 [5:08:35<120:28:25, 944.89s/it] 
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [12:14<00:00, 73.67s/it][A100%|██████████| 10/10 [12:14<00:00, 73.41s/it]
 12%|█▏        | 61/520 [5:09:02<120:28:26, 944.90s/it] 
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [12:14<00:00, 73.68s/it][A100%|██████████| 10/10 [12:14<00:00, 73.41s/it]
 12%|█▏        | 61/520 [5:09:46<120:28:36, 944.92s/it] 
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [12:14<00:00, 73.68s/it][A100%|██████████| 10/10 [12:14<00:00, 73.42s/it]
 12%|█▏        | 61/520 [5:07:31<120:28:19, 944.88s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_240
Training on 1280 of 1280 sentences.

  0%|          | 0/10 [00:00<?, ?it/s][A
 10%|█         | 1/10 [00:56<08:29, 56.65s/it][A[2024-05-30 03:03:27,450] [INFO] [logging.py:96:log_dist] [Rank 0] step=601, skipped=0, lr=[1.9705627363210574e-05], mom=[(0.9, 0.999)]
steps: 601 loss: 0.6543 iter time (s): 55.505 samples/sec: 2.306

 10%|█         | 1/10 [00:56<08:26, 56.33s/it][A
 10%|█         | 1/10 [00:56<08:27, 56.37s/it][A
 10%|█         | 1/10 [00:56<08:27, 56.34s/it][A
 10%|█         | 1/10 [00:56<08:27, 56.35s/it][A
 10%|█         | 1/10 [00:56<08:26, 56.33s/it][A
 10%|█         | 1/10 [00:56<08:26, 56.29s/it][A
 10%|█         | 1/10 [00:56<08:26, 56.33s/it][A
 20%|██        | 2/10 [01:52<07:30, 56.29s/it][A[2024-05-30 03:04:23,501] [INFO] [logging.py:96:log_dist] [Rank 0] step=602, skipped=0, lr=[1.970426167641804e-05], mom=[(0.9, 0.999)]
steps: 602 loss: 0.6839 iter time (s): 55.419 samples/sec: 2.310

 20%|██        | 2/10 [01:52<07:29, 56.16s/it][A
 20%|██        | 2/10 [01:52<07:29, 56.14s/it][A
 20%|██        | 2/10 [01:52<07:29, 56.17s/it][A
 20%|██        | 2/10 [01:52<07:29, 56.14s/it][A
 20%|██        | 2/10 [01:52<07:29, 56.16s/it][A
 20%|██        | 2/10 [01:52<07:29, 56.15s/it][A
 20%|██        | 2/10 [01:52<07:29, 56.15s/it][A
 30%|███       | 3/10 [02:49<06:36, 56.64s/it][A[2024-05-30 03:05:20,537] [INFO] [logging.py:96:log_dist] [Rank 0] step=603, skipped=0, lr=[1.970289287657829e-05], mom=[(0.9, 0.999)]
steps: 603 loss: 0.6822 iter time (s): 56.416 samples/sec: 2.269

 30%|███       | 3/10 [02:49<06:35, 56.56s/it][A
 30%|███       | 3/10 [02:49<06:36, 56.57s/it][A
 30%|███       | 3/10 [02:49<06:35, 56.54s/it][A
 30%|███       | 3/10 [02:49<06:35, 56.53s/it][A
 30%|███       | 3/10 [02:49<06:35, 56.55s/it][A
 30%|███       | 3/10 [02:49<06:35, 56.54s/it][A
 30%|███       | 3/10 [02:49<06:35, 56.54s/it][A
 40%|████      | 4/10 [03:46<05:39, 56.51s/it][A[2024-05-30 03:06:16,842] [INFO] [logging.py:96:log_dist] [Rank 0] step=604, skipped=0, lr=[1.970152096413048e-05], mom=[(0.9, 0.999)]
steps: 604 loss: 0.6467 iter time (s): 55.697 samples/sec: 2.298

 40%|████      | 4/10 [03:45<05:38, 56.47s/it][A
 40%|████      | 4/10 [03:45<05:38, 56.45s/it][A
 40%|████      | 4/10 [03:45<05:38, 56.46s/it][A
 40%|████      | 4/10 [03:45<05:38, 56.45s/it][A
 40%|████      | 4/10 [03:45<05:38, 56.47s/it][A
 40%|████      | 4/10 [03:45<05:38, 56.46s/it][A
 40%|████      | 4/10 [03:45<05:38, 56.45s/it][A
 50%|█████     | 5/10 [04:40<04:39, 55.92s/it][A[2024-05-30 03:07:11,733] [INFO] [logging.py:96:log_dist] [Rank 0] step=605, skipped=0, lr=[1.9700145939514747e-05], mom=[(0.9, 0.999)]
steps: 605 loss: 0.6151 iter time (s): 54.267 samples/sec: 2.359

 50%|█████     | 5/10 [04:40<04:39, 55.89s/it][A
 50%|█████     | 5/10 [04:40<04:39, 55.89s/it][A
 50%|█████     | 5/10 [04:40<04:39, 55.90s/it][A
 50%|█████     | 5/10 [04:40<04:39, 55.91s/it][A
 50%|█████     | 5/10 [04:40<04:39, 55.90s/it][A
 50%|█████     | 5/10 [04:40<04:39, 55.89s/it][A
 50%|█████     | 5/10 [04:40<04:39, 55.89s/it][A
 60%|██████    | 6/10 [05:35<03:41, 55.44s/it][A[2024-05-30 03:08:06,236] [INFO] [logging.py:96:log_dist] [Rank 0] step=606, skipped=0, lr=[1.9698767803172238e-05], mom=[(0.9, 0.999)]
steps: 606 loss: 0.6199 iter time (s): 53.893 samples/sec: 2.375

 60%|██████    | 6/10 [05:35<03:41, 55.42s/it][A
 60%|██████    | 6/10 [05:35<03:41, 55.41s/it][A
 60%|██████    | 6/10 [05:35<03:41, 55.43s/it][A
 60%|██████    | 6/10 [05:35<03:41, 55.42s/it][A
 60%|██████    | 6/10 [05:35<03:41, 55.42s/it][A
 60%|██████    | 6/10 [05:35<03:41, 55.41s/it][A
 60%|██████    | 6/10 [05:35<03:41, 55.42s/it][A
 70%|███████   | 7/10 [06:30<02:45, 55.19s/it][A[2024-05-30 03:09:00,909] [INFO] [logging.py:96:log_dist] [Rank 0] step=607, skipped=0, lr=[1.9697386555545092e-05], mom=[(0.9, 0.999)]
steps: 607 loss: 0.5746 iter time (s): 54.103 samples/sec: 2.366

 70%|███████   | 7/10 [06:29<02:45, 55.19s/it][A
 70%|███████   | 7/10 [06:29<02:45, 55.20s/it][A
 70%|███████   | 7/10 [06:29<02:45, 55.17s/it][A
 70%|███████   | 7/10 [06:29<02:45, 55.17s/it][A
 70%|███████   | 7/10 [06:29<02:45, 55.18s/it][A
 70%|███████   | 7/10 [06:29<02:45, 55.17s/it][A
 70%|███████   | 7/10 [06:29<02:45, 55.18s/it][A
 80%|████████  | 8/10 [07:25<01:50, 55.13s/it][A[2024-05-30 03:09:55,910] [INFO] [logging.py:96:log_dist] [Rank 0] step=608, skipped=0, lr=[1.9696002197076443e-05], mom=[(0.9, 0.999)]
steps: 608 loss: 0.6108 iter time (s): 54.370 samples/sec: 2.354

 80%|████████  | 8/10 [07:24<01:50, 55.12s/it][A
 80%|████████  | 8/10 [07:24<01:50, 55.12s/it][A
 80%|████████  | 8/10 [07:24<01:50, 55.12s/it][A
 80%|████████  | 8/10 [07:24<01:50, 55.11s/it][A
 80%|████████  | 8/10 [07:24<01:50, 55.11s/it][A
 80%|████████  | 8/10 [07:24<01:50, 55.11s/it][A
 80%|████████  | 8/10 [07:24<01:50, 55.11s/it][A
 90%|█████████ | 9/10 [08:20<00:55, 55.36s/it][A[2024-05-30 03:10:51,782] [INFO] [logging.py:96:log_dist] [Rank 0] step=609, skipped=0, lr=[1.9694614728210435e-05], mom=[(0.9, 0.999)]
steps: 609 loss: 0.5924 iter time (s): 55.282 samples/sec: 2.315

 90%|█████████ | 9/10 [08:20<00:55, 55.35s/it][A
 90%|█████████ | 9/10 [08:20<00:55, 55.35s/it][A
 90%|█████████ | 9/10 [08:20<00:55, 55.34s/it][A
 90%|█████████ | 9/10 [08:20<00:55, 55.35s/it][A
 90%|█████████ | 9/10 [08:20<00:55, 55.36s/it][A
 90%|█████████ | 9/10 [08:20<00:55, 55.34s/it][A
 90%|█████████ | 9/10 [08:20<00:55, 55.35s/it][A
100%|██████████| 10/10 [09:18<00:00, 55.89s/it][A100%|██████████| 10/10 [09:18<00:00, 55.81s/it]
 12%|█▏        | 62/520 [5:18:52<105:34:20, 829.83s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A[2024-05-30 03:11:48,862] [INFO] [logging.py:96:log_dist] [Rank 0] step=610, skipped=0, lr=[1.96932241493922e-05], mom=[(0.9, 0.999)]
steps: 610 loss: 0.5938 iter time (s): 56.534 samples/sec: 2.264

100%|██████████| 10/10 [09:17<00:00, 55.90s/it][A100%|██████████| 10/10 [09:17<00:00, 55.78s/it]
 12%|█▏        | 62/520 [5:18:24<105:34:09, 829.80s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [09:17<00:00, 55.89s/it][A100%|██████████| 10/10 [09:17<00:00, 55.78s/it]
 12%|█▏        | 62/520 [5:19:01<105:34:16, 829.82s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [09:17<00:00, 55.91s/it][A100%|██████████| 10/10 [09:17<00:00, 55.78s/it]
 12%|█▏        | 62/520 [5:19:01<105:34:22, 829.83s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [09:17<00:00, 55.89s/it][A100%|██████████| 10/10 [09:17<00:00, 55.77s/it]
 12%|█▏        | 62/520 [5:17:53<105:34:10, 829.81s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [09:17<00:00, 55.89s/it][A100%|██████████| 10/10 [09:17<00:00, 55.77s/it]
 12%|█▏        | 62/520 [5:18:20<105:34:11, 829.81s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [09:17<00:00, 55.90s/it][A100%|██████████| 10/10 [09:17<00:00, 55.77s/it]
 12%|█▏        | 62/520 [5:19:03<105:34:20, 829.83s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [09:17<00:00, 55.90s/it][A100%|██████████| 10/10 [09:17<00:00, 55.77s/it]
 12%|█▏        | 62/520 [5:16:48<105:34:05, 829.79s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_297
Training on 1280 of 1280 sentences.

  0%|          | 0/10 [00:00<?, ?it/s][A
 10%|█         | 1/10 [01:21<12:10, 81.16s/it][A[2024-05-30 03:13:10,923] [INFO] [logging.py:96:log_dist] [Rank 0] step=611, skipped=0, lr=[1.9691830461067862e-05], mom=[(0.9, 0.999)]
steps: 611 loss: 0.5960 iter time (s): 81.325 samples/sec: 1.574

 10%|█         | 1/10 [01:22<12:18, 82.04s/it][A
 10%|█         | 1/10 [01:22<12:19, 82.16s/it][A
 10%|█         | 1/10 [01:22<12:19, 82.11s/it][A
 10%|█         | 1/10 [01:22<12:19, 82.21s/it][A
 10%|█         | 1/10 [01:22<12:20, 82.23s/it][A
 10%|█         | 1/10 [01:22<12:20, 82.22s/it][A
 10%|█         | 1/10 [01:22<12:20, 82.23s/it][A
 20%|██        | 2/10 [02:44<10:59, 82.48s/it][A[2024-05-30 03:14:34,332] [INFO] [logging.py:96:log_dist] [Rank 0] step=612, skipped=0, lr=[1.9690433663684562e-05], mom=[(0.9, 0.999)]
steps: 612 loss: 0.6069 iter time (s): 82.689 samples/sec: 1.548

 20%|██        | 2/10 [02:45<11:03, 82.90s/it][A
 20%|██        | 2/10 [02:45<11:03, 82.92s/it][A
 20%|██        | 2/10 [02:45<11:03, 82.90s/it][A
 20%|██        | 2/10 [02:45<11:03, 82.92s/it][A
 20%|██        | 2/10 [02:45<11:03, 82.97s/it][A
 20%|██        | 2/10 [02:45<11:03, 82.94s/it][A
 20%|██        | 2/10 [02:45<11:03, 82.95s/it][A
 30%|███       | 3/10 [04:09<09:44, 83.51s/it][A[2024-05-30 03:15:59,062] [INFO] [logging.py:96:log_dist] [Rank 0] step=613, skipped=0, lr=[1.968903375769042e-05], mom=[(0.9, 0.999)]
steps: 613 loss: 0.6069 iter time (s): 83.891 samples/sec: 1.526

 30%|███       | 3/10 [04:10<09:46, 83.72s/it][A
 30%|███       | 3/10 [04:10<09:45, 83.71s/it][A
 30%|███       | 3/10 [04:10<09:46, 83.72s/it][A
 30%|███       | 3/10 [04:10<09:46, 83.72s/it][A
 30%|███       | 3/10 [04:10<09:46, 83.73s/it][A
 30%|███       | 3/10 [04:10<09:46, 83.72s/it][A
 30%|███       | 3/10 [04:10<09:46, 83.73s/it][A
 40%|████      | 4/10 [05:34<08:25, 84.29s/it][A[2024-05-30 03:17:24,546] [INFO] [logging.py:96:log_dist] [Rank 0] step=614, skipped=0, lr=[1.9687630743534567e-05], mom=[(0.9, 0.999)]
steps: 614 loss: 0.5953 iter time (s): 84.740 samples/sec: 1.511

 40%|████      | 4/10 [05:35<08:26, 84.43s/it][A
 40%|████      | 4/10 [05:35<08:26, 84.42s/it][A
 40%|████      | 4/10 [05:35<08:26, 84.44s/it][A
 40%|████      | 4/10 [05:35<08:26, 84.44s/it][A
 40%|████      | 4/10 [05:35<08:26, 84.44s/it][A
 40%|████      | 4/10 [05:35<08:26, 84.44s/it][A
 40%|████      | 4/10 [05:35<08:26, 84.45s/it][A
 50%|█████     | 5/10 [07:00<07:04, 84.85s/it][A[2024-05-30 03:18:50,405] [INFO] [logging.py:96:log_dist] [Rank 0] step=615, skipped=0, lr=[1.968622462166712e-05], mom=[(0.9, 0.999)]
steps: 615 loss: 0.5929 iter time (s): 85.032 samples/sec: 1.505

 50%|█████     | 5/10 [07:01<07:04, 84.93s/it][A
 50%|█████     | 5/10 [07:01<07:04, 84.92s/it][A
 50%|█████     | 5/10 [07:01<07:04, 84.89s/it][A
 50%|█████     | 5/10 [07:01<07:04, 84.93s/it][A
 50%|█████     | 5/10 [07:01<07:04, 84.93s/it][A
 50%|█████     | 5/10 [07:01<07:04, 84.92s/it][A
 50%|█████     | 5/10 [07:01<07:04, 84.93s/it][A
 60%|██████    | 6/10 [08:22<05:35, 83.85s/it][A[2024-05-30 03:20:12,304] [INFO] [logging.py:96:log_dist] [Rank 0] step=616, skipped=0, lr=[1.9684815392539197e-05], mom=[(0.9, 0.999)]
steps: 616 loss: 0.6030 iter time (s): 81.133 samples/sec: 1.578

 60%|██████    | 6/10 [08:23<05:35, 83.90s/it][A
 60%|██████    | 6/10 [08:23<05:35, 83.92s/it][A
 60%|██████    | 6/10 [08:23<05:35, 83.91s/it][A
 60%|██████    | 6/10 [08:23<05:35, 83.91s/it][A
 60%|██████    | 6/10 [08:23<05:35, 83.90s/it][A
 60%|██████    | 6/10 [08:23<05:35, 83.91s/it][A
 60%|██████    | 6/10 [08:23<05:35, 83.91s/it][A
 70%|███████   | 7/10 [09:42<04:07, 82.62s/it][A[2024-05-30 03:21:32,409] [INFO] [logging.py:96:log_dist] [Rank 0] step=617, skipped=0, lr=[1.968340305660292e-05], mom=[(0.9, 0.999)]
steps: 617 loss: 0.6023 iter time (s): 79.313 samples/sec: 1.614

 70%|███████   | 7/10 [09:43<04:07, 82.66s/it][A
 70%|███████   | 7/10 [09:43<04:07, 82.66s/it][A
 70%|███████   | 7/10 [09:43<04:07, 82.65s/it][A
 70%|███████   | 7/10 [09:43<04:07, 82.65s/it][A
 70%|███████   | 7/10 [09:43<04:07, 82.67s/it][A
 70%|███████   | 7/10 [09:43<04:07, 82.66s/it][A
 70%|███████   | 7/10 [09:43<04:07, 82.66s/it][A
 80%|████████  | 8/10 [11:03<02:44, 82.05s/it][A[2024-05-30 03:22:53,216] [INFO] [logging.py:96:log_dist] [Rank 0] step=618, skipped=0, lr=[1.9681987614311394e-05], mom=[(0.9, 0.999)]
steps: 618 loss: 0.5986 iter time (s): 80.039 samples/sec: 1.599

 80%|████████  | 8/10 [11:04<02:44, 82.06s/it][A
 80%|████████  | 8/10 [11:04<02:44, 82.06s/it][A
 80%|████████  | 8/10 [11:04<02:44, 82.07s/it][A
 80%|████████  | 8/10 [11:04<02:44, 82.09s/it][A
 80%|████████  | 8/10 [11:04<02:44, 82.08s/it][A
 80%|████████  | 8/10 [11:04<02:44, 82.07s/it][A
 80%|████████  | 8/10 [11:04<02:44, 82.08s/it][A
 90%|█████████ | 9/10 [12:24<01:21, 81.74s/it][A[2024-05-30 03:24:14,278] [INFO] [logging.py:96:log_dist] [Rank 0] step=619, skipped=0, lr=[1.9680569066118732e-05], mom=[(0.9, 0.999)]
steps: 619 loss: 0.5913 iter time (s): 80.270 samples/sec: 1.595

 90%|█████████ | 9/10 [12:25<01:21, 81.74s/it][A
 90%|█████████ | 9/10 [12:25<01:21, 81.77s/it][A
 90%|█████████ | 9/10 [12:25<01:21, 81.76s/it][A
 90%|█████████ | 9/10 [12:25<01:21, 81.75s/it][A
 90%|█████████ | 9/10 [12:25<01:21, 81.74s/it][A
 90%|█████████ | 9/10 [12:25<01:21, 81.74s/it][A
 90%|█████████ | 9/10 [12:25<01:21, 81.75s/it][A
100%|██████████| 10/10 [13:45<00:00, 81.61s/it][A100%|██████████| 10/10 [13:45<00:00, 82.58s/it]
 12%|█▏        | 63/520 [5:32:39<105:11:58, 828.71s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A[2024-05-30 03:25:35,596] [INFO] [logging.py:96:log_dist] [Rank 0] step=620, skipped=0, lr=[1.9679147412480035e-05], mom=[(0.9, 0.999)]
steps: 620 loss: 0.5997 iter time (s): 80.578 samples/sec: 1.589

100%|██████████| 10/10 [13:46<00:00, 81.62s/it][A100%|██████████| 10/10 [13:46<00:00, 82.68s/it]
 12%|█▏        | 63/520 [5:32:11<105:13:27, 828.90s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:46<00:00, 81.62s/it][A100%|██████████| 10/10 [13:46<00:00, 82.68s/it]
 12%|█▏        | 63/520 [5:32:48<105:13:39, 828.93s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:46<00:00, 81.60s/it][A100%|██████████| 10/10 [13:46<00:00, 82.67s/it]
 12%|█▏        | 63/520 [5:32:47<105:13:27, 828.90s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:46<00:00, 81.63s/it][A100%|██████████| 10/10 [13:46<00:00, 82.69s/it]
 12%|█▏        | 63/520 [5:31:40<105:13:45, 828.94s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:46<00:00, 81.63s/it][A100%|██████████| 10/10 [13:46<00:00, 82.69s/it]
 12%|█▏        | 63/520 [5:32:07<105:13:46, 828.94s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:46<00:00, 81.62s/it][A100%|██████████| 10/10 [13:46<00:00, 82.69s/it]
 12%|█▏        | 63/520 [5:32:50<105:13:48, 828.95s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:46<00:00, 81.62s/it][A100%|██████████| 10/10 [13:46<00:00, 82.69s/it]
 12%|█▏        | 63/520 [5:30:35<105:13:37, 828.92s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_2
Training on 1280 of 1280 sentences.

  0%|          | 0/10 [00:00<?, ?it/s][A
 10%|█         | 1/10 [02:02<18:18, 122.08s/it][A[2024-05-30 03:27:38,631] [INFO] [logging.py:96:log_dist] [Rank 0] step=621, skipped=0, lr=[1.9677722653851413e-05], mom=[(0.9, 0.999)]
steps: 621 loss: 0.8697 iter time (s): 122.337 samples/sec: 1.046

 10%|█         | 1/10 [02:03<18:29, 123.27s/it][A
 10%|█         | 1/10 [02:03<18:29, 123.29s/it][A
 10%|█         | 1/10 [02:03<18:31, 123.45s/it][A
 10%|█         | 1/10 [02:03<18:29, 123.31s/it][A
 10%|█         | 1/10 [02:03<18:30, 123.42s/it][A
 10%|█         | 1/10 [02:03<18:31, 123.49s/it][A
 10%|█         | 1/10 [02:03<18:31, 123.50s/it][A
 20%|██        | 2/10 [04:05<16:23, 122.89s/it][A[2024-05-30 03:29:42,074] [INFO] [logging.py:96:log_dist] [Rank 0] step=622, skipped=0, lr=[1.967629479068996e-05], mom=[(0.9, 0.999)]
steps: 622 loss: 0.8563 iter time (s): 122.473 samples/sec: 1.045

 20%|██        | 2/10 [04:06<16:27, 123.46s/it][A
 20%|██        | 2/10 [04:06<16:27, 123.43s/it][A
 20%|██        | 2/10 [04:06<16:27, 123.43s/it][A
 20%|██        | 2/10 [04:06<16:27, 123.40s/it][A
 20%|██        | 2/10 [04:06<16:27, 123.38s/it][A
 20%|██        | 2/10 [04:06<16:27, 123.38s/it][A
 20%|██        | 2/10 [04:06<16:26, 123.37s/it][A
 30%|███       | 3/10 [06:09<14:23, 123.29s/it][A[2024-05-30 03:31:45,846] [INFO] [logging.py:96:log_dist] [Rank 0] step=623, skipped=0, lr=[1.9674863823453768e-05], mom=[(0.9, 0.999)]
steps: 623 loss: 0.8332 iter time (s): 122.922 samples/sec: 1.041

 30%|███       | 3/10 [06:10<14:26, 123.73s/it][A
 30%|███       | 3/10 [06:10<14:25, 123.65s/it][A
 30%|███       | 3/10 [06:10<14:25, 123.70s/it][A
 30%|███       | 3/10 [06:10<14:25, 123.63s/it][A
 30%|███       | 3/10 [06:10<14:25, 123.67s/it][A
 30%|███       | 3/10 [06:11<14:26, 123.76s/it][A
 30%|███       | 3/10 [06:11<14:27, 123.88s/it][A
 40%|████      | 4/10 [08:13<12:20, 123.46s/it][A[2024-05-30 03:33:49,579] [INFO] [logging.py:96:log_dist] [Rank 0] step=624, skipped=0, lr=[1.9673429752601926e-05], mom=[(0.9, 0.999)]
steps: 624 loss: 0.8628 iter time (s): 122.164 samples/sec: 1.048

 40%|████      | 4/10 [08:14<12:21, 123.56s/it][A
 40%|████      | 4/10 [08:14<12:21, 123.58s/it][A
 40%|████      | 4/10 [08:14<12:21, 123.60s/it][A
 40%|████      | 4/10 [08:14<12:21, 123.55s/it][A
 40%|████      | 4/10 [08:14<12:21, 123.52s/it][A
 40%|████      | 4/10 [08:14<12:21, 123.57s/it][A
 40%|████      | 4/10 [08:14<12:21, 123.57s/it][A
 50%|█████     | 5/10 [10:16<10:17, 123.40s/it][A[2024-05-30 03:35:52,845] [INFO] [logging.py:96:log_dist] [Rank 0] step=625, skipped=0, lr=[1.967199257859452e-05], mom=[(0.9, 0.999)]
steps: 625 loss: 0.8498 iter time (s): 122.363 samples/sec: 1.046

 50%|█████     | 5/10 [10:17<10:17, 123.48s/it][A
 50%|█████     | 5/10 [10:17<10:17, 123.48s/it][A
 50%|█████     | 5/10 [10:17<10:17, 123.51s/it][A
 50%|█████     | 5/10 [10:17<10:17, 123.49s/it][A
 50%|█████     | 5/10 [10:17<10:17, 123.51s/it][A
 50%|█████     | 5/10 [10:17<10:17, 123.44s/it][A
 50%|█████     | 5/10 [10:17<10:17, 123.49s/it][A
 60%|██████    | 6/10 [12:19<08:13, 123.37s/it][A[2024-05-30 03:37:56,165] [INFO] [logging.py:96:log_dist] [Rank 0] step=626, skipped=0, lr=[1.967055230189264e-05], mom=[(0.9, 0.999)]
steps: 626 loss: 0.8793 iter time (s): 122.510 samples/sec: 1.045

 60%|██████    | 6/10 [12:20<08:13, 123.43s/it][A
 60%|██████    | 6/10 [12:20<08:13, 123.45s/it][A
 60%|██████    | 6/10 [12:21<08:13, 123.47s/it][A
 60%|██████    | 6/10 [12:20<08:13, 123.46s/it][A
 60%|██████    | 6/10 [12:20<08:13, 123.44s/it][A
 60%|██████    | 6/10 [12:20<08:13, 123.44s/it][A
 60%|██████    | 6/10 [12:20<08:13, 123.42s/it][A
 70%|███████   | 7/10 [14:23<06:10, 123.46s/it][A[2024-05-30 03:39:59,829] [INFO] [logging.py:96:log_dist] [Rank 0] step=627, skipped=0, lr=[1.9669108922958348e-05], mom=[(0.9, 0.999)]
steps: 627 loss: 0.8564 iter time (s): 122.729 samples/sec: 1.043

 70%|███████   | 7/10 [14:24<06:10, 123.52s/it][A
 70%|███████   | 7/10 [14:24<06:10, 123.53s/it][A
 70%|███████   | 7/10 [14:24<06:10, 123.51s/it][A
 70%|███████   | 7/10 [14:24<06:10, 123.56s/it][A
 70%|███████   | 7/10 [14:24<06:10, 123.54s/it][A
 70%|███████   | 7/10 [14:24<06:10, 123.50s/it][A
 70%|███████   | 7/10 [14:24<06:10, 123.48s/it][A
 80%|████████  | 8/10 [16:26<04:06, 123.32s/it][A[2024-05-30 03:42:02,842] [INFO] [logging.py:96:log_dist] [Rank 0] step=628, skipped=0, lr=[1.9667662442254724e-05], mom=[(0.9, 0.999)]
steps: 628 loss: 0.8834 iter time (s): 122.180 samples/sec: 1.048

 80%|████████  | 8/10 [16:27<04:06, 123.37s/it][A
 80%|████████  | 8/10 [16:27<04:06, 123.34s/it][A
 80%|████████  | 8/10 [16:27<04:06, 123.35s/it][A
 80%|████████  | 8/10 [16:27<04:06, 123.37s/it][A
 80%|████████  | 8/10 [16:27<04:06, 123.37s/it][A
 80%|████████  | 8/10 [16:27<04:06, 123.36s/it][A
 80%|████████  | 8/10 [16:27<04:06, 123.35s/it][A
 90%|█████████ | 9/10 [18:30<02:03, 123.54s/it][A[2024-05-30 03:44:06,859] [INFO] [logging.py:96:log_dist] [Rank 0] step=629, skipped=0, lr=[1.9666212860245836e-05], mom=[(0.9, 0.999)]
steps: 629 loss: 0.8349 iter time (s): 123.139 samples/sec: 1.039

 90%|█████████ | 9/10 [18:31<02:03, 123.64s/it][A
 90%|█████████ | 9/10 [18:31<02:03, 123.63s/it][A
 90%|█████████ | 9/10 [18:31<02:03, 123.60s/it][A
 90%|█████████ | 9/10 [18:32<02:03, 123.65s/it][A
 90%|█████████ | 9/10 [18:31<02:03, 123.63s/it][A
 90%|█████████ | 9/10 [18:31<02:03, 123.61s/it][A
 90%|█████████ | 9/10 [18:31<02:03, 123.60s/it][A
100%|██████████| 10/10 [20:33<00:00, 123.52s/it][A100%|██████████| 10/10 [20:33<00:00, 123.38s/it]
 12%|█▏        | 64/520 [5:53:12<120:17:38, 949.69s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A[2024-05-30 03:46:10,326] [INFO] [logging.py:96:log_dist] [Rank 0] step=630, skipped=0, lr=[1.9664760177396745e-05], mom=[(0.9, 0.999)]
steps: 630 loss: 0.7963 iter time (s): 122.408 samples/sec: 1.046

100%|██████████| 10/10 [20:35<00:00, 123.50s/it][A100%|██████████| 10/10 [20:35<00:00, 123.51s/it]
 12%|█▏        | 64/520 [5:52:46<120:21:31, 950.20s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [20:35<00:00, 123.52s/it][A100%|██████████| 10/10 [20:35<00:00, 123.51s/it]
 12%|█▏        | 64/520 [5:53:23<120:21:42, 950.23s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [20:35<00:00, 123.54s/it][A
100%|██████████| 10/10 [20:35<00:00, 123.51s/it]
 12%|█▏        | 64/520 [5:52:15<120:21:54, 950.25s/it]100%|██████████| 10/10 [20:35<00:00, 123.56s/it][A100%|██████████| 10/10 [20:35<00:00, 123.54s/it]
 12%|█▏        | 64/520 [5:53:23<120:22:11, 950.29s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [20:35<00:00, 123.54s/it][A100%|██████████| 10/10 [20:35<00:00, 123.51s/it]
 12%|█▏        | 64/520 [5:52:42<120:21:55, 950.25s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [20:35<00:00, 123.52s/it][A100%|██████████| 10/10 [20:35<00:00, 123.51s/it]
 12%|█▏        | 64/520 [5:51:10<120:21:47, 950.24s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_127

100%|██████████| 10/10 [20:35<00:00, 123.53s/it][A100%|██████████| 10/10 [20:35<00:00, 123.51s/it]
 12%|█▏        | 64/520 [5:53:26<120:21:57, 950.26s/it]Training on 1280 of 1280 sentences.

  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
 10%|█         | 1/10 [01:48<16:15, 108.33s/it][A[2024-05-30 03:47:58,583] [INFO] [logging.py:96:log_dist] [Rank 0] step=631, skipped=0, lr=[1.9663304394173507e-05], mom=[(0.9, 0.999)]
steps: 631 loss: 0.5817 iter time (s): 107.071 samples/sec: 1.195

 10%|█         | 1/10 [01:47<16:10, 107.89s/it][A
 10%|█         | 1/10 [01:47<16:10, 107.84s/it][A
 10%|█         | 1/10 [01:47<16:09, 107.67s/it][A
 10%|█         | 1/10 [01:47<16:09, 107.70s/it][A
 10%|█         | 1/10 [01:47<16:09, 107.76s/it][A
 10%|█         | 1/10 [01:47<16:09, 107.76s/it][A
 10%|█         | 1/10 [01:47<16:10, 107.80s/it][A
 20%|██        | 2/10 [03:35<14:19, 107.46s/it][A[2024-05-30 03:49:45,451] [INFO] [logging.py:96:log_dist] [Rank 0] step=632, skipped=0, lr=[1.9661845511043168e-05], mom=[(0.9, 0.999)]
steps: 632 loss: 0.5932 iter time (s): 106.142 samples/sec: 1.206

 20%|██        | 2/10 [03:34<14:18, 107.34s/it][A
 20%|██        | 2/10 [03:34<14:18, 107.31s/it][A
 20%|██        | 2/10 [03:34<14:18, 107.32s/it][A
 20%|██        | 2/10 [03:34<14:19, 107.40s/it][A
 20%|██        | 2/10 [03:34<14:19, 107.40s/it][A
 20%|██        | 2/10 [03:35<14:20, 107.61s/it][A
 20%|██        | 2/10 [03:35<14:21, 107.72s/it][A
 30%|███       | 3/10 [05:22<12:31, 107.29s/it][A[2024-05-30 03:51:32,524] [INFO] [logging.py:96:log_dist] [Rank 0] step=633, skipped=0, lr=[1.9660383528473782e-05], mom=[(0.9, 0.999)]
steps: 633 loss: 0.5657 iter time (s): 105.564 samples/sec: 1.213

 30%|███       | 3/10 [05:21<12:30, 107.19s/it][A
 30%|███       | 3/10 [05:21<12:30, 107.17s/it][A
 30%|███       | 3/10 [05:21<12:29, 107.12s/it][A
 30%|███       | 3/10 [05:21<12:30, 107.15s/it][A
 30%|███       | 3/10 [05:21<12:29, 107.08s/it][A
 30%|███       | 3/10 [05:21<12:29, 107.14s/it][A
 30%|███       | 3/10 [05:21<12:29, 107.07s/it][A
 40%|████      | 4/10 [07:20<11:09, 111.61s/it][A[2024-05-30 03:53:30,762] [INFO] [logging.py:96:log_dist] [Rank 0] step=634, skipped=0, lr=[1.965891844693439e-05], mom=[(0.9, 0.999)]
steps: 634 loss: 0.5728 iter time (s): 117.506 samples/sec: 1.089

 40%|████      | 4/10 [07:20<11:09, 111.55s/it][A
 40%|████      | 4/10 [07:20<11:09, 111.57s/it][A
 40%|████      | 4/10 [07:19<11:09, 111.50s/it][A
 40%|████      | 4/10 [07:19<11:09, 111.50s/it][A
 40%|████      | 4/10 [07:19<11:08, 111.48s/it][A
 40%|████      | 4/10 [07:19<11:09, 111.52s/it][A
 40%|████      | 4/10 [07:19<11:08, 111.48s/it][A
 50%|█████     | 5/10 [09:13<09:20, 112.15s/it][A[2024-05-30 03:55:23,857] [INFO] [logging.py:96:log_dist] [Rank 0] step=635, skipped=0, lr=[1.9657450266895016e-05], mom=[(0.9, 0.999)]
steps: 635 loss: 0.5978 iter time (s): 112.352 samples/sec: 1.139

 50%|█████     | 5/10 [09:13<09:20, 112.10s/it][A
 50%|█████     | 5/10 [09:13<09:20, 112.08s/it][A
 50%|█████     | 5/10 [09:12<09:20, 112.09s/it][A
 50%|█████     | 5/10 [09:13<09:20, 112.10s/it][A
 50%|█████     | 5/10 [09:13<09:20, 112.07s/it][A
 50%|█████     | 5/10 [09:13<09:20, 112.09s/it][A
 50%|█████     | 5/10 [09:13<09:20, 112.06s/it][A
 60%|██████    | 6/10 [11:00<07:21, 110.38s/it][A[2024-05-30 03:57:10,834] [INFO] [logging.py:96:log_dist] [Rank 0] step=636, skipped=0, lr=[1.96559789888267e-05], mom=[(0.9, 0.999)]
steps: 636 loss: 0.5923 iter time (s): 106.246 samples/sec: 1.205

 60%|██████    | 6/10 [11:00<07:21, 110.34s/it][A
 60%|██████    | 6/10 [11:00<07:21, 110.34s/it][A
 60%|██████    | 6/10 [10:59<07:21, 110.34s/it][A
 60%|██████    | 6/10 [10:59<07:21, 110.33s/it][A
 60%|██████    | 6/10 [10:59<07:21, 110.32s/it][A
 60%|██████    | 6/10 [10:59<07:21, 110.33s/it][A
 60%|██████    | 6/10 [10:59<07:21, 110.31s/it][A
 70%|███████   | 7/10 [12:44<05:25, 108.43s/it][A[2024-05-30 03:58:55,211] [INFO] [logging.py:96:log_dist] [Rank 0] step=637, skipped=0, lr=[1.9654504613201456e-05], mom=[(0.9, 0.999)]
steps: 637 loss: 0.5843 iter time (s): 103.711 samples/sec: 1.234

 70%|███████   | 7/10 [12:44<05:25, 108.41s/it][A
 70%|███████   | 7/10 [12:44<05:25, 108.39s/it][A
 70%|███████   | 7/10 [12:44<05:25, 108.38s/it][A
 70%|███████   | 7/10 [12:44<05:25, 108.40s/it][A
 70%|███████   | 7/10 [12:44<05:25, 108.39s/it][A
 70%|███████   | 7/10 [12:44<05:25, 108.41s/it][A
 70%|███████   | 7/10 [12:44<05:25, 108.39s/it][A
 80%|████████  | 8/10 [14:29<03:34, 107.14s/it][A[2024-05-30 04:00:39,578] [INFO] [logging.py:96:log_dist] [Rank 0] step=638, skipped=0, lr=[1.9653027140492307e-05], mom=[(0.9, 0.999)]
steps: 638 loss: 0.5595 iter time (s): 103.642 samples/sec: 1.235

 80%|████████  | 8/10 [14:28<03:34, 107.11s/it][A
 80%|████████  | 8/10 [14:28<03:34, 107.12s/it][A
 80%|████████  | 8/10 [14:28<03:34, 107.10s/it][A
 80%|████████  | 8/10 [14:28<03:34, 107.14s/it][A
 80%|████████  | 8/10 [14:28<03:34, 107.10s/it][A
 80%|████████  | 8/10 [14:28<03:34, 107.12s/it][A
 80%|████████  | 8/10 [14:28<03:34, 107.11s/it][A
 90%|█████████ | 9/10 [16:14<01:46, 106.52s/it][A[2024-05-30 04:02:24,740] [INFO] [logging.py:96:log_dist] [Rank 0] step=639, skipped=0, lr=[1.9651546571173262e-05], mom=[(0.9, 0.999)]
steps: 639 loss: 0.5906 iter time (s): 104.438 samples/sec: 1.226

 90%|█████████ | 9/10 [16:14<01:46, 106.51s/it][A
 90%|█████████ | 9/10 [16:13<01:46, 106.51s/it][A
 90%|█████████ | 9/10 [16:13<01:46, 106.50s/it][A
 90%|█████████ | 9/10 [16:13<01:46, 106.50s/it][A
 90%|█████████ | 9/10 [16:13<01:46, 106.49s/it][A
 90%|█████████ | 9/10 [16:13<01:46, 106.51s/it][A
 90%|█████████ | 9/10 [16:13<01:46, 106.50s/it][A
100%|██████████| 10/10 [18:02<00:00, 107.06s/it][A100%|██████████| 10/10 [18:02<00:00, 108.28s/it]
[2024-05-30 04:04:13,012] [INFO] [logging.py:96:log_dist] [Rank 0] step=640, skipped=0, lr=[1.9650062905719316e-05], mom=[(0.9, 0.999)]
steps: 640 loss: 0.5740 iter time (s): 107.538 samples/sec: 1.190

100%|██████████| 10/10 [18:02<00:00, 107.04s/it][A100%|██████████| 10/10 [18:02<00:00, 108.23s/it]

100%|██████████| 10/10 [18:02<00:00, 107.04s/it][A100%|██████████| 10/10 [18:02<00:00, 108.22s/it]

100%|██████████| 10/10 [18:02<00:00, 107.02s/it][A100%|██████████| 10/10 [18:02<00:00, 108.21s/it]

100%|██████████| 10/10 [18:02<00:00, 107.04s/it][A100%|██████████| 10/10 [18:02<00:00, 108.21s/it]

100%|██████████| 10/10 [18:02<00:00, 107.04s/it][A100%|██████████| 10/10 [18:02<00:00, 108.22s/it]

100%|██████████| 10/10 [18:02<00:00, 107.04s/it][A100%|██████████| 10/10 [18:02<00:00, 108.22s/it]

100%|██████████| 10/10 [18:02<00:00, 107.03s/it][A100%|██████████| 10/10 [18:02<00:00, 108.22s/it]
Checkpointing at shard 65
[2024-05-30 04:04:13,717] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step640 is about to be saved!
[2024-05-30 04:04:15,595] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step640/layer_00-model_states.pt...
[2024-05-30 04:04:19,749] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step640/layer_00-model_states.pt.
[2024-05-30 04:04:21,686] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step640/layer_02-model_states.pt...
[2024-05-30 04:04:23,111] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step640/layer_04-model_states.pt...
[2024-05-30 04:04:23,226] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step640/layer_03-model_states.pt...
[2024-05-30 04:04:27,115] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step640/layer_06-model_states.pt...
[2024-05-30 04:04:27,335] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step640/layer_05-model_states.pt...
[2024-05-30 04:04:28,300] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step640/layer_01-model_states.pt...
[2024-05-30 04:04:29,460] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step640/layer_08-model_states.pt...
[2024-05-30 04:04:29,541] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step640/layer_07-model_states.pt...
[2024-05-30 04:10:41,797] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step640/layer_02-model_states.pt.
[2024-05-30 04:10:42,307] [INFO] [logging.py:96:log_dist] [Rank 1] Saving model checkpoint: /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step640/mp_rank_01_model_states.pt
[2024-05-30 04:10:42,307] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step640/mp_rank_01_model_states.pt...
[2024-05-30 04:10:44,198] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step640/mp_rank_01_model_states.pt.
[2024-05-30 04:10:44,198] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step640 is ready now!
[2024-05-30 04:10:44,508] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step640/layer_04-model_states.pt.
[2024-05-30 04:10:44,510] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step640/layer_03-model_states.pt.
[2024-05-30 04:10:44,966] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step640/mp_rank_02_model_states.pt...
[2024-05-30 04:10:45,131] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step640/mp_rank_03_model_states.pt...
[2024-05-30 04:10:45,133] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step640/mp_rank_02_model_states.pt.
[2024-05-30 04:10:45,133] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step640 is ready now!
[2024-05-30 04:10:45,285] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step640/mp_rank_03_model_states.pt.
[2024-05-30 04:10:45,286] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step640 is ready now!
[2024-05-30 04:11:03,490] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step640/layer_06-model_states.pt.
[2024-05-30 04:11:04,235] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step640/mp_rank_05_model_states.pt...
[2024-05-30 04:11:04,498] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step640/mp_rank_05_model_states.pt.
[2024-05-30 04:11:04,498] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step640 is ready now!
[2024-05-30 04:11:12,600] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step640/layer_08-model_states.pt.
[2024-05-30 04:11:12,693] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step640/layer_05-model_states.pt.
[2024-05-30 04:11:12,722] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step640/layer_01-model_states.pt.
[2024-05-30 04:11:13,318] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step640/mp_rank_04_model_states.pt...
[2024-05-30 04:11:13,354] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step640/layer_09-model_states.pt...
[2024-05-30 04:11:13,400] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step640/mp_rank_04_model_states.pt.
[2024-05-30 04:11:13,401] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step640 is ready now!
[2024-05-30 04:11:13,753] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step640/mp_rank_00_model_states.pt
[2024-05-30 04:11:13,753] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step640/mp_rank_00_model_states.pt...
[2024-05-30 04:11:14,201] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step640/layer_09-model_states.pt.
[2024-05-30 04:11:14,204] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step640/mp_rank_07_model_states.pt...
[2024-05-30 04:11:14,589] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step640/mp_rank_07_model_states.pt.
[2024-05-30 04:11:14,589] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step640 is ready now!
[2024-05-30 04:11:16,185] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step640/mp_rank_00_model_states.pt.
[2024-05-30 04:11:16,185] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step640 is ready now!
[2024-05-30 04:11:28,636] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step640/layer_07-model_states.pt.
[2024-05-30 04:11:29,306] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step640/mp_rank_06_model_states.pt...
[2024-05-30 04:11:29,421] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step640/mp_rank_06_model_states.pt.
[2024-05-30 04:11:29,421] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step640 is ready now!
Checkpoint saved using --- 435.70569109916687 seconds ---
 12%|█▎        | 65/520 [6:17:33<141:33:32, 1120.03s/it] 12%|█▎        | 65/520 [6:18:05<141:34:19, 1120.13s/it] 12%|█▎        | 65/520 [6:18:34<141:39:13, 1120.78s/it] 12%|█▎        | 65/520 [6:18:43<141:33:25, 1120.01s/it] 12%|█▎        | 65/520 [6:18:00<141:33:28, 1120.02s/it] 12%|█▎        | 65/520 [6:16:28<141:33:19, 1120.00s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_314
 12%|█▎        | 65/520 [6:18:41<141:33:44, 1120.05s/it] 12%|█▎        | 65/520 [6:18:42<141:34:03, 1120.10s/it]Training on 1280 of 1280 sentences.

  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s][A

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s][A
 10%|█         | 1/10 [01:20<12:07, 80.79s/it][A[2024-05-30 04:12:52,432] [INFO] [logging.py:96:log_dist] [Rank 0] step=641, skipped=0, lr=[1.9648576144606476e-05], mom=[(0.9, 0.999)]
steps: 641 loss: 0.5852 iter time (s): 82.540 samples/sec: 1.551

 10%|█         | 1/10 [01:22<12:25, 82.86s/it][A
 10%|█         | 1/10 [01:23<12:27, 83.05s/it][A
 10%|█         | 1/10 [01:23<12:28, 83.12s/it][A
 10%|█         | 1/10 [01:23<12:28, 83.21s/it][A
 10%|█         | 1/10 [01:23<12:29, 83.29s/it][A
 10%|█         | 1/10 [01:23<12:30, 83.34s/it][A
 10%|█         | 1/10 [01:23<12:30, 83.34s/it][A
 20%|██        | 2/10 [02:42<10:51, 81.46s/it][A[2024-05-30 04:14:14,368] [INFO] [logging.py:96:log_dist] [Rank 0] step=642, skipped=0, lr=[1.9647086288311728e-05], mom=[(0.9, 0.999)]
steps: 642 loss: 0.5991 iter time (s): 81.167 samples/sec: 1.577

 20%|██        | 2/10 [02:44<10:58, 82.33s/it][A
 20%|██        | 2/10 [02:44<10:58, 82.37s/it][A
 20%|██        | 2/10 [02:45<10:59, 82.43s/it][A
 20%|██        | 2/10 [02:45<10:59, 82.45s/it][A
 20%|██        | 2/10 [02:45<10:59, 82.49s/it][A
 20%|██        | 2/10 [02:45<10:59, 82.50s/it][A
 20%|██        | 2/10 [02:45<11:00, 82.52s/it][A
 30%|███       | 3/10 [04:04<09:32, 81.81s/it][A[2024-05-30 04:15:36,593] [INFO] [logging.py:96:log_dist] [Rank 0] step=643, skipped=0, lr=[1.9645593337313054e-05], mom=[(0.9, 0.999)]
steps: 643 loss: 0.5872 iter time (s): 81.451 samples/sec: 1.572

 30%|███       | 3/10 [04:07<09:36, 82.29s/it][A
 30%|███       | 3/10 [04:07<09:36, 82.31s/it][A
 30%|███       | 3/10 [04:07<09:36, 82.35s/it][A
 30%|███       | 3/10 [04:07<09:36, 82.39s/it][A
 30%|███       | 3/10 [04:07<09:36, 82.39s/it][A
 30%|███       | 3/10 [04:07<09:36, 82.40s/it][A
 30%|███       | 3/10 [04:07<09:36, 82.40s/it][A
 40%|████      | 4/10 [05:30<08:18, 83.13s/it][A[2024-05-30 04:17:01,752] [INFO] [logging.py:96:log_dist] [Rank 0] step=644, skipped=0, lr=[1.964409729208943e-05], mom=[(0.9, 0.999)]
steps: 644 loss: 0.6018 iter time (s): 84.395 samples/sec: 1.517

 40%|████      | 4/10 [05:32<08:20, 83.43s/it][A
 40%|████      | 4/10 [05:32<08:20, 83.45s/it][A
 40%|████      | 4/10 [05:32<08:20, 83.45s/it][A
 40%|████      | 4/10 [05:32<08:20, 83.50s/it][A
 40%|████      | 4/10 [05:32<08:20, 83.49s/it][A
 40%|████      | 4/10 [05:32<08:20, 83.49s/it][A
 40%|████      | 4/10 [05:32<08:21, 83.51s/it][A
 50%|█████     | 5/10 [06:54<06:57, 83.41s/it][A[2024-05-30 04:18:25,661] [INFO] [logging.py:96:log_dist] [Rank 0] step=645, skipped=0, lr=[1.9642598153120828e-05], mom=[(0.9, 0.999)]
steps: 645 loss: 0.5958 iter time (s): 83.075 samples/sec: 1.541

 50%|█████     | 5/10 [06:56<06:58, 83.63s/it][A
 50%|█████     | 5/10 [06:56<06:58, 83.64s/it][A
 50%|█████     | 5/10 [06:56<06:58, 83.66s/it][A
 50%|█████     | 5/10 [06:56<06:58, 83.67s/it][A
 50%|█████     | 5/10 [06:56<06:58, 83.66s/it][A
 50%|█████     | 5/10 [06:56<06:58, 83.66s/it][A
 50%|█████     | 5/10 [06:56<06:58, 83.66s/it][A
 60%|██████    | 6/10 [08:16<05:32, 83.12s/it][A[2024-05-30 04:19:47,720] [INFO] [logging.py:96:log_dist] [Rank 0] step=646, skipped=0, lr=[1.9641095920888203e-05], mom=[(0.9, 0.999)]
steps: 646 loss: 0.5922 iter time (s): 81.174 samples/sec: 1.577

 60%|██████    | 6/10 [08:18<05:32, 83.07s/it][A
 60%|██████    | 6/10 [08:18<05:32, 83.09s/it][A
 60%|██████    | 6/10 [08:18<05:32, 83.08s/it][A
 60%|██████    | 6/10 [08:18<05:32, 83.08s/it][A
 60%|██████    | 6/10 [08:18<05:32, 83.09s/it][A
 60%|██████    | 6/10 [08:18<05:32, 83.10s/it][A
 60%|██████    | 6/10 [08:18<05:32, 83.10s/it][A
 70%|███████   | 7/10 [09:40<04:10, 83.39s/it][A[2024-05-30 04:21:12,145] [INFO] [logging.py:96:log_dist] [Rank 0] step=647, skipped=0, lr=[1.9639590595873516e-05], mom=[(0.9, 0.999)]
steps: 647 loss: 0.5860 iter time (s): 83.590 samples/sec: 1.531

 70%|███████   | 7/10 [09:42<04:10, 83.51s/it][A
 70%|███████   | 7/10 [09:42<04:10, 83.53s/it][A
 70%|███████   | 7/10 [09:42<04:10, 83.50s/it][A
 70%|███████   | 7/10 [09:42<04:10, 83.49s/it][A
 70%|███████   | 7/10 [09:43<04:10, 83.51s/it][A
 70%|███████   | 7/10 [09:43<04:10, 83.51s/it][A
 70%|███████   | 7/10 [09:43<04:10, 83.51s/it][A
 80%|████████  | 8/10 [11:03<02:46, 83.32s/it][A[2024-05-30 04:22:35,328] [INFO] [logging.py:96:log_dist] [Rank 0] step=648, skipped=0, lr=[1.9638082178559704e-05], mom=[(0.9, 0.999)]
steps: 648 loss: 0.5956 iter time (s): 82.431 samples/sec: 1.553

 80%|████████  | 8/10 [11:05<02:46, 83.42s/it][A
 80%|████████  | 8/10 [11:05<02:46, 83.42s/it][A
 80%|████████  | 8/10 [11:06<02:46, 83.47s/it][A
 80%|████████  | 8/10 [11:06<02:46, 83.46s/it][A
 80%|████████  | 8/10 [11:06<02:46, 83.47s/it][A
 80%|████████  | 8/10 [11:06<02:46, 83.46s/it][A
 80%|████████  | 8/10 [11:06<02:46, 83.46s/it][A
 90%|█████████ | 9/10 [12:28<01:23, 83.75s/it][A[2024-05-30 04:24:00,009] [INFO] [logging.py:96:log_dist] [Rank 0] step=649, skipped=0, lr=[1.9636570669430706e-05], mom=[(0.9, 0.999)]
steps: 649 loss: 0.5817 iter time (s): 83.794 samples/sec: 1.528

 90%|█████████ | 9/10 [12:30<01:23, 83.80s/it][A
 90%|█████████ | 9/10 [12:30<01:23, 83.82s/it][A
 90%|█████████ | 9/10 [12:30<01:23, 83.82s/it][A
 90%|█████████ | 9/10 [12:30<01:23, 83.82s/it][A
 90%|█████████ | 9/10 [12:30<01:23, 83.81s/it][A
 90%|█████████ | 9/10 [12:31<01:23, 83.83s/it][A
 90%|█████████ | 9/10 [12:31<01:23, 83.83s/it][A
100%|██████████| 10/10 [13:51<00:00, 83.48s/it][A100%|██████████| 10/10 [13:51<00:00, 83.13s/it]
 13%|█▎        | 66/520 [6:32:26<130:25:48, 1034.25s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A[2024-05-30 04:25:22,900] [INFO] [logging.py:96:log_dist] [Rank 0] step=650, skipped=0, lr=[1.963505606897146e-05], mom=[(0.9, 0.999)]
steps: 650 loss: 0.5851 iter time (s): 82.007 samples/sec: 1.561

100%|██████████| 10/10 [13:53<00:00, 83.52s/it][A100%|██████████| 10/10 [13:53<00:00, 83.34s/it]
 13%|█▎        | 66/520 [6:31:58<130:27:12, 1034.43s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:53<00:00, 83.51s/it][A100%|██████████| 10/10 [13:53<00:00, 83.35s/it]
 13%|█▎        | 66/520 [6:32:36<130:27:19, 1034.45s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:53<00:00, 83.51s/it][A100%|██████████| 10/10 [13:53<00:00, 83.36s/it]
 13%|█▎        | 66/520 [6:32:35<130:27:18, 1034.45s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:53<00:00, 83.49s/it][A100%|██████████| 10/10 [13:53<00:00, 83.37s/it]
 13%|█▎        | 66/520 [6:31:27<130:27:17, 1034.44s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:53<00:00, 83.51s/it][A100%|██████████| 10/10 [13:53<00:00, 83.38s/it]
 13%|█▎        | 66/520 [6:31:54<130:27:28, 1034.47s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:53<00:00, 83.50s/it][A100%|██████████| 10/10 [13:53<00:00, 83.38s/it]
 13%|█▎        | 66/520 [6:32:38<130:27:29, 1034.47s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:53<00:00, 83.50s/it][A100%|██████████| 10/10 [13:53<00:00, 83.38s/it]
 13%|█▎        | 66/520 [6:30:23<130:27:28, 1034.47s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_160
Training on 1280 of 1280 sentences.

  0%|          | 0/10 [00:00<?, ?it/s][A
 10%|█         | 1/10 [01:48<16:13, 108.21s/it][A[2024-05-30 04:27:11,916] [INFO] [logging.py:96:log_dist] [Rank 0] step=651, skipped=0, lr=[1.963353837766788e-05], mom=[(0.9, 0.999)]
steps: 651 loss: 0.5532 iter time (s): 108.265 samples/sec: 1.182

 10%|█         | 1/10 [01:49<16:21, 109.08s/it][A
 10%|█         | 1/10 [01:49<16:21, 109.04s/it][A
 10%|█         | 1/10 [01:49<16:21, 109.06s/it][A
 10%|█         | 1/10 [01:49<16:22, 109.16s/it][A
 10%|█         | 1/10 [01:49<16:21, 109.09s/it][A
 10%|█         | 1/10 [01:49<16:22, 109.12s/it][A
 10%|█         | 1/10 [01:49<16:21, 109.09s/it][A
 20%|██        | 2/10 [03:35<14:21, 107.73s/it][A[2024-05-30 04:28:59,323] [INFO] [logging.py:96:log_dist] [Rank 0] step=652, skipped=0, lr=[1.963201759600688e-05], mom=[(0.9, 0.999)]
steps: 652 loss: 0.5490 iter time (s): 106.556 samples/sec: 1.201

 20%|██        | 2/10 [03:36<14:24, 108.01s/it][A
 20%|██        | 2/10 [03:36<14:23, 107.99s/it][A
 20%|██        | 2/10 [03:36<14:23, 108.00s/it][A
 20%|██        | 2/10 [03:36<14:24, 108.06s/it][A
 20%|██        | 2/10 [03:36<14:24, 108.01s/it][A
 20%|██        | 2/10 [03:36<14:24, 108.01s/it][A
 20%|██        | 2/10 [03:36<14:24, 108.00s/it][A
 30%|███       | 3/10 [05:20<12:25, 106.50s/it][A[2024-05-30 04:30:44,353] [INFO] [logging.py:96:log_dist] [Rank 0] step=653, skipped=0, lr=[1.963049372447637e-05], mom=[(0.9, 0.999)]
steps: 653 loss: 0.5656 iter time (s): 104.332 samples/sec: 1.227

 30%|███       | 3/10 [05:21<12:26, 106.66s/it][A
 30%|███       | 3/10 [05:21<12:26, 106.65s/it][A
 30%|███       | 3/10 [05:21<12:26, 106.66s/it][A
 30%|███       | 3/10 [05:21<12:26, 106.67s/it][A
 30%|███       | 3/10 [05:21<12:26, 106.64s/it][A
 30%|███       | 3/10 [05:21<12:26, 106.64s/it][A
 30%|███       | 3/10 [05:21<12:26, 106.65s/it][A
 40%|████      | 4/10 [07:07<10:39, 106.60s/it][A[2024-05-30 04:32:31,096] [INFO] [logging.py:96:log_dist] [Rank 0] step=654, skipped=0, lr=[1.9628966763565235e-05], mom=[(0.9, 0.999)]
steps: 654 loss: 0.5523 iter time (s): 106.042 samples/sec: 1.207

 40%|████      | 4/10 [07:08<10:40, 106.70s/it][A
 40%|████      | 4/10 [07:08<10:40, 106.70s/it][A
 40%|████      | 4/10 [07:08<10:40, 106.71s/it][A
 40%|████      | 4/10 [07:08<10:40, 106.72s/it][A
 40%|████      | 4/10 [07:08<10:40, 106.71s/it][A
 40%|████      | 4/10 [07:08<10:40, 106.72s/it][A
 40%|████      | 4/10 [07:08<10:40, 106.72s/it][A
 50%|█████     | 5/10 [08:52<08:50, 106.05s/it][A[2024-05-30 04:34:16,180] [INFO] [logging.py:96:log_dist] [Rank 0] step=655, skipped=0, lr=[1.962743671376337e-05], mom=[(0.9, 0.999)]
steps: 655 loss: 0.5617 iter time (s): 104.299 samples/sec: 1.227

 50%|█████     | 5/10 [08:53<08:50, 106.10s/it][A
 50%|█████     | 5/10 [08:53<08:50, 106.12s/it][A
 50%|█████     | 5/10 [08:53<08:50, 106.12s/it][A
 50%|█████     | 5/10 [08:53<08:50, 106.09s/it][A
 50%|█████     | 5/10 [08:53<08:50, 106.12s/it][A
 50%|█████     | 5/10 [08:53<08:50, 106.11s/it][A
 50%|█████     | 5/10 [08:53<08:50, 106.11s/it][A
 60%|██████    | 6/10 [10:40<07:06, 106.73s/it][A[2024-05-30 04:36:04,245] [INFO] [logging.py:96:log_dist] [Rank 0] step=656, skipped=0, lr=[1.9625903575561652e-05], mom=[(0.9, 0.999)]
steps: 656 loss: 0.5725 iter time (s): 107.384 samples/sec: 1.192

 60%|██████    | 6/10 [10:41<07:07, 106.80s/it][A
 60%|██████    | 6/10 [10:41<07:07, 106.79s/it][A
 60%|██████    | 6/10 [10:41<07:07, 106.79s/it][A
 60%|██████    | 6/10 [10:41<07:07, 106.79s/it][A
 60%|██████    | 6/10 [10:41<07:07, 106.79s/it][A
 60%|██████    | 6/10 [10:41<07:07, 106.79s/it][A
 60%|██████    | 6/10 [10:41<07:07, 106.79s/it][A
 70%|███████   | 7/10 [12:26<05:19, 106.55s/it][A[2024-05-30 04:37:50,419] [INFO] [logging.py:96:log_dist] [Rank 0] step=657, skipped=0, lr=[1.9624367349451948e-05], mom=[(0.9, 0.999)]
steps: 657 loss: 0.5613 iter time (s): 105.424 samples/sec: 1.214

 70%|███████   | 7/10 [12:27<05:19, 106.58s/it][A
 70%|███████   | 7/10 [12:27<05:19, 106.58s/it][A
 70%|███████   | 7/10 [12:27<05:19, 106.56s/it][A
 70%|███████   | 7/10 [12:27<05:19, 106.57s/it][A
 70%|███████   | 7/10 [12:27<05:19, 106.57s/it][A
 70%|███████   | 7/10 [12:27<05:19, 106.62s/it][A
 70%|███████   | 7/10 [12:27<05:19, 106.61s/it][A
 80%|████████  | 8/10 [14:13<03:33, 106.57s/it][A[2024-05-30 04:39:37,032] [INFO] [logging.py:96:log_dist] [Rank 0] step=658, skipped=0, lr=[1.962282803592712e-05], mom=[(0.9, 0.999)]
steps: 658 loss: 0.5669 iter time (s): 105.762 samples/sec: 1.210

 80%|████████  | 8/10 [14:14<03:33, 106.58s/it][A
 80%|████████  | 8/10 [14:14<03:33, 106.59s/it][A
 80%|████████  | 8/10 [14:14<03:33, 106.60s/it][A
 80%|████████  | 8/10 [14:14<03:33, 106.60s/it][A
 80%|████████  | 8/10 [14:14<03:33, 106.59s/it][A
 80%|████████  | 8/10 [14:14<03:33, 106.58s/it][A
 80%|████████  | 8/10 [14:14<03:33, 106.58s/it][A
 90%|█████████ | 9/10 [16:07<01:48, 108.97s/it][A[2024-05-30 04:41:31,285] [INFO] [logging.py:96:log_dist] [Rank 0] step=659, skipped=0, lr=[1.9621285635481014e-05], mom=[(0.9, 0.999)]
steps: 659 loss: 0.5439 iter time (s): 113.515 samples/sec: 1.128

 90%|█████████ | 9/10 [16:08<01:48, 108.98s/it][A
 90%|█████████ | 9/10 [16:08<01:48, 108.98s/it][A
 90%|█████████ | 9/10 [16:08<01:48, 108.98s/it][A
 90%|█████████ | 9/10 [16:08<01:48, 108.98s/it][A
 90%|█████████ | 9/10 [16:08<01:48, 108.99s/it][A
 90%|█████████ | 9/10 [16:08<01:48, 108.98s/it][A
 90%|█████████ | 9/10 [16:08<01:48, 108.98s/it][A
100%|██████████| 10/10 [17:56<00:00, 108.98s/it][A100%|██████████| 10/10 [17:56<00:00, 107.66s/it]
 13%|█▎        | 67/520 [6:50:23<131:44:42, 1046.98s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A[2024-05-30 04:43:20,298] [INFO] [logging.py:96:log_dist] [Rank 0] step=660, skipped=0, lr=[1.961974014860848e-05], mom=[(0.9, 0.999)]
steps: 660 loss: 0.5498 iter time (s): 108.269 samples/sec: 1.182

100%|██████████| 10/10 [17:57<00:00, 108.97s/it][A100%|██████████| 10/10 [17:57<00:00, 107.73s/it]
 13%|█▎        | 67/520 [6:49:56<131:46:51, 1047.27s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [17:57<00:00, 109.00s/it][A100%|██████████| 10/10 [17:57<00:00, 107.73s/it]
 13%|█▎        | 67/520 [6:50:33<131:47:07, 1047.30s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [17:57<00:00, 108.98s/it][A100%|██████████| 10/10 [17:57<00:00, 107.73s/it]
 13%|█▎        | 67/520 [6:50:32<131:47:05, 1047.30s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [17:57<00:00, 108.98s/it][A100%|██████████| 10/10 [17:57<00:00, 107.73s/it]
 13%|█▎        | 67/520 [6:49:25<131:47:06, 1047.30s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [17:57<00:00, 108.99s/it][A100%|██████████| 10/10 [17:57<00:00, 107.73s/it]
 13%|█▎        | 67/520 [6:49:51<131:47:11, 1047.31s/it]
100%|██████████| 10/10 [17:57<00:00, 108.97s/it][A100%|██████████| 10/10 [17:57<00:00, 107.73s/it]
 13%|█▎        | 67/520 [6:50:35<131:47:09, 1047.31s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [17:57<00:00, 108.97s/it][A100%|██████████| 10/10 [17:57<00:00, 107.73s/it]
 13%|█▎        | 67/520 [6:48:20<131:47:08, 1047.30s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_475
Training on 1280 of 1280 sentences.

  0%|          | 0/10 [00:00<?, ?it/s][A
 10%|█         | 1/10 [01:18<11:43, 78.12s/it][A[2024-05-30 04:44:37,769] [INFO] [logging.py:96:log_dist] [Rank 0] step=661, skipped=0, lr=[1.9618191575805334e-05], mom=[(0.9, 0.999)]
steps: 661 loss: 2.0249 iter time (s): 76.646 samples/sec: 1.670

 10%|█         | 1/10 [01:17<11:38, 77.56s/it][A
 10%|█         | 1/10 [01:17<11:37, 77.47s/it][A
 10%|█         | 1/10 [01:17<11:36, 77.43s/it][A
 10%|█         | 1/10 [01:17<11:36, 77.43s/it][A
 10%|█         | 1/10 [01:17<11:36, 77.43s/it][A
 10%|█         | 1/10 [01:17<11:37, 77.47s/it][A
 10%|█         | 1/10 [01:17<11:37, 77.46s/it][A
 20%|██        | 2/10 [02:34<10:14, 76.87s/it][A[2024-05-30 04:45:53,765] [INFO] [logging.py:96:log_dist] [Rank 0] step=662, skipped=0, lr=[1.9616639917568404e-05], mom=[(0.9, 0.999)]
steps: 662 loss: 1.8565 iter time (s): 75.302 samples/sec: 1.700

 20%|██        | 2/10 [02:33<10:12, 76.61s/it][A
 20%|██        | 2/10 [02:33<10:12, 76.54s/it][A
 20%|██        | 2/10 [02:33<10:12, 76.59s/it][A
 20%|██        | 2/10 [02:33<10:12, 76.59s/it][A
 20%|██        | 2/10 [02:33<10:12, 76.59s/it][A
 20%|██        | 2/10 [02:33<10:13, 76.67s/it][A
 20%|██        | 2/10 [02:33<10:13, 76.66s/it][A
 30%|███       | 3/10 [03:49<08:53, 76.26s/it][A[2024-05-30 04:47:09,296] [INFO] [logging.py:96:log_dist] [Rank 0] step=663, skipped=0, lr=[1.9615085174395502e-05], mom=[(0.9, 0.999)]
steps: 663 loss: 1.7587 iter time (s): 74.738 samples/sec: 1.713

 30%|███       | 3/10 [03:49<08:52, 76.11s/it][A
 30%|███       | 3/10 [03:48<08:52, 76.12s/it][A
 30%|███       | 3/10 [03:48<08:52, 76.12s/it][A
 30%|███       | 3/10 [03:48<08:52, 76.11s/it][A
 30%|███       | 3/10 [03:48<08:52, 76.10s/it][A
 30%|███       | 3/10 [03:48<08:52, 76.10s/it][A
 30%|███       | 3/10 [03:48<08:52, 76.10s/it][A
 40%|████      | 4/10 [05:04<07:33, 75.53s/it][A[2024-05-30 04:48:23,717] [INFO] [logging.py:96:log_dist] [Rank 0] step=664, skipped=0, lr=[1.9613527346785424e-05], mom=[(0.9, 0.999)]
steps: 664 loss: 1.6601 iter time (s): 73.732 samples/sec: 1.736

 40%|████      | 4/10 [05:03<07:32, 75.45s/it][A
 40%|████      | 4/10 [05:03<07:32, 75.43s/it][A
 40%|████      | 4/10 [05:03<07:32, 75.44s/it][A
 40%|████      | 4/10 [05:03<07:32, 75.46s/it][A
 40%|████      | 4/10 [05:03<07:32, 75.42s/it][A
 40%|████      | 4/10 [05:03<07:32, 75.44s/it][A
 40%|████      | 4/10 [05:03<07:32, 75.43s/it][A
 50%|█████     | 5/10 [06:18<06:15, 75.02s/it][A[2024-05-30 04:49:37,836] [INFO] [logging.py:96:log_dist] [Rank 0] step=665, skipped=0, lr=[1.9611966435237965e-05], mom=[(0.9, 0.999)]
steps: 665 loss: 1.5996 iter time (s): 73.436 samples/sec: 1.743

 50%|█████     | 5/10 [06:17<06:14, 74.98s/it][A
 50%|█████     | 5/10 [06:17<06:14, 74.96s/it][A
 50%|█████     | 5/10 [06:17<06:14, 74.96s/it][A
 50%|█████     | 5/10 [06:17<06:14, 74.95s/it][A
 50%|█████     | 5/10 [06:17<06:14, 74.96s/it][A
 50%|█████     | 5/10 [06:17<06:14, 74.96s/it][A
 50%|█████     | 5/10 [06:17<06:14, 74.96s/it][A
 60%|██████    | 6/10 [07:34<05:02, 75.51s/it][A[2024-05-30 04:50:54,296] [INFO] [logging.py:96:log_dist] [Rank 0] step=666, skipped=0, lr=[1.9610402440253906e-05], mom=[(0.9, 0.999)]
steps: 666 loss: 1.5490 iter time (s): 75.789 samples/sec: 1.689

 60%|██████    | 6/10 [07:33<05:01, 75.46s/it][A
 60%|██████    | 6/10 [07:33<05:01, 75.47s/it][A
 60%|██████    | 6/10 [07:33<05:01, 75.46s/it][A
 60%|██████    | 6/10 [07:34<05:01, 75.49s/it][A
 60%|██████    | 6/10 [07:33<05:01, 75.48s/it][A
 60%|██████    | 6/10 [07:33<05:01, 75.47s/it][A
 60%|██████    | 6/10 [07:33<05:01, 75.47s/it][A
 70%|███████   | 7/10 [08:49<03:46, 75.38s/it][A[2024-05-30 04:52:09,398] [INFO] [logging.py:96:log_dist] [Rank 0] step=667, skipped=0, lr=[1.9608835362335003e-05], mom=[(0.9, 0.999)]
steps: 667 loss: 1.5238 iter time (s): 74.432 samples/sec: 1.720

 70%|███████   | 7/10 [08:49<03:46, 75.37s/it][A
 70%|███████   | 7/10 [08:49<03:46, 75.36s/it][A
 70%|███████   | 7/10 [08:49<03:46, 75.37s/it][A
 70%|███████   | 7/10 [08:49<03:46, 75.36s/it][A
 70%|███████   | 7/10 [08:49<03:46, 75.36s/it][A
 70%|███████   | 7/10 [08:49<03:46, 75.37s/it][A
 70%|███████   | 7/10 [08:49<03:46, 75.36s/it][A
 80%|████████  | 8/10 [10:04<02:30, 75.07s/it][A[2024-05-30 04:53:23,817] [INFO] [logging.py:96:log_dist] [Rank 0] step=668, skipped=0, lr=[1.9607265201984024e-05], mom=[(0.9, 0.999)]
steps: 668 loss: 1.4344 iter time (s): 73.736 samples/sec: 1.736

 80%|████████  | 8/10 [10:03<02:30, 75.08s/it][A
 80%|████████  | 8/10 [10:03<02:30, 75.06s/it][A
 80%|████████  | 8/10 [10:03<02:30, 75.08s/it][A
 80%|████████  | 8/10 [10:03<02:30, 75.07s/it][A
 80%|████████  | 8/10 [10:03<02:30, 75.06s/it][A
 80%|████████  | 8/10 [10:03<02:30, 75.08s/it][A
 80%|████████  | 8/10 [10:03<02:30, 75.07s/it][A
 90%|█████████ | 9/10 [11:17<01:14, 74.41s/it][A[2024-05-30 04:54:36,775] [INFO] [logging.py:96:log_dist] [Rank 0] step=669, skipped=0, lr=[1.9605691959704714e-05], mom=[(0.9, 0.999)]
steps: 669 loss: 1.4404 iter time (s): 72.269 samples/sec: 1.771

 90%|█████████ | 9/10 [11:16<01:14, 74.40s/it][A
 90%|█████████ | 9/10 [11:16<01:14, 74.40s/it][A
 90%|█████████ | 9/10 [11:16<01:14, 74.39s/it][A
 90%|█████████ | 9/10 [11:16<01:14, 74.41s/it][A
 90%|█████████ | 9/10 [11:16<01:14, 74.39s/it][A
 90%|█████████ | 9/10 [11:16<01:14, 74.40s/it][A
 90%|█████████ | 9/10 [11:16<01:14, 74.40s/it][A
100%|██████████| 10/10 [12:32<00:00, 74.57s/it][A100%|██████████| 10/10 [12:32<00:00, 75.21s/it]
 13%|█▎        | 68/520 [7:02:55<120:21:51, 958.65s/it] 
  0%|          | 0/10 [00:00<?, ?it/s][A[2024-05-30 04:55:51,706] [INFO] [logging.py:96:log_dist] [Rank 0] step=670, skipped=0, lr=[1.960411563600181e-05], mom=[(0.9, 0.999)]
steps: 670 loss: 1.3739 iter time (s): 74.226 samples/sec: 1.724

100%|██████████| 10/10 [12:31<00:00, 74.57s/it][A100%|██████████| 10/10 [12:31<00:00, 75.15s/it]
 13%|█▎        | 68/520 [7:02:27<120:21:43, 958.64s/it] 
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [12:31<00:00, 74.57s/it][A100%|██████████| 10/10 [12:31<00:00, 75.14s/it]
 13%|█▎        | 68/520 [7:03:04<120:21:39, 958.63s/it] 
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [12:31<00:00, 74.56s/it][A100%|██████████| 10/10 [12:31<00:00, 75.14s/it]
 13%|█▎        | 68/520 [7:03:04<120:21:42, 958.63s/it] 
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [12:31<00:00, 74.56s/it][A100%|██████████| 10/10 [12:31<00:00, 75.14s/it]
 13%|█▎        | 68/520 [7:01:56<120:21:41, 958.63s/it] 
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [12:31<00:00, 74.56s/it][A100%|██████████| 10/10 [12:31<00:00, 75.14s/it]
 13%|█▎        | 68/520 [7:02:23<120:21:41, 958.63s/it] 
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [12:31<00:00, 74.57s/it][A100%|██████████| 10/10 [12:31<00:00, 75.14s/it]

 13%|█▎        | 68/520 [7:03:06<120:21:48, 958.65s/it] 100%|██████████| 10/10 [12:31<00:00, 74.56s/it][A100%|██████████| 10/10 [12:31<00:00, 75.14s/it]
 13%|█▎        | 68/520 [7:00:51<120:21:44, 958.64s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_92

  0%|          | 0/10 [00:00<?, ?it/s][ATraining on 1280 of 1280 sentences.

  0%|          | 0/10 [00:00<?, ?it/s][A
 10%|█         | 1/10 [01:16<11:25, 76.14s/it][A[2024-05-30 04:57:08,029] [INFO] [logging.py:96:log_dist] [Rank 0] step=671, skipped=0, lr=[1.9602536231381025e-05], mom=[(0.9, 0.999)]
steps: 671 loss: 1.1312 iter time (s): 75.507 samples/sec: 1.695

 10%|█         | 1/10 [01:16<11:26, 76.30s/it][A
 10%|█         | 1/10 [01:16<11:26, 76.31s/it][A
 10%|█         | 1/10 [01:16<11:26, 76.23s/it][A
 10%|█         | 1/10 [01:16<11:26, 76.28s/it][A
 10%|█         | 1/10 [01:16<11:27, 76.36s/it][A
 10%|█         | 1/10 [01:16<11:26, 76.27s/it][A
 10%|█         | 1/10 [01:16<11:26, 76.32s/it][A
 20%|██        | 2/10 [02:30<10:02, 75.29s/it][A[2024-05-30 04:58:22,714] [INFO] [logging.py:96:log_dist] [Rank 0] step=672, skipped=0, lr=[1.9600953746349084e-05], mom=[(0.9, 0.999)]
steps: 672 loss: 1.1685 iter time (s): 73.964 samples/sec: 1.731

 20%|██        | 2/10 [02:30<10:02, 75.30s/it][A
 20%|██        | 2/10 [02:31<10:03, 75.38s/it][A
 20%|██        | 2/10 [02:31<10:03, 75.40s/it][A
 20%|██        | 2/10 [02:31<10:03, 75.38s/it][A
 20%|██        | 2/10 [02:31<10:03, 75.40s/it][A
 20%|██        | 2/10 [02:31<10:02, 75.37s/it][A
 20%|██        | 2/10 [02:31<10:02, 75.37s/it][A
 30%|███       | 3/10 [03:45<08:44, 74.94s/it][A[2024-05-30 04:59:37,233] [INFO] [logging.py:96:log_dist] [Rank 0] step=673, skipped=0, lr=[1.959936818141368e-05], mom=[(0.9, 0.999)]
steps: 673 loss: 1.1303 iter time (s): 73.789 samples/sec: 1.735

 30%|███       | 3/10 [03:45<08:44, 74.98s/it][A
 30%|███       | 3/10 [03:45<08:44, 74.98s/it][A
 30%|███       | 3/10 [03:45<08:44, 74.98s/it][A
 30%|███       | 3/10 [03:45<08:44, 74.97s/it][A
 30%|███       | 3/10 [03:45<08:44, 74.98s/it][A
 30%|███       | 3/10 [03:45<08:44, 74.98s/it][A
 30%|███       | 3/10 [03:45<08:44, 74.98s/it][A
 40%|████      | 4/10 [04:59<07:28, 74.78s/it][A[2024-05-30 05:00:51,769] [INFO] [logging.py:96:log_dist] [Rank 0] step=674, skipped=0, lr=[1.9597779537083507e-05], mom=[(0.9, 0.999)]
steps: 674 loss: 1.1464 iter time (s): 73.804 samples/sec: 1.734

 40%|████      | 4/10 [05:00<07:28, 74.81s/it][A
 40%|████      | 4/10 [05:00<07:28, 74.78s/it][A
 40%|████      | 4/10 [05:00<07:28, 74.81s/it][A
 40%|████      | 4/10 [05:00<07:28, 74.79s/it][A
 40%|████      | 4/10 [05:00<07:28, 74.81s/it][A
 40%|████      | 4/10 [05:00<07:28, 74.80s/it][A
 40%|████      | 4/10 [05:00<07:28, 74.81s/it][A
 50%|█████     | 5/10 [06:16<06:17, 75.50s/it][A[2024-05-30 05:02:08,544] [INFO] [logging.py:96:log_dist] [Rank 0] step=675, skipped=0, lr=[1.9596187813868238e-05], mom=[(0.9, 0.999)]
steps: 675 loss: 1.1606 iter time (s): 76.075 samples/sec: 1.683

 50%|█████     | 5/10 [06:16<06:17, 75.53s/it][A
 50%|█████     | 5/10 [06:16<06:17, 75.51s/it][A
 50%|█████     | 5/10 [06:16<06:17, 75.51s/it][A
 50%|█████     | 5/10 [06:16<06:17, 75.50s/it][A
 50%|█████     | 5/10 [06:16<06:17, 75.52s/it][A
 50%|█████     | 5/10 [06:16<06:17, 75.50s/it][A
 50%|█████     | 5/10 [06:16<06:17, 75.51s/it][A
 60%|██████    | 6/10 [07:33<05:04, 76.08s/it][A[2024-05-30 05:03:25,741] [INFO] [logging.py:96:log_dist] [Rank 0] step=676, skipped=0, lr=[1.9594593012278537e-05], mom=[(0.9, 0.999)]
steps: 676 loss: 1.1436 iter time (s): 76.461 samples/sec: 1.674

 60%|██████    | 6/10 [07:33<05:04, 76.07s/it][A
 60%|██████    | 6/10 [07:33<05:04, 76.07s/it][A
 60%|██████    | 6/10 [07:34<05:04, 76.10s/it][A
 60%|██████    | 6/10 [07:34<05:04, 76.10s/it][A
 60%|██████    | 6/10 [07:34<05:04, 76.09s/it][A
 60%|██████    | 6/10 [07:34<05:04, 76.09s/it][A
 60%|██████    | 6/10 [07:34<05:04, 76.08s/it][A
 70%|███████   | 7/10 [08:51<03:49, 76.61s/it][A[2024-05-30 05:04:43,479] [INFO] [logging.py:96:log_dist] [Rank 0] step=677, skipped=0, lr=[1.959299513282606e-05], mom=[(0.9, 0.999)]
steps: 677 loss: 1.1472 iter time (s): 77.003 samples/sec: 1.662

 70%|███████   | 7/10 [08:51<03:49, 76.61s/it][A
 70%|███████   | 7/10 [08:51<03:49, 76.62s/it][A
 70%|███████   | 7/10 [08:51<03:49, 76.60s/it][A
 70%|███████   | 7/10 [08:51<03:49, 76.62s/it][A
 70%|███████   | 7/10 [08:51<03:49, 76.63s/it][A
 70%|███████   | 7/10 [08:51<03:49, 76.62s/it][A
 70%|███████   | 7/10 [08:51<03:49, 76.62s/it][A
 80%|████████  | 8/10 [10:11<02:35, 77.71s/it][A[2024-05-30 05:06:03,446] [INFO] [logging.py:96:log_dist] [Rank 0] step=678, skipped=0, lr=[1.959139417602344e-05], mom=[(0.9, 0.999)]
steps: 678 loss: 1.1230 iter time (s): 79.273 samples/sec: 1.615

 80%|████████  | 8/10 [10:11<02:35, 77.69s/it][A
 80%|████████  | 8/10 [10:11<02:35, 77.70s/it][A
 80%|████████  | 8/10 [10:11<02:35, 77.69s/it][A
 80%|████████  | 8/10 [10:11<02:35, 77.69s/it][A
 80%|████████  | 8/10 [10:11<02:35, 77.68s/it][A
 80%|████████  | 8/10 [10:11<02:35, 77.68s/it][A
 80%|████████  | 8/10 [10:11<02:35, 77.69s/it][A
 90%|█████████ | 9/10 [11:30<01:17, 77.94s/it][A[2024-05-30 05:07:21,969] [INFO] [logging.py:96:log_dist] [Rank 0] step=679, skipped=0, lr=[1.9589790142384307e-05], mom=[(0.9, 0.999)]
steps: 679 loss: 1.1069 iter time (s): 77.829 samples/sec: 1.645

 90%|█████████ | 9/10 [11:30<01:18, 78.01s/it][A
 90%|█████████ | 9/10 [11:30<01:18, 78.00s/it][A
 90%|█████████ | 9/10 [11:30<01:17, 77.99s/it][A
 90%|█████████ | 9/10 [11:30<01:17, 77.99s/it][A
 90%|█████████ | 9/10 [11:30<01:18, 78.01s/it][A
 90%|█████████ | 9/10 [11:30<01:17, 78.00s/it][A
 90%|█████████ | 9/10 [11:30<01:18, 78.00s/it][A
100%|██████████| 10/10 [12:47<00:00, 77.79s/it][A100%|██████████| 10/10 [12:47<00:00, 76.75s/it]
 13%|█▎        | 69/520 [7:15:42<112:55:32, 901.40s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A[2024-05-30 05:08:39,412] [INFO] [logging.py:96:log_dist] [Rank 0] step=680, skipped=0, lr=[1.9588183032423273e-05], mom=[(0.9, 0.999)]
steps: 680 loss: 1.1055 iter time (s): 76.601 samples/sec: 1.671

100%|██████████| 10/10 [12:47<00:00, 77.78s/it][A100%|██████████| 10/10 [12:47<00:00, 76.77s/it]
 13%|█▎        | 69/520 [7:15:15<112:55:30, 901.40s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [12:47<00:00, 77.77s/it][A100%|██████████| 10/10 [12:47<00:00, 76.77s/it]
 13%|█▎        | 69/520 [7:15:52<112:55:26, 901.39s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [12:47<00:00, 77.81s/it][A100%|██████████| 10/10 [12:47<00:00, 76.78s/it]
 13%|█▎        | 69/520 [7:15:51<112:55:42, 901.43s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [12:47<00:00, 77.78s/it][A100%|██████████| 10/10 [12:47<00:00, 76.77s/it]
 13%|█▎        | 69/520 [7:14:44<112:55:36, 901.41s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [12:47<00:00, 77.80s/it][A100%|██████████| 10/10 [12:47<00:00, 76.78s/it]
 13%|█▎        | 69/520 [7:15:10<112:55:38, 901.42s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [12:47<00:00, 77.80s/it][A100%|██████████| 10/10 [12:47<00:00, 76.77s/it]
 13%|█▎        | 69/520 [7:15:54<112:55:41, 901.42s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [12:47<00:00, 77.79s/it][A100%|██████████| 10/10 [12:47<00:00, 76.78s/it]
 13%|█▎        | 69/520 [7:13:39<112:55:39, 901.42s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_100
Training on 1280 of 1280 sentences.

  0%|          | 0/10 [00:00<?, ?it/s][A
 10%|█         | 1/10 [01:15<11:22, 75.84s/it][A[2024-05-30 05:09:55,377] [INFO] [logging.py:96:log_dist] [Rank 0] step=681, skipped=0, lr=[1.9586572846655943e-05], mom=[(0.9, 0.999)]
steps: 681 loss: 1.0960 iter time (s): 75.089 samples/sec: 1.705

 10%|█         | 1/10 [01:15<11:22, 75.87s/it][A
 10%|█         | 1/10 [01:15<11:22, 75.87s/it][A
 10%|█         | 1/10 [01:15<11:22, 75.81s/it][A
 10%|█         | 1/10 [01:15<11:22, 75.85s/it][A
 10%|█         | 1/10 [01:15<11:22, 75.84s/it][A
 10%|█         | 1/10 [01:15<11:22, 75.82s/it][A
 10%|█         | 1/10 [01:15<11:22, 75.82s/it][A
 20%|██        | 2/10 [02:33<10:13, 76.72s/it][A[2024-05-30 05:11:12,711] [INFO] [logging.py:96:log_dist] [Rank 0] step=682, skipped=0, lr=[1.9584959585598902e-05], mom=[(0.9, 0.999)]
steps: 682 loss: 1.1107 iter time (s): 76.696 samples/sec: 1.669

 20%|██        | 2/10 [02:33<10:14, 76.81s/it][A
 20%|██        | 2/10 [02:33<10:15, 76.90s/it][A
 20%|██        | 2/10 [02:33<10:15, 76.88s/it][A
 20%|██        | 2/10 [02:33<10:15, 76.88s/it][A
 20%|██        | 2/10 [02:33<10:15, 76.92s/it][A
 20%|██        | 2/10 [02:33<10:15, 76.92s/it][A
 20%|██        | 2/10 [02:33<10:15, 76.93s/it][A
 30%|███       | 3/10 [03:49<08:56, 76.65s/it][A[2024-05-30 05:12:29,281] [INFO] [logging.py:96:log_dist] [Rank 0] step=683, skipped=0, lr=[1.9583343249769725e-05], mom=[(0.9, 0.999)]
steps: 683 loss: 1.0946 iter time (s): 75.564 samples/sec: 1.694

 30%|███       | 3/10 [03:49<08:56, 76.65s/it][A
 30%|███       | 3/10 [03:49<08:56, 76.65s/it][A
 30%|███       | 3/10 [03:49<08:56, 76.60s/it][A
 30%|███       | 3/10 [03:49<08:56, 76.62s/it][A
 30%|███       | 3/10 [03:49<08:56, 76.63s/it][A
 30%|███       | 3/10 [03:49<08:56, 76.62s/it][A
 30%|███       | 3/10 [03:49<08:56, 76.62s/it][A
 40%|████      | 4/10 [05:03<07:32, 75.43s/it][A[2024-05-30 05:13:42,847] [INFO] [logging.py:96:log_dist] [Rank 0] step=684, skipped=0, lr=[1.958172383968697e-05], mom=[(0.9, 0.999)]
steps: 684 loss: 1.0987 iter time (s): 72.877 samples/sec: 1.756

 40%|████      | 4/10 [05:03<07:32, 75.43s/it][A
 40%|████      | 4/10 [05:03<07:32, 75.42s/it][A
 40%|████      | 4/10 [05:03<07:32, 75.43s/it][A
 40%|████      | 4/10 [05:03<07:32, 75.44s/it][A
 40%|████      | 4/10 [05:03<07:32, 75.42s/it][A
 40%|████      | 4/10 [05:03<07:32, 75.44s/it][A
 40%|████      | 4/10 [05:03<07:32, 75.42s/it][A
 50%|█████     | 5/10 [06:21<06:22, 76.51s/it][A[2024-05-30 05:15:01,256] [INFO] [logging.py:96:log_dist] [Rank 0] step=685, skipped=0, lr=[1.9580101355870188e-05], mom=[(0.9, 0.999)]
steps: 685 loss: 1.0804 iter time (s): 77.814 samples/sec: 1.645

 50%|█████     | 5/10 [06:21<06:22, 76.56s/it][A
 50%|█████     | 5/10 [06:21<06:22, 76.54s/it][A
 50%|█████     | 5/10 [06:21<06:22, 76.55s/it][A
 50%|█████     | 5/10 [06:21<06:22, 76.54s/it][A
 50%|█████     | 5/10 [06:21<06:22, 76.54s/it][A
 50%|█████     | 5/10 [06:21<06:22, 76.55s/it][A
 50%|█████     | 5/10 [06:21<06:22, 76.54s/it][A
 60%|██████    | 6/10 [07:45<05:15, 78.90s/it][A[2024-05-30 05:16:24,793] [INFO] [logging.py:96:log_dist] [Rank 0] step=686, skipped=0, lr=[1.957847579883991e-05], mom=[(0.9, 0.999)]
steps: 686 loss: 1.0872 iter time (s): 82.715 samples/sec: 1.547

 60%|██████    | 6/10 [07:45<05:15, 78.92s/it][A
 60%|██████    | 6/10 [07:45<05:15, 78.91s/it][A
 60%|██████    | 6/10 [07:45<05:15, 78.87s/it][A
 60%|██████    | 6/10 [07:45<05:15, 78.90s/it][A
 60%|██████    | 6/10 [07:45<05:15, 78.89s/it][A
 60%|██████    | 6/10 [07:45<05:15, 78.92s/it][A
 60%|██████    | 6/10 [07:45<05:15, 78.92s/it][A
 70%|███████   | 7/10 [09:12<04:05, 81.70s/it][A[2024-05-30 05:17:52,280] [INFO] [logging.py:96:log_dist] [Rank 0] step=687, skipped=0, lr=[1.9576847169117654e-05], mom=[(0.9, 0.999)]
steps: 687 loss: 1.0803 iter time (s): 86.660 samples/sec: 1.477

 70%|███████   | 7/10 [09:12<04:05, 81.69s/it][A
 70%|███████   | 7/10 [09:12<04:05, 81.68s/it][A
 70%|███████   | 7/10 [09:12<04:05, 81.69s/it][A
 70%|███████   | 7/10 [09:12<04:05, 81.70s/it][A
 70%|███████   | 7/10 [09:12<04:05, 81.69s/it][A
 70%|███████   | 7/10 [09:12<04:05, 81.68s/it][A
 70%|███████   | 7/10 [09:12<04:05, 81.68s/it][A
 80%|████████  | 8/10 [10:56<02:57, 88.66s/it][A[2024-05-30 05:19:35,822] [INFO] [logging.py:96:log_dist] [Rank 0] step=688, skipped=0, lr=[1.9575215467225925e-05], mom=[(0.9, 0.999)]
steps: 688 loss: 1.1128 iter time (s): 102.826 samples/sec: 1.245

 80%|████████  | 8/10 [10:56<02:57, 88.66s/it][A
 80%|████████  | 8/10 [10:56<02:57, 88.66s/it][A
 80%|████████  | 8/10 [10:56<02:57, 88.65s/it][A
 80%|████████  | 8/10 [10:56<02:57, 88.66s/it][A
 80%|████████  | 8/10 [10:56<02:57, 88.65s/it][A
 80%|████████  | 8/10 [10:56<02:57, 88.67s/it][A
 80%|████████  | 8/10 [10:56<02:57, 88.68s/it][A
 90%|█████████ | 9/10 [12:34<01:31, 91.76s/it][A[2024-05-30 05:21:14,411] [INFO] [logging.py:96:log_dist] [Rank 0] step=689, skipped=0, lr=[1.9573580693688217e-05], mom=[(0.9, 0.999)]
steps: 689 loss: 1.1103 iter time (s): 97.766 samples/sec: 1.309

 90%|█████████ | 9/10 [12:34<01:31, 91.77s/it][A
 90%|█████████ | 9/10 [12:34<01:31, 91.76s/it][A
 90%|█████████ | 9/10 [12:34<01:31, 91.75s/it][A
 90%|█████████ | 9/10 [12:35<01:31, 91.77s/it][A
 90%|█████████ | 9/10 [12:34<01:31, 91.76s/it][A
 90%|█████████ | 9/10 [12:34<01:31, 91.75s/it][A
 90%|█████████ | 9/10 [12:34<01:31, 91.75s/it][A
100%|██████████| 10/10 [14:14<00:00, 94.21s/it][A100%|██████████| 10/10 [14:14<00:00, 85.46s/it]
[2024-05-30 05:22:54,086] [INFO] [logging.py:96:log_dist] [Rank 0] step=690, skipped=0, lr=[1.9571942849029e-05], mom=[(0.9, 0.999)]
steps: 690 loss: 1.1015 iter time (s): 98.975 samples/sec: 1.293

100%|██████████| 10/10 [14:14<00:00, 94.18s/it][A100%|██████████| 10/10 [14:14<00:00, 85.46s/it]

100%|██████████| 10/10 [14:14<00:00, 94.22s/it][A100%|██████████| 10/10 [14:14<00:00, 85.47s/it]

100%|██████████| 10/10 [14:14<00:00, 94.20s/it][A100%|██████████| 10/10 [14:14<00:00, 85.46s/it]

100%|██████████| 10/10 [14:14<00:00, 94.20s/it][A100%|██████████| 10/10 [14:14<00:00, 85.46s/it]

100%|██████████| 10/10 [14:14<00:00, 94.20s/it][A100%|██████████| 10/10 [14:14<00:00, 85.46s/it]

100%|██████████| 10/10 [14:14<00:00, 94.19s/it][A100%|██████████| 10/10 [14:14<00:00, 85.46s/it]

100%|██████████| 10/10 [14:14<00:00, 94.19s/it][A100%|██████████| 10/10 [14:14<00:00, 85.46s/it]
Checkpointing at shard 70
[2024-05-30 05:22:54,825] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step690 is about to be saved!
[2024-05-30 05:22:56,768] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step690/layer_00-model_states.pt...
[2024-05-30 05:23:03,583] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step690/layer_02-model_states.pt...
[2024-05-30 05:23:04,126] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step690/layer_03-model_states.pt...
[2024-05-30 05:23:04,562] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step690/layer_04-model_states.pt...
[2024-05-30 05:23:08,601] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step690/layer_06-model_states.pt...
[2024-05-30 05:23:09,620] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step690/layer_05-model_states.pt...
[2024-05-30 05:23:09,630] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step690/layer_00-model_states.pt.
[2024-05-30 05:23:12,266] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step690/layer_07-model_states.pt...
[2024-05-30 05:23:12,812] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step690/layer_08-model_states.pt...
[2024-05-30 05:23:20,382] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step690/layer_01-model_states.pt...
[2024-05-30 05:29:28,848] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step690/layer_04-model_states.pt.
[2024-05-30 05:29:28,860] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step690/layer_02-model_states.pt.
[2024-05-30 05:29:29,532] [INFO] [logging.py:96:log_dist] [Rank 1] Saving model checkpoint: /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step690/mp_rank_01_model_states.pt
[2024-05-30 05:29:29,533] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step690/mp_rank_01_model_states.pt...
[2024-05-30 05:29:29,909] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step690/mp_rank_03_model_states.pt...
[2024-05-30 05:29:30,245] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step690/mp_rank_01_model_states.pt.
[2024-05-30 05:29:30,245] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step690 is ready now!
[2024-05-30 05:29:30,570] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step690/mp_rank_03_model_states.pt.
[2024-05-30 05:29:30,570] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step690 is ready now!
[2024-05-30 05:29:46,508] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step690/layer_06-model_states.pt.
[2024-05-30 05:29:46,511] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step690/layer_05-model_states.pt.
[2024-05-30 05:29:46,513] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step690/layer_03-model_states.pt.
[2024-05-30 05:29:46,526] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step690/layer_08-model_states.pt.
[2024-05-30 05:29:46,530] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step690/layer_07-model_states.pt.
[2024-05-30 05:29:46,637] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step690/mp_rank_02_model_states.pt...
[2024-05-30 05:29:46,726] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step690/mp_rank_02_model_states.pt.
[2024-05-30 05:29:46,726] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step690 is ready now!
[2024-05-30 05:29:46,989] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step690/mp_rank_05_model_states.pt...
[2024-05-30 05:29:47,086] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step690/mp_rank_05_model_states.pt.
[2024-05-30 05:29:47,086] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step690 is ready now!
[2024-05-30 05:29:48,258] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step690/mp_rank_06_model_states.pt...
[2024-05-30 05:29:48,315] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step690/mp_rank_04_model_states.pt...
[2024-05-30 05:29:48,342] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step690/mp_rank_06_model_states.pt.
[2024-05-30 05:29:48,343] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step690 is ready now!
[2024-05-30 05:29:48,411] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step690/mp_rank_04_model_states.pt.
[2024-05-30 05:29:48,411] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step690 is ready now!
[2024-05-30 05:29:48,435] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step690/layer_09-model_states.pt...
[2024-05-30 05:29:49,076] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step690/layer_09-model_states.pt.
[2024-05-30 05:29:49,080] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step690/mp_rank_07_model_states.pt...
[2024-05-30 05:29:49,179] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step690/mp_rank_07_model_states.pt.
[2024-05-30 05:29:49,180] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step690 is ready now!
[2024-05-30 05:30:22,769] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step690/layer_01-model_states.pt.
[2024-05-30 05:30:23,708] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step690/mp_rank_00_model_states.pt
[2024-05-30 05:30:23,708] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step690/mp_rank_00_model_states.pt...
[2024-05-30 05:30:24,230] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step690/mp_rank_00_model_states.pt.
[2024-05-30 05:30:24,230] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step690 is ready now!
Checkpoint saved using --- 449.4078106880188 seconds ---
 13%|█▎        | 70/520 [7:35:23<127:46:02, 1022.14s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_457
 13%|█▎        | 70/520 [7:37:29<127:51:21, 1022.85s/it] 13%|█▎        | 70/520 [7:36:59<127:46:57, 1022.26s/it] 13%|█▎        | 70/520 [7:37:36<127:46:41, 1022.23s/it] 13%|█▎        | 70/520 [7:37:36<127:46:23, 1022.19s/it] 13%|█▎        | 70/520 [7:36:55<127:46:09, 1022.15s/it] 13%|█▎        | 70/520 [7:36:28<127:46:17, 1022.17s/it] 13%|█▎        | 70/520 [7:37:38<127:46:06, 1022.15s/it]Training on 1280 of 1280 sentences.

  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
 10%|█         | 1/10 [01:00<09:02, 60.28s/it][A[2024-05-30 05:31:25,990] [INFO] [logging.py:96:log_dist] [Rank 0] step=691, skipped=0, lr=[1.957030193377374e-05], mom=[(0.9, 0.999)]
steps: 691 loss: 0.3642 iter time (s): 61.572 samples/sec: 2.079

 10%|█         | 1/10 [01:01<09:16, 61.89s/it][A
 10%|█         | 1/10 [01:01<09:17, 61.95s/it][A
 10%|█         | 1/10 [01:02<09:18, 62.11s/it][A
 10%|█         | 1/10 [01:02<09:19, 62.15s/it][A
 10%|█         | 1/10 [01:02<09:20, 62.25s/it][A
 10%|█         | 1/10 [01:02<09:20, 62.25s/it][A
 10%|█         | 1/10 [01:02<09:20, 62.28s/it][A
 20%|██        | 2/10 [02:03<08:14, 61.75s/it][A[2024-05-30 05:32:28,777] [INFO] [logging.py:96:log_dist] [Rank 0] step=692, skipped=0, lr=[1.956865794844888e-05], mom=[(0.9, 0.999)]
steps: 692 loss: 0.3610 iter time (s): 62.105 samples/sec: 2.061

 20%|██        | 2/10 [02:04<08:19, 62.43s/it][A
 20%|██        | 2/10 [02:04<08:19, 62.46s/it][A
 20%|██        | 2/10 [02:04<08:19, 62.46s/it][A
 20%|██        | 2/10 [02:04<08:20, 62.50s/it][A
 20%|██        | 2/10 [02:04<08:20, 62.52s/it][A
 20%|██        | 2/10 [02:04<08:20, 62.53s/it][A
 20%|██        | 2/10 [02:05<08:20, 62.54s/it][A
 30%|███       | 3/10 [03:06<07:18, 62.67s/it][A[2024-05-30 05:33:32,540] [INFO] [logging.py:96:log_dist] [Rank 0] step=693, skipped=0, lr=[1.9567010893581858e-05], mom=[(0.9, 0.999)]
steps: 693 loss: 0.3429 iter time (s): 63.137 samples/sec: 2.027

 30%|███       | 3/10 [03:08<07:21, 63.02s/it][A
 30%|███       | 3/10 [03:08<07:21, 63.02s/it][A
 30%|███       | 3/10 [03:08<07:21, 63.06s/it][A
 30%|███       | 3/10 [03:08<07:21, 63.09s/it][A
 30%|███       | 3/10 [03:08<07:21, 63.09s/it][A
 30%|███       | 3/10 [03:08<07:21, 63.10s/it][A
 30%|███       | 3/10 [03:08<07:21, 63.11s/it][A
 40%|████      | 4/10 [04:10<06:17, 62.99s/it][A[2024-05-30 05:34:36,015] [INFO] [logging.py:96:log_dist] [Rank 0] step=694, skipped=0, lr=[1.956536076970108e-05], mom=[(0.9, 0.999)]
steps: 694 loss: 0.3504 iter time (s): 62.842 samples/sec: 2.037

 40%|████      | 4/10 [04:11<06:19, 63.19s/it][A
 40%|████      | 4/10 [04:11<06:19, 63.22s/it][A
 40%|████      | 4/10 [04:12<06:19, 63.27s/it][A
 40%|████      | 4/10 [04:12<06:19, 63.25s/it][A
 40%|████      | 4/10 [04:12<06:19, 63.26s/it][A
 40%|████      | 4/10 [04:12<06:19, 63.27s/it][A
 40%|████      | 4/10 [04:12<06:19, 63.27s/it][A
 50%|█████     | 5/10 [05:13<05:15, 63.06s/it][A[2024-05-30 05:35:39,191] [INFO] [logging.py:96:log_dist] [Rank 0] step=695, skipped=0, lr=[1.9563707577335952e-05], mom=[(0.9, 0.999)]
steps: 695 loss: 0.3385 iter time (s): 62.487 samples/sec: 2.048

 50%|█████     | 5/10 [05:15<05:15, 63.19s/it][A
 50%|█████     | 5/10 [05:15<05:16, 63.22s/it][A
 50%|█████     | 5/10 [05:15<05:16, 63.22s/it][A
 50%|█████     | 5/10 [05:15<05:16, 63.23s/it][A
 50%|█████     | 5/10 [05:15<05:16, 63.24s/it][A
 50%|█████     | 5/10 [05:15<05:16, 63.24s/it][A
 50%|█████     | 5/10 [05:15<05:16, 63.24s/it][A
 60%|██████    | 6/10 [06:16<04:12, 63.16s/it][A[2024-05-30 05:36:42,288] [INFO] [logging.py:96:log_dist] [Rank 0] step=696, skipped=0, lr=[1.9562051317016863e-05], mom=[(0.9, 0.999)]
steps: 696 loss: 0.3209 iter time (s): 62.404 samples/sec: 2.051

 60%|██████    | 6/10 [06:18<04:12, 63.17s/it][A
 60%|██████    | 6/10 [06:18<04:12, 63.18s/it][A
 60%|██████    | 6/10 [06:18<04:12, 63.17s/it][A
 60%|██████    | 6/10 [06:18<04:12, 63.18s/it][A
 60%|██████    | 6/10 [06:18<04:12, 63.19s/it][A
 60%|██████    | 6/10 [06:18<04:12, 63.20s/it][A
 60%|██████    | 6/10 [06:18<04:12, 63.20s/it][A
 70%|███████   | 7/10 [07:19<03:09, 63.07s/it][A[2024-05-30 05:37:45,450] [INFO] [logging.py:96:log_dist] [Rank 0] step=697, skipped=0, lr=[1.9560391989275175e-05], mom=[(0.9, 0.999)]
steps: 697 loss: 0.3381 iter time (s): 62.449 samples/sec: 2.050

 70%|███████   | 7/10 [07:21<03:09, 63.14s/it][A
 70%|███████   | 7/10 [07:21<03:09, 63.19s/it][A
 70%|███████   | 7/10 [07:21<03:09, 63.18s/it][A
 70%|███████   | 7/10 [07:21<03:09, 63.21s/it][A
 70%|███████   | 7/10 [07:21<03:09, 63.20s/it][A
 70%|███████   | 7/10 [07:22<03:09, 63.31s/it][A
 70%|███████   | 7/10 [07:22<03:10, 63.57s/it][A
 80%|████████  | 8/10 [08:26<02:08, 64.17s/it][A[2024-05-30 05:38:51,989] [INFO] [logging.py:96:log_dist] [Rank 0] step=698, skipped=0, lr=[1.9558729594643247e-05], mom=[(0.9, 0.999)]
steps: 698 loss: 0.3202 iter time (s): 64.663 samples/sec: 1.979

 80%|████████  | 8/10 [08:27<02:08, 64.24s/it][A
 80%|████████  | 8/10 [08:27<02:08, 64.21s/it][A
 80%|████████  | 8/10 [08:28<02:08, 64.22s/it][A
 80%|████████  | 8/10 [08:28<02:08, 64.21s/it][A
 80%|████████  | 8/10 [08:28<02:08, 64.20s/it][A
 80%|████████  | 8/10 [08:28<02:08, 64.18s/it][A
 80%|████████  | 8/10 [08:28<02:08, 64.11s/it][A
 90%|█████████ | 9/10 [09:30<01:04, 64.25s/it][A[2024-05-30 05:39:56,380] [INFO] [logging.py:96:log_dist] [Rank 0] step=699, skipped=0, lr=[1.9557064133654417e-05], mom=[(0.9, 0.999)]
steps: 699 loss: 0.3084 iter time (s): 63.792 samples/sec: 2.007

 90%|█████████ | 9/10 [09:32<01:04, 64.29s/it][A
 90%|█████████ | 9/10 [09:32<01:04, 64.27s/it][A
 90%|█████████ | 9/10 [09:32<01:04, 64.30s/it][A
 90%|█████████ | 9/10 [09:32<01:04, 64.28s/it][A
 90%|█████████ | 9/10 [09:32<01:04, 64.28s/it][A
 90%|█████████ | 9/10 [09:32<01:04, 64.26s/it][A
 90%|█████████ | 9/10 [09:32<01:04, 64.21s/it][A
100%|██████████| 10/10 [10:36<00:00, 64.89s/it][A100%|██████████| 10/10 [10:36<00:00, 63.70s/it]
 14%|█▎        | 71/520 [7:48:06<113:08:47, 907.19s/it] 
  0%|          | 0/10 [00:00<?, ?it/s][A[2024-05-30 05:41:02,704] [INFO] [logging.py:96:log_dist] [Rank 0] step=700, skipped=0, lr=[1.9555395606842998e-05], mom=[(0.9, 0.999)]
steps: 700 loss: 0.3090 iter time (s): 65.690 samples/sec: 1.949

100%|██████████| 10/10 [10:38<00:00, 64.93s/it][A100%|██████████| 10/10 [10:38<00:00, 63.86s/it]
 14%|█▎        | 71/520 [7:47:38<113:09:21, 907.26s/it] 
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [10:38<00:00, 64.90s/it][A100%|██████████| 10/10 [10:38<00:00, 63.86s/it]
 14%|█▎        | 71/520 [7:48:15<113:09:13, 907.25s/it] 
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [10:38<00:00, 64.91s/it][A100%|██████████| 10/10 [10:38<00:00, 63.88s/it]
 14%|█▎        | 71/520 [7:48:15<113:09:19, 907.26s/it] 
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [10:38<00:00, 64.92s/it][A100%|██████████| 10/10 [10:38<00:00, 63.89s/it]
 14%|█▎        | 71/520 [7:47:07<113:09:26, 907.27s/it] 
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [10:38<00:00, 64.93s/it][A100%|██████████| 10/10 [10:38<00:00, 63.89s/it]
 14%|█▎        | 71/520 [7:47:34<113:09:31, 907.29s/it] 
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [10:38<00:00, 64.91s/it][A100%|██████████| 10/10 [10:38<00:00, 63.90s/it]
 14%|█▎        | 71/520 [7:48:17<113:09:32, 907.29s/it] 
100%|██████████| 10/10 [10:38<00:00, 64.87s/it][A100%|██████████| 10/10 [10:38<00:00, 63.90s/it]
 14%|█▎        | 71/520 [7:46:02<113:09:31, 907.29s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_109

  0%|          | 0/10 [00:00<?, ?it/s][ATraining on 1280 of 1280 sentences.

  0%|          | 0/10 [00:00<?, ?it/s][A
 10%|█         | 1/10 [01:14<11:08, 74.29s/it][A[2024-05-30 05:42:17,399] [INFO] [logging.py:96:log_dist] [Rank 0] step=701, skipped=0, lr=[1.9553724014744304e-05], mom=[(0.9, 0.999)]
steps: 701 loss: 1.0717 iter time (s): 73.926 samples/sec: 1.731

 10%|█         | 1/10 [01:14<11:12, 74.75s/it][A
 10%|█         | 1/10 [01:14<11:13, 74.83s/it][A
 10%|█         | 1/10 [01:14<11:13, 74.84s/it][A
 10%|█         | 1/10 [01:14<11:13, 74.82s/it][A
 10%|█         | 1/10 [01:14<11:13, 74.79s/it][A
 10%|█         | 1/10 [01:14<11:13, 74.78s/it][A
 10%|█         | 1/10 [01:14<11:13, 74.81s/it][A
 20%|██        | 2/10 [02:28<09:51, 73.96s/it][A[2024-05-30 05:43:31,133] [INFO] [logging.py:96:log_dist] [Rank 0] step=702, skipped=0, lr=[1.955204935789462e-05], mom=[(0.9, 0.999)]
steps: 702 loss: 1.1075 iter time (s): 73.035 samples/sec: 1.753

 20%|██        | 2/10 [02:28<09:53, 74.16s/it][A
 20%|██        | 2/10 [02:28<09:53, 74.21s/it][A
 20%|██        | 2/10 [02:28<09:53, 74.21s/it][A
 20%|██        | 2/10 [02:28<09:53, 74.21s/it][A
 20%|██        | 2/10 [02:28<09:53, 74.19s/it][A
 20%|██        | 2/10 [02:28<09:53, 74.20s/it][A
 20%|██        | 2/10 [02:28<09:53, 74.21s/it][A
 30%|███       | 3/10 [03:41<08:34, 73.55s/it][A[2024-05-30 05:44:44,210] [INFO] [logging.py:96:log_dist] [Rank 0] step=703, skipped=0, lr=[1.9550371636831217e-05], mom=[(0.9, 0.999)]
steps: 703 loss: 1.0681 iter time (s): 72.232 samples/sec: 1.772

 30%|███       | 3/10 [03:41<08:35, 73.62s/it][A
 30%|███       | 3/10 [03:41<08:35, 73.66s/it][A
 30%|███       | 3/10 [03:41<08:35, 73.63s/it][A
 30%|███       | 3/10 [03:41<08:35, 73.65s/it][A
 30%|███       | 3/10 [03:41<08:35, 73.65s/it][A
 30%|███       | 3/10 [03:41<08:35, 73.64s/it][A
 30%|███       | 3/10 [03:41<08:35, 73.65s/it][A
 40%|████      | 4/10 [04:55<07:22, 73.82s/it][A[2024-05-30 05:45:58,444] [INFO] [logging.py:96:log_dist] [Rank 0] step=704, skipped=0, lr=[1.9548690852092347e-05], mom=[(0.9, 0.999)]
steps: 704 loss: 1.0851 iter time (s): 73.480 samples/sec: 1.742

 40%|████      | 4/10 [04:55<07:23, 73.86s/it][A
 40%|████      | 4/10 [04:55<07:23, 73.88s/it][A
 40%|████      | 4/10 [04:55<07:23, 73.88s/it][A
 40%|████      | 4/10 [04:55<07:23, 73.88s/it][A
 40%|████      | 4/10 [04:55<07:23, 73.87s/it][A
 40%|████      | 4/10 [04:55<07:23, 73.88s/it][A
 40%|████      | 4/10 [04:55<07:23, 73.87s/it][A
 50%|█████     | 5/10 [06:09<06:08, 73.78s/it][A[2024-05-30 05:47:12,142] [INFO] [logging.py:96:log_dist] [Rank 0] step=705, skipped=0, lr=[1.9547007004217252e-05], mom=[(0.9, 0.999)]
steps: 705 loss: 1.0592 iter time (s): 72.987 samples/sec: 1.754

 50%|█████     | 5/10 [06:09<06:09, 73.83s/it][A
 50%|█████     | 5/10 [06:09<06:09, 73.81s/it][A
 50%|█████     | 5/10 [06:09<06:09, 73.82s/it][A
 50%|█████     | 5/10 [06:09<06:09, 73.82s/it][A
 50%|█████     | 5/10 [06:09<06:09, 73.81s/it][A
 50%|█████     | 5/10 [06:09<06:09, 73.81s/it][A
 50%|█████     | 5/10 [06:09<06:09, 73.81s/it][A
 60%|██████    | 6/10 [07:24<04:57, 74.30s/it][A[2024-05-30 05:48:27,452] [INFO] [logging.py:96:log_dist] [Rank 0] step=706, skipped=0, lr=[1.9545320093746153e-05], mom=[(0.9, 0.999)]
steps: 706 loss: 1.0640 iter time (s): 74.569 samples/sec: 1.717

 60%|██████    | 6/10 [07:24<04:57, 74.32s/it][A
 60%|██████    | 6/10 [07:24<04:57, 74.36s/it][A
 60%|██████    | 6/10 [07:24<04:57, 74.33s/it][A
 60%|██████    | 6/10 [07:24<04:57, 74.33s/it][A
 60%|██████    | 6/10 [07:24<04:57, 74.33s/it][A
 60%|██████    | 6/10 [07:24<04:57, 74.33s/it][A
 60%|██████    | 6/10 [07:24<04:57, 74.33s/it][A
 70%|███████   | 7/10 [08:38<03:43, 74.37s/it][A[2024-05-30 05:49:41,984] [INFO] [logging.py:96:log_dist] [Rank 0] step=707, skipped=0, lr=[1.9543630121220246e-05], mom=[(0.9, 0.999)]
steps: 707 loss: 1.0731 iter time (s): 73.762 samples/sec: 1.735

 70%|███████   | 7/10 [08:39<03:43, 74.37s/it][A
 70%|███████   | 7/10 [08:39<03:43, 74.38s/it][A
 70%|███████   | 7/10 [08:39<03:43, 74.40s/it][A
 70%|███████   | 7/10 [08:39<03:43, 74.40s/it][A
 70%|███████   | 7/10 [08:39<03:43, 74.39s/it][A
 70%|███████   | 7/10 [08:39<03:43, 74.39s/it][A
 70%|███████   | 7/10 [08:39<03:43, 74.40s/it][A
 80%|████████  | 8/10 [09:54<02:29, 74.67s/it][A[2024-05-30 05:50:57,277] [INFO] [logging.py:96:log_dist] [Rank 0] step=708, skipped=0, lr=[1.954193708718172e-05], mom=[(0.9, 0.999)]
steps: 708 loss: 1.0738 iter time (s): 74.550 samples/sec: 1.717

 80%|████████  | 8/10 [09:54<02:29, 74.69s/it][A
 80%|████████  | 8/10 [09:54<02:29, 74.67s/it][A
 80%|████████  | 8/10 [09:54<02:29, 74.65s/it][A
 80%|████████  | 8/10 [09:54<02:29, 74.66s/it][A
 80%|████████  | 8/10 [09:54<02:29, 74.67s/it][A
 80%|████████  | 8/10 [09:54<02:29, 74.67s/it][A
 80%|████████  | 8/10 [09:54<02:29, 74.68s/it][A
 90%|█████████ | 9/10 [11:08<01:14, 74.43s/it][A[2024-05-30 05:52:11,201] [INFO] [logging.py:96:log_dist] [Rank 0] step=709, skipped=0, lr=[1.9540240992173746e-05], mom=[(0.9, 0.999)]
steps: 709 loss: 1.0998 iter time (s): 73.179 samples/sec: 1.749

 90%|█████████ | 9/10 [11:08<01:14, 74.43s/it][A
 90%|█████████ | 9/10 [11:08<01:14, 74.45s/it][A
 90%|█████████ | 9/10 [11:08<01:14, 74.45s/it][A
 90%|█████████ | 9/10 [11:08<01:14, 74.44s/it][A
 90%|█████████ | 9/10 [11:08<01:14, 74.46s/it][A
 90%|█████████ | 9/10 [11:08<01:14, 74.44s/it][A
 90%|█████████ | 9/10 [11:08<01:14, 74.44s/it][A
100%|██████████| 10/10 [12:23<00:00, 74.77s/it][A100%|██████████| 10/10 [12:23<00:00, 74.36s/it]
 14%|█▍        | 72/520 [8:00:30<106:47:40, 858.17s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A[2024-05-30 05:53:26,723] [INFO] [logging.py:96:log_dist] [Rank 0] step=710, skipped=0, lr=[1.953854183674047e-05], mom=[(0.9, 0.999)]
steps: 710 loss: 1.0553 iter time (s): 74.773 samples/sec: 1.712

100%|██████████| 10/10 [12:24<00:00, 74.78s/it][A100%|██████████| 10/10 [12:24<00:00, 74.40s/it]
 14%|█▍        | 72/520 [8:00:02<106:48:40, 858.31s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [12:24<00:00, 74.76s/it][A100%|██████████| 10/10 [12:24<00:00, 74.41s/it]
 14%|█▍        | 72/520 [8:00:39<106:48:40, 858.30s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [12:24<00:00, 74.77s/it][A100%|██████████| 10/10 [12:24<00:00, 74.41s/it]
 14%|█▍        | 72/520 [8:00:39<106:48:47, 858.32s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [12:24<00:00, 74.75s/it][A100%|██████████| 10/10 [12:24<00:00, 74.41s/it]
 14%|█▍        | 72/520 [7:59:31<106:48:49, 858.32s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [12:24<00:00, 74.76s/it][A100%|██████████| 10/10 [12:24<00:00, 74.40s/it]
 14%|█▍        | 72/520 [8:00:41<106:48:48, 858.32s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [12:24<00:00, 74.78s/it][A100%|██████████| 10/10 [12:24<00:00, 74.41s/it]
 14%|█▍        | 72/520 [7:59:58<106:48:54, 858.34s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [12:24<00:00, 74.76s/it][A100%|██████████| 10/10 [12:24<00:00, 74.41s/it]
 14%|█▍        | 72/520 [7:58:26<106:48:52, 858.33s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_228
Training on 1280 of 1280 sentences.

  0%|          | 0/10 [00:00<?, ?it/s][A
 10%|█         | 1/10 [00:56<08:26, 56.23s/it][A[2024-05-30 05:54:22,616] [INFO] [logging.py:96:log_dist] [Rank 0] step=711, skipped=0, lr=[1.9536839621427022e-05], mom=[(0.9, 0.999)]
steps: 711 loss: 0.6930 iter time (s): 55.053 samples/sec: 2.325

 10%|█         | 1/10 [00:55<08:22, 55.83s/it][A
 10%|█         | 1/10 [00:55<08:22, 55.85s/it][A
 10%|█         | 1/10 [00:55<08:22, 55.82s/it][A
 10%|█         | 1/10 [00:55<08:22, 55.79s/it][A
 10%|█         | 1/10 [00:55<08:21, 55.78s/it][A
 10%|█         | 1/10 [00:55<08:22, 55.78s/it][A
 10%|█         | 1/10 [00:55<08:22, 55.83s/it][A
 20%|██        | 2/10 [01:52<07:32, 56.53s/it][A[2024-05-30 05:55:19,362] [INFO] [logging.py:96:log_dist] [Rank 0] step=712, skipped=0, lr=[1.9535134346779515e-05], mom=[(0.9, 0.999)]
steps: 712 loss: 0.6405 iter time (s): 56.137 samples/sec: 2.280

 20%|██        | 2/10 [01:52<07:31, 56.38s/it][A
 20%|██        | 2/10 [01:52<07:31, 56.38s/it][A
 20%|██        | 2/10 [01:52<07:30, 56.34s/it][A
 20%|██        | 2/10 [01:52<07:30, 56.36s/it][A
 20%|██        | 2/10 [01:52<07:30, 56.33s/it][A
 20%|██        | 2/10 [01:52<07:30, 56.35s/it][A
 20%|██        | 2/10 [01:52<07:30, 56.35s/it][A
 30%|███       | 3/10 [02:49<06:36, 56.59s/it][A[2024-05-30 05:56:16,006] [INFO] [logging.py:96:log_dist] [Rank 0] step=713, skipped=0, lr=[1.9533426013345048e-05], mom=[(0.9, 0.999)]
steps: 713 loss: 0.6605 iter time (s): 56.097 samples/sec: 2.282

 30%|███       | 3/10 [02:49<06:35, 56.52s/it][A
 30%|███       | 3/10 [02:49<06:35, 56.53s/it][A
 30%|███       | 3/10 [02:49<06:35, 56.53s/it][A
 30%|███       | 3/10 [02:49<06:35, 56.55s/it][A
 30%|███       | 3/10 [02:49<06:35, 56.53s/it][A
 30%|███       | 3/10 [02:49<06:35, 56.52s/it][A
 30%|███       | 3/10 [02:49<06:35, 56.54s/it][A
 40%|████      | 4/10 [03:45<05:37, 56.24s/it][A[2024-05-30 05:57:11,713] [INFO] [logging.py:96:log_dist] [Rank 0] step=714, skipped=0, lr=[1.9531714621671693e-05], mom=[(0.9, 0.999)]
steps: 714 loss: 0.6359 iter time (s): 55.002 samples/sec: 2.327

 40%|████      | 4/10 [03:44<05:37, 56.18s/it][A
 40%|████      | 4/10 [03:45<05:37, 56.21s/it][A
 40%|████      | 4/10 [03:44<05:36, 56.17s/it][A
 40%|████      | 4/10 [03:44<05:36, 56.15s/it][A
 40%|████      | 4/10 [03:44<05:37, 56.18s/it][A
 40%|████      | 4/10 [03:44<05:36, 56.16s/it][A
 40%|████      | 4/10 [03:44<05:37, 56.17s/it][A
 50%|█████     | 5/10 [04:42<04:42, 56.59s/it][A[2024-05-30 05:58:08,934] [INFO] [logging.py:96:log_dist] [Rank 0] step=715, skipped=0, lr=[1.953000017230851e-05], mom=[(0.9, 0.999)]
steps: 715 loss: 0.6529 iter time (s): 56.602 samples/sec: 2.261

 50%|█████     | 5/10 [04:42<04:42, 56.53s/it][A
 50%|█████     | 5/10 [04:42<04:42, 56.56s/it][A
 50%|█████     | 5/10 [04:42<04:42, 56.56s/it][A
 50%|█████     | 5/10 [04:42<04:42, 56.55s/it][A
 50%|█████     | 5/10 [04:42<04:42, 56.56s/it][A
 50%|█████     | 5/10 [04:42<04:42, 56.56s/it][A
 50%|█████     | 5/10 [04:42<04:42, 56.55s/it][A
 60%|██████    | 6/10 [05:39<03:46, 56.60s/it][A[2024-05-30 05:59:05,550] [INFO] [logging.py:96:log_dist] [Rank 0] step=716, skipped=0, lr=[1.9528282665805523e-05], mom=[(0.9, 0.999)]
steps: 716 loss: 0.6471 iter time (s): 55.987 samples/sec: 2.286

 60%|██████    | 6/10 [05:38<03:46, 56.57s/it][A
 60%|██████    | 6/10 [05:38<03:46, 56.57s/it][A
 60%|██████    | 6/10 [05:38<03:46, 56.56s/it][A
 60%|██████    | 6/10 [05:38<03:46, 56.57s/it][A
 60%|██████    | 6/10 [05:38<03:46, 56.58s/it][A
 60%|██████    | 6/10 [05:38<03:46, 56.59s/it][A
 60%|██████    | 6/10 [05:38<03:46, 56.58s/it][A
 70%|███████   | 7/10 [06:35<02:49, 56.43s/it][A[2024-05-30 06:00:01,619] [INFO] [logging.py:96:log_dist] [Rank 0] step=717, skipped=0, lr=[1.9526562102713776e-05], mom=[(0.9, 0.999)]
steps: 717 loss: 0.6981 iter time (s): 55.435 samples/sec: 2.309

 70%|███████   | 7/10 [06:34<02:49, 56.40s/it][A
 70%|███████   | 7/10 [06:34<02:49, 56.41s/it][A
 70%|███████   | 7/10 [06:34<02:49, 56.39s/it][A
 70%|███████   | 7/10 [06:34<02:49, 56.38s/it][A
 70%|███████   | 7/10 [06:34<02:49, 56.40s/it][A
 70%|███████   | 7/10 [06:34<02:49, 56.40s/it][A
 70%|███████   | 7/10 [06:34<02:49, 56.40s/it][A
 80%|████████  | 8/10 [07:31<01:52, 56.23s/it][A[2024-05-30 06:00:57,429] [INFO] [logging.py:96:log_dist] [Rank 0] step=718, skipped=0, lr=[1.9524838483585245e-05], mom=[(0.9, 0.999)]
steps: 718 loss: 0.6223 iter time (s): 55.264 samples/sec: 2.316

 80%|████████  | 8/10 [07:30<01:52, 56.24s/it][A
 80%|████████  | 8/10 [07:30<01:52, 56.23s/it][A
 80%|████████  | 8/10 [07:30<01:52, 56.22s/it][A
 80%|████████  | 8/10 [07:30<01:52, 56.23s/it][A
 80%|████████  | 8/10 [07:30<01:52, 56.22s/it][A
 80%|████████  | 8/10 [07:30<01:52, 56.23s/it][A
 80%|████████  | 8/10 [07:30<01:52, 56.23s/it][A
 90%|█████████ | 9/10 [08:26<00:56, 56.09s/it][A[2024-05-30 06:01:53,204] [INFO] [logging.py:96:log_dist] [Rank 0] step=719, skipped=0, lr=[1.9523111808972924e-05], mom=[(0.9, 0.999)]
steps: 719 loss: 0.6451 iter time (s): 55.100 samples/sec: 2.323

 90%|█████████ | 9/10 [08:26<00:56, 56.06s/it][A
 90%|█████████ | 9/10 [08:26<00:56, 56.10s/it][A
 90%|█████████ | 9/10 [08:26<00:56, 56.09s/it][A
 90%|█████████ | 9/10 [08:26<00:56, 56.06s/it][A
 90%|█████████ | 9/10 [08:26<00:56, 56.08s/it][A
 90%|█████████ | 9/10 [08:26<00:56, 56.08s/it][A
 90%|█████████ | 9/10 [08:26<00:56, 56.08s/it][A
100%|██████████| 10/10 [09:21<00:00, 55.53s/it][A100%|██████████| 10/10 [09:21<00:00, 56.11s/it]
 14%|█▍        | 73/520 [8:09:51<95:29:49, 769.10s/it] 
  0%|          | 0/10 [00:00<?, ?it/s][A[2024-05-30 06:02:47,054] [INFO] [logging.py:96:log_dist] [Rank 0] step=720, skipped=0, lr=[1.9521382079430765e-05], mom=[(0.9, 0.999)]
steps: 720 loss: 0.6600 iter time (s): 53.222 samples/sec: 2.405

100%|██████████| 10/10 [09:20<00:00, 55.38s/it][A100%|██████████| 10/10 [09:20<00:00, 56.02s/it]
 14%|█▍        | 73/520 [8:09:22<95:28:17, 768.90s/it] 
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [09:20<00:00, 55.39s/it][A100%|██████████| 10/10 [09:20<00:00, 56.03s/it]
 14%|█▍        | 73/520 [8:10:00<95:28:30, 768.93s/it] 
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [09:20<00:00, 55.37s/it][A100%|██████████| 10/10 [09:20<00:00, 56.02s/it]
 14%|█▍        | 73/520 [8:09:59<95:28:16, 768.90s/it] 
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [09:20<00:00, 55.38s/it][A100%|██████████| 10/10 [09:20<00:00, 56.03s/it]
 14%|█▍        | 73/520 [8:08:51<95:28:29, 768.92s/it] 
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [09:20<00:00, 55.39s/it][A100%|██████████| 10/10 [09:20<00:00, 56.02s/it]
 14%|█▍        | 73/520 [8:09:18<95:28:26, 768.92s/it] 
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [09:20<00:00, 55.39s/it][A100%|██████████| 10/10 [09:20<00:00, 56.02s/it]
 14%|█▍        | 73/520 [8:10:02<95:28:27, 768.92s/it] 
100%|██████████| 10/10 [09:20<00:00, 55.39s/it][A100%|██████████| 10/10 [09:20<00:00, 56.02s/it]
 14%|█▍        | 73/520 [8:07:47<95:28:26, 768.92s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_304

  0%|          | 0/10 [00:00<?, ?it/s][ATraining on 1280 of 1280 sentences.

  0%|          | 0/10 [00:00<?, ?it/s][A
 10%|█         | 1/10 [01:17<11:41, 77.89s/it][A[2024-05-30 06:04:06,251] [INFO] [logging.py:96:log_dist] [Rank 0] step=721, skipped=0, lr=[1.9519649295513715e-05], mom=[(0.9, 0.999)]
steps: 721 loss: 0.6238 iter time (s): 78.438 samples/sec: 1.632

 10%|█         | 1/10 [01:19<11:53, 79.29s/it][A
 10%|█         | 1/10 [01:19<11:53, 79.27s/it][A
 10%|█         | 1/10 [01:19<11:54, 79.40s/it][A
 10%|█         | 1/10 [01:19<11:53, 79.32s/it][A
 10%|█         | 1/10 [01:19<11:54, 79.40s/it][A
 10%|█         | 1/10 [01:19<11:54, 79.41s/it][A
 10%|█         | 1/10 [01:19<11:54, 79.41s/it][A
 20%|██        | 2/10 [02:38<10:36, 79.60s/it][A[2024-05-30 06:05:27,044] [INFO] [logging.py:96:log_dist] [Rank 0] step=722, skipped=0, lr=[1.9517913457777686e-05], mom=[(0.9, 0.999)]
steps: 722 loss: 0.6127 iter time (s): 80.008 samples/sec: 1.600

 20%|██        | 2/10 [02:40<10:42, 80.25s/it][A
 20%|██        | 2/10 [02:40<10:41, 80.25s/it][A
 20%|██        | 2/10 [02:40<10:42, 80.28s/it][A
 20%|██        | 2/10 [02:40<10:42, 80.25s/it][A
 20%|██        | 2/10 [02:40<10:41, 80.25s/it][A
 20%|██        | 2/10 [02:40<10:42, 80.26s/it][A
 20%|██        | 2/10 [02:40<10:42, 80.27s/it][A
 30%|███       | 3/10 [04:00<09:24, 80.70s/it][A[2024-05-30 06:06:48,793] [INFO] [logging.py:96:log_dist] [Rank 0] step=723, skipped=0, lr=[1.9516174566779588e-05], mom=[(0.9, 0.999)]
steps: 723 loss: 0.6014 iter time (s): 80.840 samples/sec: 1.583

 30%|███       | 3/10 [04:01<09:26, 80.89s/it][A
 30%|███       | 3/10 [04:01<09:26, 80.88s/it][A
 30%|███       | 3/10 [04:01<09:26, 80.88s/it][A
 30%|███       | 3/10 [04:01<09:26, 80.91s/it][A
 30%|███       | 3/10 [04:01<09:26, 80.89s/it][A
 30%|███       | 3/10 [04:01<09:26, 80.89s/it][A
 30%|███       | 3/10 [04:01<09:26, 80.90s/it][A
 40%|████      | 4/10 [05:21<08:05, 80.84s/it][A[2024-05-30 06:08:10,122] [INFO] [logging.py:96:log_dist] [Rank 0] step=724, skipped=0, lr=[1.951443262307729e-05], mom=[(0.9, 0.999)]
steps: 724 loss: 0.5927 iter time (s): 80.513 samples/sec: 1.590

 40%|████      | 4/10 [05:23<08:06, 81.05s/it][A
 40%|████      | 4/10 [05:23<08:06, 81.09s/it][A
 40%|████      | 4/10 [05:23<08:06, 81.08s/it][A
 40%|████      | 4/10 [05:23<08:06, 81.08s/it][A
 40%|████      | 4/10 [05:23<08:06, 81.09s/it][A
 40%|████      | 4/10 [05:23<08:06, 81.08s/it][A
 40%|████      | 4/10 [05:23<08:06, 81.08s/it][A
 50%|█████     | 5/10 [06:43<06:45, 81.01s/it][A[2024-05-30 06:09:31,425] [INFO] [logging.py:96:log_dist] [Rank 0] step=725, skipped=0, lr=[1.9512687627229657e-05], mom=[(0.9, 0.999)]
steps: 725 loss: 0.5954 iter time (s): 80.443 samples/sec: 1.591

 50%|█████     | 5/10 [06:44<06:45, 81.16s/it][A
 50%|█████     | 5/10 [06:44<06:45, 81.15s/it][A
 50%|█████     | 5/10 [06:44<06:45, 81.16s/it][A
 50%|█████     | 5/10 [06:44<06:45, 81.16s/it][A
 50%|█████     | 5/10 [06:44<06:45, 81.16s/it][A
 50%|█████     | 5/10 [06:44<06:45, 81.17s/it][A
 50%|█████     | 5/10 [06:44<06:45, 81.16s/it][A
 60%|██████    | 6/10 [08:05<05:25, 81.35s/it][A[2024-05-30 06:10:53,418] [INFO] [logging.py:96:log_dist] [Rank 0] step=726, skipped=0, lr=[1.9510939579796526e-05], mom=[(0.9, 0.999)]
steps: 726 loss: 0.5971 iter time (s): 81.149 samples/sec: 1.577

 60%|██████    | 6/10 [08:06<05:25, 81.44s/it][A
 60%|██████    | 6/10 [08:06<05:25, 81.41s/it][A
 60%|██████    | 6/10 [08:06<05:25, 81.42s/it][A
 60%|██████    | 6/10 [08:06<05:25, 81.45s/it][A
 60%|██████    | 6/10 [08:06<05:25, 81.48s/it][A
 60%|██████    | 6/10 [08:06<05:25, 81.47s/it][A
 60%|██████    | 6/10 [08:06<05:25, 81.48s/it][A
 70%|███████   | 7/10 [09:26<04:04, 81.54s/it][A[2024-05-30 06:12:15,345] [INFO] [logging.py:96:log_dist] [Rank 0] step=727, skipped=0, lr=[1.9509188481338714e-05], mom=[(0.9, 0.999)]
steps: 727 loss: 0.5834 iter time (s): 80.983 samples/sec: 1.581

 70%|███████   | 7/10 [09:28<04:04, 81.58s/it][A
 70%|███████   | 7/10 [09:28<04:04, 81.59s/it][A
 70%|███████   | 7/10 [09:28<04:04, 81.59s/it][A
 70%|███████   | 7/10 [09:28<04:04, 81.57s/it][A
 70%|███████   | 7/10 [09:28<04:04, 81.57s/it][A
 70%|███████   | 7/10 [09:28<04:04, 81.58s/it][A
 70%|███████   | 7/10 [09:28<04:04, 81.57s/it][A
 80%|████████  | 8/10 [10:48<02:42, 81.46s/it][A[2024-05-30 06:13:36,640] [INFO] [logging.py:96:log_dist] [Rank 0] step=728, skipped=0, lr=[1.9507434332418014e-05], mom=[(0.9, 0.999)]
steps: 728 loss: 0.5725 iter time (s): 80.510 samples/sec: 1.590

 80%|████████  | 8/10 [10:49<02:43, 81.51s/it][A
 80%|████████  | 8/10 [10:49<02:42, 81.49s/it][A
 80%|████████  | 8/10 [10:49<02:43, 81.52s/it][A
 80%|████████  | 8/10 [10:49<02:43, 81.50s/it][A
 80%|████████  | 8/10 [10:49<02:42, 81.50s/it][A
 80%|████████  | 8/10 [10:49<02:42, 81.50s/it][A
 80%|████████  | 8/10 [10:49<02:42, 81.50s/it][A
 90%|█████████ | 9/10 [12:09<01:21, 81.48s/it][A[2024-05-30 06:14:58,162] [INFO] [logging.py:96:log_dist] [Rank 0] step=729, skipped=0, lr=[1.9505677133597203e-05], mom=[(0.9, 0.999)]
steps: 729 loss: 0.5950 iter time (s): 80.693 samples/sec: 1.586

 90%|█████████ | 9/10 [12:11<01:21, 81.50s/it][A
 90%|█████████ | 9/10 [12:11<01:21, 81.51s/it][A
 90%|█████████ | 9/10 [12:11<01:21, 81.51s/it][A
 90%|█████████ | 9/10 [12:11<01:21, 81.49s/it][A
 90%|█████████ | 9/10 [12:11<01:21, 81.50s/it][A
 90%|█████████ | 9/10 [12:11<01:21, 81.50s/it][A
 90%|█████████ | 9/10 [12:11<01:21, 81.50s/it][A
100%|██████████| 10/10 [13:30<00:00, 81.37s/it][A100%|██████████| 10/10 [13:30<00:00, 81.09s/it]
 14%|█▍        | 74/520 [8:23:22<96:50:39, 781.70s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A[2024-05-30 06:16:19,273] [INFO] [logging.py:96:log_dist] [Rank 0] step=730, skipped=0, lr=[1.9503916885440035e-05], mom=[(0.9, 0.999)]
steps: 730 loss: 0.5918 iter time (s): 80.301 samples/sec: 1.594

100%|██████████| 10/10 [13:32<00:00, 81.38s/it][A100%|██████████| 10/10 [13:32<00:00, 81.23s/it]
 14%|█▍        | 74/520 [8:22:55<96:52:16, 781.92s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:32<00:00, 81.38s/it][A100%|██████████| 10/10 [13:32<00:00, 81.23s/it]
 14%|█▍        | 74/520 [8:23:32<96:52:25, 781.94s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:32<00:00, 81.38s/it][A100%|██████████| 10/10 [13:32<00:00, 81.24s/it]
 14%|█▍        | 74/520 [8:23:31<96:52:27, 781.94s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:32<00:00, 81.38s/it][A100%|██████████| 10/10 [13:32<00:00, 81.24s/it]
 14%|█▍        | 74/520 [8:22:24<96:52:34, 781.96s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:32<00:00, 81.38s/it][A100%|██████████| 10/10 [13:32<00:00, 81.24s/it]
 14%|█▍        | 74/520 [8:22:50<96:52:31, 781.95s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:32<00:00, 81.38s/it][A100%|██████████| 10/10 [13:32<00:00, 81.24s/it]
 14%|█▍        | 74/520 [8:23:34<96:52:36, 781.97s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [13:32<00:00, 81.38s/it][A100%|██████████| 10/10 [13:32<00:00, 81.24s/it]
 14%|█▍        | 74/520 [8:21:19<96:52:38, 781.97s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_201
Training on 1280 of 1280 sentences.

  0%|          | 0/10 [00:00<?, ?it/s][A
 10%|█         | 1/10 [00:57<08:36, 57.34s/it][A[2024-05-30 06:17:16,068] [INFO] [logging.py:96:log_dist] [Rank 0] step=731, skipped=0, lr=[1.950215358851124e-05], mom=[(0.9, 0.999)]
steps: 731 loss: 0.6120 iter time (s): 55.862 samples/sec: 2.291

 10%|█         | 1/10 [00:56<08:30, 56.75s/it][A
 10%|█         | 1/10 [00:56<08:29, 56.65s/it][A
 10%|█         | 1/10 [00:56<08:29, 56.62s/it][A
 10%|█         | 1/10 [00:56<08:29, 56.58s/it][A
 10%|█         | 1/10 [00:56<08:29, 56.62s/it][A
 10%|█         | 1/10 [00:56<08:30, 56.70s/it][A
 10%|█         | 1/10 [00:56<08:30, 56.68s/it][A
 20%|██        | 2/10 [01:53<07:31, 56.49s/it][A[2024-05-30 06:18:11,961] [INFO] [logging.py:96:log_dist] [Rank 0] step=732, skipped=0, lr=[1.9500387243376528e-05], mom=[(0.9, 0.999)]
steps: 732 loss: 0.6037 iter time (s): 55.181 samples/sec: 2.320

 20%|██        | 2/10 [01:52<07:30, 56.26s/it][A
 20%|██        | 2/10 [01:52<07:29, 56.22s/it][A
 20%|██        | 2/10 [01:52<07:29, 56.21s/it][A
 20%|██        | 2/10 [01:52<07:29, 56.18s/it][A
 20%|██        | 2/10 [01:52<07:29, 56.20s/it][A
 20%|██        | 2/10 [01:52<07:29, 56.16s/it][A
 20%|██        | 2/10 [01:52<07:29, 56.16s/it][A
 30%|███       | 3/10 [02:49<06:35, 56.50s/it][A[2024-05-30 06:19:08,493] [INFO] [logging.py:96:log_dist] [Rank 0] step=733, skipped=0, lr=[1.9498617850602584e-05], mom=[(0.9, 0.999)]
steps: 733 loss: 0.6144 iter time (s): 55.930 samples/sec: 2.289

 30%|███       | 3/10 [02:49<06:34, 56.38s/it][A
 30%|███       | 3/10 [02:49<06:34, 56.38s/it][A
 30%|███       | 3/10 [02:49<06:34, 56.37s/it][A
 30%|███       | 3/10 [02:49<06:34, 56.36s/it][A
 30%|███       | 3/10 [02:49<06:34, 56.37s/it][A
 30%|███       | 3/10 [02:49<06:34, 56.35s/it][A
 30%|███       | 3/10 [02:49<06:34, 56.34s/it][A
 40%|████      | 4/10 [03:46<05:38, 56.50s/it][A[2024-05-30 06:20:04,974] [INFO] [logging.py:96:log_dist] [Rank 0] step=734, skipped=0, lr=[1.949684541075708e-05], mom=[(0.9, 0.999)]
steps: 734 loss: 0.6536 iter time (s): 55.840 samples/sec: 2.292

 40%|████      | 4/10 [03:45<05:38, 56.39s/it][A
 40%|████      | 4/10 [03:45<05:38, 56.39s/it][A
 40%|████      | 4/10 [03:45<05:38, 56.42s/it][A
 40%|████      | 4/10 [03:45<05:38, 56.41s/it][A
 40%|████      | 4/10 [03:45<05:38, 56.40s/it][A
 40%|████      | 4/10 [03:45<05:38, 56.40s/it][A
 40%|████      | 4/10 [03:45<05:38, 56.40s/it][A
 50%|█████     | 5/10 [04:42<04:41, 56.27s/it][A[2024-05-30 06:21:00,833] [INFO] [logging.py:96:log_dist] [Rank 0] step=735, skipped=0, lr=[1.9495069924408652e-05], mom=[(0.9, 0.999)]
steps: 735 loss: 0.6160 iter time (s): 55.219 samples/sec: 2.318

 50%|█████     | 5/10 [04:41<04:41, 56.21s/it][A
 50%|█████     | 5/10 [04:41<04:40, 56.19s/it][A
 50%|█████     | 5/10 [04:41<04:41, 56.24s/it][A
 50%|█████     | 5/10 [04:41<04:40, 56.20s/it][A
 50%|█████     | 5/10 [04:41<04:40, 56.20s/it][A
 50%|█████     | 5/10 [04:41<04:40, 56.20s/it][A
 50%|█████     | 5/10 [04:41<04:40, 56.20s/it][A
 60%|██████    | 6/10 [05:38<03:45, 56.31s/it][A[2024-05-30 06:21:57,219] [INFO] [logging.py:96:log_dist] [Rank 0] step=736, skipped=0, lr=[1.949329139212692e-05], mom=[(0.9, 0.999)]
steps: 736 loss: 0.5718 iter time (s): 55.782 samples/sec: 2.295

 60%|██████    | 6/10 [05:37<03:45, 56.29s/it][A
 60%|██████    | 6/10 [05:37<03:45, 56.25s/it][A
 60%|██████    | 6/10 [05:37<03:45, 56.27s/it][A
 60%|██████    | 6/10 [05:37<03:45, 56.26s/it][A
 60%|██████    | 6/10 [05:37<03:45, 56.27s/it][A
 60%|██████    | 6/10 [05:37<03:45, 56.26s/it][A
 60%|██████    | 6/10 [05:37<03:45, 56.26s/it][A
 70%|███████   | 7/10 [06:35<02:49, 56.47s/it][A[2024-05-30 06:22:54,028] [INFO] [logging.py:96:log_dist] [Rank 0] step=737, skipped=0, lr=[1.9491509814482483e-05], mom=[(0.9, 0.999)]
steps: 737 loss: 0.6027 iter time (s): 56.209 samples/sec: 2.277

 70%|███████   | 7/10 [06:34<02:49, 56.45s/it][A
 70%|███████   | 7/10 [06:34<02:49, 56.44s/it][A
 70%|███████   | 7/10 [06:34<02:49, 56.45s/it][A
 70%|███████   | 7/10 [06:34<02:49, 56.46s/it][A
 70%|███████   | 7/10 [06:34<02:49, 56.47s/it][A
 70%|███████   | 7/10 [06:34<02:49, 56.46s/it][A
 70%|███████   | 7/10 [06:34<02:49, 56.45s/it][A
 80%|████████  | 8/10 [07:32<01:53, 56.62s/it][A[2024-05-30 06:23:50,956] [INFO] [logging.py:96:log_dist] [Rank 0] step=738, skipped=0, lr=[1.948972519204692e-05], mom=[(0.9, 0.999)]
steps: 738 loss: 0.6545 iter time (s): 56.257 samples/sec: 2.275

 80%|████████  | 8/10 [07:31<01:53, 56.59s/it][A
 80%|████████  | 8/10 [07:31<01:53, 56.60s/it][A
 80%|████████  | 8/10 [07:31<01:53, 56.59s/it][A
 80%|████████  | 8/10 [07:31<01:53, 56.60s/it][A
 80%|████████  | 8/10 [07:31<01:53, 56.59s/it][A
 80%|████████  | 8/10 [07:31<01:53, 56.60s/it][A
 80%|████████  | 8/10 [07:31<01:53, 56.60s/it][A
 90%|█████████ | 9/10 [08:27<00:56, 56.28s/it][A[2024-05-30 06:24:46,500] [INFO] [logging.py:96:log_dist] [Rank 0] step=739, skipped=0, lr=[1.9487937525392773e-05], mom=[(0.9, 0.999)]
steps: 739 loss: 0.5786 iter time (s): 54.899 samples/sec: 2.332

 90%|█████████ | 9/10 [08:27<00:56, 56.30s/it][A
 90%|█████████ | 9/10 [08:27<00:56, 56.30s/it][A
 90%|█████████ | 9/10 [08:27<00:56, 56.33s/it][A
 90%|█████████ | 9/10 [08:27<00:56, 56.31s/it][A
 90%|█████████ | 9/10 [08:27<00:56, 56.34s/it][A
 90%|█████████ | 9/10 [08:27<00:56, 56.39s/it][A
 90%|█████████ | 9/10 [08:27<00:56, 56.40s/it][A
100%|██████████| 10/10 [09:24<00:00, 56.34s/it][A100%|██████████| 10/10 [09:24<00:00, 56.42s/it]
[2024-05-30 06:25:42,980] [INFO] [logging.py:96:log_dist] [Rank 0] step=740, skipped=0, lr=[1.9486146815093573e-05], mom=[(0.9, 0.999)]
steps: 740 loss: 0.6311 iter time (s): 55.428 samples/sec: 2.309

100%|██████████| 10/10 [09:23<00:00, 56.34s/it][A100%|██████████| 10/10 [09:23<00:00, 56.37s/it]

100%|██████████| 10/10 [09:23<00:00, 56.33s/it][A100%|██████████| 10/10 [09:23<00:00, 56.36s/it]

100%|██████████| 10/10 [09:23<00:00, 56.33s/it][A100%|██████████| 10/10 [09:23<00:00, 56.36s/it]

100%|██████████| 10/10 [09:23<00:00, 56.32s/it][A100%|██████████| 10/10 [09:23<00:00, 56.35s/it]

100%|██████████| 10/10 [09:23<00:00, 56.32s/it][A100%|██████████| 10/10 [09:23<00:00, 56.36s/it]

100%|██████████| 10/10 [09:23<00:00, 56.29s/it][A100%|██████████| 10/10 [09:23<00:00, 56.35s/it]

100%|██████████| 10/10 [09:23<00:00, 56.29s/it][A100%|██████████| 10/10 [09:23<00:00, 56.35s/it]
Checkpointing at shard 75
[2024-05-30 06:25:43,624] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step740 is about to be saved!
[2024-05-30 06:25:45,372] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step740/layer_00-model_states.pt...
[2024-05-30 06:25:50,479] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step740/layer_00-model_states.pt.
[2024-05-30 06:25:55,912] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step740/layer_03-model_states.pt...
[2024-05-30 06:25:56,245] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step740/layer_04-model_states.pt...
[2024-05-30 06:25:56,626] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step740/layer_02-model_states.pt...
[2024-05-30 06:25:57,594] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step740/layer_06-model_states.pt...
[2024-05-30 06:25:58,127] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step740/layer_05-model_states.pt...
[2024-05-30 06:25:58,742] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step740/layer_07-model_states.pt...
[2024-05-30 06:25:59,088] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step740/layer_08-model_states.pt...
[2024-05-30 06:26:03,880] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step740/layer_01-model_states.pt...
[2024-05-30 06:29:44,136] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step740/layer_08-model_states.pt.
[2024-05-30 06:29:44,141] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step740/layer_07-model_states.pt.
[2024-05-30 06:29:44,144] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step740/layer_05-model_states.pt.
[2024-05-30 06:29:44,144] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step740/layer_06-model_states.pt.
[2024-05-30 06:29:44,148] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step740/layer_04-model_states.pt.
[2024-05-30 06:29:44,153] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step740/layer_02-model_states.pt.
[2024-05-30 06:29:44,166] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step740/layer_03-model_states.pt.
[2024-05-30 06:29:44,698] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step740/mp_rank_05_model_states.pt...
[2024-05-30 06:29:44,999] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step740/mp_rank_05_model_states.pt.
[2024-05-30 06:29:44,999] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step740 is ready now!
[2024-05-30 06:29:45,144] [INFO] [logging.py:96:log_dist] [Rank 1] Saving model checkpoint: /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step740/mp_rank_01_model_states.pt
[2024-05-30 06:29:45,145] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step740/mp_rank_01_model_states.pt...
[2024-05-30 06:29:45,367] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step740/mp_rank_01_model_states.pt.
[2024-05-30 06:29:45,368] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step740 is ready now!
[2024-05-30 06:29:45,636] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step740/mp_rank_02_model_states.pt...
[2024-05-30 06:29:45,673] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step740/mp_rank_04_model_states.pt...
[2024-05-30 06:29:45,747] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step740/mp_rank_02_model_states.pt.
[2024-05-30 06:29:45,748] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step740 is ready now!
[2024-05-30 06:29:45,813] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step740/mp_rank_04_model_states.pt.
[2024-05-30 06:29:45,813] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step740 is ready now!
[2024-05-30 06:29:45,881] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step740/mp_rank_06_model_states.pt...
[2024-05-30 06:29:46,007] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step740/mp_rank_06_model_states.pt.
[2024-05-30 06:29:46,007] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step740 is ready now!
[2024-05-30 06:29:46,112] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step740/mp_rank_03_model_states.pt...
[2024-05-30 06:29:46,246] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step740/mp_rank_03_model_states.pt.
[2024-05-30 06:29:46,246] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step740 is ready now!
[2024-05-30 06:29:46,278] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step740/layer_09-model_states.pt...
[2024-05-30 06:29:48,230] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step740/layer_09-model_states.pt.
[2024-05-30 06:29:48,234] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step740/mp_rank_07_model_states.pt...
[2024-05-30 06:29:48,350] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step740/mp_rank_07_model_states.pt.
[2024-05-30 06:29:48,350] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step740 is ready now!
[2024-05-30 06:29:51,111] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step740/layer_01-model_states.pt.
[2024-05-30 06:29:52,267] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step740/mp_rank_00_model_states.pt
[2024-05-30 06:29:52,268] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step740/mp_rank_00_model_states.pt...
[2024-05-30 06:29:52,747] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint/global_step740/mp_rank_00_model_states.pt.
[2024-05-30 06:29:52,748] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step740 is ready now!
Checkpoint saved using --- 249.12647080421448 seconds ---
 14%|█▍        | 75/520 [8:34:52<97:47:50, 791.17s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_182
 14%|█▍        | 75/520 [8:36:57<97:52:17, 791.77s/it] 14%|█▍        | 75/520 [8:37:07<97:47:53, 791.18s/it] 14%|█▍        | 75/520 [8:37:04<97:48:16, 791.23s/it] 14%|█▍        | 75/520 [8:36:28<97:48:44, 791.29s/it] 14%|█▍        | 75/520 [8:35:56<97:48:04, 791.20s/it] 14%|█▍        | 75/520 [8:37:05<97:48:29, 791.26s/it] 14%|█▍        | 75/520 [8:36:23<97:47:57, 791.18s/it]Training on 1280 of 1280 sentences.

  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
 10%|█         | 1/10 [01:40<15:07, 100.81s/it][A[2024-05-30 06:31:36,129] [INFO] [logging.py:96:log_dist] [Rank 0] step=741, skipped=0, lr=[1.948435306172383e-05], mom=[(0.9, 0.999)]
steps: 741 loss: 0.6011 iter time (s): 103.193 samples/sec: 1.240

 10%|█         | 1/10 [01:43<15:31, 103.52s/it][A
 10%|█         | 1/10 [01:43<15:32, 103.63s/it][A
 10%|█         | 1/10 [01:43<15:34, 103.86s/it][A
 10%|█         | 1/10 [01:43<15:35, 103.91s/it][A
 10%|█         | 1/10 [01:43<15:35, 103.92s/it][A
 10%|█         | 1/10 [01:43<15:35, 103.98s/it][A
 10%|█         | 1/10 [01:43<15:35, 103.98s/it][A
 20%|██        | 2/10 [03:24<13:41, 102.64s/it][A[2024-05-30 06:33:20,039] [INFO] [logging.py:96:log_dist] [Rank 0] step=742, skipped=0, lr=[1.948255626585902e-05], mom=[(0.9, 0.999)]
steps: 742 loss: 0.6120 iter time (s): 103.177 samples/sec: 1.241

 20%|██        | 2/10 [03:27<13:50, 103.76s/it][A
 20%|██        | 2/10 [03:27<13:50, 103.82s/it][A
 20%|██        | 2/10 [03:27<13:50, 103.85s/it][A
 20%|██        | 2/10 [03:27<13:50, 103.85s/it][A
 20%|██        | 2/10 [03:27<13:51, 103.93s/it][A
 20%|██        | 2/10 [03:27<13:51, 103.93s/it][A
 20%|██        | 2/10 [03:27<13:51, 103.95s/it][A
 30%|███       | 3/10 [05:09<12:04, 103.43s/it][A[2024-05-30 06:35:04,440] [INFO] [logging.py:96:log_dist] [Rank 0] step=743, skipped=0, lr=[1.94807564280756e-05], mom=[(0.9, 0.999)]
steps: 743 loss: 0.6075 iter time (s): 103.659 samples/sec: 1.235

 30%|███       | 3/10 [05:12<12:09, 104.17s/it][A
 30%|███       | 3/10 [05:12<12:09, 104.20s/it][A
 30%|███       | 3/10 [05:12<12:09, 104.23s/it][A
 30%|███       | 3/10 [05:12<12:09, 104.22s/it][A
 30%|███       | 3/10 [05:12<12:09, 104.25s/it][A
 30%|███       | 3/10 [05:12<12:09, 104.23s/it][A
 30%|███       | 3/10 [05:12<12:09, 104.25s/it][A
 40%|████      | 4/10 [06:53<10:22, 103.72s/it][A[2024-05-30 06:36:48,067] [INFO] [logging.py:96:log_dist] [Rank 0] step=744, skipped=0, lr=[1.9478953548951004e-05], mom=[(0.9, 0.999)]
steps: 744 loss: 0.5900 iter time (s): 102.662 samples/sec: 1.247

 40%|████      | 4/10 [06:55<10:23, 103.85s/it][A
 40%|████      | 4/10 [06:55<10:23, 103.87s/it][A
 40%|████      | 4/10 [06:55<10:23, 103.88s/it][A
 40%|████      | 4/10 [06:55<10:23, 103.90s/it][A
 40%|████      | 4/10 [06:55<10:23, 103.90s/it][A
 40%|████      | 4/10 [06:55<10:23, 103.90s/it][A
 40%|████      | 4/10 [06:55<10:23, 103.91s/it][A
 50%|█████     | 5/10 [08:36<08:37, 103.44s/it][A[2024-05-30 06:38:31,533] [INFO] [logging.py:96:log_dist] [Rank 0] step=745, skipped=0, lr=[1.9477147629063637e-05], mom=[(0.9, 0.999)]
steps: 745 loss: 0.5970 iter time (s): 102.740 samples/sec: 1.246

 50%|█████     | 5/10 [08:38<08:38, 103.72s/it][A
 50%|█████     | 5/10 [08:39<08:38, 103.74s/it][A
 50%|█████     | 5/10 [08:39<08:38, 103.72s/it][A
 50%|█████     | 5/10 [08:39<08:38, 103.75s/it][A
 50%|█████     | 5/10 [08:39<08:38, 103.77s/it][A
 50%|█████     | 5/10 [08:39<08:38, 103.77s/it][A
 50%|█████     | 5/10 [08:39<08:38, 103.76s/it][A
 60%|██████    | 6/10 [10:20<06:54, 103.61s/it][A[2024-05-30 06:40:15,456] [INFO] [logging.py:96:log_dist] [Rank 0] step=746, skipped=0, lr=[1.9475338668992883e-05], mom=[(0.9, 0.999)]
steps: 746 loss: 0.5947 iter time (s): 103.157 samples/sec: 1.241

 60%|██████    | 6/10 [10:22<06:55, 103.80s/it][A
 60%|██████    | 6/10 [10:22<06:55, 103.79s/it][A
 60%|██████    | 6/10 [10:23<06:55, 103.83s/it][A
 60%|██████    | 6/10 [10:23<06:55, 103.81s/it][A
 60%|██████    | 6/10 [10:23<06:55, 103.83s/it][A
 60%|██████    | 6/10 [10:23<06:55, 103.83s/it][A
 60%|██████    | 6/10 [10:23<06:55, 103.83s/it][A
 70%|███████   | 7/10 [12:04<05:11, 103.95s/it][A[2024-05-30 06:42:00,127] [INFO] [logging.py:96:log_dist] [Rank 0] step=747, skipped=0, lr=[1.947352666931911e-05], mom=[(0.9, 0.999)]
steps: 747 loss: 0.5541 iter time (s): 103.874 samples/sec: 1.232

 70%|███████   | 7/10 [12:07<05:12, 104.07s/it][A
 70%|███████   | 7/10 [12:07<05:12, 104.09s/it][A
 70%|███████   | 7/10 [12:07<05:12, 104.07s/it][A
 70%|███████   | 7/10 [12:07<05:12, 104.09s/it][A
 70%|███████   | 7/10 [12:07<05:12, 104.07s/it][A
 70%|███████   | 7/10 [12:07<05:12, 104.09s/it][A
 70%|███████   | 7/10 [12:07<05:12, 104.10s/it][A
 80%|████████  | 8/10 [13:48<03:27, 103.80s/it][A[2024-05-30 06:43:43,608] [INFO] [logging.py:96:log_dist] [Rank 0] step=748, skipped=0, lr=[1.947171163062364e-05], mom=[(0.9, 0.999)]
steps: 748 loss: 0.5453 iter time (s): 102.733 samples/sec: 1.246

 80%|████████  | 8/10 [13:51<03:27, 103.91s/it][A
 80%|████████  | 8/10 [13:51<03:27, 103.89s/it][A
 80%|████████  | 8/10 [13:51<03:27, 103.88s/it][A
 80%|████████  | 8/10 [13:51<03:27, 103.90s/it][A
 80%|████████  | 8/10 [13:51<03:27, 103.90s/it][A
 80%|████████  | 8/10 [13:51<03:27, 103.89s/it][A
 80%|████████  | 8/10 [13:51<03:27, 103.90s/it][A
 90%|█████████ | 9/10 [15:32<01:43, 103.96s/it][A[2024-05-30 06:45:27,919] [INFO] [logging.py:96:log_dist] [Rank 0] step=749, skipped=0, lr=[1.9469893553488793e-05], mom=[(0.9, 0.999)]
steps: 749 loss: 0.5810 iter time (s): 103.545 samples/sec: 1.236

 90%|█████████ | 9/10 [15:35<01:44, 104.03s/it][A
 90%|█████████ | 9/10 [15:35<01:44, 104.01s/it][A
 90%|█████████ | 9/10 [15:35<01:44, 104.04s/it][A
 90%|█████████ | 9/10 [15:35<01:44, 104.03s/it][A
 90%|█████████ | 9/10 [15:35<01:44, 104.02s/it][A
 90%|█████████ | 9/10 [15:35<01:44, 104.03s/it][A
 90%|█████████ | 9/10 [15:35<01:44, 104.03s/it][A
100%|██████████| 10/10 [17:16<00:00, 104.04s/it][A100%|██████████| 10/10 [17:16<00:00, 103.68s/it]
 15%|█▍        | 76/520 [8:54:14<106:43:27, 865.33s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A[2024-05-30 06:47:12,145] [INFO] [logging.py:96:log_dist] [Rank 0] step=750, skipped=0, lr=[1.946807243849784e-05], mom=[(0.9, 0.999)]
steps: 750 loss: 0.5692 iter time (s): 103.466 samples/sec: 1.237

100%|██████████| 10/10 [17:19<00:00, 104.06s/it][A100%|██████████| 10/10 [17:19<00:00, 103.95s/it]
 15%|█▍        | 76/520 [8:53:48<106:46:56, 865.80s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [17:19<00:00, 104.06s/it][A100%|██████████| 10/10 [17:19<00:00, 103.96s/it]
 15%|█▍        | 76/520 [8:54:25<106:46:58, 865.81s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [17:19<00:00, 104.08s/it][A100%|██████████| 10/10 [17:19<00:00, 103.98s/it]
 15%|█▍        | 76/520 [8:54:24<106:47:15, 865.85s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [17:19<00:00, 104.08s/it][A100%|██████████| 10/10 [17:19<00:00, 103.99s/it]
 15%|█▍        | 76/520 [8:53:17<106:47:18, 865.85s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [17:19<00:00, 104.09s/it][A100%|██████████| 10/10 [17:19<00:00, 103.99s/it]
 15%|█▍        | 76/520 [8:53:43<106:47:20, 865.86s/it]
100%|██████████| 10/10 [17:19<00:00, 104.08s/it][A100%|██████████| 10/10 [17:19<00:00, 104.00s/it]
 15%|█▍        | 76/520 [8:54:27<106:47:19, 865.86s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [17:19<00:00, 104.08s/it][A100%|██████████| 10/10 [17:19<00:00, 104.00s/it]
 15%|█▍        | 76/520 [8:52:12<106:47:21, 865.86s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_180
Training on 1280 of 1280 sentences.

  0%|          | 0/10 [00:00<?, ?it/s][A
 10%|█         | 1/10 [02:33<23:05, 154.00s/it][A[2024-05-30 06:49:47,707] [INFO] [logging.py:96:log_dist] [Rank 0] step=751, skipped=0, lr=[1.946624828623506e-05], mom=[(0.9, 0.999)]
steps: 751 loss: 0.5831 iter time (s): 154.677 samples/sec: 0.828

 10%|█         | 1/10 [02:35<23:20, 155.58s/it][A
 10%|█         | 1/10 [02:35<23:20, 155.56s/it][A
 10%|█         | 1/10 [02:35<23:19, 155.55s/it][A
 10%|█         | 1/10 [02:35<23:20, 155.66s/it][A
 10%|█         | 1/10 [02:35<23:20, 155.56s/it][A
 10%|█         | 1/10 [02:35<23:19, 155.54s/it][A
 10%|█         | 1/10 [02:35<23:20, 155.58s/it][A
 20%|██        | 2/10 [05:10<20:43, 155.41s/it][A[2024-05-30 06:52:24,096] [INFO] [logging.py:96:log_dist] [Rank 0] step=752, skipped=0, lr=[1.9464421097285668e-05], mom=[(0.9, 0.999)]
steps: 752 loss: 0.5565 iter time (s): 155.654 samples/sec: 0.822

 20%|██        | 2/10 [05:11<20:48, 156.06s/it][A
 20%|██        | 2/10 [05:12<20:48, 156.10s/it][A
 20%|██        | 2/10 [05:11<20:48, 156.05s/it][A
 20%|██        | 2/10 [05:11<20:48, 156.01s/it][A
 20%|██        | 2/10 [05:11<20:48, 156.02s/it][A
 20%|██        | 2/10 [05:11<20:48, 156.03s/it][A
 20%|██        | 2/10 [05:11<20:48, 156.02s/it][A
 30%|███       | 3/10 [07:45<18:06, 155.21s/it][A[2024-05-30 06:54:59,068] [INFO] [logging.py:96:log_dist] [Rank 0] step=753, skipped=0, lr=[1.946259087223588e-05], mom=[(0.9, 0.999)]
steps: 753 loss: 0.5748 iter time (s): 154.268 samples/sec: 0.830

 30%|███       | 3/10 [07:46<18:08, 155.56s/it][A
 30%|███       | 3/10 [07:46<18:09, 155.58s/it][A
 30%|███       | 3/10 [07:46<18:08, 155.52s/it][A
 30%|███       | 3/10 [07:46<18:08, 155.56s/it][A
 30%|███       | 3/10 [07:46<18:08, 155.54s/it][A
 30%|███       | 3/10 [07:46<18:08, 155.53s/it][A
 30%|███       | 3/10 [07:46<18:08, 155.55s/it][A
 40%|████      | 4/10 [10:22<15:36, 156.01s/it][A[2024-05-30 06:57:36,326] [INFO] [logging.py:96:log_dist] [Rank 0] step=754, skipped=0, lr=[1.9460757611672877e-05], mom=[(0.9, 0.999)]
steps: 754 loss: 0.5668 iter time (s): 156.596 samples/sec: 0.817

 40%|████      | 4/10 [10:24<15:37, 156.22s/it][A
 40%|████      | 4/10 [10:24<15:37, 156.21s/it][A
 40%|████      | 4/10 [10:24<15:37, 156.21s/it][A
 40%|████      | 4/10 [10:24<15:37, 156.21s/it][A
 40%|████      | 4/10 [10:24<15:37, 156.21s/it][A
 40%|████      | 4/10 [10:24<15:37, 156.21s/it][A
 40%|████      | 4/10 [10:24<15:37, 156.22s/it][A
 50%|█████     | 5/10 [12:57<12:58, 155.62s/it][A[2024-05-30 07:00:11,234] [INFO] [logging.py:96:log_dist] [Rank 0] step=755, skipped=0, lr=[1.945892131618481e-05], mom=[(0.9, 0.999)]
steps: 755 loss: 0.5575 iter time (s): 154.247 samples/sec: 0.830

 50%|█████     | 5/10 [12:59<12:58, 155.77s/it][A
 50%|█████     | 5/10 [12:59<12:58, 155.74s/it][A
 50%|█████     | 5/10 [12:59<12:58, 155.74s/it][A
 50%|█████     | 5/10 [12:58<12:58, 155.74s/it][A
 50%|█████     | 5/10 [12:59<12:58, 155.74s/it][A
 50%|█████     | 5/10 [12:59<12:58, 155.73s/it][A
 50%|█████     | 5/10 [12:59<12:58, 155.74s/it][A
 60%|██████    | 6/10 [15:35<10:25, 156.35s/it][A[2024-05-30 07:02:49,016] [INFO] [logging.py:96:log_dist] [Rank 0] step=756, skipped=0, lr=[1.9457081986360816e-05], mom=[(0.9, 0.999)]
steps: 756 loss: 0.5500 iter time (s): 157.112 samples/sec: 0.815

 60%|██████    | 6/10 [15:36<10:25, 156.43s/it][A
 60%|██████    | 6/10 [15:36<10:25, 156.43s/it][A
 60%|██████    | 6/10 [15:36<10:25, 156.43s/it][A
 60%|██████    | 6/10 [15:36<10:25, 156.45s/it][A
 60%|██████    | 6/10 [15:36<10:25, 156.44s/it][A
 60%|██████    | 6/10 [15:36<10:25, 156.44s/it][A
 60%|██████    | 6/10 [15:36<10:25, 156.44s/it][A
 70%|███████   | 7/10 [18:12<07:49, 156.49s/it][A[2024-05-30 07:05:25,793] [INFO] [logging.py:96:log_dist] [Rank 0] step=757, skipped=0, lr=[1.945523962279099e-05], mom=[(0.9, 0.999)]
steps: 757 loss: 0.5772 iter time (s): 156.095 samples/sec: 0.820

 70%|███████   | 7/10 [18:13<07:49, 156.57s/it][A
 70%|███████   | 7/10 [18:13<07:49, 156.55s/it][A
 70%|███████   | 7/10 [18:13<07:49, 156.54s/it][A
 70%|███████   | 7/10 [18:13<07:49, 156.55s/it][A
 70%|███████   | 7/10 [18:13<07:49, 156.53s/it][A
 70%|███████   | 7/10 [18:13<07:49, 156.54s/it][A
 70%|███████   | 7/10 [18:13<07:49, 156.54s/it][A
 80%|████████  | 8/10 [20:47<05:12, 156.02s/it][A[2024-05-30 07:08:00,818] [INFO] [logging.py:96:log_dist] [Rank 0] step=758, skipped=0, lr=[1.945339422606641e-05], mom=[(0.9, 0.999)]
steps: 758 loss: 0.5629 iter time (s): 154.360 samples/sec: 0.829

 80%|████████  | 8/10 [20:48<05:12, 156.07s/it][A
 80%|████████  | 8/10 [20:48<05:12, 156.08s/it][A
 80%|████████  | 8/10 [20:48<05:12, 156.06s/it][A
 80%|████████  | 8/10 [20:48<05:12, 156.07s/it][A
 80%|████████  | 8/10 [20:48<05:12, 156.07s/it][A
 80%|████████  | 8/10 [20:48<05:12, 156.07s/it][A
 80%|████████  | 8/10 [20:48<05:12, 156.07s/it][A
 90%|█████████ | 9/10 [23:25<02:36, 156.77s/it][A[2024-05-30 07:10:39,240] [INFO] [logging.py:96:log_dist] [Rank 0] step=759, skipped=0, lr=[1.9451545796779134e-05], mom=[(0.9, 0.999)]
steps: 759 loss: 0.5779 iter time (s): 157.758 samples/sec: 0.811

 90%|█████████ | 9/10 [23:27<02:36, 156.80s/it][A
 90%|█████████ | 9/10 [23:27<02:36, 156.81s/it][A
 90%|█████████ | 9/10 [23:27<02:36, 156.81s/it][A
 90%|█████████ | 9/10 [23:27<02:36, 156.82s/it][A
 90%|█████████ | 9/10 [23:27<02:36, 156.81s/it][A
 90%|█████████ | 9/10 [23:27<02:36, 156.81s/it][A
 90%|█████████ | 9/10 [23:27<02:36, 156.81s/it][A
100%|██████████| 10/10 [26:01<00:00, 156.52s/it][A100%|██████████| 10/10 [26:01<00:00, 156.15s/it]
 15%|█▍        | 77/520 [9:20:16<132:11:13, 1074.21s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A[2024-05-30 07:13:15,314] [INFO] [logging.py:96:log_dist] [Rank 0] step=760, skipped=0, lr=[1.9449694335522173e-05], mom=[(0.9, 0.999)]
steps: 760 loss: 0.5915 iter time (s): 155.425 samples/sec: 0.824

100%|██████████| 10/10 [26:02<00:00, 156.40s/it][A100%|██████████| 10/10 [26:02<00:00, 156.25s/it]
 15%|█▍        | 77/520 [9:18:14<132:16:00, 1074.85s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_448
Training on 1280 of 1280 sentences.

  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [26:03<00:00, 156.58s/it][A100%|██████████| 10/10 [26:03<00:00, 156.32s/it]
 15%|█▍        | 77/520 [9:19:51<132:17:11, 1075.01s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [26:03<00:00, 156.59s/it][A100%|██████████| 10/10 [26:03<00:00, 156.32s/it]
 15%|█▍        | 77/520 [9:20:28<132:17:18, 1075.03s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [26:03<00:00, 156.56s/it][A100%|██████████| 10/10 [26:03<00:00, 156.31s/it]
 15%|█▍        | 77/520 [9:20:27<132:17:13, 1075.02s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [26:03<00:00, 156.57s/it][A100%|██████████| 10/10 [26:03<00:00, 156.31s/it]
 15%|█▍        | 77/520 [9:19:20<132:17:09, 1075.01s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [26:03<00:00, 156.55s/it][A100%|██████████| 10/10 [26:03<00:00, 156.30s/it]
 15%|█▍        | 77/520 [9:19:46<132:17:07, 1075.01s/it]
100%|██████████| 10/10 [26:03<00:00, 156.55s/it][A100%|██████████| 10/10 [26:03<00:00, 156.30s/it]
 15%|█▍        | 77/520 [9:20:30<132:17:06, 1075.00s/it]
  0%|          | 0/10 [00:00<?, ?it/s][A
  0%|          | 0/10 [00:00<?, ?it/s][A
 10%|█         | 1/10 [01:03<09:30, 63.43s/it][A[2024-05-30 07:14:16,162] [INFO] [logging.py:96:log_dist] [Rank 0] step=761, skipped=0, lr=[1.9447839842889523e-05], mom=[(0.9, 0.999)]
steps: 761 loss: 0.3152 iter time (s): 60.589 samples/sec: 2.113

 10%|█         | 1/10 [01:00<09:06, 60.75s/it][A
 10%|█         | 1/10 [01:00<09:06, 60.77s/it][A
 10%|█         | 1/10 [01:00<09:07, 60.82s/it][A
 10%|█         | 1/10 [01:00<09:07, 60.84s/it][A
 10%|█         | 1/10 [01:00<09:07, 60.87s/it][A
 10%|█         | 1/10 [01:00<09:07, 60.87s/it][A
 10%|█         | 1/10 [01:01<09:12, 61.39s/it][A
 20%|██        | 2/10 [02:04<08:15, 61.90s/it][A[2024-05-30 07:15:17,002] [INFO] [logging.py:96:log_dist] [Rank 0] step=762, skipped=0, lr=[1.9445982319476153e-05], mom=[(0.9, 0.999)]
steps: 762 loss: 0.2934 iter time (s): 60.176 samples/sec: 2.127

 20%|██        | 2/10 [02:01<08:07, 60.88s/it][A
 20%|██        | 2/10 [02:01<08:07, 60.95s/it][A
 20%|██        | 2/10 [02:01<08:07, 60.99s/it][A
 20%|██        | 2/10 [02:01<08:07, 60.97s/it][A
 20%|██        | 2/10 [02:01<08:07, 61.00s/it][A
 20%|██        | 2/10 [02:01<08:07, 60.99s/it][A
 20%|██        | 2/10 [02:02<08:09, 61.19s/it][A
 30%|███       | 3/10 [03:03<07:03, 60.52s/it][A[2024-05-30 07:16:15,878] [INFO] [logging.py:96:log_dist] [Rank 0] step=763, skipped=0, lr=[1.9444121765878002e-05], mom=[(0.9, 0.999)]
steps: 763 loss: 0.2969 iter time (s): 57.988 samples/sec: 2.207

 30%|███       | 3/10 [03:00<06:59, 59.94s/it][A
 30%|███       | 3/10 [03:00<06:58, 59.85s/it][A
 30%|███       | 3/10 [03:00<06:59, 59.89s/it][A
 30%|███       | 3/10 [03:00<06:59, 59.89s/it][A
 30%|███       | 3/10 [03:00<06:59, 59.91s/it][A
 30%|███       | 3/10 [03:00<06:59, 59.91s/it][A
 30%|███       | 3/10 [03:01<07:00, 60.02s/it][A
 40%|████      | 4/10 [04:02<06:00, 60.14s/it][A[2024-05-30 07:17:15,444] [INFO] [logging.py:96:log_dist] [Rank 0] step=764, skipped=0, lr=[1.944225818269199e-05], mom=[(0.9, 0.999)]
steps: 764 loss: 0.3217 iter time (s): 58.935 samples/sec: 2.172

 40%|████      | 4/10 [04:00<05:58, 59.77s/it][A
 40%|████      | 4/10 [04:00<05:58, 59.76s/it][A
 40%|████      | 4/10 [04:00<05:58, 59.75s/it][A
 40%|████      | 4/10 [04:00<05:58, 59.77s/it][A
 40%|████      | 4/10 [04:00<05:58, 59.77s/it][A
 40%|████      | 4/10 [04:00<05:58, 59.77s/it][A
 40%|████      | 4/10 [04:00<05:59, 59.84s/it][A
 50%|█████     | 5/10 [05:02<05:00, 60.19s/it][A[2024-05-30 07:18:15,705] [INFO] [logging.py:96:log_dist] [Rank 0] step=765, skipped=0, lr=[1.9440391570515985e-05], mom=[(0.9, 0.999)]
steps: 765 loss: 0.2907 iter time (s): 59.627 samples/sec: 2.147

 50%|█████     | 5/10 [05:00<04:59, 59.96s/it][A
 50%|█████     | 5/10 [05:00<04:59, 59.95s/it][A
 50%|█████     | 5/10 [05:00<04:59, 59.95s/it][A
 50%|█████     | 5/10 [05:00<04:59, 59.95s/it][A
 50%|█████     | 5/10 [05:00<04:59, 59.97s/it][A
 50%|█████     | 5/10 [05:00<04:59, 59.96s/it][A
 50%|█████     | 5/10 [05:00<05:00, 60.01s/it][A
 60%|██████    | 6/10 [06:03<04:00, 60.15s/it][A[2024-05-30 07:19:15,776] [INFO] [logging.py:96:log_dist] [Rank 0] step=766, skipped=0, lr=[1.9438521929948858e-05], mom=[(0.9, 0.999)]
steps: 766 loss: 0.2879 iter time (s): 59.389 samples/sec: 2.155

 60%|██████    | 6/10 [06:00<03:59, 60.00s/it][A
 60%|██████    | 6/10 [06:00<03:59, 59.97s/it][A
 60%|██████    | 6/10 [06:00<03:59, 59.99s/it][A
 60%|██████    | 6/10 [06:00<03:59, 60.00s/it][A
 60%|██████    | 6/10 [06:00<03:59, 59.99s/it][A
 60%|██████    | 6/10 [06:00<03:59, 59.99s/it][A
 60%|██████    | 6/10 [06:00<04:00, 60.02s/it][A
 70%|███████   | 7/10 [07:02<02:59, 59.88s/it][A[2024-05-30 07:20:15,129] [INFO] [logging.py:96:log_dist] [Rank 0] step=767, skipped=0, lr=[1.9436649261590425e-05], mom=[(0.9, 0.999)]
steps: 767 loss: 0.2825 iter time (s): 58.723 samples/sec: 2.180

 70%|███████   | 7/10 [06:59<02:59, 59.78s/it][A
 70%|███████   | 7/10 [06:59<02:59, 59.78s/it][A
 70%|███████   | 7/10 [06:59<02:59, 59.78s/it][A
 70%|███████   | 7/10 [06:59<02:59, 59.80s/it][A
 70%|███████   | 7/10 [06:59<02:59, 59.79s/it][A
 70%|███████   | 7/10 [06:59<02:59, 59.80s/it][A
 70%|███████   | 7/10 [07:00<02:59, 59.81s/it][A
 80%|████████  | 8/10 [08:02<01:59, 59.88s/it][A[2024-05-30 07:21:15,001] [INFO] [logging.py:96:log_dist] [Rank 0] step=768, skipped=0, lr=[1.9434773566041492e-05], mom=[(0.9, 0.999)]
steps: 768 loss: 0.2981 iter time (s): 59.193 samples/sec: 2.162

 80%|████████  | 8/10 [07:59<01:59, 59.80s/it][A
 80%|████████  | 8/10 [07:59<01:59, 59.81s/it][A
 80%|████████  | 8/10 [07:59<01:59, 59.80s/it][A
 80%|████████  | 8/10 [07:59<01:59, 59.79s/it][A
 80%|████████  | 8/10 [07:59<01:59, 59.80s/it][A
 80%|████████  | 8/10 [07:59<01:59, 59.81s/it][A
 80%|████████  | 8/10 [08:00<01:59, 59.82s/it][A
 90%|█████████ | 9/10 [09:01<00:59, 59.70s/it][A[2024-05-30 07:22:14,295] [INFO] [logging.py:96:log_dist] [Rank 0] step=769, skipped=0, lr=[1.9432894843903823e-05], mom=[(0.9, 0.999)]
steps: 769 loss: 0.3009 iter time (s): 58.638 samples/sec: 2.183

 90%|█████████ | 9/10 [08:58<00:59, 59.65s/it][A
 90%|█████████ | 9/10 [08:58<00:59, 59.64s/it][A
 90%|█████████ | 9/10 [08:58<00:59, 59.65s/it][A
 90%|█████████ | 9/10 [08:58<00:59, 59.65s/it][A
 90%|█████████ | 9/10 [08:58<00:59, 59.65s/it][A
 90%|█████████ | 9/10 [08:59<00:59, 59.65s/it][A
 90%|█████████ | 9/10 [08:59<00:59, 59.65s/it][A
100%|██████████| 10/10 [10:02<00:00, 60.08s/it][A100%|██████████| 10/10 [10:02<00:00, 60.25s/it]
 15%|█▌        | 78/520 [9:30:19<114:31:14, 932.75s/it] 
  0%|          | 0/10 [00:00<?, ?it/s][A[2024-05-30 07:23:15,247] [INFO] [logging.py:96:log_dist] [Rank 0] step=770, skipped=0, lr=[1.943101309578016e-05], mom=[(0.9, 0.999)]
steps: 770 loss: 0.2846 iter time (s): 60.310 samples/sec: 2.122

100%|██████████| 10/10 [09:59<00:00, 60.06s/it][A100%|██████████| 10/10 [09:59<00:00, 59.99s/it]
 15%|█▌        | 78/520 [9:29:51<114:29:18, 932.48s/it] 
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [09:59<00:00, 60.04s/it][A100%|██████████| 10/10 [09:59<00:00, 59.98s/it]
 15%|█▌        | 78/520 [9:30:28<114:29:08, 932.46s/it] 
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [09:59<00:00, 60.05s/it][A100%|██████████| 10/10 [09:59<00:00, 59.99s/it]
 15%|█▌        | 78/520 [9:30:27<114:29:14, 932.48s/it] 
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [09:59<00:00, 60.05s/it][A100%|██████████| 10/10 [09:59<00:00, 59.99s/it]
 15%|█▌        | 78/520 [9:29:20<114:29:20, 932.49s/it] 
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [09:59<00:00, 60.03s/it][A100%|██████████| 10/10 [09:59<00:00, 59.99s/it]
 15%|█▌        | 78/520 [9:30:30<114:29:16, 932.48s/it] 
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [09:59<00:00, 60.05s/it][A100%|██████████| 10/10 [09:59<00:00, 59.99s/it]
 15%|█▌        | 78/520 [9:29:46<114:29:21, 932.49s/it] 
  0%|          | 0/10 [00:00<?, ?it/s][A
100%|██████████| 10/10 [10:00<00:00, 60.05s/it][A100%|██████████| 10/10 [10:00<00:00, 60.04s/it]
 15%|█▌        | 78/520 [9:28:15<114:29:39, 932.53s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_369
Training on 1280 of 1280 sentences.

  0%|          | 0/10 [00:00<?, ?it/s][A
 10%|█         | 1/10 [02:33<22:57, 153.06s/it][A[2024-05-30 07:25:51,115] [INFO] [logging.py:96:log_dist] [Rank 0] step=771, skipped=0, lr=[1.9429128322274217e-05], mom=[(0.9, 0.999)]
steps: 771 loss: 0.8047 iter time (s): 155.120 samples/sec: 0.825

 10%|█         | 1/10 [02:36<23:24, 156.03s/it][A
 10%|█         | 1/10 [02:36<23:24, 156.05s/it][A
 10%|█         | 1/10 [02:35<23:23, 155.96s/it][A
 10%|█         | 1/10 [02:35<23:23, 155.99s/it][A
 10%|█         | 1/10 [02:36<23:24, 156.04s/it][A
 10%|█         | 1/10 [02:36<23:24, 156.05s/it][A
 10%|█         | 1/10 [02:36<23:24, 156.10s/it][A
 20%|██        | 2/10 [05:08<20:36, 154.58s/it][A[2024-05-30 07:28:26,758] [INFO] [logging.py:96:log_dist] [Rank 0] step=772, skipped=0, lr=[1.9427240523990677e-05], mom=[(0.9, 0.999)]
steps: 772 loss: 0.7876 iter time (s): 154.839 samples/sec: 0.827

 20%|██        | 2/10 [05:11<20:45, 155.72s/it][A
 20%|██        | 2/10 [05:11<20:46, 155.76s/it][A
 20%|██        | 2/10 [05:11<20:46, 155.77s/it][A
 20%|██        | 2/10 [05:11<20:46, 155.77s/it][A
 20%|██        | 2/10 [05:11<20:46, 155.75s/it][A
 20%|██        | 2/10 [05:11<20:46, 155.77s/it][A
 20%|██        | 2/10 [05:11<20:46, 155.78s/it][A 20%|██        | 2/10 [07:12<28:50, 216.26s/it]
 15%|█▌        | 78/520 [9:35:27<54:20:57, 442.66s/it] 
Traceback (most recent call last):
  File "llava/train_parallel_deepspeed_mixtral_lora.py", line 401, in <module>
    main()
  File "llava/train_parallel_deepspeed_mixtral_lora.py", line 379, in main
    loss = engine.train_batch(data_iter=training_dataloader)
  File "/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/lib/python3.8/site-packages/deepspeed/runtime/pipe/engine.py", line 373, in train_batch
    self._exec_schedule(sched)
  File "/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/lib/python3.8/site-packages/deepspeed/runtime/pipe/engine.py", line 1373, in _exec_schedule
    self._exec_instr(**cmd.kwargs)
  File "/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/lib/python3.8/site-packages/deepspeed/runtime/pipe/engine.py", line 679, in _exec_forward_pass
    outputs = super().forward(inputs)
  File "/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 1852, in forward
    loss = self.module(*inputs, **kwargs)
  File "/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/lib/python3.8/site-packages/deepspeed/runtime/pipe/module.py", line 351, in forward
    x = func(forward_input)
  File "/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/lib/python3.8/site-packages/deepspeed/runtime/pipe/module.py", line 344, in exec_func
    inputs = layer(inputs)
  File "/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/hpc/b207dd/b207dd11/llava/deepspeed_pipeline_model.py", line 135, in forward
    layer_outputs = layer(
  File "/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/hpc/b207dd/b207dd11/llava/mixtral_modification/modeling_mixtral.py", line 1110, in forward
    hidden_states, router_logits, shared_sparse_adapter_router_logits = self.block_sparse_moe(hidden_states)
  File "/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/hpc/b207dd/b207dd11/llava/mixtral_modification/modeling_mixtral.py", line 992, in forward
    current_hidden_states = expert_layer(current_state) * routing_weights[top_x_list, idx_list, None]
  File "/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/hpc/b207dd/b207dd11/llava/mixtral_modification/modeling_mixtral.py", line 882, in forward
    current_hidden_states = self.act_fn(self.w1(hidden_states)) * self.w3(hidden_states)
  File "/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 116, in forward
    return F.linear(input, self.weight, self.bias)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 116.00 MiB. GPU 0 has a total capacity of 79.14 GiB of which 92.75 MiB is free. Including non-PyTorch memory, this process has 79.04 GiB memory in use. Of the allocated memory 68.35 GiB is allocated by PyTorch, and 6.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[2024-05-30 07:30:52,961] [INFO] [launch.py:316:sigkill_handler] Killing subprocess 746893
[2024-05-30 07:30:52,961] [INFO] [launch.py:316:sigkill_handler] Killing subprocess 746894
[2024-05-30 07:30:54,939] [INFO] [launch.py:316:sigkill_handler] Killing subprocess 746895
[2024-05-30 07:30:57,967] [INFO] [launch.py:316:sigkill_handler] Killing subprocess 746896
[2024-05-30 07:31:01,164] [INFO] [launch.py:316:sigkill_handler] Killing subprocess 746897
[2024-05-30 07:31:02,934] [INFO] [launch.py:316:sigkill_handler] Killing subprocess 746898
[2024-05-30 07:31:04,181] [INFO] [launch.py:316:sigkill_handler] Killing subprocess 746899
[2024-05-30 07:31:06,362] [INFO] [launch.py:316:sigkill_handler] Killing subprocess 746900
[2024-05-30 07:31:07,934] [ERROR] [launch.py:322:sigkill_handler] ['/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/bin/python', '-u', 'llava/train_parallel_deepspeed_mixtral_lora.py', '--local_rank=7', '--num_stages=8', '--lora_r=128', '--lora_alpha=256', '--save_model_shard=5', '--skip_shard=40', '--checkpoint_dir=/home/atuin/b207dd/b207dd11/LLaVA-PEFT_lora_128_256_checkpoint'] exits with return code = 1
