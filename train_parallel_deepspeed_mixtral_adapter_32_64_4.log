[2024-06-29 19:23:18,939] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-06-29 19:23:28,533] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2024-06-29 19:23:28,534] [INFO] [runner.py:568:main] cmd = /home/hpc/b207dd/b207dd11/miniconda3/envs/py38/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None llava/train_parallel_deepspeed_mixtral_adapter.py --num_stages=8 --shared_adapter_num=4 --shared_adapter_type=Parallel_Adapter --hidden_dim=32 --save_model_shard=100 --skip_shard=0 --checkpoint_dir=/home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint
[2024-06-29 19:23:32,260] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-06-29 19:23:33,978] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]}
[2024-06-29 19:23:33,978] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=8, node_rank=0
[2024-06-29 19:23:33,978] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]})
[2024-06-29 19:23:33,978] [INFO] [launch.py:163:main] dist_world_size=8
[2024-06-29 19:23:33,978] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
[2024-06-29 19:23:33,985] [INFO] [launch.py:253:main] process 1319650 spawned with command: ['/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/bin/python', '-u', 'llava/train_parallel_deepspeed_mixtral_adapter.py', '--local_rank=0', '--num_stages=8', '--shared_adapter_num=4', '--shared_adapter_type=Parallel_Adapter', '--hidden_dim=32', '--save_model_shard=100', '--skip_shard=0', '--checkpoint_dir=/home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint']
[2024-06-29 19:23:33,992] [INFO] [launch.py:253:main] process 1319651 spawned with command: ['/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/bin/python', '-u', 'llava/train_parallel_deepspeed_mixtral_adapter.py', '--local_rank=1', '--num_stages=8', '--shared_adapter_num=4', '--shared_adapter_type=Parallel_Adapter', '--hidden_dim=32', '--save_model_shard=100', '--skip_shard=0', '--checkpoint_dir=/home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint']
[2024-06-29 19:23:34,003] [INFO] [launch.py:253:main] process 1319652 spawned with command: ['/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/bin/python', '-u', 'llava/train_parallel_deepspeed_mixtral_adapter.py', '--local_rank=2', '--num_stages=8', '--shared_adapter_num=4', '--shared_adapter_type=Parallel_Adapter', '--hidden_dim=32', '--save_model_shard=100', '--skip_shard=0', '--checkpoint_dir=/home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint']
[2024-06-29 19:23:34,015] [INFO] [launch.py:253:main] process 1319654 spawned with command: ['/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/bin/python', '-u', 'llava/train_parallel_deepspeed_mixtral_adapter.py', '--local_rank=3', '--num_stages=8', '--shared_adapter_num=4', '--shared_adapter_type=Parallel_Adapter', '--hidden_dim=32', '--save_model_shard=100', '--skip_shard=0', '--checkpoint_dir=/home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint']
[2024-06-29 19:23:34,028] [INFO] [launch.py:253:main] process 1319655 spawned with command: ['/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/bin/python', '-u', 'llava/train_parallel_deepspeed_mixtral_adapter.py', '--local_rank=4', '--num_stages=8', '--shared_adapter_num=4', '--shared_adapter_type=Parallel_Adapter', '--hidden_dim=32', '--save_model_shard=100', '--skip_shard=0', '--checkpoint_dir=/home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint']
[2024-06-29 19:23:34,037] [INFO] [launch.py:253:main] process 1319657 spawned with command: ['/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/bin/python', '-u', 'llava/train_parallel_deepspeed_mixtral_adapter.py', '--local_rank=5', '--num_stages=8', '--shared_adapter_num=4', '--shared_adapter_type=Parallel_Adapter', '--hidden_dim=32', '--save_model_shard=100', '--skip_shard=0', '--checkpoint_dir=/home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint']
[2024-06-29 19:23:34,044] [INFO] [launch.py:253:main] process 1319658 spawned with command: ['/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/bin/python', '-u', 'llava/train_parallel_deepspeed_mixtral_adapter.py', '--local_rank=6', '--num_stages=8', '--shared_adapter_num=4', '--shared_adapter_type=Parallel_Adapter', '--hidden_dim=32', '--save_model_shard=100', '--skip_shard=0', '--checkpoint_dir=/home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint']
[2024-06-29 19:23:34,055] [INFO] [launch.py:253:main] process 1319660 spawned with command: ['/home/hpc/b207dd/b207dd11/miniconda3/envs/py38/bin/python', '-u', 'llava/train_parallel_deepspeed_mixtral_adapter.py', '--local_rank=7', '--num_stages=8', '--shared_adapter_num=4', '--shared_adapter_type=Parallel_Adapter', '--hidden_dim=32', '--save_model_shard=100', '--skip_shard=0', '--checkpoint_dir=/home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint']
[2024-06-29 19:23:47,645] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-06-29 19:23:49,075] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-06-29 19:23:50,983] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-06-29 19:23:51,786] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-06-29 19:23:57,523] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-06-29 19:23:57,538] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-06-29 19:23:58,013] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-06-29 19:23:58,289] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-06-29 19:23:58,295] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-06-29 19:23:58,295] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-06-29 19:23:58,779] [INFO] [comm.py:637:init_distributed] cdb=None
Loading checkpoint shards:   0%|          | 0/20 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/20 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/20 [00:00<?, ?it/s]Loading checkpoint shards:   5%|▌         | 1/20 [00:00<00:13,  1.40it/s]Loading checkpoint shards:   0%|          | 0/20 [00:00<?, ?it/s]Loading checkpoint shards:   5%|▌         | 1/20 [00:00<00:17,  1.09it/s]Loading checkpoint shards:   5%|▌         | 1/20 [00:01<00:20,  1.10s/it]Loading checkpoint shards:   5%|▌         | 1/20 [00:01<00:21,  1.12s/it]Loading checkpoint shards:  10%|█         | 2/20 [00:02<00:19,  1.09s/it]Loading checkpoint shards:  10%|█         | 2/20 [00:02<00:19,  1.10s/it]Loading checkpoint shards:  10%|█         | 2/20 [00:02<00:19,  1.07s/it]Loading checkpoint shards:  15%|█▌        | 3/20 [00:03<00:18,  1.08s/it]Loading checkpoint shards:  10%|█         | 2/20 [00:02<00:21,  1.21s/it][2024-06-29 19:24:05,552] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Loading checkpoint shards:  15%|█▌        | 3/20 [00:03<00:18,  1.07s/it][2024-06-29 19:24:05,702] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Loading checkpoint shards:  15%|█▌        | 3/20 [00:03<00:19,  1.13s/it]Loading checkpoint shards:  20%|██        | 4/20 [00:04<00:16,  1.06s/it]Loading checkpoint shards:  15%|█▌        | 3/20 [00:03<00:20,  1.19s/it]Loading checkpoint shards:  20%|██        | 4/20 [00:04<00:16,  1.02s/it]Loading checkpoint shards:  20%|██        | 4/20 [00:04<00:18,  1.17s/it]Loading checkpoint shards:  25%|██▌       | 5/20 [00:05<00:15,  1.05s/it]Loading checkpoint shards:  20%|██        | 4/20 [00:04<00:18,  1.14s/it]Loading checkpoint shards:  25%|██▌       | 5/20 [00:05<00:14,  1.02it/s][2024-06-29 19:24:07,551] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-06-29 19:24:07,566] [INFO] [comm.py:637:init_distributed] cdb=None
Loading checkpoint shards:  30%|███       | 6/20 [00:06<00:14,  1.02s/it]Loading checkpoint shards:  25%|██▌       | 5/20 [00:05<00:17,  1.16s/it]Loading checkpoint shards:  30%|███       | 6/20 [00:06<00:15,  1.09s/it]Loading checkpoint shards:  25%|██▌       | 5/20 [00:05<00:18,  1.21s/it]Loading checkpoint shards:  35%|███▌      | 7/20 [00:07<00:13,  1.07s/it]Loading checkpoint shards:  30%|███       | 6/20 [00:07<00:19,  1.37s/it]Loading checkpoint shards:  30%|███       | 6/20 [00:07<00:19,  1.39s/it]Loading checkpoint shards:  35%|███▌      | 7/20 [00:08<00:17,  1.38s/it]Loading checkpoint shards:  40%|████      | 8/20 [00:08<00:14,  1.21s/it]Loading checkpoint shards:  35%|███▌      | 7/20 [00:09<00:18,  1.41s/it]Loading checkpoint shards:  35%|███▌      | 7/20 [00:08<00:17,  1.33s/it]Loading checkpoint shards:  40%|████      | 8/20 [00:09<00:15,  1.32s/it]Loading checkpoint shards:  40%|████      | 8/20 [00:10<00:15,  1.29s/it]Loading checkpoint shards:  45%|████▌     | 9/20 [00:10<00:14,  1.36s/it]Loading checkpoint shards:   0%|          | 0/20 [00:00<?, ?it/s]Loading checkpoint shards:  45%|████▌     | 9/20 [00:10<00:12,  1.17s/it]Loading checkpoint shards:   0%|          | 0/20 [00:00<?, ?it/s]Loading checkpoint shards:  40%|████      | 8/20 [00:10<00:15,  1.30s/it]Loading checkpoint shards:  45%|████▌     | 9/20 [00:11<00:14,  1.35s/it]Loading checkpoint shards:   5%|▌         | 1/20 [00:01<00:23,  1.26s/it]Loading checkpoint shards:  50%|█████     | 10/20 [00:12<00:13,  1.39s/it]Loading checkpoint shards:   5%|▌         | 1/20 [00:01<00:24,  1.30s/it]Loading checkpoint shards:  45%|████▌     | 9/20 [00:11<00:14,  1.29s/it]Loading checkpoint shards:  50%|█████     | 10/20 [00:12<00:14,  1.50s/it]Loading checkpoint shards:  10%|█         | 2/20 [00:02<00:23,  1.31s/it]Loading checkpoint shards:  10%|█         | 2/20 [00:02<00:23,  1.28s/it]Loading checkpoint shards:  55%|█████▌    | 11/20 [00:13<00:12,  1.40s/it]Loading checkpoint shards:  50%|█████     | 10/20 [00:13<00:13,  1.40s/it]Loading checkpoint shards:  50%|█████     | 10/20 [00:13<00:13,  1.39s/it]Loading checkpoint shards:  55%|█████▌    | 11/20 [00:14<00:13,  1.51s/it]Loading checkpoint shards:  55%|█████▌    | 11/20 [00:14<00:11,  1.33s/it]Loading checkpoint shards:  60%|██████    | 12/20 [00:14<00:10,  1.36s/it]Loading checkpoint shards:  15%|█▌        | 3/20 [00:04<00:23,  1.39s/it]Loading checkpoint shards:  55%|█████▌    | 11/20 [00:14<00:11,  1.32s/it]Loading checkpoint shards:  15%|█▌        | 3/20 [00:04<00:26,  1.58s/it]Loading checkpoint shards:  60%|██████    | 12/20 [00:15<00:11,  1.38s/it]Loading checkpoint shards:  65%|██████▌   | 13/20 [00:16<00:09,  1.41s/it]Loading checkpoint shards:  60%|██████    | 12/20 [00:15<00:12,  1.57s/it]Loading checkpoint shards:  20%|██        | 4/20 [00:05<00:23,  1.45s/it]Loading checkpoint shards:  60%|██████    | 12/20 [00:16<00:12,  1.54s/it]Loading checkpoint shards:  20%|██        | 4/20 [00:06<00:27,  1.75s/it]Loading checkpoint shards:  65%|██████▌   | 13/20 [00:16<00:09,  1.32s/it]Loading checkpoint shards:  70%|███████   | 14/20 [00:17<00:08,  1.47s/it]Loading checkpoint shards:  65%|██████▌   | 13/20 [00:17<00:11,  1.61s/it]Loading checkpoint shards:  25%|██▌       | 5/20 [00:07<00:22,  1.50s/it]Loading checkpoint shards:  70%|███████   | 14/20 [00:18<00:08,  1.33s/it]Loading checkpoint shards:  25%|██▌       | 5/20 [00:08<00:25,  1.69s/it]Loading checkpoint shards:  65%|██████▌   | 13/20 [00:18<00:11,  1.67s/it]Loading checkpoint shards:  75%|███████▌  | 15/20 [00:19<00:07,  1.43s/it]Loading checkpoint shards:  30%|███       | 6/20 [00:08<00:20,  1.48s/it]Loading checkpoint shards:  70%|███████   | 14/20 [00:19<00:09,  1.63s/it]Loading checkpoint shards:  75%|███████▌  | 15/20 [00:20<00:07,  1.47s/it]Loading checkpoint shards:  30%|███       | 6/20 [00:09<00:24,  1.71s/it]Loading checkpoint shards:  75%|███████▌  | 15/20 [00:20<00:07,  1.51s/it]Loading checkpoint shards:  70%|███████   | 14/20 [00:20<00:10,  1.75s/it]Loading checkpoint shards:  35%|███▌      | 7/20 [00:10<00:22,  1.71s/it]Loading checkpoint shards:  80%|████████  | 16/20 [00:21<00:07,  1.78s/it]Loading checkpoint shards:  80%|████████  | 16/20 [00:21<00:05,  1.48s/it]Loading checkpoint shards:  80%|████████  | 16/20 [00:21<00:05,  1.47s/it]Loading checkpoint shards:  75%|███████▌  | 15/20 [00:21<00:08,  1.63s/it]Loading checkpoint shards:  35%|███▌      | 7/20 [00:11<00:23,  1.83s/it]Loading checkpoint shards:  85%|████████▌ | 17/20 [00:22<00:04,  1.42s/it]Loading checkpoint shards:  40%|████      | 8/20 [00:12<00:21,  1.75s/it][2024-06-29 19:24:25,457] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Loading checkpoint shards:  85%|████████▌ | 17/20 [00:23<00:05,  1.80s/it]Loading checkpoint shards:  80%|████████  | 16/20 [00:22<00:06,  1.55s/it]Loading checkpoint shards:  85%|████████▌ | 17/20 [00:23<00:04,  1.47s/it]Loading checkpoint shards:  40%|████      | 8/20 [00:13<00:22,  1.84s/it]Loading checkpoint shards:  90%|█████████ | 18/20 [00:24<00:02,  1.43s/it]Loading checkpoint shards:  45%|████▌     | 9/20 [00:14<00:18,  1.65s/it]Loading checkpoint shards:  85%|████████▌ | 17/20 [00:24<00:04,  1.46s/it]Loading checkpoint shards:  90%|█████████ | 18/20 [00:24<00:02,  1.39s/it]Loading checkpoint shards:  90%|█████████ | 18/20 [00:25<00:03,  1.72s/it][2024-06-29 19:24:27,368] [INFO] [comm.py:637:init_distributed] cdb=None
Loading checkpoint shards:  95%|█████████▌| 19/20 [00:25<00:01,  1.36s/it]Loading checkpoint shards: 100%|██████████| 20/20 [00:26<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 20/20 [00:26<00:00,  1.30s/it]
Some weights of LlavaForConditionalGeneration were not initialized from the model checkpoint at /home/vault/b207dd/b207dd11/llava-mixtral/llava-mixtral-pretrained-2/ and are newly initialized: ['language_model.model.layers.0.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Loading checkpoint shards:  95%|█████████▌| 19/20 [00:26<00:01,  1.47s/it]Loading checkpoint shards:  90%|█████████ | 18/20 [00:25<00:03,  1.52s/it] ######################### trying init params ######################### 
language_model.model.layers.0.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.0.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.0.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Loading checkpoint shards:  50%|█████     | 10/20 [00:15<00:17,  1.72s/it]Initialized adapter matrices for language_model.model.layers.0.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.0.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.0.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.0.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.0.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.1.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.1.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.1.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Loading checkpoint shards:  95%|█████████▌| 19/20 [00:26<00:01,  1.72s/it]Initialized adapter matrices for language_model.model.layers.1.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.1.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.1.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.1.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.1.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.2.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.2.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.2.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Loading checkpoint shards:  45%|████▌     | 9/20 [00:16<00:22,  2.01s/it]Initialized adapter matrices for language_model.model.layers.2.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.2.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.2.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.2.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.2.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.3.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.3.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.3.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.3.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.3.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.3.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.3.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.3.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.4.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Loading checkpoint shards: 100%|██████████| 20/20 [00:26<00:00,  1.22s/it]Loading checkpoint shards: 100%|██████████| 20/20 [00:26<00:00,  1.34s/it]
Some weights of LlavaForConditionalGeneration were not initialized from the model checkpoint at /home/vault/b207dd/b207dd11/llava-mixtral/llava-mixtral-pretrained-2/ and are newly initialized: ['language_model.model.layers.0.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Initialized adapter matrices for language_model.model.layers.4.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.4.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.4.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.4.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.4.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.4.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.4.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.5.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.5.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.5.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.5.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.5.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.5.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.5.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.5.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.6.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.6.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.6.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.6.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.6.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.6.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.6.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.6.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.7.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.7.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.7.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
 ######################### trying init params ######################### 
language_model.model.layers.0.block_sparse_moe.shared_adapter.0.unitInitialized adapter matrices for language_model.model.layers.7.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.7.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
 MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.7.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.7.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.7.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.8.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.8.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.8.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.8.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.8.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.8.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.8.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.8.block_sparse_moe.shared_adapter.3.unit
Initialized adapter matrices for language_model.model.layers.0.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.0.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
language_model.model.layers.9.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.9.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.9.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.9.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.9.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.0.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.0.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.9.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.9.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.9.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.10.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.0.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.0.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.10.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.10.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.0.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.1.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.10.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.10.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.10.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.10.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.1.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.1.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.10.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.11.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.1.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.1.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.11.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.11.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.1.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.1.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.11.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.11.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.11.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.11.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.1.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.2.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.11.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.12.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.2.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.2.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.12.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.12.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.2.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.2.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.12.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.12.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.12.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.12.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.2.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.2.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.12.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.13.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.2.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.3.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.13.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.13.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.3.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.3.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.13.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.13.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.3.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.3.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.13.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.13.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.3.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.3.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.13.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.14.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.3.block_sparse_moe.shared_adapter.3.unit
Initialized adapter matrices for language_model.model.layers.14.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.14.block_sparse_moe.shared_adapter.1.unit language_model.model.layers.4.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)

Initialized adapter matrices for language_model.model.layers.14.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.14.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.4.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.4.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.14.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.14.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.14.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.15.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.4.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.4.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.15.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.15.block_sparse_moe.shared_adapter.1.unitInitialized adapter matrices for language_model.model.layers.4.block_sparse_moe.shared_adapter.2.unit
 language_model.model.layers.4.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)

Initialized adapter matrices for language_model.model.layers.4.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.5.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.15.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.15.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.5.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.5.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.15.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.15.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.5.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.5.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.15.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.16.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.5.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.5.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.16.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.16.block_sparse_moe.shared_adapter.1.unitInitialized adapter matrices for language_model.model.layers.5.block_sparse_moe.shared_adapter.3.unit
 MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
language_model.model.layers.6.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.6.block_sparse_moe.shared_adapter.0.unitInitialized adapter matrices for language_model.model.layers.16.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.6.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.16.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
) MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)

Initialized adapter matrices for language_model.model.layers.16.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.16.block_sparse_moe.shared_adapter.3.unitInitialized adapter matrices for language_model.model.layers.6.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)

language_model.model.layers.6.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.16.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.17.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.6.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.6.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.17.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.17.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.6.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.7.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.17.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.17.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.7.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.7.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.17.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.17.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.7.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.7.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.17.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.18.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.7.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.7.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.18.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.18.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.7.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.8.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.18.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.18.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.18.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.18.block_sparse_moe.shared_adapter.3.unitInitialized adapter matrices for language_model.model.layers.8.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)

language_model.model.layers.8.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Loading checkpoint shards: 100%|██████████| 20/20 [00:28<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 20/20 [00:28<00:00,  1.41s/it]
Some weights of LlavaForConditionalGeneration were not initialized from the model checkpoint at /home/vault/b207dd/b207dd11/llava-mixtral/llava-mixtral-pretrained-2/ and are newly initialized: ['language_model.model.layers.0.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Initialized adapter matrices for language_model.model.layers.8.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.8.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.18.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.19.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.8.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.8.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.19.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.19.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.19.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.19.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.8.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.9.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.19.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.19.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.19.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.20.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.9.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.9.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.20.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.20.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.9.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.9.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.20.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.20.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.9.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.9.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.20.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.20.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.20.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.21.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.9.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.10.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.21.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.21.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
 ######################### trying init params ######################### Initialized adapter matrices for language_model.model.layers.10.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.10.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)

language_model.model.layers.0.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.10.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.10.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.21.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.21.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.21.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.21.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.21.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.22.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.22.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.22.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.10.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.10.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.22.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.22.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.22.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.22.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.22.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.23.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.10.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.11.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.23.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.23.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.0.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.0.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.11.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.11.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.23.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.23.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.11.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.11.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.23.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.23.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.11.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.11.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.23.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.24.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.11.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.12.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.24.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.24.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.0.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.0.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.12.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.12.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.24.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.24.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.12.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.12.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.24.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.24.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.12.block_sparse_moe.shared_adapter.2.unitInitialized adapter matrices for language_model.model.layers.24.block_sparse_moe.shared_adapter.3.unit

language_model.model.layers.12.block_sparse_moe.shared_adapter.3.unitlanguage_model.model.layers.25.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
 MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.0.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.0.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.25.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.25.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.25.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.25.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.25.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.25.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.12.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.13.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.25.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.26.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.0.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.1.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.26.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.26.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.26.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.26.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.13.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.13.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.26.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.26.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.26.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.27.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.13.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.13.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.1.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.1.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.27.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.27.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.13.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.13.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.27.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.27.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.27.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.27.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.27.block_sparse_moe.shared_adapter.3.unit
Initialized adapter matrices for language_model.model.layers.13.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.28.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
language_model.model.layers.14.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.28.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.28.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.1.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.1.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.14.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.14.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.28.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.28.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.28.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.28.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.14.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.14.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.28.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.29.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.14.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.14.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.29.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.29.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.1.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.1.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.29.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.29.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.14.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.15.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.29.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.29.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.29.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.30.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.15.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.15.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.1.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.2.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.30.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.30.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.30.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.30.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Loading checkpoint shards:  95%|█████████▌| 19/20 [00:27<00:01,  1.73s/it]Initialized adapter matrices for language_model.model.layers.30.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.30.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.15.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.15.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.30.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.31.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.2.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.2.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.2.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.2.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.15.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.15.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.2.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.2.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.31.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.31.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.31.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.31.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.15.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.16.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.31.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.31.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.2.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.3.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.31.block_sparse_moe.shared_adapter.3.unit
Initialized adapter matrices for language_model.model.layers.16.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.16.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.3.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.3.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Convert trainable params: 33554432 || all params: 47060850688 || trainable%: 0.07
Initialized adapter matrices for language_model.model.layers.3.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.3.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.16.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.16.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.3.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.3.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.16.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.16.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Print trainable params: 54534144 || all params: 47060850688 || trainable%: 0.12
Initialized adapter matrices for language_model.model.layers.16.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.17.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.3.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.4.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.17.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.17.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.4.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.4.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.17.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.17.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.4.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.4.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.17.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.17.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.17.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.18.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.18.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.18.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.4.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.4.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.18.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.18.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.4.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.5.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.18.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.18.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.18.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.19.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.5.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.5.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.19.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.19.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.19.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.19.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Loading checkpoint shards:  55%|█████▌    | 11/20 [00:18<00:17,  1.92s/it]Initialized adapter matrices for language_model.model.layers.19.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.19.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.5.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.5.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.19.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.20.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.20.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.20.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.5.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.5.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.20.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.20.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.5.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.6.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.20.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.20.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.20.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.21.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Loading checkpoint shards:  50%|█████     | 10/20 [00:18<00:20,  2.10s/it]Initialized adapter matrices for language_model.model.layers.6.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.6.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.21.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.21.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.6.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.6.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.6.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.6.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.6.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.7.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.7.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.7.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.7.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.7.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.7.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.7.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.21.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.21.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.7.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.8.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.21.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.21.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.8.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.8.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.21.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.22.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.8.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.8.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.22.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.22.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.8.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.8.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.22.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.22.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.8.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.9.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.22.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.22.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.9.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.9.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.22.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.23.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.9.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.9.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.23.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.23.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.23.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.23.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.9.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.9.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.23.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.23.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.9.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.10.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.23.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.24.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.10.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.10.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.24.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.24.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.10.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.10.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.10.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.10.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.24.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.24.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.24.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.24.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.10.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.11.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.24.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.25.block_sparse_moe.shared_adapter.0.unitInitialized adapter matrices for language_model.model.layers.11.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.11.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
 MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.25.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.25.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.11.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.11.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.25.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.25.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.25.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.25.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.11.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.11.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.25.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.26.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.26.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.26.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.11.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.12.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.26.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.26.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.26.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.26.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.12.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.12.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.26.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.27.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.12.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.12.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.27.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.27.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.27.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.27.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.12.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.12.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Loading checkpoint shards: 100%|██████████| 20/20 [00:29<00:00,  1.57s/it]Initialized adapter matrices for language_model.model.layers.27.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.27.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)Loading checkpoint shards: 100%|██████████| 20/20 [00:29<00:00,  1.46s/it]

Some weights of LlavaForConditionalGeneration were not initialized from the model checkpoint at /home/vault/b207dd/b207dd11/llava-mixtral/llava-mixtral-pretrained-2/ and are newly initialized: ['language_model.model.layers.0.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Initialized adapter matrices for language_model.model.layers.27.block_sparse_moe.shared_adapter.3.unit
Initialized adapter matrices for language_model.model.layers.12.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.28.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
language_model.model.layers.13.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.28.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.28.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.13.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.13.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.28.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.28.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.28.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.28.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.13.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.13.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.28.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.29.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.29.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.29.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.13.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.13.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.29.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.29.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.29.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.29.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.29.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.30.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.13.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.14.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.30.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.30.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.30.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.30.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.30.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.30.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.14.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.14.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.30.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.31.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.31.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.31.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.14.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.14.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.31.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.31.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.31.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.31.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.14.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.14.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.31.block_sparse_moe.shared_adapter.3.unit
Initialized adapter matrices for language_model.model.layers.14.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.15.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Convert trainable params: 33554432 || all params: 47060850688 || trainable%: 0.07
Initialized adapter matrices for language_model.model.layers.15.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.15.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Print trainable params: 54534144 || all params: 47060850688 || trainable%: 0.12
 ######################### trying init params ######################### 
language_model.model.layers.0.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.15.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.15.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.0.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.0.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.0.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.0.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.15.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.15.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.0.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.0.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.0.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.1.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.15.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.16.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.1.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.1.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.1.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.1.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.1.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.1.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.1.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.2.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.16.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.16.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.2.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.2.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.2.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.2.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.2.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.2.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.2.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.3.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.3.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.3.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.16.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.16.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.3.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.3.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.3.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.3.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.3.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.4.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.4.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.4.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.4.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.4.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.16.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.16.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.4.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.4.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.4.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.5.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.16.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.17.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.5.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.5.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.5.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.5.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.5.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.5.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.5.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.6.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.17.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.17.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.6.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.6.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.6.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.6.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.17.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.17.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.17.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.17.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.6.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.6.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.6.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.7.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.7.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.7.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.7.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.7.block_sparse_moe.shared_adapter.2.unitInitialized adapter matrices for language_model.model.layers.17.block_sparse_moe.shared_adapter.3.unit
 MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
language_model.model.layers.18.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.7.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.7.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.7.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.8.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.18.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.18.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.8.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.8.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.8.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.8.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.8.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.8.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.18.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.18.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.8.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.9.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.9.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.9.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.9.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.9.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.9.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.9.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.9.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.10.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.18.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.18.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.10.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.10.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.10.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.10.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.10.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.10.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.18.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.19.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.10.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.11.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.11.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.11.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.11.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.11.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.11.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.11.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.19.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.19.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.11.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.12.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Loading checkpoint shards:  55%|█████▌    | 11/20 [00:19<00:16,  1.88s/it]Initialized adapter matrices for language_model.model.layers.12.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.12.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Loading checkpoint shards:  60%|██████    | 12/20 [00:19<00:14,  1.82s/it]Initialized adapter matrices for language_model.model.layers.19.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.19.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.12.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.12.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.12.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.12.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.12.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.13.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.13.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.13.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.13.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.13.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.13.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.13.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)Initialized adapter matrices for language_model.model.layers.19.block_sparse_moe.shared_adapter.2.unit

language_model.model.layers.19.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.13.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.14.block_sparse_moe.shared_adapter.0.unitInitialized adapter matrices for language_model.model.layers.19.block_sparse_moe.shared_adapter.3.unit
 MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)language_model.model.layers.20.block_sparse_moe.shared_adapter.0.unit
 MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.14.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.14.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.20.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.20.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.20.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.20.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.14.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.14.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.20.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.20.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.14.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.14.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.20.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.21.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.21.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.21.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.14.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.15.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.21.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.21.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.15.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.15.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.21.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.21.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.21.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.22.block_sparse_moe.shared_adapter.0.unitInitialized adapter matrices for language_model.model.layers.15.block_sparse_moe.shared_adapter.1.unit 
language_model.model.layers.15.block_sparse_moe.shared_adapter.2.unitMixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
 MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.15.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.15.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.22.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.22.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.15.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.16.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.22.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.22.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.22.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.22.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.22.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.23.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.16.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.16.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.23.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.23.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.23.block_sparse_moe.shared_adapter.1.unitInitialized adapter matrices for language_model.model.layers.16.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.16.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)

language_model.model.layers.23.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.23.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.23.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.16.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.16.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.23.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.24.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.24.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.24.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.16.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.17.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.24.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.24.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.24.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.24.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.17.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.17.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.24.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.25.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.25.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.25.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.17.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.17.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.25.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.25.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.17.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.17.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.25.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.25.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.17.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.18.block_sparse_moe.shared_adapter.0.unitInitialized adapter matrices for language_model.model.layers.25.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.26.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
 MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.18.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.18.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.26.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.26.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.18.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.18.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.26.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.26.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.18.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.18.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.26.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.26.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.18.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.19.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.26.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.27.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.19.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.19.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.27.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.27.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.19.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.19.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.27.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.27.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.19.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.19.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.27.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.27.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.19.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.20.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.27.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.28.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.20.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.20.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.28.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.28.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.20.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.20.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.28.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.28.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.20.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.20.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.28.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.28.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.20.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.21.block_sparse_moe.shared_adapter.0.unitInitialized adapter matrices for language_model.model.layers.28.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.29.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
 MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.29.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.29.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.21.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.21.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.29.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.29.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.21.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.21.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.29.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.29.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.29.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.30.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.21.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.21.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.30.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.30.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.21.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.22.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.30.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.30.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.22.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.22.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.30.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.30.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.30.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.31.block_sparse_moe.shared_adapter.0.unitInitialized adapter matrices for language_model.model.layers.22.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.22.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
) MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)

Initialized adapter matrices for language_model.model.layers.31.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.31.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.22.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.22.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.31.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.31.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.22.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.23.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.23.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.23.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.31.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.31.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.23.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.23.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.23.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.23.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.31.block_sparse_moe.shared_adapter.3.unit
Initialized adapter matrices for language_model.model.layers.23.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.24.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.24.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.24.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.24.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.24.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.24.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.24.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.24.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.25.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Convert trainable params: 33554432 || all params: 47060850688 || trainable%: 0.07
Initialized adapter matrices for language_model.model.layers.25.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.25.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.25.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.25.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.25.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.25.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.25.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.26.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.26.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.26.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Print trainable params: 54534144 || all params: 47060850688 || trainable%: 0.12
Initialized adapter matrices for language_model.model.layers.26.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.26.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.26.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.26.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.26.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.27.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.27.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.27.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.27.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.27.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.27.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.27.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.27.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.28.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.28.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.28.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.28.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.28.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.28.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.28.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.28.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.29.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.29.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.29.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.29.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.29.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.29.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.29.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.29.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.30.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.30.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.30.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.30.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.30.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.30.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.30.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.30.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.31.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.31.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.31.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.31.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.31.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.31.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.31.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.31.block_sparse_moe.shared_adapter.3.unit
Convert trainable params: 33554432 || all params: 47060850688 || trainable%: 0.07
Loading checkpoint shards:  60%|██████    | 12/20 [00:21<00:13,  1.66s/it]Print trainable params: 54534144 || all params: 47060850688 || trainable%: 0.12
Loading checkpoint shards:   0%|          | 0/20 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/20 [00:00<?, ?it/s]Loading checkpoint shards:  65%|██████▌   | 13/20 [00:21<00:11,  1.68s/it]Loading checkpoint shards:   5%|▌         | 1/20 [00:00<00:18,  1.02it/s]Loading checkpoint shards:   5%|▌         | 1/20 [00:01<00:20,  1.09s/it]Loading checkpoint shards:  65%|██████▌   | 13/20 [00:22<00:11,  1.63s/it]Loading checkpoint shards:  70%|███████   | 14/20 [00:22<00:10,  1.68s/it]Loading checkpoint shards:  10%|█         | 2/20 [00:02<00:18,  1.03s/it]Loading checkpoint shards:  10%|█         | 2/20 [00:02<00:20,  1.13s/it]Loading checkpoint shards:  15%|█▌        | 3/20 [00:03<00:17,  1.01s/it]Loading checkpoint shards:  15%|█▌        | 3/20 [00:03<00:16,  1.04it/s]Loading checkpoint shards:  70%|███████   | 14/20 [00:24<00:09,  1.65s/it]Loading checkpoint shards:  75%|███████▌  | 15/20 [00:24<00:08,  1.65s/it]Rank 1 initialized with CUDA_MEM (60881108992, 85100068864)
Deepspeed engine initializing at --- RANK 1 --- ...
Loading checkpoint shards:  20%|██        | 4/20 [00:04<00:17,  1.06s/it]Loading checkpoint shards:  20%|██        | 4/20 [00:04<00:16,  1.00s/it]Loading checkpoint shards:  80%|████████  | 16/20 [00:25<00:06,  1.52s/it]Loading checkpoint shards:  75%|███████▌  | 15/20 [00:25<00:08,  1.67s/it]Loading checkpoint shards:  25%|██▌       | 5/20 [00:05<00:14,  1.02it/s]Loading checkpoint shards:  25%|██▌       | 5/20 [00:05<00:15,  1.02s/it]Loading checkpoint shards:  30%|███       | 6/20 [00:05<00:12,  1.10it/s]Loading checkpoint shards:  30%|███       | 6/20 [00:06<00:14,  1.02s/it]Loading checkpoint shards:  85%|████████▌ | 17/20 [00:27<00:04,  1.49s/it]Loading checkpoint shards:  80%|████████  | 16/20 [00:27<00:06,  1.62s/it]Loading checkpoint shards:  35%|███▌      | 7/20 [00:06<00:12,  1.07it/s]Rank 7 initialized with CUDA_MEM (60354723840, 85100068864)
Deepspeed engine initializing at --- RANK 7 --- ...
Loading checkpoint shards:  35%|███▌      | 7/20 [00:07<00:13,  1.05s/it]Loading checkpoint shards:  90%|█████████ | 18/20 [00:28<00:02,  1.43s/it]Using /home/hpc/b207dd/b207dd11/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Loading checkpoint shards:  85%|████████▌ | 17/20 [00:28<00:04,  1.52s/it]Loading checkpoint shards:  40%|████      | 8/20 [00:07<00:11,  1.03it/s]Rank 2 initialized with CUDA_MEM (60881108992, 85100068864)
Deepspeed engine initializing at --- RANK 2 --- ...
Loading checkpoint shards:  40%|████      | 8/20 [00:08<00:12,  1.05s/it]Loading checkpoint shards:  95%|█████████▌| 19/20 [00:29<00:01,  1.35s/it]Loading checkpoint shards:  90%|█████████ | 18/20 [00:29<00:02,  1.38s/it]Loading checkpoint shards:  45%|████▌     | 9/20 [00:08<00:10,  1.03it/s]Loading checkpoint shards: 100%|██████████| 20/20 [00:30<00:00,  1.10s/it]Loading checkpoint shards: 100%|██████████| 20/20 [00:30<00:00,  1.51s/it]
Some weights of LlavaForConditionalGeneration were not initialized from the model checkpoint at /home/vault/b207dd/b207dd11/llava-mixtral/llava-mixtral-pretrained-2/ and are newly initialized: ['language_model.model.layers.0.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using /home/hpc/b207dd/b207dd11/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
 ######################### trying init params ######################### 
language_model.model.layers.0.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.0.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.0.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.0.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.0.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.0.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.0.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.0.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.1.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.1.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.1.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.1.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.1.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Detected CUDA files, patching ldflags
Emitting ninja build file /home/hpc/b207dd/b207dd11/.cache/torch_extensions/py38_cu121/fused_adam/build.ninja...
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Initialized adapter matrices for language_model.model.layers.1.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.1.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.1.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.2.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.2.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.2.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.2.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.2.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Loading checkpoint shards:  45%|████▌     | 9/20 [00:09<00:11,  1.06s/it]Initialized adapter matrices for language_model.model.layers.2.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.2.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.2.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.3.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.3.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.3.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.3.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.3.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.3.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.3.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.3.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.4.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.4.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.4.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.4.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.4.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.4.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.4.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.4.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.5.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.5.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.5.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.5.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.5.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.5.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.5.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.5.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.6.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.6.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.6.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.6.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.6.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.6.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.6.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.6.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.7.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.7.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.7.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.7.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.7.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.7.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.7.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.7.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.8.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.8.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.8.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.8.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.8.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.8.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.8.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.8.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.9.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.9.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.9.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.9.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.9.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.9.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.9.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.9.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.10.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.10.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.10.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.10.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.10.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.10.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.10.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
RankInitialized adapter matrices for language_model.model.layers.10.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.11.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
 4 initialized with CUDA_MEM (60881108992, 85100068864)
Initialized adapter matrices for language_model.model.layers.11.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.11.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.11.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.11.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.11.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.11.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)Deepspeed engine initializing at --- RANK 4 --- ...

Initialized adapter matrices for language_model.model.layers.11.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.12.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.12.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.12.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.12.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.12.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.12.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.12.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.12.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.13.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.13.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.13.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.13.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.13.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.13.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.13.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.13.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.14.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.14.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.14.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.14.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.14.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.14.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.14.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.14.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.15.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.15.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.15.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.15.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.15.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.15.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.15.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.15.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.16.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.16.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.16.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.16.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.16.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.16.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.16.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.16.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.17.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.17.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.17.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.17.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.17.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.17.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.17.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.17.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.18.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.18.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.18.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.18.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.18.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.18.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.18.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Loading checkpoint shards:  95%|█████████▌| 19/20 [00:30<00:01,  1.30s/it]Initialized adapter matrices for language_model.model.layers.18.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.19.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Loading checkpoint shards:  50%|█████     | 10/20 [00:09<00:09,  1.05it/s]Initialized adapter matrices for language_model.model.layers.19.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.19.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.19.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.19.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.19.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.19.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.19.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.20.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.20.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.20.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.20.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.20.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.20.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.20.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.20.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.21.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.21.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.21.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.21.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.21.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.21.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.21.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.21.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.22.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.22.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.22.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.22.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.22.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.22.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.22.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.22.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.23.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Loading checkpoint shards: 100%|██████████| 20/20 [00:31<00:00,  1.02it/s]Loading checkpoint shards: 100%|██████████| 20/20 [00:31<00:00,  1.56s/it]
Some weights of LlavaForConditionalGeneration were not initialized from the model checkpoint at /home/vault/b207dd/b207dd11/llava-mixtral/llava-mixtral-pretrained-2/ and are newly initialized: ['language_model.model.layers.0.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Initialized adapter matrices for language_model.model.layers.23.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.23.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.23.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.23.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.23.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.23.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.23.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.24.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.24.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.24.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.24.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.24.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.24.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.24.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.24.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.25.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.25.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.25.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
 ######################### trying init params ######################### 
language_model.model.layers.0.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.25.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.25.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.0.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.0.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.25.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.25.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.0.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.0.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.25.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.26.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.26.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.26.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.0.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.0.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.0.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.1.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.26.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.26.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.1.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.1.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.26.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.26.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.26.block_sparse_moe.shared_adapter.3.unit
Initialized adapter matrices for language_model.model.layers.1.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.1.block_sparse_moe.shared_adapter.2.unitlanguage_model.model.layers.27.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
 MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.1.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.1.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.27.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.27.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Loading checkpoint shards:  50%|█████     | 10/20 [00:10<00:10,  1.03s/it]Initialized adapter matrices for language_model.model.layers.1.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.2.block_sparse_moe.shared_adapter.0.unitInitialized adapter matrices for language_model.model.layers.27.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.27.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
 MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.2.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.2.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.27.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.27.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.2.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.2.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.27.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.28.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.2.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.2.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.28.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.28.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.2.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.3.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)Initialized adapter matrices for language_model.model.layers.28.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.28.block_sparse_moe.shared_adapter.2.unit
 MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.28.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.28.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.3.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.3.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.28.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.29.block_sparse_moe.shared_adapter.0.unitInitialized adapter matrices for language_model.model.layers.3.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.3.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
 MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.29.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.29.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.3.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.3.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.3.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.4.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.29.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.29.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.4.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.4.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.29.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.29.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.29.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.30.block_sparse_moe.shared_adapter.0.unitInitialized adapter matrices for language_model.model.layers.4.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.4.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
 MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.30.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.30.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.4.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.4.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.30.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.30.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.4.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.5.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.30.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.30.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.5.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.5.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.30.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.31.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.5.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.5.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.31.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.31.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.31.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.31.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.5.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.5.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.31.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.31.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.5.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.6.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.31.block_sparse_moe.shared_adapter.3.unit
Initialized adapter matrices for language_model.model.layers.6.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.6.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.6.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.6.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.6.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.6.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Convert trainable params: 33554432 || all params: 47060850688 || trainable%: 0.07
Initialized adapter matrices for language_model.model.layers.6.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.7.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.7.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.7.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Print trainable params: 54534144 || all params: 47060850688 || trainable%: 0.12Initialized adapter matrices for language_model.model.layers.7.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.7.block_sparse_moe.shared_adapter.2.unit
 MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.7.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.7.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.7.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.8.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.8.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.8.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.8.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.8.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.8.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.8.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.8.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.9.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.9.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.9.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.9.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.9.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.9.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.9.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.9.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.10.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.10.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.10.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.10.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.10.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.10.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.10.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.10.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.11.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.11.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.11.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.11.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.11.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.11.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.11.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.11.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.12.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.12.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.12.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.12.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.12.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.12.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.12.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.12.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.13.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.13.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.13.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.13.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.13.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.13.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.13.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.13.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.14.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.14.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.14.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.14.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.14.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.14.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.14.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.14.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.15.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.15.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.15.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.15.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.15.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.15.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.15.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.15.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.16.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.16.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.16.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.16.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.16.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.16.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.16.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.16.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.17.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.17.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.17.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.17.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.17.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.17.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.17.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.17.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.18.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.18.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.18.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Loading checkpoint shards:  55%|█████▌    | 11/20 [00:10<00:08,  1.00it/s]Initialized adapter matrices for language_model.model.layers.18.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.18.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.18.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.18.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.18.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.19.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.19.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.19.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.19.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.19.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.19.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.19.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.19.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.20.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.20.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.20.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.20.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.20.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.20.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.20.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.20.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.21.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.21.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.21.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.21.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.21.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.21.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.21.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.21.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.22.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.22.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.22.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.22.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.22.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.22.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.22.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.22.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.23.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.23.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.23.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.23.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.23.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.23.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.23.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Using /home/hpc/b207dd/b207dd11/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...Initialized adapter matrices for language_model.model.layers.23.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.24.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)

Initialized adapter matrices for language_model.model.layers.24.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.24.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.24.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.24.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.24.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.24.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
ninja: no work to do.
Initialized adapter matrices for language_model.model.layers.24.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.25.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Loading extension module fused_adam...
Initialized adapter matrices for language_model.model.layers.25.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.25.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.25.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.25.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.25.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.25.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.25.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.26.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.26.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.26.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.26.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.26.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.26.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.26.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.26.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.27.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.27.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.27.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Loading extension module fused_adam...
Initialized adapter matrices for language_model.model.layers.27.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.27.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.27.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.27.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Time to load fused_adam op: 2.126713275909424 seconds
Time to load fused_adam op: 3.6982617378234863 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 0.10506963729858398 seconds
[2024-06-29 19:24:45,144] [INFO] [engine.py:141:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[2024-06-29 19:24:45,144] [INFO] [engine.py:141:__init__] is_pipe_partitioned= False is_grad_partitioned= False
Initialized adapter matrices for language_model.model.layers.27.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.28.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
[2024-06-29 19:24:45,152] [INFO] [engine.py:141:__init__] is_pipe_partitioned= False is_grad_partitioned= False
Initialized adapter matrices for language_model.model.layers.28.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.28.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.28.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.28.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.28.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.28.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.28.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.29.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.29.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.29.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.29.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.29.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Loading checkpoint shards:  55%|█████▌    | 11/20 [00:11<00:09,  1.03s/it]Initialized adapter matrices for language_model.model.layers.29.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.29.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.29.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.30.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.30.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.30.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.30.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.30.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.30.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.30.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.30.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.31.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.31.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.31.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.31.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.31.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.31.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.31.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.31.block_sparse_moe.shared_adapter.3.unit
Convert trainable params: 33554432 || all params: 47060850688 || trainable%: 0.07
Print trainable params: 54534144 || all params: 47060850688 || trainable%: 0.12
Using /home/hpc/b207dd/b207dd11/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Loading checkpoint shards:  60%|██████    | 12/20 [00:11<00:07,  1.05it/s]Loading checkpoint shards:  60%|██████    | 12/20 [00:12<00:07,  1.04it/s]Loading checkpoint shards:  65%|██████▌   | 13/20 [00:12<00:05,  1.18it/s]Loading checkpoint shards:  65%|██████▌   | 13/20 [00:12<00:06,  1.15it/s]Detected CUDA files, patching ldflags
Emitting ninja build file /home/hpc/b207dd/b207dd11/.cache/torch_extensions/py38_cu121/fused_adam/build.ninja...
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading checkpoint shards:  70%|███████   | 14/20 [00:12<00:04,  1.30it/s]Loading checkpoint shards:  70%|███████   | 14/20 [00:13<00:04,  1.27it/s]Loading checkpoint shards:  75%|███████▌  | 15/20 [00:13<00:03,  1.32it/s]ninja: no work to do.
Loading extension module fused_adam...
Time to load fused_adam op: 2.2509515285491943 seconds
[2024-06-29 19:24:47,660] [INFO] [engine.py:141:__init__] is_pipe_partitioned= False is_grad_partitioned= False
Loading checkpoint shards:  75%|███████▌  | 15/20 [00:13<00:03,  1.40it/s]Loading checkpoint shards:  80%|████████  | 16/20 [00:14<00:02,  1.36it/s]Loading checkpoint shards:  80%|████████  | 16/20 [00:14<00:02,  1.51it/s]Loading checkpoint shards:  85%|████████▌ | 17/20 [00:14<00:02,  1.41it/s]Loading checkpoint shards:  85%|████████▌ | 17/20 [00:15<00:01,  1.52it/s]Loading checkpoint shards:  90%|█████████ | 18/20 [00:15<00:01,  1.53it/s]Loading checkpoint shards:  90%|█████████ | 18/20 [00:15<00:01,  1.36it/s]Rank 6 initialized with CUDA_MEM (60881108992, 85100068864)
Deepspeed engine initializing at --- RANK 6 --- ...
Loading checkpoint shards:  95%|█████████▌| 19/20 [00:16<00:00,  1.52it/s]Loading checkpoint shards:  95%|█████████▌| 19/20 [00:16<00:00,  1.52it/s]Loading checkpoint shards: 100%|██████████| 20/20 [00:16<00:00,  1.97it/s]Loading checkpoint shards: 100%|██████████| 20/20 [00:16<00:00,  1.22it/s]
Some weights of LlavaForConditionalGeneration were not initialized from the model checkpoint at /home/vault/b207dd/b207dd11/llava-mixtral/llava-mixtral-pretrained-2/ and are newly initialized: ['language_model.model.layers.0.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Rank 5 initialized with CUDA_MEM (60881108992, 85100068864)
Deepspeed engine initializing at --- RANK 5 --- ...
 ######################### trying init params ######################### 
language_model.model.layers.0.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.0.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.0.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.0.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.0.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.0.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.0.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.0.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.1.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.1.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.1.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.1.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.1.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.1.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.1.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.1.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.2.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.2.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.2.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.2.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.2.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.2.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.2.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.2.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.3.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.3.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.3.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.3.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.3.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.3.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.3.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.3.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.4.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.4.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.4.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.4.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.4.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.4.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.4.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.4.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.5.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.5.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.5.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.5.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.5.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.5.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.5.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.5.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.6.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.6.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.6.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.6.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.6.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Loading checkpoint shards: 100%|██████████| 20/20 [00:16<00:00,  1.84it/s]Loading checkpoint shards: 100%|██████████| 20/20 [00:16<00:00,  1.20it/s]
Some weights of LlavaForConditionalGeneration were not initialized from the model checkpoint at /home/vault/b207dd/b207dd11/llava-mixtral/llava-mixtral-pretrained-2/ and are newly initialized: ['language_model.model.layers.0.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.0.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.1.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.10.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.11.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.12.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.13.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.14.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.15.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.16.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.17.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.18.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.19.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.2.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.20.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.21.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.22.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.23.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.24.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.25.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.26.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.27.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.28.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.29.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.3.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.30.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.31.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.4.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.5.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.6.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.7.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.8.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.0.unit.adapter_w1.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.0.unit.adapter_w2.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.1.unit.adapter_w1.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.1.unit.adapter_w2.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.2.unit.adapter_w1.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.2.unit.adapter_w2.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.3.unit.adapter_w1.weight', 'language_model.model.layers.9.block_sparse_moe.shared_adapter.3.unit.adapter_w2.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Initialized adapter matrices for language_model.model.layers.6.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.6.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.6.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.7.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.7.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.7.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.7.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.7.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.7.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.7.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.7.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.8.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.8.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.8.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.8.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.8.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.8.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.8.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.8.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.9.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.9.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.9.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.9.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.9.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.9.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.9.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
 ######################### trying init params ######################### 
language_model.model.layers.0.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.9.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.10.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.0.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.0.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.0.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.0.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.0.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.0.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.10.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.10.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.10.block_sparse_moe.shared_adapter.1.unitInitialized adapter matrices for language_model.model.layers.0.block_sparse_moe.shared_adapter.3.unit

language_model.model.layers.10.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
language_model.model.layers.1.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.10.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.10.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.1.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.1.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.1.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.1.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.1.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.1.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.10.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.11.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.1.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.2.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.11.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.11.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.2.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.2.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.11.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.11.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.2.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.2.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.2.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.2.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.11.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.11.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.2.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.3.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.3.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.3.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.11.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.12.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.3.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.3.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.12.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.12.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.3.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.3.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.12.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.12.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.3.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.4.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.12.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.12.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.4.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.4.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.12.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.13.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.4.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.4.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.13.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.13.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.4.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.4.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.13.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.13.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.4.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.5.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.13.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.13.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.13.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.14.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.5.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.5.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.14.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.14.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.5.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.5.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.14.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.14.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.14.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.14.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.5.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.5.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.5.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.6.block_sparse_moe.shared_adapter.0.unitInitialized adapter matrices for language_model.model.layers.14.block_sparse_moe.shared_adapter.3.unit
 MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
language_model.model.layers.15.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.6.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.6.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.15.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.15.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.6.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.6.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.15.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.15.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.6.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.6.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.15.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.15.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.15.block_sparse_moe.shared_adapter.3.unit
Initialized adapter matrices for language_model.model.layers.6.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.16.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
language_model.model.layers.7.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.7.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.7.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.16.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.16.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.16.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.16.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.7.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.7.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.16.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.16.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.16.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.17.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.7.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.7.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.17.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.17.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.7.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.8.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.17.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.17.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.8.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.8.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.8.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.8.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.17.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.17.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.8.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.8.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.17.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.18.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.18.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.18.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.8.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.9.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.18.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.18.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.18.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.18.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.9.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.9.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.18.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.19.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.19.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.19.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.19.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.19.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.9.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.9.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.19.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.19.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.9.block_sparse_moe.shared_adapter.2.unitInitialized adapter matrices for language_model.model.layers.19.block_sparse_moe.shared_adapter.3.unit

language_model.model.layers.9.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
language_model.model.layers.20.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.20.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.20.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.9.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.10.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.20.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.20.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.10.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.10.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.20.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.20.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.20.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.21.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.10.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.10.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.21.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.21.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.10.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.10.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.21.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.21.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.21.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.21.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.10.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.11.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.21.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.22.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.11.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.11.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.22.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.22.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.22.block_sparse_moe.shared_adapter.1.unit
Initialized adapter matrices for language_model.model.layers.11.block_sparse_moe.shared_adapter.1.unitlanguage_model.model.layers.22.block_sparse_moe.shared_adapter.2.unit 
language_model.model.layers.11.block_sparse_moe.shared_adapter.2.unitMixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
 MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.22.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.22.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.11.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.11.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.11.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.12.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.22.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.23.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.12.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.12.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.23.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.23.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.12.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.12.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.23.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.23.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.12.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.12.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.12.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.13.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.23.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.23.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.13.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.13.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.23.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.24.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.13.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.13.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.24.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.24.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.13.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.13.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.24.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.24.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.13.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.14.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.14.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.14.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.14.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.14.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.14.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.14.block_sparse_moe.shared_adapter.3.unitInitialized adapter matrices for language_model.model.layers.24.block_sparse_moe.shared_adapter.2.unit 
MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
language_model.model.layers.24.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.14.block_sparse_moe.shared_adapter.3.unit
Initialized adapter matrices for language_model.model.layers.24.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.15.block_sparse_moe.shared_adapter.0.unitlanguage_model.model.layers.25.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
 MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.25.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.25.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)Initialized adapter matrices for language_model.model.layers.15.block_sparse_moe.shared_adapter.0.unit

language_model.model.layers.15.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.25.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.25.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.15.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.15.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.25.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.25.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.15.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.15.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.25.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.26.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.15.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.16.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.26.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.26.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.16.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.16.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.26.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.26.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.26.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.26.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.16.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.16.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.26.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.27.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.16.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.16.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.27.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.27.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.27.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.27.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.16.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.17.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.27.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.27.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.27.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.28.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.17.block_sparse_moe.shared_adapter.0.unit
Initialized adapter matrices for language_model.model.layers.28.block_sparse_moe.shared_adapter.0.unitlanguage_model.model.layers.17.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
language_model.model.layers.28.block_sparse_moe.shared_adapter.1.unit
 MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.28.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.28.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.17.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.17.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.28.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.28.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.28.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.29.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.29.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.29.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.17.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.17.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.29.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.29.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.29.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.29.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.17.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.18.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.29.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.30.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.18.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.18.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.30.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.30.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.18.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.18.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.30.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.30.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.18.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.18.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.30.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.30.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.18.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.19.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.30.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.31.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.31.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.31.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.19.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.19.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.31.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.31.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.31.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.31.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.19.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.19.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.31.block_sparse_moe.shared_adapter.3.unit
Initialized adapter matrices for language_model.model.layers.19.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.19.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Convert trainable params: 33554432 || all params: 47060850688 || trainable%: 0.07
Initialized adapter matrices for language_model.model.layers.19.block_sparse_moe.shared_adapter.3.unit
Print trainable params: 54534144 || all params: 47060850688 || trainable%: 0.12
language_model.model.layers.20.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.20.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.20.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.20.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.20.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.20.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.20.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.20.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.21.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.21.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.21.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.21.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.21.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.21.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.21.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.21.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.22.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.22.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.22.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.22.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.22.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.22.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.22.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.22.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.23.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.23.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.23.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.23.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.23.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.23.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.23.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.23.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.24.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.24.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.24.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.24.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.24.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.24.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.24.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.24.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.25.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.25.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.25.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.25.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.25.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.25.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.25.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.25.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.26.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.26.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.26.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.26.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.26.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.26.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.26.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.26.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.27.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.27.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.27.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.27.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.27.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.27.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.27.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.27.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.28.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.28.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.28.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.28.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.28.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.28.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.28.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.28.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.29.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.29.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.29.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.29.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.29.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.29.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.29.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.29.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.30.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.30.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.30.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.30.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.30.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.30.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.30.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.30.block_sparse_moe.shared_adapter.3.unit
language_model.model.layers.31.block_sparse_moe.shared_adapter.0.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.31.block_sparse_moe.shared_adapter.0.unit
language_model.model.layers.31.block_sparse_moe.shared_adapter.1.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.31.block_sparse_moe.shared_adapter.1.unit
language_model.model.layers.31.block_sparse_moe.shared_adapter.2.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.31.block_sparse_moe.shared_adapter.2.unit
language_model.model.layers.31.block_sparse_moe.shared_adapter.3.unit MixtralBlockParallelAdapterExpert(
  (adapter_w1): Linear(in_features=4096, out_features=32, bias=False)
  (adapter_w2): Linear(in_features=32, out_features=4096, bias=False)
  (act_fn): SiLU()
  (dropout): Dropout(p=0.1, inplace=False)
)
Initialized adapter matrices for language_model.model.layers.31.block_sparse_moe.shared_adapter.3.unit
Convert trainable params: 33554432 || all params: 47060850688 || trainable%: 0.07
Print trainable params: 54534144 || all params: 47060850688 || trainable%: 0.12
SEED_LAYERS=False BASE_SEED=1234 SEED_FN=None
Using topology: {ProcessCoord(pipe=0, data=0): 0, ProcessCoord(pipe=1, data=0): 1, ProcessCoord(pipe=2, data=0): 2, ProcessCoord(pipe=3, data=0): 3, ProcessCoord(pipe=4, data=0): 4, ProcessCoord(pipe=5, data=0): 5, ProcessCoord(pipe=6, data=0): 6, ProcessCoord(pipe=7, data=0): 7}
[2024-06-29 19:24:51,624] [INFO] [module.py:375:_partition_layers] Partitioning pipeline stages with method type:LanguageModelLayerWrapper
stage=0 layers=2Using /home/hpc/b207dd/b207dd11/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...

     0: LlavaMultiModalModuleWrapper
     1: LanguageModelLayerWrapper
stage=1 layers=1
     2: LanguageModelLayerWrapper
stage=2 layers=1
     3: LanguageModelLayerWrapper
stage=3 layers=1
     4: LanguageModelLayerWrapper
stage=4 layers=1
     5: LanguageModelLayerWrapper
stage=5 layers=1
     6: LanguageModelLayerWrapper
stage=6 layers=1
     7: LanguageModelLayerWrapper
stage=7 layers=2
     8: LanguageModelLayerWrapper
     9: LanguageModelFinalWrapper
  loss: loss_fn
Using /home/hpc/b207dd/b207dd11/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/hpc/b207dd/b207dd11/.cache/torch_extensions/py38_cu121/fused_adam/build.ninja...
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module fused_adam...
Time to load fused_adam op: 1.1054320335388184 seconds
[2024-06-29 19:24:52,742] [INFO] [engine.py:141:__init__] is_pipe_partitioned= False is_grad_partitioned= False
Loading extension module fused_adam...
Time to load fused_adam op: 1.0058021545410156 seconds
[2024-06-29 19:24:52,819] [INFO] [engine.py:141:__init__] is_pipe_partitioned= False is_grad_partitioned= False
Rank 3 initialized with CUDA_MEM (60881108992, 85100068864)
Deepspeed engine initializing at --- RANK 3 --- ...
Rank 0 initialized with CUDA_MEM (59041906688, 85100068864)
Deepspeed engine initializing at --- RANK 0 --- ...
[2024-06-29 19:24:54,520] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown
Using /home/hpc/b207dd/b207dd11/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
[2024-06-29 19:24:54,921] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
Using /home/hpc/b207dd/b207dd11/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/hpc/b207dd/b207dd11/.cache/torch_extensions/py38_cu121/fused_adam/build.ninja...
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module fused_adam...
Time to load fused_adam op: 1.5638971328735352 seconds
[2024-06-29 19:24:56,225] [INFO] [engine.py:141:__init__] is_pipe_partitioned= False is_grad_partitioned= False
Loading extension module fused_adam...
Time to load fused_adam op: 0.9065713882446289 seconds
[2024-06-29 19:24:56,313] [INFO] [logging.py:96:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adam as basic optimizer
[2024-06-29 19:24:56,313] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-06-29 19:24:56,322] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
[2024-06-29 19:24:56,322] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = adam
[2024-06-29 19:24:56,322] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = WarmupCosineLR
[2024-06-29 19:24:56,322] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupCosineLR object at 0x148262c28c40>
[2024-06-29 19:24:56,323] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2024-06-29 19:24:56,323] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-06-29 19:24:56,323] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-06-29 19:24:56,323] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-06-29 19:24:56,323] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-06-29 19:24:56,323] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   bfloat16_enabled ............. False
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x148262afd9d0>
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 128
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 65536
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   loss_scale ................... 0
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-06-29 19:24:56,324] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-06-29 19:24:56,325] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=True, output_path='/home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint', job_name='deepspeed_monitor_logs') enabled=True
[2024-06-29 19:24:56,325] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-06-29 19:24:56,325] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-06-29 19:24:56,325] [INFO] [config.py:1000:print]   optimizer_name ............... adam
[2024-06-29 19:24:56,325] [INFO] [config.py:1000:print]   optimizer_params ............. {'lr': 2e-05}
[2024-06-29 19:24:56,325] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True, 'use_reentrant': False}
[2024-06-29 19:24:56,325] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-06-29 19:24:56,325] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-06-29 19:24:56,325] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-06-29 19:24:56,325] [INFO] [config.py:1000:print]   scheduler_name ............... WarmupCosineLR
[2024-06-29 19:24:56,325] [INFO] [config.py:1000:print]   scheduler_params ............. {'total_num_steps': 5718, 'warmup_min_ratio': 0.1, 'warmup_num_steps': 171.54}
[2024-06-29 19:24:56,325] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-06-29 19:24:56,325] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-06-29 19:24:56,325] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-06-29 19:24:56,325] [INFO] [config.py:1000:print]   steps_per_print .............. 1
[2024-06-29 19:24:56,325] [INFO] [config.py:1000:print]   train_batch_size ............. 128
[2024-06-29 19:24:56,325] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  1
[2024-06-29 19:24:56,325] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-06-29 19:24:56,325] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-06-29 19:24:56,325] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2024-06-29 19:24:56,325] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-06-29 19:24:56,325] [INFO] [config.py:1000:print]   world_size ................... 1
[2024-06-29 19:24:56,325] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  False
[2024-06-29 19:24:56,325] [INFO] [config.py:1000:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-06-29 19:24:56,325] [INFO] [config.py:1000:print]   zero_enabled ................. False
[2024-06-29 19:24:56,325] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2024-06-29 19:24:56,325] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 0
[2024-06-29 19:24:56,325] [INFO] [config.py:986:print_user_config]   json = {
    "train_batch_size": 128, 
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 128, 
    "steps_per_print": 1, 
    "optimizer": {
        "type": "Adam", 
        "params": {
            "lr": 2e-05
        }
    }, 
    "scheduler": {
        "type": "WarmupCosineLR", 
        "params": {
            "total_num_steps": 5.718000e+03, 
            "warmup_min_ratio": 0.1, 
            "warmup_num_steps": 171.54
        }
    }, 
    "pipeline": {
        "use_reentrant": false
    }, 
    "csv_monitor": {
        "enabled": true, 
        "output_path": "/home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint", 
        "job_name": "deepspeed_monitor_logs"
    }
}
[2024-06-29 19:24:56,325] [INFO] [engine.py:101:__init__] CONFIG: micro_batches=128 micro_batch_size=1
[2024-06-29 19:24:56,325] [INFO] [engine.py:141:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[2024-06-29 19:25:00,729] [INFO] [engine.py:160:__init__] RANK=0 STAGE=0 LAYERS=2 [0, 2) STAGE_PARAMS=25174016 (25.174M) TOTAL_PARAMS=54534144 (54.534M) UNIQUE_PARAMS=54534144 (54.534M)
[2024-06-29 19:25:00,729] [INFO] [engine.py:160:__init__] RANK=3 STAGE=3 LAYERS=1 [4, 5) STAGE_PARAMS=4194304 (4.194M) TOTAL_PARAMS=54534144 (54.534M) UNIQUE_PARAMS=54534144 (54.534M)
[2024-06-29 19:25:00,729] [INFO] [engine.py:160:__init__] RANK=6 STAGE=6 LAYERS=1 [7, 8) STAGE_PARAMS=4194304 (4.194M) TOTAL_PARAMS=54534144 (54.534M) UNIQUE_PARAMS=54534144 (54.534M)
[2024-06-29 19:25:00,729] [INFO] [engine.py:160:__init__] RANK=4 STAGE=4 LAYERS=1 [5, 6) STAGE_PARAMS=4194304 (4.194M) TOTAL_PARAMS=54534144 (54.534M) UNIQUE_PARAMS=54534144 (54.534M)
[2024-06-29 19:25:00,729] [INFO] [engine.py:160:__init__] RANK=2 STAGE=2 LAYERS=1 [3, 4) STAGE_PARAMS=4194304 (4.194M) TOTAL_PARAMS=54534144 (54.534M) UNIQUE_PARAMS=54534144 (54.534M)
[2024-06-29 19:25:00,729] [INFO] [engine.py:160:__init__] RANK=7 STAGE=7 LAYERS=2 [8, 10) STAGE_PARAMS=4194304 (4.194M) TOTAL_PARAMS=54534144 (54.534M) UNIQUE_PARAMS=54534144 (54.534M)
[2024-06-29 19:25:00,729] [INFO] [engine.py:160:__init__] RANK=5 STAGE=5 LAYERS=1 [6, 7) STAGE_PARAMS=4194304 (4.194M) TOTAL_PARAMS=54534144 (54.534M) UNIQUE_PARAMS=54534144 (54.534M)
[2024-06-29 19:25:00,730] [INFO] [engine.py:160:__init__] RANK=1 STAGE=1 LAYERS=1 [2, 3) STAGE_PARAMS=4194304 (4.194M) TOTAL_PARAMS=54534144 (54.534M) UNIQUE_PARAMS=54534144 (54.534M)
Deepspeed engine successfully initialized at --- RANK 0 --- hosting 36 of 260 trainable parameters
  0%|          | 0/5198 [00:00<?, ?it/s]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_0
Deepspeed engine successfully initialized at --- RANK 7 --- hosting 32 of 260 trainable parameters
  0%|          | 0/5198 [00:00<?, ?it/s]Training on 128 of 128 sentences.


  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s][ADeepspeed engine successfully initialized at --- RANK 1 --- hosting 32 of 260 trainable parameters
Deepspeed engine successfully initialized at --- RANK 2 --- hosting 32 of 260 trainable parameters
  0%|          | 0/5198 [00:00<?, ?it/s]  0%|          | 0/5198 [00:00<?, ?it/s]Deepspeed engine successfully initialized at --- RANK 4 --- hosting 32 of 260 trainable parameters
Deepspeed engine successfully initialized at --- RANK 3 --- hosting 32 of 260 trainable parameters
  0%|          | 0/5198 [00:00<?, ?it/s]  0%|          | 0/5198 [00:00<?, ?it/s]Deepspeed engine successfully initialized at --- RANK 6 --- hosting 32 of 260 trainable parameters
Deepspeed engine successfully initialized at --- RANK 5 --- hosting 32 of 260 trainable parameters

  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/5198 [00:00<?, ?it/s]  0%|          | 0/5198 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 19:27:14,642] [INFO] [logging.py:96:log_dist] [Rank 0] step=1, skipped=0, lr=[2.0000000000000003e-06], mom=[(0.9, 0.999)]
steps: 1 loss: 2.3512 iter time (s): 135.164 samples/sec: 0.947

100%|██████████| 1/1 [02:15<00:00, 135.30s/it][A100%|██████████| 1/1 [02:15<00:00, 135.30s/it]
  0%|          | 1/5198 [02:16<196:44:45, 136.29s/it]
100%|██████████| 1/1 [02:14<00:00, 134.00s/it][A100%|██████████| 1/1 [02:14<00:00, 134.00s/it]
  0%|          | 1/5198 [02:14<194:03:28, 134.43s/it]
100%|██████████| 1/1 [02:14<00:00, 134.15s/it][A100%|██████████| 1/1 [02:14<00:00, 134.15s/it]
  0%|          | 1/5198 [02:14<194:13:54, 134.55s/it]
100%|██████████| 1/1 [02:14<00:00, 134.61s/it][A100%|██████████| 1/1 [02:14<00:00, 134.62s/it]
  0%|          | 1/5198 [02:14<194:48:46, 134.95s/it]
100%|██████████| 1/1 [02:14<00:00, 134.61s/it][A100%|██████████| 1/1 [02:14<00:00, 134.61s/it]
  0%|          | 1/5198 [02:14<194:48:46, 134.95s/it]
100%|██████████| 1/1 [02:14<00:00, 134.77s/it][A100%|██████████| 1/1 [02:14<00:00, 134.77s/it]
  0%|          | 1/5198 [02:15<194:59:55, 135.08s/it]
100%|██████████| 1/1 [02:14<00:00, 134.82s/it][A100%|██████████| 1/1 [02:14<00:00, 134.82s/it]
  0%|          | 1/5198 [02:15<195:04:30, 135.13s/it]
100%|██████████| 1/1 [02:15<00:00, 135.92s/it][A100%|██████████| 1/1 [02:15<00:00, 135.92s/it]
  0%|          | 1/5198 [02:17<198:20:41, 137.39s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_1
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:07<00:00, 127.74s/it][A100%|██████████| 1/1 [02:07<00:00, 127.74s/it]
  0%|          | 2/5198 [04:25<190:25:53, 131.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 19:29:30,953] [INFO] [logging.py:96:log_dist] [Rank 0] step=2, skipped=0, lr=[4.425091217411297e-06], mom=[(0.9, 0.999)]
steps: 2 loss: 1.5492 iter time (s): 130.267 samples/sec: 0.983

100%|██████████| 1/1 [02:10<00:00, 130.66s/it][A100%|██████████| 1/1 [02:10<00:00, 130.66s/it]
  0%|          | 2/5198 [04:26<191:39:17, 132.79s/it]
100%|██████████| 1/1 [02:10<00:00, 130.81s/it][A100%|██████████| 1/1 [02:10<00:00, 130.81s/it]
  0%|          | 2/5198 [04:26<191:44:48, 132.85s/it]
100%|██████████| 1/1 [02:10<00:00, 130.85s/it][A100%|██████████| 1/1 [02:10<00:00, 130.85s/it]
  0%|          | 2/5198 [04:26<191:53:20, 132.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:10<00:00, 130.90s/it][A100%|██████████| 1/1 [02:10<00:00, 130.90s/it]
  0%|          | 2/5198 [04:26<191:55:15, 132.97s/it]
100%|██████████| 1/1 [02:11<00:00, 131.02s/it][A100%|██████████| 1/1 [02:11<00:00, 131.02s/it]
  0%|          | 2/5198 [04:26<192:03:16, 133.06s/it]
100%|██████████| 1/1 [02:11<00:00, 131.04s/it][A100%|██████████| 1/1 [02:11<00:00, 131.04s/it]
  0%|          | 2/5198 [04:26<192:03:01, 133.06s/it]
100%|██████████| 1/1 [02:11<00:00, 131.09s/it][A100%|██████████| 1/1 [02:11<00:00, 131.09s/it]
  0%|          | 2/5198 [04:29<193:24:05, 134.00s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_2

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:11<00:00, 131.33s/it][A100%|██████████| 1/1 [02:11<00:00, 131.33s/it]
  0%|          | 3/5198 [06:37<190:43:52, 132.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 19:31:43,491] [INFO] [logging.py:96:log_dist] [Rank 0] step=3, skipped=0, lr=[5.843678640425123e-06], mom=[(0.9, 0.999)]
steps: 3 loss: 1.3888 iter time (s): 130.760 samples/sec: 0.979

100%|██████████| 1/1 [02:11<00:00, 131.88s/it][A100%|██████████| 1/1 [02:11<00:00, 131.88s/it]
  0%|          | 3/5198 [06:38<191:09:57, 132.47s/it]
100%|██████████| 1/1 [02:11<00:00, 131.74s/it][A100%|██████████| 1/1 [02:11<00:00, 131.74s/it]
  0%|          | 3/5198 [06:38<191:15:10, 132.53s/it]
100%|██████████| 1/1 [02:11<00:00, 131.82s/it][A100%|██████████| 1/1 [02:11<00:00, 131.82s/it]
  0%|          | 3/5198 [06:38<191:21:28, 132.61s/it]
100%|██████████| 1/1 [02:11<00:00, 131.92s/it][A100%|██████████| 1/1 [02:11<00:00, 131.92s/it]
  0%|          | 3/5198 [06:38<191:23:46, 132.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:11<00:00, 131.95s/it][A100%|██████████| 1/1 [02:11<00:00, 131.95s/it]
  0%|          | 3/5198 [06:38<191:27:03, 132.67s/it]
100%|██████████| 1/1 [02:11<00:00, 131.62s/it][A100%|██████████| 1/1 [02:11<00:00, 131.62s/it]
  0%|          | 3/5198 [06:38<191:27:41, 132.68s/it]
100%|██████████| 1/1 [02:11<00:00, 131.65s/it][A100%|██████████| 1/1 [02:11<00:00, 131.65s/it]
  0%|          | 3/5198 [06:41<192:10:52, 133.18s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_3

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.84s/it][A100%|██████████| 1/1 [02:03<00:00, 123.84s/it]
  0%|          | 4/5198 [08:42<186:29:50, 129.26s/it][2024-06-29 19:33:48,091] [INFO] [logging.py:96:log_dist] [Rank 0] step=4, skipped=0, lr=[6.850182434822594e-06], mom=[(0.9, 0.999)]
steps: 4 loss: 1.3054 iter time (s): 123.509 samples/sec: 1.036

100%|██████████| 1/1 [02:04<00:00, 124.29s/it][A100%|██████████| 1/1 [02:04<00:00, 124.29s/it]
  0%|          | 4/5198 [08:42<186:43:19, 129.42s/it]
100%|██████████| 1/1 [02:04<00:00, 124.32s/it][A100%|██████████| 1/1 [02:04<00:00, 124.32s/it]
  0%|          | 4/5198 [08:43<186:45:11, 129.44s/it]
100%|██████████| 1/1 [02:04<00:00, 124.18s/it][A100%|██████████| 1/1 [02:04<00:00, 124.18s/it]
  0%|          | 4/5198 [08:43<186:47:57, 129.47s/it]
100%|██████████| 1/1 [02:04<00:00, 124.29s/it][A100%|██████████| 1/1 [02:04<00:00, 124.29s/it]
  0%|          | 4/5198 [08:43<186:51:39, 129.51s/it]
100%|██████████| 1/1 [02:04<00:00, 124.25s/it][A100%|██████████| 1/1 [02:04<00:00, 124.25s/it]
  0%|          | 4/5198 [08:43<186:50:54, 129.51s/it]
100%|██████████| 1/1 [02:04<00:00, 124.35s/it][A100%|██████████| 1/1 [02:04<00:00, 124.35s/it]
  0%|          | 4/5198 [08:43<186:51:58, 129.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A

  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:04<00:00, 124.40s/it][A100%|██████████| 1/1 [02:04<00:00, 124.40s/it]
  0%|          | 4/5198 [08:45<187:18:38, 129.83s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_4
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:27<00:00, 147.87s/it][A100%|██████████| 1/1 [02:27<00:00, 147.87s/it]
  0%|          | 5/5198 [11:13<197:40:24, 137.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 19:36:19,264] [INFO] [logging.py:96:log_dist] [Rank 0] step=5, skipped=0, lr=[7.630887430371887e-06], mom=[(0.9, 0.999)]
steps: 5 loss: 1.2503 iter time (s): 149.921 samples/sec: 0.854

100%|██████████| 1/1 [02:30<00:00, 150.62s/it][A100%|██████████| 1/1 [02:30<00:00, 150.62s/it]
  0%|          | 5/5198 [11:13<197:56:26, 137.22s/it]
100%|██████████| 1/1 [02:30<00:00, 150.62s/it][A100%|██████████| 1/1 [02:30<00:00, 150.62s/it]
  0%|          | 5/5198 [11:13<197:52:39, 137.18s/it]
100%|██████████| 1/1 [02:30<00:00, 150.81s/it][A100%|██████████| 1/1 [02:30<00:00, 150.81s/it]
  0%|          | 5/5198 [11:14<197:58:31, 137.24s/it]
100%|██████████| 1/1 [02:30<00:00, 150.54s/it][A100%|██████████| 1/1 [02:30<00:00, 150.54s/it]
  0%|          | 5/5198 [11:14<197:58:50, 137.25s/it]
100%|██████████| 1/1 [02:30<00:00, 150.59s/it][A100%|██████████| 1/1 [02:30<00:00, 150.59s/it]
  0%|          | 5/5198 [11:14<197:59:12, 137.25s/it]
100%|██████████| 1/1 [02:30<00:00, 150.62s/it][A100%|██████████| 1/1 [02:30<00:00, 150.62s/it]
  0%|          | 5/5198 [11:14<197:59:38, 137.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A

  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:30<00:00, 150.72s/it][A100%|██████████| 1/1 [02:30<00:00, 150.72s/it]
  0%|          | 5/5198 [11:16<198:18:11, 137.47s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_5

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:22<00:00, 142.38s/it][A100%|██████████| 1/1 [02:22<00:00, 142.38s/it]
  0%|          | 6/5198 [13:37<201:00:22, 139.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 19:38:43,329] [INFO] [logging.py:96:log_dist] [Rank 0] step=6, skipped=0, lr=[8.26876985783642e-06], mom=[(0.9, 0.999)]
steps: 6 loss: 1.1459 iter time (s): 142.962 samples/sec: 0.895

100%|██████████| 1/1 [02:23<00:00, 143.74s/it][A100%|██████████| 1/1 [02:23<00:00, 143.74s/it]
  0%|          | 6/5198 [13:38<201:18:13, 139.58s/it]
100%|██████████| 1/1 [02:23<00:00, 143.81s/it][A100%|██████████| 1/1 [02:23<00:00, 143.81s/it]
  0%|          | 6/5198 [13:38<201:17:57, 139.58s/it]
100%|██████████| 1/1 [02:24<00:00, 144.02s/it][A100%|██████████| 1/1 [02:24<00:00, 144.02s/it]
  0%|          | 6/5198 [13:38<201:22:22, 139.63s/it]
100%|██████████| 1/1 [02:23<00:00, 143.75s/it][A100%|██████████| 1/1 [02:23<00:00, 143.75s/it]
  0%|          | 6/5198 [13:38<201:20:30, 139.61s/it]
100%|██████████| 1/1 [02:23<00:00, 143.80s/it][A100%|██████████| 1/1 [02:23<00:00, 143.80s/it]
  0%|          | 6/5198 [13:38<201:20:39, 139.61s/it]
100%|██████████| 1/1 [02:23<00:00, 143.88s/it][A100%|██████████| 1/1 [02:23<00:00, 143.88s/it]
  0%|          | 6/5198 [13:38<201:21:31, 139.62s/it]
100%|██████████| 1/1 [02:23<00:00, 143.89s/it][A100%|██████████| 1/1 [02:23<00:00, 143.89s/it]
  0%|          | 6/5198 [13:41<201:32:15, 139.74s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_6

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s]
[A  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:29<00:00, 149.67s/it][A100%|██████████| 1/1 [02:29<00:00, 149.67s/it]
  0%|          | 7/5198 [16:08<206:22:39, 143.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 19:41:14,518] [INFO] [logging.py:96:log_dist] [Rank 0] step=7, skipped=0, lr=[8.808091765638272e-06], mom=[(0.9, 0.999)]
steps: 7 loss: 1.1104 iter time (s): 150.087 samples/sec: 0.853

100%|██████████| 1/1 [02:30<00:00, 150.63s/it][A100%|██████████| 1/1 [02:30<00:00, 150.63s/it]
  0%|          | 7/5198 [16:09<206:40:42, 143.33s/it]
100%|██████████| 1/1 [02:30<00:00, 150.60s/it][A100%|██████████| 1/1 [02:30<00:00, 150.60s/it]
  0%|          | 7/5198 [16:09<206:41:20, 143.34s/it]
100%|██████████| 1/1 [02:30<00:00, 150.80s/it][A100%|██████████| 1/1 [02:30<00:00, 150.80s/it]
  0%|          | 7/5198 [16:09<206:44:04, 143.37s/it]
100%|██████████| 1/1 [02:30<00:00, 150.81s/it][A100%|██████████| 1/1 [02:30<00:00, 150.81s/it]
  0%|          | 7/5198 [16:09<206:43:00, 143.36s/it]
100%|██████████| 1/1 [02:30<00:00, 150.73s/it][A100%|██████████| 1/1 [02:30<00:00, 150.73s/it]
  0%|          | 7/5198 [16:09<206:42:18, 143.35s/it]
100%|██████████| 1/1 [02:30<00:00, 150.75s/it][A100%|██████████| 1/1 [02:30<00:00, 150.75s/it]
  0%|          | 7/5198 [16:09<206:43:14, 143.36s/it]
100%|██████████| 1/1 [02:30<00:00, 150.82s/it][A100%|██████████| 1/1 [02:30<00:00, 150.82s/it]
  0%|          | 7/5198 [16:12<206:50:14, 143.44s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_7

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:28<00:00, 148.94s/it][A100%|██████████| 1/1 [02:28<00:00, 148.94s/it]
  0%|          | 8/5198 [18:37<209:20:26, 145.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 19:43:43,965] [INFO] [logging.py:96:log_dist] [Rank 0] step=8, skipped=0, lr=[9.27527365223389e-06], mom=[(0.9, 0.999)]
steps: 8 loss: 1.0561 iter time (s): 148.404 samples/sec: 0.863

100%|██████████| 1/1 [02:28<00:00, 148.99s/it][A100%|██████████| 1/1 [02:28<00:00, 148.99s/it]
  0%|          | 8/5198 [18:38<209:28:08, 145.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:29<00:00, 149.19s/it][A100%|██████████| 1/1 [02:29<00:00, 149.19s/it]
  0%|          | 8/5198 [18:38<209:31:10, 145.33s/it]
100%|██████████| 1/1 [02:29<00:00, 149.07s/it][A100%|██████████| 1/1 [02:29<00:00, 149.07s/it]
  0%|          | 8/5198 [18:39<209:29:17, 145.31s/it]
100%|██████████| 1/1 [02:28<00:00, 148.87s/it][A100%|██████████| 1/1 [02:28<00:00, 148.87s/it]
  0%|          | 8/5198 [18:39<209:30:12, 145.32s/it]
100%|██████████| 1/1 [02:29<00:00, 149.08s/it][A100%|██████████| 1/1 [02:29<00:00, 149.08s/it]
  0%|          | 8/5198 [18:39<209:30:46, 145.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:29<00:00, 149.13s/it][A100%|██████████| 1/1 [02:29<00:00, 149.13s/it]
  0%|          | 8/5198 [18:39<209:31:36, 145.34s/it]
100%|██████████| 1/1 [02:29<00:00, 149.16s/it][A100%|██████████| 1/1 [02:29<00:00, 149.16s/it]
  0%|          | 8/5198 [18:41<209:35:50, 145.39s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_8

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:46<00:00, 166.19s/it][A100%|██████████| 1/1 [02:46<00:00, 166.19s/it]
  0%|          | 9/5198 [21:24<219:06:12, 152.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 19:46:31,553] [INFO] [logging.py:96:log_dist] [Rank 0] step=9, skipped=0, lr=[9.687357280850246e-06], mom=[(0.9, 0.999)]
steps: 9 loss: 1.0352 iter time (s): 166.537 samples/sec: 0.769

100%|██████████| 1/1 [02:47<00:00, 167.31s/it][A100%|██████████| 1/1 [02:47<00:00, 167.31s/it]
  0%|          | 9/5198 [21:26<219:26:09, 152.24s/it]
100%|██████████| 1/1 [02:47<00:00, 167.23s/it][A100%|██████████| 1/1 [02:47<00:00, 167.23s/it]
  0%|          | 9/5198 [21:26<219:26:16, 152.24s/it]
100%|██████████| 1/1 [02:47<00:00, 167.45s/it][A100%|██████████| 1/1 [02:47<00:00, 167.45s/it]
  0%|          | 9/5198 [21:26<219:29:18, 152.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:47<00:00, 167.36s/it][A100%|██████████| 1/1 [02:47<00:00, 167.36s/it]
  0%|          | 9/5198 [21:26<219:28:40, 152.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:47<00:00, 167.34s/it][A100%|██████████| 1/1 [02:47<00:00, 167.34s/it]
  0%|          | 9/5198 [21:26<219:28:28, 152.27s/it]
100%|██████████| 1/1 [02:47<00:00, 167.26s/it][A100%|██████████| 1/1 [02:47<00:00, 167.26s/it]
  0%|          | 9/5198 [21:26<219:28:05, 152.26s/it]
100%|██████████| 1/1 [02:47<00:00, 167.29s/it][A100%|██████████| 1/1 [02:47<00:00, 167.29s/it]
  0%|          | 9/5198 [21:29<219:31:37, 152.30s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_9

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:29<00:00, 149.58s/it][A100%|██████████| 1/1 [02:29<00:00, 149.58s/it]
  0%|          | 10/5198 [23:54<218:16:06, 151.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 19:49:00,825] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=0, lr=[1.0055978647783185e-05], mom=[(0.9, 0.999)]
steps: 10 loss: 1.0486 iter time (s): 148.098 samples/sec: 0.864

100%|██████████| 1/1 [02:28<00:00, 148.99s/it][A100%|██████████| 1/1 [02:28<00:00, 148.99s/it]
  0%|          | 10/5198 [23:55<218:06:31, 151.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:29<00:00, 149.17s/it][A100%|██████████| 1/1 [02:29<00:00, 149.17s/it]
  0%|          | 10/5198 [23:55<218:08:43, 151.37s/it]
100%|██████████| 1/1 [02:28<00:00, 148.82s/it][A100%|██████████| 1/1 [02:28<00:00, 148.82s/it]
  0%|          | 10/5198 [23:56<218:08:12, 151.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:28<00:00, 148.88s/it][A100%|██████████| 1/1 [02:28<00:00, 148.88s/it]
  0%|          | 10/5198 [23:56<218:08:52, 151.37s/it]
100%|██████████| 1/1 [02:28<00:00, 148.91s/it][A100%|██████████| 1/1 [02:28<00:00, 148.91s/it]
  0%|          | 10/5198 [23:56<218:08:20, 151.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:28<00:00, 148.96s/it][A100%|██████████| 1/1 [02:28<00:00, 148.96s/it]
  0%|          | 10/5198 [23:56<218:08:09, 151.37s/it]
100%|██████████| 1/1 [02:28<00:00, 148.95s/it][A100%|██████████| 1/1 [02:28<00:00, 148.95s/it]
  0%|          | 10/5198 [23:58<218:09:54, 151.39s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_10

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:04<00:00, 124.65s/it][A100%|██████████| 1/1 [02:04<00:00, 124.65s/it]
  0%|          | 11/5198 [25:59<206:35:17, 143.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 19:51:05,649] [INFO] [logging.py:96:log_dist] [Rank 0] step=11, skipped=0, lr=[1.0389437235592257e-05], mom=[(0.9, 0.999)]
steps: 11 loss: 0.9746 iter time (s): 123.921 samples/sec: 1.033

100%|██████████| 1/1 [02:04<00:00, 124.72s/it][A100%|██████████| 1/1 [02:04<00:00, 124.72s/it]
  0%|          | 11/5198 [26:00<206:23:11, 143.24s/it]
100%|██████████| 1/1 [02:04<00:00, 124.69s/it][A100%|██████████| 1/1 [02:04<00:00, 124.69s/it]
  0%|          | 11/5198 [26:00<206:23:41, 143.25s/it]
100%|██████████| 1/1 [02:04<00:00, 124.68s/it][A100%|██████████| 1/1 [02:04<00:00, 124.68s/it]
  0%|          | 11/5198 [26:00<206:22:42, 143.24s/it]
100%|██████████| 1/1 [02:04<00:00, 124.73s/it][A100%|██████████| 1/1 [02:04<00:00, 124.73s/it]
  0%|          | 11/5198 [26:01<206:24:33, 143.26s/it]
100%|██████████| 1/1 [02:04<00:00, 124.76s/it][A100%|██████████| 1/1 [02:04<00:00, 124.76s/it]
  0%|          | 11/5198 [26:01<206:24:48, 143.26s/it]
100%|██████████| 1/1 [02:04<00:00, 124.78s/it][A100%|██████████| 1/1 [02:04<00:00, 124.78s/it]
  0%|          | 11/5198 [26:01<206:25:21, 143.27s/it]
100%|██████████| 1/1 [02:04<00:00, 124.81s/it][A100%|██████████| 1/1 [02:04<00:00, 124.81s/it]
  0%|          | 11/5198 [26:03<206:27:06, 143.29s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_11

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:16<00:00, 136.20s/it][A100%|██████████| 1/1 [02:16<00:00, 136.20s/it]
  0%|          | 12/5198 [28:16<203:46:12, 141.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 19:53:22,989] [INFO] [logging.py:96:log_dist] [Rank 0] step=12, skipped=0, lr=[1.0693861075247718e-05], mom=[(0.9, 0.999)]
steps: 12 loss: 0.9227 iter time (s): 136.114 samples/sec: 0.940

100%|██████████| 1/1 [02:16<00:00, 136.71s/it][A100%|██████████| 1/1 [02:16<00:00, 136.71s/it]
  0%|          | 12/5198 [28:17<203:44:34, 141.43s/it]
100%|██████████| 1/1 [02:16<00:00, 136.83s/it][A100%|██████████| 1/1 [02:16<00:00, 136.83s/it]
  0%|          | 12/5198 [28:17<203:43:36, 141.42s/it]
100%|██████████| 1/1 [02:16<00:00, 136.96s/it][A100%|██████████| 1/1 [02:16<00:00, 136.96s/it]
  0%|          | 12/5198 [28:18<203:43:40, 141.42s/it]
100%|██████████| 1/1 [02:16<00:00, 136.89s/it][A100%|██████████| 1/1 [02:16<00:00, 136.89s/it]
  0%|          | 12/5198 [28:18<203:42:22, 141.41s/it]
100%|██████████| 1/1 [02:17<00:00, 137.07s/it][A100%|██████████| 1/1 [02:17<00:00, 137.07s/it]
  0%|          | 12/5198 [28:18<203:43:54, 141.43s/it]
100%|██████████| 1/1 [02:16<00:00, 136.68s/it][A100%|██████████| 1/1 [02:16<00:00, 136.68s/it]
  0%|          | 12/5198 [28:18<203:43:25, 141.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:16<00:00, 136.86s/it][A100%|██████████| 1/1 [02:16<00:00, 136.86s/it]
  0%|          | 12/5198 [28:20<203:44:55, 141.44s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_12

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:19<00:00, 139.31s/it][A100%|██████████| 1/1 [02:19<00:00, 139.31s/it]
  0%|          | 13/5198 [30:37<203:13:12, 141.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 19:55:43,321] [INFO] [logging.py:96:log_dist] [Rank 0] step=13, skipped=0, lr=[1.0973903861023899e-05], mom=[(0.9, 0.999)]
steps: 13 loss: 0.8811 iter time (s): 139.020 samples/sec: 0.921

100%|██████████| 1/1 [02:19<00:00, 139.86s/it][A100%|██████████| 1/1 [02:19<00:00, 139.86s/it]
  0%|          | 13/5198 [30:37<203:12:15, 141.09s/it]
100%|██████████| 1/1 [02:19<00:00, 139.98s/it][A100%|██████████| 1/1 [02:19<00:00, 139.98s/it]
  0%|          | 13/5198 [30:38<203:13:13, 141.10s/it]
100%|██████████| 1/1 [02:20<00:00, 140.13s/it][A100%|██████████| 1/1 [02:20<00:00, 140.13s/it]
  0%|          | 13/5198 [30:38<203:12:28, 141.09s/it]
100%|██████████| 1/1 [02:20<00:00, 140.16s/it][A100%|██████████| 1/1 [02:20<00:00, 140.16s/it]
  0%|          | 13/5198 [30:38<203:13:12, 141.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:20<00:00, 140.02s/it][A100%|██████████| 1/1 [02:20<00:00, 140.02s/it]
  0%|          | 13/5198 [30:38<203:12:50, 141.09s/it]
100%|██████████| 1/1 [02:19<00:00, 139.95s/it][A100%|██████████| 1/1 [02:19<00:00, 139.95s/it]
  0%|          | 13/5198 [30:38<203:13:15, 141.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:19<00:00, 139.90s/it][A100%|██████████| 1/1 [02:19<00:00, 139.90s/it]
  0%|          | 13/5198 [30:41<203:14:19, 141.11s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_13

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.


  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:13<00:00, 133.08s/it][A100%|██████████| 1/1 [02:13<00:00, 133.08s/it]
  0%|          | 14/5198 [32:51<200:06:07, 138.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 19:57:57,307] [INFO] [logging.py:96:log_dist] [Rank 0] step=14, skipped=0, lr=[1.123318298304957e-05], mom=[(0.9, 0.999)]
steps: 14 loss: 0.9409 iter time (s): 132.926 samples/sec: 0.963

100%|██████████| 1/1 [02:13<00:00, 133.71s/it][A100%|██████████| 1/1 [02:13<00:00, 133.71s/it]
  0%|          | 14/5198 [32:52<200:07:53, 138.98s/it]
100%|██████████| 1/1 [02:13<00:00, 133.69s/it][A100%|██████████| 1/1 [02:13<00:00, 133.69s/it]
  0%|          | 14/5198 [32:52<200:05:42, 138.95s/it]
100%|██████████| 1/1 [02:13<00:00, 133.74s/it][A100%|██████████| 1/1 [02:13<00:00, 133.75s/it]
  0%|          | 14/5198 [32:52<200:06:56, 138.97s/it]
100%|██████████| 1/1 [02:13<00:00, 133.74s/it][A100%|██████████| 1/1 [02:13<00:00, 133.74s/it]
  0%|          | 14/5198 [32:52<200:07:04, 138.97s/it]
100%|██████████| 1/1 [02:13<00:00, 133.76s/it][A100%|██████████| 1/1 [02:13<00:00, 133.76s/it]
  0%|          | 14/5198 [32:52<200:07:42, 138.98s/it]
100%|██████████| 1/1 [02:13<00:00, 133.71s/it][A100%|██████████| 1/1 [02:13<00:00, 133.71s/it]
  0%|          | 14/5198 [32:52<200:06:53, 138.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:13<00:00, 133.76s/it][A100%|██████████| 1/1 [02:13<00:00, 133.76s/it]
  0%|          | 14/5198 [32:55<200:07:46, 138.98s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_14

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:07<00:00, 127.03s/it][A100%|██████████| 1/1 [02:07<00:00, 127.03s/it]
  0%|          | 15/5198 [34:59<195:25:47, 135.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 20:00:05,416] [INFO] [logging.py:96:log_dist] [Rank 0] step=15, skipped=0, lr=[1.1474566070797012e-05], mom=[(0.9, 0.999)]
steps: 15 loss: 0.8666 iter time (s): 127.048 samples/sec: 1.007

100%|██████████| 1/1 [02:07<00:00, 127.67s/it][A100%|██████████| 1/1 [02:07<00:00, 127.67s/it]
  0%|          | 15/5198 [35:00<195:22:13, 135.70s/it]
100%|██████████| 1/1 [02:07<00:00, 127.72s/it][A100%|██████████| 1/1 [02:07<00:00, 127.73s/it]
  0%|          | 15/5198 [35:00<195:23:01, 135.71s/it]
100%|██████████| 1/1 [02:07<00:00, 127.78s/it][A100%|██████████| 1/1 [02:07<00:00, 127.78s/it]
  0%|          | 15/5198 [35:00<195:20:52, 135.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:07<00:00, 127.86s/it][A100%|██████████| 1/1 [02:07<00:00, 127.86s/it]
  0%|          | 15/5198 [35:00<195:21:55, 135.70s/it]
100%|██████████| 1/1 [02:07<00:00, 127.75s/it][A100%|██████████| 1/1 [02:07<00:00, 127.75s/it]
  0%|          | 15/5198 [35:00<195:21:00, 135.69s/it]
100%|██████████| 1/1 [02:07<00:00, 127.85s/it][A100%|██████████| 1/1 [02:07<00:00, 127.85s/it]
  0%|          | 15/5198 [35:00<195:22:29, 135.70s/it]
100%|██████████| 1/1 [02:07<00:00, 127.87s/it][A100%|██████████| 1/1 [02:07<00:00, 127.87s/it]
  0%|          | 15/5198 [35:03<195:22:10, 135.70s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_0

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:09<00:00, 129.66s/it][A100%|██████████| 1/1 [02:09<00:00, 129.66s/it]
  0%|          | 16/5198 [37:10<193:14:05, 134.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 20:02:16,862] [INFO] [logging.py:96:log_dist] [Rank 0] step=16, skipped=0, lr=[1.1700364869645189e-05], mom=[(0.9, 0.999)]
steps: 16 loss: 1.0696 iter time (s): 130.399 samples/sec: 0.982

100%|██████████| 1/1 [02:11<00:00, 131.36s/it][A100%|██████████| 1/1 [02:11<00:00, 131.36s/it]
  0%|          | 16/5198 [37:11<193:35:13, 134.49s/it]
100%|██████████| 1/1 [02:10<00:00, 130.95s/it][A100%|██████████| 1/1 [02:10<00:00, 130.95s/it]
  0%|          | 16/5198 [37:11<193:32:28, 134.46s/it]
100%|██████████| 1/1 [02:11<00:00, 131.05s/it][A100%|██████████| 1/1 [02:11<00:00, 131.05s/it]
  0%|          | 16/5198 [37:12<193:32:03, 134.45s/it]
100%|██████████| 1/1 [02:11<00:00, 131.17s/it][A100%|██████████| 1/1 [02:11<00:00, 131.17s/it]
  0%|          | 16/5198 [37:12<193:33:13, 134.46s/it]
100%|██████████| 1/1 [02:11<00:00, 131.22s/it][A100%|██████████| 1/1 [02:11<00:00, 131.23s/it]
  0%|          | 16/5198 [37:12<193:32:02, 134.45s/it]
100%|██████████| 1/1 [02:11<00:00, 131.09s/it][A100%|██████████| 1/1 [02:11<00:00, 131.09s/it]
  0%|          | 16/5198 [37:12<193:31:09, 134.44s/it]
100%|██████████| 1/1 [02:11<00:00, 131.13s/it][A100%|██████████| 1/1 [02:11<00:00, 131.13s/it]
  0%|          | 16/5198 [37:14<193:31:40, 134.45s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_15

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:19<00:00, 139.85s/it][A100%|██████████| 1/1 [02:19<00:00, 139.85s/it]
  0%|          | 17/5198 [39:30<195:56:00, 136.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 20:04:37,079] [INFO] [logging.py:96:log_dist] [Rank 0] step=17, skipped=0, lr=[1.1912470237811225e-05], mom=[(0.9, 0.999)]
steps: 17 loss: 0.8581 iter time (s): 138.723 samples/sec: 0.923

100%|██████████| 1/1 [02:19<00:00, 139.15s/it][A100%|██████████| 1/1 [02:19<00:00, 139.15s/it]
  0%|          | 17/5198 [39:31<195:54:41, 136.13s/it]
100%|██████████| 1/1 [02:19<00:00, 139.34s/it][A100%|██████████| 1/1 [02:19<00:00, 139.34s/it]
  0%|          | 17/5198 [39:32<195:56:56, 136.15s/it]
100%|██████████| 1/1 [02:19<00:00, 139.66s/it][A100%|██████████| 1/1 [02:19<00:00, 139.66s/it]
  0%|          | 17/5198 [39:32<195:56:30, 136.15s/it]
100%|██████████| 1/1 [02:19<00:00, 139.67s/it][A100%|██████████| 1/1 [02:19<00:00, 139.67s/it]
  0%|          | 17/5198 [39:32<195:54:20, 136.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:19<00:00, 139.77s/it][A100%|██████████| 1/1 [02:19<00:00, 139.77s/it]
  0%|          | 17/5198 [39:32<195:56:05, 136.14s/it]
100%|██████████| 1/1 [02:19<00:00, 139.82s/it][A100%|██████████| 1/1 [02:19<00:00, 139.83s/it]
  0%|          | 17/5198 [39:32<195:56:49, 136.15s/it]
100%|██████████| 1/1 [02:19<00:00, 139.62s/it][A100%|██████████| 1/1 [02:19<00:00, 139.62s/it]
  0%|          | 17/5198 [39:34<195:56:34, 136.15s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_16

  0%|          | 0/1 [00:00<?, ?it/s][A

  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:12<00:00, 132.07s/it][A100%|██████████| 1/1 [02:12<00:00, 132.07s/it]
  0%|          | 18/5198 [41:44<194:40:18, 135.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 20:06:49,970] [INFO] [logging.py:96:log_dist] [Rank 0] step=18, skipped=0, lr=[1.2112448498261542e-05], mom=[(0.9, 0.999)]
steps: 18 loss: 0.8662 iter time (s): 131.644 samples/sec: 0.972

100%|██████████| 1/1 [02:12<00:00, 132.63s/it][A100%|██████████| 1/1 [02:12<00:00, 132.63s/it]
  0%|          | 18/5198 [41:44<194:29:51, 135.17s/it]
100%|██████████| 1/1 [02:12<00:00, 132.53s/it][A100%|██████████| 1/1 [02:12<00:00, 132.53s/it]
  0%|          | 18/5198 [41:44<194:29:34, 135.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:12<00:00, 132.61s/it][A100%|██████████| 1/1 [02:12<00:00, 132.61s/it]
  0%|          | 18/5198 [41:45<194:30:21, 135.18s/it]
100%|██████████| 1/1 [02:12<00:00, 132.67s/it][A100%|██████████| 1/1 [02:12<00:00, 132.67s/it]
  0%|          | 18/5198 [41:45<194:31:27, 135.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:12<00:00, 132.90s/it][A100%|██████████| 1/1 [02:12<00:00, 132.90s/it]
  0%|          | 18/5198 [41:45<194:34:44, 135.23s/it]
100%|██████████| 1/1 [02:12<00:00, 132.77s/it][A100%|██████████| 1/1 [02:12<00:00, 132.77s/it]
  0%|          | 18/5198 [41:45<194:33:32, 135.21s/it]
100%|██████████| 1/1 [02:12<00:00, 132.67s/it][A100%|██████████| 1/1 [02:12<00:00, 132.67s/it]
  0%|          | 18/5198 [41:47<194:33:26, 135.21s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_17

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:15<00:00, 135.08s/it][A100%|██████████| 1/1 [02:15<00:00, 135.08s/it]
  0%|          | 19/5198 [44:00<194:51:26, 135.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 20:09:05,906] [INFO] [logging.py:96:log_dist] [Rank 0] step=19, skipped=0, lr=[1.2301611705051847e-05], mom=[(0.9, 0.999)]
steps: 19 loss: 0.7875 iter time (s): 134.776 samples/sec: 0.950

100%|██████████| 1/1 [02:15<00:00, 135.84s/it][A100%|██████████| 1/1 [02:15<00:00, 135.84s/it]
  0%|          | 19/5198 [44:00<194:48:35, 135.42s/it]
100%|██████████| 1/1 [02:15<00:00, 135.60s/it][A100%|██████████| 1/1 [02:15<00:00, 135.60s/it]
  0%|          | 19/5198 [44:00<194:47:59, 135.41s/it]
100%|██████████| 1/1 [02:15<00:00, 135.85s/it][A100%|██████████| 1/1 [02:15<00:00, 135.85s/it]
  0%|          | 19/5198 [44:01<194:50:20, 135.44s/it]
100%|██████████| 1/1 [02:15<00:00, 135.76s/it][A100%|██████████| 1/1 [02:15<00:00, 135.76s/it]
  0%|          | 19/5198 [44:01<194:50:00, 135.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:15<00:00, 135.59s/it][A100%|██████████| 1/1 [02:15<00:00, 135.59s/it]
  0%|          | 19/5198 [44:01<194:49:13, 135.42s/it]
100%|██████████| 1/1 [02:15<00:00, 135.59s/it][A100%|██████████| 1/1 [02:15<00:00, 135.59s/it]
  0%|          | 19/5198 [44:01<194:48:19, 135.41s/it]
100%|██████████| 1/1 [02:15<00:00, 135.60s/it][A100%|██████████| 1/1 [02:15<00:00, 135.60s/it]
  0%|          | 19/5198 [44:03<194:48:44, 135.42s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_18

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.41s/it][A100%|██████████| 1/1 [02:00<00:00, 120.41s/it]
  0%|          | 20/5198 [46:01<188:54:04, 131.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 20:11:07,399] [INFO] [logging.py:96:log_dist] [Rank 0] step=20, skipped=0, lr=[1.2481069865194482e-05], mom=[(0.9, 0.999)]
steps: 20 loss: 0.8534 iter time (s): 120.389 samples/sec: 1.063

100%|██████████| 1/1 [02:00<00:00, 120.98s/it][A100%|██████████| 1/1 [02:00<00:00, 120.98s/it]
  0%|          | 20/5198 [46:02<188:43:39, 131.21s/it]
100%|██████████| 1/1 [02:00<00:00, 120.94s/it][A100%|██████████| 1/1 [02:00<00:00, 120.94s/it]
  0%|          | 20/5198 [46:02<188:41:31, 131.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.93s/it][A100%|██████████| 1/1 [02:00<00:00, 120.93s/it]
  0%|          | 20/5198 [46:02<188:42:25, 131.20s/it]
100%|██████████| 1/1 [02:01<00:00, 121.04s/it][A100%|██████████| 1/1 [02:01<00:00, 121.04s/it]
  0%|          | 20/5198 [46:02<188:42:42, 131.20s/it]
100%|██████████| 1/1 [02:00<00:00, 120.90s/it][A100%|██████████| 1/1 [02:00<00:00, 120.90s/it]
  0%|          | 20/5198 [46:02<188:40:42, 131.18s/it]
100%|██████████| 1/1 [02:01<00:00, 121.02s/it][A100%|██████████| 1/1 [02:01<00:00, 121.02s/it]
  0%|          | 20/5198 [46:02<188:42:22, 131.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:01<00:00, 121.15s/it][A100%|██████████| 1/1 [02:01<00:00, 121.15s/it]
  0%|          | 20/5198 [46:05<188:42:19, 131.20s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_19

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.30s/it][A100%|██████████| 1/1 [01:56<00:00, 116.30s/it]
  0%|          | 21/5198 [47:59<182:57:37, 127.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 20:13:05,338] [INFO] [logging.py:96:log_dist] [Rank 0] step=21, skipped=0, lr=[1.2651770406063393e-05], mom=[(0.9, 0.999)]
steps: 21 loss: 0.7593 iter time (s): 117.062 samples/sec: 1.093

100%|██████████| 1/1 [01:57<00:00, 117.80s/it][A100%|██████████| 1/1 [01:57<00:00, 117.80s/it]
  0%|          | 21/5198 [48:00<182:57:37, 127.23s/it]
100%|██████████| 1/1 [01:57<00:00, 117.88s/it][A100%|██████████| 1/1 [01:57<00:00, 117.88s/it]
  0%|          | 21/5198 [48:00<182:57:24, 127.23s/it]
100%|██████████| 1/1 [01:57<00:00, 117.83s/it][A100%|██████████| 1/1 [01:57<00:00, 117.83s/it]
  0%|          | 21/5198 [48:00<182:57:09, 127.22s/it]
100%|██████████| 1/1 [01:57<00:00, 117.80s/it][A100%|██████████| 1/1 [01:57<00:00, 117.80s/it]
  0%|          | 21/5198 [48:00<182:59:22, 127.25s/it]
100%|██████████| 1/1 [01:57<00:00, 117.89s/it][A100%|██████████| 1/1 [01:57<00:00, 117.89s/it]
  0%|          | 21/5198 [48:00<182:56:56, 127.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:57<00:00, 117.86s/it][A100%|██████████| 1/1 [01:57<00:00, 117.86s/it]
  0%|          | 21/5198 [48:00<182:57:35, 127.23s/it]
100%|██████████| 1/1 [01:57<00:00, 117.90s/it][A100%|██████████| 1/1 [01:57<00:00, 117.90s/it]
  0%|          | 21/5198 [48:03<182:57:49, 127.23s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_20

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.36s/it][A100%|██████████| 1/1 [01:46<00:00, 106.36s/it]
  0%|          | 22/5198 [49:46<174:07:18, 121.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 20:14:52,237] [INFO] [logging.py:96:log_dist] [Rank 0] step=22, skipped=0, lr=[1.2814528453003555e-05], mom=[(0.9, 0.999)]
steps: 22 loss: 0.8265 iter time (s): 105.644 samples/sec: 1.212

100%|██████████| 1/1 [01:46<00:00, 106.48s/it][A100%|██████████| 1/1 [01:46<00:00, 106.48s/it]
  0%|          | 22/5198 [49:46<174:07:55, 121.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.66s/it][A100%|██████████| 1/1 [01:46<00:00, 106.66s/it]
  0%|          | 22/5198 [49:47<174:09:54, 121.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.75s/it][A100%|██████████| 1/1 [01:46<00:00, 106.75s/it]
  0%|          | 22/5198 [49:47<174:08:17, 121.12s/it]
100%|██████████| 1/1 [01:46<00:00, 106.80s/it][A100%|██████████| 1/1 [01:46<00:00, 106.81s/it]
  0%|          | 22/5198 [49:47<174:08:16, 121.12s/it]
100%|██████████| 1/1 [01:46<00:00, 106.86s/it][A100%|██████████| 1/1 [01:46<00:00, 106.86s/it]
  0%|          | 22/5198 [49:47<174:08:47, 121.12s/it]
100%|██████████| 1/1 [01:46<00:00, 106.52s/it][A100%|██████████| 1/1 [01:46<00:00, 106.52s/it]
  0%|          | 22/5198 [49:47<174:07:21, 121.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.47s/it][A100%|██████████| 1/1 [01:46<00:00, 106.47s/it]
  0%|          | 22/5198 [49:49<174:08:08, 121.11s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_21
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:47<00:00, 167.54s/it][A100%|██████████| 1/1 [02:47<00:00, 167.54s/it]
  0%|          | 23/5198 [52:34<194:18:40, 135.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 20:17:41,180] [INFO] [logging.py:96:log_dist] [Rank 0] step=23, skipped=0, lr=[1.297005037104973e-05], mom=[(0.9, 0.999)]
steps: 23 loss: 0.7258 iter time (s): 168.131 samples/sec: 0.761

100%|██████████| 1/1 [02:48<00:00, 168.97s/it][A100%|██████████| 1/1 [02:48<00:00, 168.97s/it]
  0%|          | 23/5198 [52:35<194:44:58, 135.48s/it]
100%|██████████| 1/1 [02:48<00:00, 168.84s/it][A100%|██████████| 1/1 [02:48<00:00, 168.84s/it]
  0%|          | 23/5198 [52:36<194:44:26, 135.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:48<00:00, 169.00s/it][A100%|██████████| 1/1 [02:48<00:00, 169.00s/it]
  0%|          | 23/5198 [52:36<194:49:34, 135.53s/it]
100%|██████████| 1/1 [02:49<00:00, 169.01s/it][A100%|██████████| 1/1 [02:49<00:00, 169.01s/it]
  0%|          | 23/5198 [52:36<194:47:14, 135.50s/it]
100%|██████████| 1/1 [02:49<00:00, 169.03s/it][A100%|██████████| 1/1 [02:49<00:00, 169.03s/it]
  0%|          | 23/5198 [52:36<194:48:58, 135.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:49<00:00, 169.07s/it][A100%|██████████| 1/1 [02:49<00:00, 169.07s/it]
  0%|          | 23/5198 [52:36<194:47:50, 135.51s/it]
100%|██████████| 1/1 [02:49<00:00, 169.06s/it][A100%|██████████| 1/1 [02:49<00:00, 169.06s/it]
  0%|          | 23/5198 [52:39<194:47:16, 135.50s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_22
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A

  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:17<00:00, 137.24s/it][A100%|██████████| 1/1 [02:17<00:00, 137.24s/it]
  0%|          | 24/5198 [54:52<195:43:45, 136.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 20:19:58,367] [INFO] [logging.py:96:log_dist] [Rank 0] step=24, skipped=0, lr=[1.3118952292659016e-05], mom=[(0.9, 0.999)]
steps: 24 loss: 0.7245 iter time (s): 135.892 samples/sec: 0.942

100%|██████████| 1/1 [02:16<00:00, 136.76s/it][A100%|██████████| 1/1 [02:16<00:00, 136.76s/it]
  0%|          | 24/5198 [54:53<195:27:14, 135.99s/it]
100%|██████████| 1/1 [02:16<00:00, 136.90s/it][A100%|██████████| 1/1 [02:16<00:00, 136.90s/it]
  0%|          | 24/5198 [54:53<195:30:00, 136.03s/it]
100%|██████████| 1/1 [02:16<00:00, 136.48s/it][A100%|██████████| 1/1 [02:16<00:00, 136.48s/it]
  0%|          | 24/5198 [54:53<195:25:56, 135.98s/it]
100%|██████████| 1/1 [02:16<00:00, 136.48s/it][A100%|██████████| 1/1 [02:16<00:00, 136.48s/it]
  0%|          | 24/5198 [54:53<195:27:24, 136.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:16<00:00, 136.63s/it][A100%|██████████| 1/1 [02:16<00:00, 136.63s/it]
  0%|          | 24/5198 [54:53<195:27:32, 136.00s/it]
100%|██████████| 1/1 [02:16<00:00, 136.67s/it][A100%|██████████| 1/1 [02:16<00:00, 136.67s/it]
  0%|          | 24/5198 [54:53<195:27:14, 135.99s/it]
100%|██████████| 1/1 [02:16<00:00, 136.70s/it][A100%|██████████| 1/1 [02:16<00:00, 136.71s/it]
  0%|          | 24/5198 [54:56<195:27:14, 135.99s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_23

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:26<00:00, 146.79s/it][A100%|██████████| 1/1 [02:26<00:00, 146.79s/it]
  0%|          | 25/5198 [57:20<200:43:58, 139.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 20:22:26,389] [INFO] [logging.py:96:log_dist] [Rank 0] step=25, skipped=0, lr=[1.3261774860743774e-05], mom=[(0.9, 0.999)]
steps: 25 loss: 0.7446 iter time (s): 146.950 samples/sec: 0.871

100%|██████████| 1/1 [02:27<00:00, 147.60s/it][A100%|██████████| 1/1 [02:27<00:00, 147.60s/it]
  0%|          | 25/5198 [57:21<200:35:15, 139.59s/it]
100%|██████████| 1/1 [02:27<00:00, 147.69s/it][A100%|██████████| 1/1 [02:27<00:00, 147.69s/it]
  0%|          | 25/5198 [57:21<200:34:43, 139.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:27<00:00, 147.70s/it][A100%|██████████| 1/1 [02:27<00:00, 147.70s/it]
  0%|          | 25/5198 [57:21<200:34:14, 139.58s/it]
100%|██████████| 1/1 [02:26<00:00, 147.00s/it][A100%|██████████| 1/1 [02:26<00:00, 147.00s/it]
  0%|          | 25/5198 [57:21<200:36:19, 139.61s/it]
100%|██████████| 1/1 [02:27<00:00, 147.77s/it][A100%|██████████| 1/1 [02:27<00:00, 147.77s/it]
  0%|          | 25/5198 [57:21<200:35:09, 139.59s/it]
100%|██████████| 1/1 [02:27<00:00, 147.82s/it][A100%|██████████| 1/1 [02:27<00:00, 147.82s/it]
  0%|          | 25/5198 [57:21<200:34:18, 139.58s/it]
100%|██████████| 1/1 [02:27<00:00, 147.77s/it][A100%|██████████| 1/1 [02:27<00:00, 147.77s/it]
  0%|          | 25/5198 [57:24<200:34:50, 139.59s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_24

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:33<00:00, 153.56s/it][A100%|██████████| 1/1 [02:33<00:00, 153.56s/it]
  1%|          | 26/5198 [59:55<207:07:37, 144.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 20:25:01,381] [INFO] [logging.py:96:log_dist] [Rank 0] step=26, skipped=0, lr=[1.3398995078435195e-05], mom=[(0.9, 0.999)]
steps: 26 loss: 0.6869 iter time (s): 153.754 samples/sec: 0.833

100%|██████████| 1/1 [02:34<00:00, 154.81s/it][A100%|██████████| 1/1 [02:34<00:00, 154.81s/it]
  1%|          | 26/5198 [59:56<207:13:21, 144.24s/it]
100%|██████████| 1/1 [02:34<00:00, 154.62s/it][A100%|██████████| 1/1 [02:34<00:00, 154.62s/it]
  1%|          | 26/5198 [59:56<207:11:57, 144.22s/it]
100%|██████████| 1/1 [02:34<00:00, 154.62s/it][A100%|██████████| 1/1 [02:34<00:00, 154.62s/it]
  1%|          | 26/5198 [59:56<207:10:49, 144.21s/it]
100%|██████████| 1/1 [02:34<00:00, 154.47s/it][A100%|██████████| 1/1 [02:34<00:00, 154.47s/it]
  1%|          | 26/5198 [59:56<207:10:55, 144.21s/it]
100%|██████████| 1/1 [02:34<00:00, 154.74s/it][A100%|██████████| 1/1 [02:34<00:00, 154.74s/it]
  1%|          | 26/5198 [59:56<207:12:32, 144.23s/it]
100%|██████████| 1/1 [02:34<00:00, 154.54s/it][A100%|██████████| 1/1 [02:34<00:00, 154.54s/it]
  1%|          | 26/5198 [59:56<207:11:40, 144.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:34<00:00, 154.57s/it][A100%|██████████| 1/1 [02:34<00:00, 154.57s/it]
  1%|          | 26/5198 [59:59<207:11:39, 144.22s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_25

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:56<00:00, 176.68s/it][A100%|██████████| 1/1 [02:56<00:00, 176.68s/it]
  1%|          | 27/5198 [1:02:53<221:37:36, 154.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 20:27:59,763] [INFO] [logging.py:96:log_dist] [Rank 0] step=27, skipped=0, lr=[1.3531035921275369e-05], mom=[(0.9, 0.999)]
steps: 27 loss: 0.7081 iter time (s): 177.226 samples/sec: 0.722

100%|██████████| 1/1 [02:57<00:00, 177.84s/it][A100%|██████████| 1/1 [02:57<00:00, 177.84s/it]
  1%|          | 27/5198 [1:02:54<221:50:37, 154.45s/it]
100%|██████████| 1/1 [02:58<00:00, 178.06s/it][A100%|██████████| 1/1 [02:58<00:00, 178.06s/it]
  1%|          | 27/5198 [1:02:54<221:53:06, 154.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:58<00:00, 178.20s/it][A100%|██████████| 1/1 [02:58<00:00, 178.20s/it]
  1%|          | 27/5198 [1:02:55<221:53:30, 154.48s/it]
100%|██████████| 1/1 [02:58<00:00, 178.17s/it][A100%|██████████| 1/1 [02:58<00:00, 178.17s/it]
  1%|          | 27/5198 [1:02:55<221:53:00, 154.47s/it]
100%|██████████| 1/1 [02:58<00:00, 178.19s/it][A100%|██████████| 1/1 [02:58<00:00, 178.19s/it]
  1%|          | 27/5198 [1:02:55<221:52:33, 154.47s/it]
100%|██████████| 1/1 [02:58<00:00, 178.15s/it][A100%|██████████| 1/1 [02:58<00:00, 178.15s/it]
  1%|          | 27/5198 [1:02:55<221:52:59, 154.47s/it]
100%|██████████| 1/1 [02:58<00:00, 178.06s/it][A100%|██████████| 1/1 [02:58<00:00, 178.06s/it]
  1%|          | 27/5198 [1:02:57<221:53:24, 154.48s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_26

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:25<00:00, 145.84s/it][A100%|██████████| 1/1 [02:25<00:00, 145.84s/it]
  1%|          | 28/5198 [1:05:20<218:22:25, 152.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 20:30:25,553] [INFO] [logging.py:96:log_dist] [Rank 0] step=28, skipped=0, lr=[1.3658274200460865e-05], mom=[(0.9, 0.999)]
steps: 28 loss: 0.7604 iter time (s): 144.754 samples/sec: 0.884

100%|██████████| 1/1 [02:25<00:00, 145.76s/it][A100%|██████████| 1/1 [02:25<00:00, 145.76s/it]
  1%|          | 28/5198 [1:05:20<218:10:19, 151.92s/it]
100%|██████████| 1/1 [02:25<00:00, 145.46s/it][A100%|██████████| 1/1 [02:25<00:00, 145.46s/it]
  1%|          | 28/5198 [1:05:20<218:08:25, 151.90s/it]
100%|██████████| 1/1 [02:25<00:00, 145.47s/it][A100%|██████████| 1/1 [02:25<00:00, 145.47s/it]
  1%|          | 28/5198 [1:05:20<218:07:34, 151.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:25<00:00, 145.60s/it][A100%|██████████| 1/1 [02:25<00:00, 145.60s/it]
  1%|          | 28/5198 [1:05:21<218:09:31, 151.91s/it]
100%|██████████| 1/1 [02:25<00:00, 145.64s/it][A100%|██████████| 1/1 [02:25<00:00, 145.64s/it]
  1%|          | 28/5198 [1:05:21<218:09:38, 151.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:25<00:00, 145.57s/it][A100%|██████████| 1/1 [02:25<00:00, 145.57s/it]
  1%|          | 28/5198 [1:05:21<218:09:54, 151.91s/it]
100%|██████████| 1/1 [02:25<00:00, 145.64s/it][A100%|██████████| 1/1 [02:25<00:00, 145.64s/it]
  1%|          | 28/5198 [1:05:23<218:10:39, 151.92s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_27

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:23<00:00, 143.60s/it][A100%|██████████| 1/1 [02:23<00:00, 143.60s/it]
  1%|          | 29/5198 [1:07:44<215:10:50, 149.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 20:32:50,786] [INFO] [logging.py:96:log_dist] [Rank 0] step=29, skipped=0, lr=[1.3781047045634868e-05], mom=[(0.9, 0.999)]
steps: 29 loss: 0.6957 iter time (s): 143.567 samples/sec: 0.892

100%|██████████| 1/1 [02:24<00:00, 144.69s/it][A100%|██████████| 1/1 [02:24<00:00, 144.69s/it]
  1%|          | 29/5198 [1:07:45<215:07:48, 149.83s/it]
100%|██████████| 1/1 [02:24<00:00, 144.80s/it][A100%|██████████| 1/1 [02:24<00:00, 144.80s/it]
  1%|          | 29/5198 [1:07:45<215:08:03, 149.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:24<00:00, 144.89s/it][A100%|██████████| 1/1 [02:24<00:00, 144.89s/it]
  1%|          | 29/5198 [1:07:46<215:08:55, 149.84s/it]
100%|██████████| 1/1 [02:24<00:00, 144.58s/it][A100%|██████████| 1/1 [02:24<00:00, 144.58s/it]
  1%|          | 29/5198 [1:07:46<215:09:11, 149.85s/it]
100%|██████████| 1/1 [02:24<00:00, 144.39s/it][A100%|██████████| 1/1 [02:24<00:00, 144.39s/it]
  1%|          | 29/5198 [1:07:46<215:08:49, 149.84s/it]
100%|██████████| 1/1 [02:24<00:00, 144.45s/it][A100%|██████████| 1/1 [02:24<00:00, 144.45s/it]
  1%|          | 29/5198 [1:07:46<215:08:53, 149.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:24<00:00, 144.41s/it][A100%|██████████| 1/1 [02:24<00:00, 144.41s/it]
  1%|          | 29/5198 [1:07:48<215:08:48, 149.84s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_28

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:04<00:00, 124.37s/it][A100%|██████████| 1/1 [02:04<00:00, 124.37s/it]
  1%|          | 30/5198 [1:09:50<204:38:26, 142.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 20:34:55,912] [INFO] [logging.py:96:log_dist] [Rank 0] step=30, skipped=0, lr=[1.3899657288208308e-05], mom=[(0.9, 0.999)]
steps: 30 loss: 0.7090 iter time (s): 123.877 samples/sec: 1.033

100%|██████████| 1/1 [02:04<00:00, 124.96s/it][A100%|██████████| 1/1 [02:04<00:00, 124.96s/it]
  1%|          | 30/5198 [1:09:50<204:29:10, 142.44s/it]
100%|██████████| 1/1 [02:04<00:00, 124.85s/it][A100%|██████████| 1/1 [02:04<00:00, 124.85s/it]
  1%|          | 30/5198 [1:09:50<204:30:00, 142.45s/it]
100%|██████████| 1/1 [02:04<00:00, 124.80s/it][A100%|██████████| 1/1 [02:04<00:00, 124.80s/it]
  1%|          | 30/5198 [1:09:51<204:27:40, 142.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:04<00:00, 124.92s/it][A100%|██████████| 1/1 [02:04<00:00, 124.92s/it]
  1%|          | 30/5198 [1:09:51<204:28:52, 142.44s/it]
100%|██████████| 1/1 [02:04<00:00, 124.96s/it][A100%|██████████| 1/1 [02:04<00:00, 124.96s/it]
  1%|          | 30/5198 [1:09:51<204:28:15, 142.43s/it]
100%|██████████| 1/1 [02:04<00:00, 124.95s/it][A100%|██████████| 1/1 [02:04<00:00, 124.95s/it]
  1%|          | 30/5198 [1:09:51<204:29:54, 142.45s/it]
100%|██████████| 1/1 [02:04<00:00, 124.73s/it][A100%|██████████| 1/1 [02:04<00:00, 124.73s/it]
  1%|          | 30/5198 [1:09:53<204:28:28, 142.44s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_29

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:40<00:00, 160.64s/it][A100%|██████████| 1/1 [02:40<00:00, 160.64s/it]
  1%|          | 31/5198 [1:12:32<212:53:02, 148.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 20:37:38,596] [INFO] [logging.py:96:log_dist] [Rank 0] step=31, skipped=0, lr=[1.4014377961650662e-05], mom=[(0.9, 0.999)]
steps: 31 loss: 0.7584 iter time (s): 161.585 samples/sec: 0.792

100%|██████████| 1/1 [02:42<00:00, 162.52s/it][A100%|██████████| 1/1 [02:42<00:00, 162.52s/it]
  1%|          | 31/5198 [1:12:33<213:13:31, 148.56s/it]
100%|██████████| 1/1 [02:42<00:00, 162.32s/it][A100%|██████████| 1/1 [02:42<00:00, 162.32s/it]
  1%|          | 31/5198 [1:12:33<213:12:22, 148.55s/it]
100%|██████████| 1/1 [02:42<00:00, 162.54s/it][A100%|██████████| 1/1 [02:42<00:00, 162.54s/it]
  1%|          | 31/5198 [1:12:34<213:14:20, 148.57s/it]
100%|██████████| 1/1 [02:42<00:00, 162.49s/it][A100%|██████████| 1/1 [02:42<00:00, 162.49s/it]
  1%|          | 31/5198 [1:12:34<213:13:48, 148.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:42<00:00, 162.59s/it][A100%|██████████| 1/1 [02:42<00:00, 162.59s/it]
  1%|          | 31/5198 [1:12:34<213:13:56, 148.57s/it]
100%|██████████| 1/1 [02:42<00:00, 162.70s/it][A100%|██████████| 1/1 [02:42<00:00, 162.70s/it]
  1%|          | 31/5198 [1:12:34<213:14:49, 148.58s/it]
100%|██████████| 1/1 [02:42<00:00, 162.47s/it][A100%|██████████| 1/1 [02:42<00:00, 162.47s/it]
  1%|          | 31/5198 [1:12:36<213:14:07, 148.57s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_1

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.29s/it][A100%|██████████| 1/1 [01:58<00:00, 118.29s/it]
  1%|          | 32/5198 [1:14:31<200:12:58, 139.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 20:39:37,316] [INFO] [logging.py:96:log_dist] [Rank 0] step=32, skipped=0, lr=[1.4125456087056486e-05], mom=[(0.9, 0.999)]
steps: 32 loss: 1.0038 iter time (s): 117.693 samples/sec: 1.088

100%|██████████| 1/1 [01:58<00:00, 118.45s/it][A100%|██████████| 1/1 [01:58<00:00, 118.45s/it]
  1%|          | 32/5198 [1:14:32<200:24:20, 139.66s/it]
100%|██████████| 1/1 [01:58<00:00, 118.60s/it][A100%|██████████| 1/1 [01:58<00:00, 118.60s/it]
  1%|          | 32/5198 [1:14:32<200:24:45, 139.66s/it]
100%|██████████| 1/1 [01:58<00:00, 118.54s/it][A100%|██████████| 1/1 [01:58<00:00, 118.54s/it]
  1%|          | 32/5198 [1:14:32<200:23:19, 139.64s/it]
100%|██████████| 1/1 [01:58<00:00, 118.46s/it][A100%|██████████| 1/1 [01:58<00:00, 118.46s/it]
  1%|          | 32/5198 [1:14:32<200:22:04, 139.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.46s/it][A100%|██████████| 1/1 [01:58<00:00, 118.46s/it]
  1%|          | 32/5198 [1:14:33<200:24:27, 139.66s/it]
100%|██████████| 1/1 [01:58<00:00, 118.57s/it][A100%|██████████| 1/1 [01:58<00:00, 118.57s/it]
  1%|          | 32/5198 [1:14:33<200:24:07, 139.65s/it]
100%|██████████| 1/1 [01:58<00:00, 118.66s/it][A100%|██████████| 1/1 [01:58<00:00, 118.66s/it]
  1%|          | 32/5198 [1:14:35<200:23:37, 139.65s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_30
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.68s/it][A100%|██████████| 1/1 [01:56<00:00, 116.68s/it]
  1%|          | 33/5198 [1:16:28<190:44:41, 132.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 20:41:34,129] [INFO] [logging.py:96:log_dist] [Rank 0] step=33, skipped=0, lr=[1.423311587601738e-05], mom=[(0.9, 0.999)]
steps: 33 loss: 0.7162 iter time (s): 115.562 samples/sec: 1.108

100%|██████████| 1/1 [01:56<00:00, 116.29s/it][A100%|██████████| 1/1 [01:56<00:00, 116.29s/it]
  1%|          | 33/5198 [1:16:28<190:27:11, 132.75s/it]
100%|██████████| 1/1 [01:56<00:00, 116.38s/it][A100%|██████████| 1/1 [01:56<00:00, 116.38s/it]
  1%|          | 33/5198 [1:16:29<190:26:55, 132.74s/it]
100%|██████████| 1/1 [01:56<00:00, 116.39s/it][A100%|██████████| 1/1 [01:56<00:00, 116.39s/it]
  1%|          | 33/5198 [1:16:29<190:24:39, 132.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.17s/it][A100%|██████████| 1/1 [01:56<00:00, 116.17s/it]
  1%|          | 33/5198 [1:16:29<190:27:07, 132.74s/it]
100%|██████████| 1/1 [01:56<00:00, 116.23s/it][A100%|██████████| 1/1 [01:56<00:00, 116.23s/it]
  1%|          | 33/5198 [1:16:29<190:26:14, 132.73s/it]
100%|██████████| 1/1 [01:56<00:00, 116.24s/it][A100%|██████████| 1/1 [01:56<00:00, 116.24s/it]
  1%|          | 33/5198 [1:16:29<190:25:31, 132.73s/it]
100%|██████████| 1/1 [01:56<00:00, 116.34s/it][A100%|██████████| 1/1 [01:56<00:00, 116.34s/it]
  1%|          | 33/5198 [1:16:31<190:26:01, 132.73s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_31

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:37<00:00, 157.47s/it][A100%|██████████| 1/1 [02:37<00:00, 157.48s/it]
  1%|          | 34/5198 [1:19:07<201:41:06, 140.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 20:44:13,700] [INFO] [logging.py:96:log_dist] [Rank 0] step=34, skipped=0, lr=[1.4337561455222523e-05], mom=[(0.9, 0.999)]
steps: 34 loss: 0.7292 iter time (s): 158.266 samples/sec: 0.809

100%|██████████| 1/1 [02:39<00:00, 159.33s/it][A100%|██████████| 1/1 [02:39<00:00, 159.33s/it]
  1%|          | 34/5198 [1:19:08<201:57:05, 140.79s/it]
100%|██████████| 1/1 [02:39<00:00, 159.09s/it][A100%|██████████| 1/1 [02:39<00:00, 159.09s/it]
  1%|          | 34/5198 [1:19:08<201:55:28, 140.77s/it]
100%|██████████| 1/1 [02:39<00:00, 159.10s/it][A100%|██████████| 1/1 [02:39<00:00, 159.10s/it]
  1%|          | 34/5198 [1:19:08<201:52:58, 140.74s/it]
100%|██████████| 1/1 [02:39<00:00, 159.21s/it][A100%|██████████| 1/1 [02:39<00:00, 159.21s/it]
  1%|          | 34/5198 [1:19:09<201:57:28, 140.79s/it]
100%|██████████| 1/1 [02:39<00:00, 159.15s/it][A100%|██████████| 1/1 [02:39<00:00, 159.15s/it]
  1%|          | 34/5198 [1:19:09<201:53:59, 140.75s/it]
100%|██████████| 1/1 [02:39<00:00, 159.24s/it][A100%|██████████| 1/1 [02:39<00:00, 159.24s/it]
  1%|          | 34/5198 [1:19:09<201:53:51, 140.75s/it]
100%|██████████| 1/1 [02:39<00:00, 159.02s/it][A100%|██████████| 1/1 [02:39<00:00, 159.02s/it]
  1%|          | 34/5198 [1:19:11<201:55:11, 140.77s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_32

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:02<00:00, 122.33s/it][A100%|██████████| 1/1 [02:02<00:00, 122.33s/it]
  1%|          | 35/5198 [1:21:10<194:17:30, 135.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 20:46:16,222] [INFO] [logging.py:96:log_dist] [Rank 0] step=35, skipped=0, lr=[1.4438979196010159e-05], mom=[(0.9, 0.999)]
steps: 35 loss: 0.7677 iter time (s): 121.252 samples/sec: 1.056

100%|██████████| 1/1 [02:01<00:00, 121.94s/it][A100%|██████████| 1/1 [02:01<00:00, 121.94s/it]
  1%|          | 35/5198 [1:21:10<193:59:36, 135.27s/it]
100%|██████████| 1/1 [02:02<00:00, 122.06s/it][A100%|██████████| 1/1 [02:02<00:00, 122.06s/it]
  1%|          | 35/5198 [1:21:11<194:00:22, 135.27s/it]
100%|██████████| 1/1 [02:02<00:00, 122.14s/it][A100%|██████████| 1/1 [02:02<00:00, 122.14s/it]
  1%|          | 35/5198 [1:21:11<193:58:58, 135.26s/it]
100%|██████████| 1/1 [02:02<00:00, 122.29s/it][A100%|██████████| 1/1 [02:02<00:00, 122.29s/it]
  1%|          | 35/5198 [1:21:11<194:01:12, 135.28s/it]
100%|██████████| 1/1 [02:02<00:00, 122.11s/it][A100%|██████████| 1/1 [02:02<00:00, 122.11s/it]
  1%|          | 35/5198 [1:21:11<193:59:45, 135.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:02<00:00, 122.32s/it][A100%|██████████| 1/1 [02:02<00:00, 122.32s/it]
  1%|          | 35/5198 [1:21:11<194:01:05, 135.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:02<00:00, 122.11s/it][A100%|██████████| 1/1 [02:02<00:00, 122.11s/it]
  1%|          | 35/5198 [1:21:13<194:00:49, 135.28s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_33

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.20s/it][A100%|██████████| 1/1 [02:00<00:00, 120.20s/it]
  1%|          | 36/5198 [1:23:11<188:04:35, 131.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 20:48:17,239] [INFO] [logging.py:96:log_dist] [Rank 0] step=36, skipped=0, lr=[1.453753971567284e-05], mom=[(0.9, 0.999)]
steps: 36 loss: 0.7347 iter time (s): 119.949 samples/sec: 1.067

100%|██████████| 1/1 [02:00<00:00, 120.64s/it][A100%|██████████| 1/1 [02:00<00:00, 120.64s/it]
  1%|          | 36/5198 [1:23:11<187:50:02, 131.00s/it]
100%|██████████| 1/1 [02:00<00:00, 120.78s/it][A100%|██████████| 1/1 [02:00<00:00, 120.78s/it]
  1%|          | 36/5198 [1:23:12<187:51:02, 131.01s/it]
100%|██████████| 1/1 [02:00<00:00, 120.83s/it][A100%|██████████| 1/1 [02:00<00:00, 120.83s/it]
  1%|          | 36/5198 [1:23:12<187:50:42, 131.00s/it]
100%|██████████| 1/1 [02:00<00:00, 120.74s/it][A100%|██████████| 1/1 [02:00<00:00, 120.74s/it]
  1%|          | 36/5198 [1:23:12<187:51:00, 131.01s/it]
100%|██████████| 1/1 [02:00<00:00, 120.61s/it][A100%|██████████| 1/1 [02:00<00:00, 120.61s/it]
  1%|          | 36/5198 [1:23:12<187:50:37, 131.00s/it]
100%|██████████| 1/1 [02:00<00:00, 120.57s/it][A100%|██████████| 1/1 [02:00<00:00, 120.57s/it]
  1%|          | 36/5198 [1:23:12<187:50:52, 131.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.71s/it][A100%|██████████| 1/1 [02:00<00:00, 120.71s/it]
  1%|          | 36/5198 [1:23:14<187:50:34, 131.00s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_34

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:15<00:00, 135.97s/it][A100%|██████████| 1/1 [02:15<00:00, 135.97s/it]
  1%|          | 37/5198 [1:25:28<190:34:27, 132.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 20:50:34,791] [INFO] [logging.py:96:log_dist] [Rank 0] step=37, skipped=0, lr=[1.4633399604500489e-05], mom=[(0.9, 0.999)]
steps: 37 loss: 0.7273 iter time (s): 136.268 samples/sec: 0.939

100%|██████████| 1/1 [02:17<00:00, 137.04s/it][A100%|██████████| 1/1 [02:17<00:00, 137.04s/it]
  1%|          | 37/5198 [1:25:29<190:35:53, 132.95s/it]
100%|██████████| 1/1 [02:17<00:00, 137.22s/it][A100%|██████████| 1/1 [02:17<00:00, 137.23s/it]
  1%|          | 37/5198 [1:25:29<190:37:17, 132.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:17<00:00, 137.53s/it][A100%|██████████| 1/1 [02:17<00:00, 137.53s/it]
  1%|          | 37/5198 [1:25:30<190:42:00, 133.02s/it]
100%|██████████| 1/1 [02:17<00:00, 137.30s/it][A100%|██████████| 1/1 [02:17<00:00, 137.30s/it]
  1%|          | 37/5198 [1:25:30<190:41:08, 133.01s/it]
100%|██████████| 1/1 [02:17<00:00, 137.32s/it][A100%|██████████| 1/1 [02:17<00:00, 137.32s/it]
  1%|          | 37/5198 [1:25:30<190:40:24, 133.00s/it]
100%|██████████| 1/1 [02:17<00:00, 137.34s/it][A100%|██████████| 1/1 [02:17<00:00, 137.34s/it]
  1%|          | 37/5198 [1:25:30<190:39:37, 132.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:17<00:00, 137.21s/it][A100%|██████████| 1/1 [02:17<00:00, 137.21s/it]
  1%|          | 37/5198 [1:25:32<190:39:25, 132.99s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_35

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:04<00:00, 124.55s/it][A100%|██████████| 1/1 [02:04<00:00, 124.55s/it]
  1%|          | 38/5198 [1:27:34<187:25:00, 130.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 20:52:40,152] [INFO] [logging.py:96:log_dist] [Rank 0] step=38, skipped=0, lr=[1.4726702922463145e-05], mom=[(0.9, 0.999)]
steps: 38 loss: 0.6785 iter time (s): 124.217 samples/sec: 1.030

100%|██████████| 1/1 [02:05<00:00, 125.09s/it][A100%|██████████| 1/1 [02:05<00:00, 125.09s/it]
  1%|          | 38/5198 [1:27:34<187:19:46, 130.69s/it]
100%|██████████| 1/1 [02:04<00:00, 124.96s/it][A100%|██████████| 1/1 [02:04<00:00, 124.96s/it]
  1%|          | 38/5198 [1:27:34<187:18:48, 130.68s/it]
100%|██████████| 1/1 [02:04<00:00, 124.95s/it][A100%|██████████| 1/1 [02:04<00:00, 124.95s/it]
  1%|          | 38/5198 [1:27:35<187:19:38, 130.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:04<00:00, 124.87s/it][A100%|██████████| 1/1 [02:04<00:00, 124.87s/it]
  1%|          | 38/5198 [1:27:35<187:17:55, 130.67s/it]
100%|██████████| 1/1 [02:04<00:00, 124.87s/it][A100%|██████████| 1/1 [02:04<00:00, 124.87s/it]
  1%|          | 38/5198 [1:27:35<187:19:05, 130.69s/it]
100%|██████████| 1/1 [02:04<00:00, 124.88s/it][A100%|██████████| 1/1 [02:04<00:00, 124.88s/it]
  1%|          | 38/5198 [1:27:35<187:19:10, 130.69s/it]
100%|██████████| 1/1 [02:04<00:00, 124.98s/it][A100%|██████████| 1/1 [02:04<00:00, 124.98s/it]
  1%|          | 38/5198 [1:27:37<187:18:23, 130.68s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_36
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:13<00:00, 133.85s/it][A100%|██████████| 1/1 [02:13<00:00, 133.85s/it]
  1%|          | 39/5198 [1:29:49<189:07:06, 131.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 20:54:55,124] [INFO] [logging.py:96:log_dist] [Rank 0] step=39, skipped=0, lr=[1.481758250144902e-05], mom=[(0.9, 0.999)]
steps: 39 loss: 0.7298 iter time (s): 134.077 samples/sec: 0.955

100%|██████████| 1/1 [02:14<00:00, 134.34s/it][A100%|██████████| 1/1 [02:14<00:00, 134.34s/it]
  1%|          | 39/5198 [1:29:49<189:07:37, 131.97s/it]
100%|██████████| 1/1 [02:14<00:00, 134.67s/it][A100%|██████████| 1/1 [02:14<00:00, 134.67s/it]
  1%|          | 39/5198 [1:29:49<189:06:02, 131.96s/it]
100%|██████████| 1/1 [02:14<00:00, 134.50s/it][A100%|██████████| 1/1 [02:14<00:00, 134.50s/it]
  1%|          | 39/5198 [1:29:50<189:07:27, 131.97s/it]
100%|██████████| 1/1 [02:14<00:00, 134.53s/it][A100%|██████████| 1/1 [02:14<00:00, 134.53s/it]
  1%|          | 39/5198 [1:29:50<189:06:42, 131.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:14<00:00, 134.73s/it][A100%|██████████| 1/1 [02:14<00:00, 134.73s/it]
  1%|          | 39/5198 [1:29:50<189:07:23, 131.97s/it]
100%|██████████| 1/1 [02:14<00:00, 134.57s/it][A100%|██████████| 1/1 [02:14<00:00, 134.57s/it]
  1%|          | 39/5198 [1:29:50<189:06:35, 131.96s/it]
100%|██████████| 1/1 [02:14<00:00, 134.84s/it][A100%|██████████| 1/1 [02:14<00:00, 134.84s/it]
  1%|          | 39/5198 [1:29:52<189:06:58, 131.97s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_37

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:06<00:00, 126.18s/it][A100%|██████████| 1/1 [02:06<00:00, 126.18s/it]
  1%|          | 40/5198 [1:31:56<186:54:51, 130.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 20:57:01,732] [INFO] [logging.py:96:log_dist] [Rank 0] step=40, skipped=0, lr=[1.4906161082605778e-05], mom=[(0.9, 0.999)]
steps: 40 loss: 0.7736 iter time (s): 125.136 samples/sec: 1.023

100%|██████████| 1/1 [02:06<00:00, 126.37s/it][A100%|██████████| 1/1 [02:06<00:00, 126.37s/it]
  1%|          | 40/5198 [1:31:56<186:50:52, 130.41s/it]
100%|██████████| 1/1 [02:06<00:00, 126.49s/it][A100%|██████████| 1/1 [02:06<00:00, 126.49s/it]
  1%|          | 40/5198 [1:31:56<186:51:22, 130.42s/it]
100%|██████████| 1/1 [02:06<00:00, 126.35s/it][A100%|██████████| 1/1 [02:06<00:00, 126.35s/it]
  1%|          | 40/5198 [1:31:57<186:48:34, 130.38s/it]
100%|██████████| 1/1 [02:06<00:00, 126.42s/it][A100%|██████████| 1/1 [02:06<00:00, 126.42s/it]
  1%|          | 40/5198 [1:31:57<186:48:56, 130.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:06<00:00, 126.34s/it][A100%|██████████| 1/1 [02:06<00:00, 126.34s/it]
  1%|          | 40/5198 [1:31:57<186:48:48, 130.39s/it]
100%|██████████| 1/1 [02:06<00:00, 126.49s/it][A100%|██████████| 1/1 [02:06<00:00, 126.49s/it]
  1%|          | 40/5198 [1:31:57<186:50:09, 130.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:06<00:00, 126.08s/it][A100%|██████████| 1/1 [02:06<00:00, 126.08s/it]
  1%|          | 40/5198 [1:31:59<186:49:22, 130.39s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_38

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:10<00:00, 130.15s/it][A100%|██████████| 1/1 [02:10<00:00, 130.15s/it]
  1%|          | 41/5198 [1:34:07<187:12:26, 130.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 20:59:13,229] [INFO] [logging.py:96:log_dist] [Rank 0] step=41, skipped=0, lr=[1.4992552313223604e-05], mom=[(0.9, 0.999)]
steps: 41 loss: 0.7303 iter time (s): 130.144 samples/sec: 0.984

100%|██████████| 1/1 [02:10<00:00, 130.97s/it][A100%|██████████| 1/1 [02:10<00:00, 130.97s/it]
  1%|          | 41/5198 [1:34:07<187:12:36, 130.69s/it]
100%|██████████| 1/1 [02:11<00:00, 131.00s/it][A100%|██████████| 1/1 [02:11<00:00, 131.00s/it]
  1%|          | 41/5198 [1:34:08<187:11:06, 130.67s/it]
100%|██████████| 1/1 [02:11<00:00, 131.07s/it][A100%|██████████| 1/1 [02:11<00:00, 131.07s/it]
  1%|          | 41/5198 [1:34:08<187:12:58, 130.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:11<00:00, 131.13s/it][A100%|██████████| 1/1 [02:11<00:00, 131.13s/it]
  1%|          | 41/5198 [1:34:08<187:14:33, 130.71s/it]
100%|██████████| 1/1 [02:11<00:00, 131.16s/it][A100%|██████████| 1/1 [02:11<00:00, 131.16s/it]
  1%|          | 41/5198 [1:34:08<187:14:00, 130.70s/it]
100%|██████████| 1/1 [02:11<00:00, 131.18s/it][A100%|██████████| 1/1 [02:11<00:00, 131.18s/it]
  1%|          | 41/5198 [1:34:08<187:13:44, 130.70s/it]
100%|██████████| 1/1 [02:11<00:00, 131.07s/it][A100%|██████████| 1/1 [02:11<00:00, 131.07s/it]
  1%|          | 41/5198 [1:34:11<187:14:20, 130.71s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_39

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:11<00:00, 131.21s/it][A100%|██████████| 1/1 [02:11<00:00, 131.21s/it]
  1%|          | 42/5198 [1:36:19<187:44:44, 131.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 21:01:25,298] [INFO] [logging.py:96:log_dist] [Rank 0] step=42, skipped=0, lr=[1.5076861623474692e-05], mom=[(0.9, 0.999)]
steps: 42 loss: 0.6989 iter time (s): 130.949 samples/sec: 0.977

100%|██████████| 1/1 [02:11<00:00, 131.73s/it][A100%|██████████| 1/1 [02:11<00:00, 131.73s/it]
  1%|          | 42/5198 [1:36:20<187:46:26, 131.11s/it]
100%|██████████| 1/1 [02:11<00:00, 131.82s/it][A100%|██████████| 1/1 [02:11<00:00, 131.82s/it]
  1%|          | 42/5198 [1:36:20<187:46:40, 131.11s/it]
100%|██████████| 1/1 [02:11<00:00, 131.67s/it][A100%|██████████| 1/1 [02:11<00:00, 131.67s/it]
  1%|          | 42/5198 [1:36:20<187:45:11, 131.09s/it]
100%|██████████| 1/1 [02:11<00:00, 131.74s/it][A100%|██████████| 1/1 [02:11<00:00, 131.74s/it]
  1%|          | 42/5198 [1:36:20<187:45:05, 131.09s/it]
100%|██████████| 1/1 [02:11<00:00, 131.77s/it][A100%|██████████| 1/1 [02:11<00:00, 131.77s/it]
  1%|          | 42/5198 [1:36:20<187:45:40, 131.10s/it]
100%|██████████| 1/1 [02:11<00:00, 131.86s/it][A100%|██████████| 1/1 [02:11<00:00, 131.86s/it]
  1%|          | 42/5198 [1:36:20<187:46:34, 131.11s/it]
100%|██████████| 1/1 [02:11<00:00, 131.82s/it][A100%|██████████| 1/1 [02:11<00:00, 131.82s/it]
  1%|          | 42/5198 [1:36:23<187:45:34, 131.10s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_40

  0%|          | 0/1 [00:00<?, ?it/s][A

  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:23<00:00, 143.15s/it][A100%|██████████| 1/1 [02:23<00:00, 143.15s/it]
  1%|          | 43/5198 [1:38:43<193:18:15, 134.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 21:03:49,823] [INFO] [logging.py:96:log_dist] [Rank 0] step=43, skipped=0, lr=[1.5159186999976524e-05], mom=[(0.9, 0.999)]
steps: 43 loss: 0.6707 iter time (s): 143.432 samples/sec: 0.892

100%|██████████| 1/1 [02:24<00:00, 144.10s/it][A100%|██████████| 1/1 [02:24<00:00, 144.10s/it]
  1%|          | 43/5198 [1:38:44<193:33:15, 135.17s/it]
100%|██████████| 1/1 [02:24<00:00, 144.12s/it][A100%|██████████| 1/1 [02:24<00:00, 144.12s/it]
  1%|          | 43/5198 [1:38:44<193:30:54, 135.14s/it]
100%|██████████| 1/1 [02:24<00:00, 144.30s/it][A100%|██████████| 1/1 [02:24<00:00, 144.30s/it]
  1%|          | 43/5198 [1:38:45<193:30:52, 135.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:24<00:00, 144.24s/it][A100%|██████████| 1/1 [02:24<00:00, 144.24s/it]
  1%|          | 43/5198 [1:38:45<193:31:45, 135.15s/it]
100%|██████████| 1/1 [02:24<00:00, 144.21s/it][A100%|██████████| 1/1 [02:24<00:00, 144.21s/it]
  1%|          | 43/5198 [1:38:45<193:30:49, 135.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:24<00:00, 144.15s/it][A100%|██████████| 1/1 [02:24<00:00, 144.15s/it]
  1%|          | 43/5198 [1:38:45<193:32:02, 135.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:24<00:00, 144.27s/it][A100%|██████████| 1/1 [02:24<00:00, 144.27s/it]
  1%|          | 43/5198 [1:38:47<193:31:37, 135.15s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_41

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.05s/it][A100%|██████████| 1/1 [01:55<00:00, 115.05s/it]
  1%|          | 44/5198 [1:40:39<185:02:09, 129.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 21:05:44,900] [INFO] [logging.py:96:log_dist] [Rank 0] step=44, skipped=0, lr=[1.523961967041485e-05], mom=[(0.9, 0.999)]
steps: 44 loss: 0.6908 iter time (s): 113.872 samples/sec: 1.124

100%|██████████| 1/1 [01:54<00:00, 114.68s/it][A100%|██████████| 1/1 [01:54<00:00, 114.69s/it]
  1%|          | 44/5198 [1:40:39<184:50:32, 129.11s/it]
100%|██████████| 1/1 [01:54<00:00, 114.78s/it][A100%|██████████| 1/1 [01:54<00:00, 114.78s/it]
  1%|          | 44/5198 [1:40:39<184:52:18, 129.13s/it]
100%|██████████| 1/1 [01:54<00:00, 114.58s/it][A100%|██████████| 1/1 [01:54<00:00, 114.58s/it]
  1%|          | 44/5198 [1:40:40<184:48:46, 129.09s/it]
100%|██████████| 1/1 [01:54<00:00, 114.82s/it][A100%|██████████| 1/1 [01:54<00:00, 114.82s/it]
  1%|          | 44/5198 [1:40:40<184:48:39, 129.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.72s/it][A100%|██████████| 1/1 [01:54<00:00, 114.73s/it]
  1%|          | 44/5198 [1:40:40<184:49:38, 129.10s/it]
100%|██████████| 1/1 [01:54<00:00, 114.78s/it][A100%|██████████| 1/1 [01:54<00:00, 114.78s/it]
  1%|          | 44/5198 [1:40:40<184:49:22, 129.10s/it]
100%|██████████| 1/1 [01:54<00:00, 114.68s/it][A100%|██████████| 1/1 [01:54<00:00, 114.68s/it]
  1%|          | 44/5198 [1:40:42<184:49:24, 129.10s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_42

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A

  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:21<00:00, 141.40s/it][A100%|██████████| 1/1 [02:21<00:00, 141.41s/it]
  1%|          | 45/5198 [1:43:01<190:43:23, 133.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 21:08:08,422] [INFO] [logging.py:96:log_dist] [Rank 0] step=45, skipped=0, lr=[1.5318244711222133e-05], mom=[(0.9, 0.999)]
steps: 45 loss: 0.6939 iter time (s): 142.551 samples/sec: 0.898

100%|██████████| 1/1 [02:23<00:00, 143.25s/it][A100%|██████████| 1/1 [02:23<00:00, 143.25s/it]
  1%|          | 45/5198 [1:43:03<190:59:49, 133.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:23<00:00, 143.33s/it][A100%|██████████| 1/1 [02:23<00:00, 143.33s/it]
  1%|          | 45/5198 [1:43:03<191:03:38, 133.48s/it]
100%|██████████| 1/1 [02:23<00:00, 143.30s/it][A100%|██████████| 1/1 [02:23<00:00, 143.30s/it]
  1%|          | 45/5198 [1:43:03<191:02:56, 133.47s/it]
100%|██████████| 1/1 [02:23<00:00, 143.40s/it][A100%|██████████| 1/1 [02:23<00:00, 143.40s/it]
  1%|          | 45/5198 [1:43:03<191:04:07, 133.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:23<00:00, 143.59s/it][A100%|██████████| 1/1 [02:23<00:00, 143.59s/it]
  1%|          | 45/5198 [1:43:04<191:06:59, 133.52s/it]
100%|██████████| 1/1 [02:23<00:00, 143.58s/it][A100%|██████████| 1/1 [02:23<00:00, 143.58s/it]
  1%|          | 45/5198 [1:43:06<191:06:36, 133.51s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_43

100%|██████████| 1/1 [02:23<00:00, 143.80s/it][A100%|██████████| 1/1 [02:23<00:00, 143.80s/it]
  1%|          | 45/5198 [1:43:04<191:13:31, 133.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.83s/it][A100%|██████████| 1/1 [01:56<00:00, 116.83s/it]
  1%|          | 46/5198 [1:44:59<184:01:16, 128.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 21:10:05,745] [INFO] [logging.py:96:log_dist] [Rank 0] step=46, skipped=0, lr=[1.5395141588461026e-05], mom=[(0.9, 0.999)]
steps: 46 loss: 0.7025 iter time (s): 115.986 samples/sec: 1.104

100%|██████████| 1/1 [01:57<00:00, 117.33s/it][A100%|██████████| 1/1 [01:57<00:00, 117.33s/it]
  1%|          | 46/5198 [1:45:00<184:05:46, 128.64s/it]
100%|██████████| 1/1 [01:57<00:00, 117.02s/it][A100%|██████████| 1/1 [01:57<00:00, 117.02s/it]
  1%|          | 46/5198 [1:45:00<184:05:31, 128.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:57<00:00, 117.09s/it][A100%|██████████| 1/1 [01:57<00:00, 117.09s/it]
  1%|          | 46/5198 [1:45:01<184:05:00, 128.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:57<00:00, 117.18s/it][A100%|██████████| 1/1 [01:57<00:00, 117.18s/it]
  1%|          | 46/5198 [1:45:01<184:04:06, 128.62s/it]
100%|██████████| 1/1 [01:56<00:00, 116.45s/it][A100%|██████████| 1/1 [01:56<00:00, 116.45s/it]
  1%|          | 46/5198 [1:45:01<184:01:12, 128.59s/it]
100%|██████████| 1/1 [01:56<00:00, 116.92s/it][A100%|██████████| 1/1 [01:56<00:00, 116.92s/it]
  1%|          | 46/5198 [1:45:01<184:03:06, 128.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.78s/it][A100%|██████████| 1/1 [01:56<00:00, 116.78s/it]
  1%|          | 46/5198 [1:45:03<184:03:04, 128.61s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_44
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.89s/it][A100%|██████████| 1/1 [01:46<00:00, 106.89s/it]
  1%|          | 47/5198 [1:46:47<174:56:25, 122.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 21:11:53,295] [INFO] [logging.py:96:log_dist] [Rank 0] step=47, skipped=0, lr=[1.547038464053414e-05], mom=[(0.9, 0.999)]
steps: 47 loss: 0.6974 iter time (s): 106.410 samples/sec: 1.203

100%|██████████| 1/1 [01:47<00:00, 107.09s/it][A100%|██████████| 1/1 [01:47<00:00, 107.09s/it]
  1%|          | 47/5198 [1:46:47<174:54:38, 122.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.15s/it][A100%|██████████| 1/1 [01:47<00:00, 107.15s/it]
  1%|          | 47/5198 [1:46:47<174:52:13, 122.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.23s/it][A100%|██████████| 1/1 [01:47<00:00, 107.23s/it]
  1%|          | 47/5198 [1:46:48<174:52:27, 122.22s/it]
100%|██████████| 1/1 [01:47<00:00, 107.14s/it][A100%|██████████| 1/1 [01:47<00:00, 107.15s/it]
  1%|          | 47/5198 [1:46:48<174:51:26, 122.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.19s/it][A100%|██████████| 1/1 [01:47<00:00, 107.19s/it]
  1%|          | 47/5198 [1:46:48<174:49:59, 122.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.18s/it][A100%|██████████| 1/1 [01:47<00:00, 107.18s/it]
  1%|          | 47/5198 [1:46:48<174:52:59, 122.22s/it]
100%|██████████| 1/1 [01:47<00:00, 107.20s/it][A100%|██████████| 1/1 [01:47<00:00, 107.20s/it]
  1%|          | 47/5198 [1:46:50<174:52:31, 122.22s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_2
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.97s/it][A100%|██████████| 1/1 [02:03<00:00, 123.97s/it]
  1%|          | 48/5198 [1:48:51<175:47:50, 122.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 21:13:57,952] [INFO] [logging.py:96:log_dist] [Rank 0] step=48, skipped=0, lr=[1.554404351007031e-05], mom=[(0.9, 0.999)]
steps: 48 loss: 0.8470 iter time (s): 124.100 samples/sec: 1.031

100%|██████████| 1/1 [02:04<00:00, 124.92s/it][A100%|██████████| 1/1 [02:04<00:00, 124.92s/it]
  1%|          | 48/5198 [1:48:52<176:02:52, 123.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:05<00:00, 125.03s/it][A100%|██████████| 1/1 [02:05<00:00, 125.03s/it]
  1%|          | 48/5198 [1:48:53<176:02:58, 123.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:05<00:00, 125.03s/it][A100%|██████████| 1/1 [02:05<00:00, 125.03s/it]
  1%|          | 48/5198 [1:48:53<176:04:55, 123.09s/it]
100%|██████████| 1/1 [02:05<00:00, 125.08s/it][A100%|██████████| 1/1 [02:05<00:00, 125.08s/it]
  1%|          | 48/5198 [1:48:53<176:04:18, 123.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:05<00:00, 125.12s/it][A100%|██████████| 1/1 [02:05<00:00, 125.12s/it]
  1%|          | 48/5198 [1:48:53<176:03:30, 123.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:05<00:00, 125.00s/it][A100%|██████████| 1/1 [02:05<00:00, 125.00s/it]
  1%|          | 48/5198 [1:48:55<176:03:05, 123.07s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_45

100%|██████████| 1/1 [02:05<00:00, 125.00s/it][A100%|██████████| 1/1 [02:05<00:00, 125.01s/it]
  1%|          | 48/5198 [1:48:53<176:04:04, 123.08s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.20s/it][A100%|██████████| 1/1 [01:29<00:00, 89.20s/it]
  1%|          | 49/5198 [1:50:21<161:30:05, 112.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 21:15:26,823] [INFO] [logging.py:96:log_dist] [Rank 0] step=49, skipped=0, lr=[1.5616183531276542e-05], mom=[(0.9, 0.999)]
steps: 49 loss: 0.7333 iter time (s): 87.716 samples/sec: 1.459

100%|██████████| 1/1 [01:28<00:00, 88.52s/it][A100%|██████████| 1/1 [01:28<00:00, 88.52s/it]
  1%|          | 49/5198 [1:50:21<161:12:34, 112.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.50s/it][A100%|██████████| 1/1 [01:28<00:00, 88.50s/it]
  1%|          | 49/5198 [1:50:21<161:13:23, 112.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.45s/it][A100%|██████████| 1/1 [01:28<00:00, 88.45s/it]
  1%|          | 49/5198 [1:50:22<161:13:11, 112.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.45s/it][A100%|██████████| 1/1 [01:28<00:00, 88.45s/it]
  1%|          | 49/5198 [1:50:22<161:12:45, 112.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.48s/it][A100%|██████████| 1/1 [01:28<00:00, 88.48s/it]
  1%|          | 49/5198 [1:50:22<161:11:22, 112.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.46s/it][A100%|██████████| 1/1 [01:28<00:00, 88.46s/it]
  1%|          | 49/5198 [1:50:22<161:12:06, 112.71s/it]
100%|██████████| 1/1 [01:28<00:00, 88.51s/it][A100%|██████████| 1/1 [01:28<00:00, 88.51s/it]
  1%|          | 49/5198 [1:50:24<161:11:44, 112.70s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_46
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.90s/it][A100%|██████████| 1/1 [01:37<00:00, 97.90s/it]
  1%|          | 50/5198 [1:51:59<155:11:48, 108.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 21:17:05,348] [INFO] [logging.py:96:log_dist] [Rank 0] step=50, skipped=0, lr=[1.568686607815507e-05], mom=[(0.9, 0.999)]
steps: 50 loss: 0.6670 iter time (s): 97.633 samples/sec: 1.311

100%|██████████| 1/1 [01:38<00:00, 98.43s/it][A100%|██████████| 1/1 [01:38<00:00, 98.43s/it]
  1%|          | 50/5198 [1:51:59<155:04:26, 108.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.30s/it][A100%|██████████| 1/1 [01:38<00:00, 98.30s/it]
  1%|          | 50/5198 [1:52:00<155:03:35, 108.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.35s/it][A100%|██████████| 1/1 [01:38<00:00, 98.35s/it]
  1%|          | 50/5198 [1:52:00<155:02:11, 108.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.42s/it][A100%|██████████| 1/1 [01:38<00:00, 98.43s/it]
  1%|          | 50/5198 [1:52:00<155:03:20, 108.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.40s/it][A100%|██████████| 1/1 [01:38<00:00, 98.40s/it]
  1%|          | 50/5198 [1:52:00<155:02:36, 108.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.36s/it][A100%|██████████| 1/1 [01:38<00:00, 98.36s/it]
  1%|          | 50/5198 [1:52:00<155:02:49, 108.42s/it]
100%|██████████| 1/1 [01:38<00:00, 98.38s/it][A100%|██████████| 1/1 [01:38<00:00, 98.38s/it]
  1%|          | 50/5198 [1:52:02<155:02:41, 108.42s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_47

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.64s/it][A100%|██████████| 1/1 [01:40<00:00, 100.65s/it]
  1%|          | 51/5198 [1:53:40<152:02:14, 106.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 21:18:46,672] [INFO] [logging.py:96:log_dist] [Rank 0] step=51, skipped=0, lr=[1.5756148878236345e-05], mom=[(0.9, 0.999)]
steps: 51 loss: 0.7239 iter time (s): 100.537 samples/sec: 1.273

100%|██████████| 1/1 [01:41<00:00, 101.33s/it][A100%|██████████| 1/1 [01:41<00:00, 101.33s/it]
  1%|          | 51/5198 [1:53:41<152:01:50, 106.34s/it]
100%|██████████| 1/1 [01:41<00:00, 101.38s/it][A100%|██████████| 1/1 [01:41<00:00, 101.38s/it]
  1%|          | 51/5198 [1:53:41<152:00:30, 106.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.41s/it][A100%|██████████| 1/1 [01:41<00:00, 101.41s/it]
  1%|          | 51/5198 [1:53:41<152:01:25, 106.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.41s/it][A100%|██████████| 1/1 [01:41<00:00, 101.41s/it]
  1%|          | 51/5198 [1:53:41<152:01:24, 106.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.42s/it][A100%|██████████| 1/1 [01:41<00:00, 101.42s/it]
  1%|          | 51/5198 [1:53:42<152:00:53, 106.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.36s/it][A100%|██████████| 1/1 [01:41<00:00, 101.36s/it]
  1%|          | 51/5198 [1:53:42<152:01:01, 106.33s/it]
100%|██████████| 1/1 [01:41<00:00, 101.35s/it][A100%|██████████| 1/1 [01:41<00:00, 101.35s/it]
  1%|          | 51/5198 [1:53:44<152:00:48, 106.32s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_48
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.85s/it][A100%|██████████| 1/1 [01:36<00:00, 96.85s/it]
  1%|          | 52/5198 [1:55:18<148:08:18, 103.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 21:20:23,832] [INFO] [logging.py:96:log_dist] [Rank 0] step=52, skipped=0, lr=[1.5824086295846492e-05], mom=[(0.9, 0.999)]
steps: 52 loss: 0.7116 iter time (s): 96.350 samples/sec: 1.328

100%|██████████| 1/1 [01:37<00:00, 97.05s/it][A100%|██████████| 1/1 [01:37<00:00, 97.05s/it]
  1%|          | 52/5198 [1:55:18<148:03:44, 103.58s/it]
100%|██████████| 1/1 [01:37<00:00, 97.14s/it][A100%|██████████| 1/1 [01:37<00:00, 97.14s/it]
  1%|          | 52/5198 [1:55:18<148:03:53, 103.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.13s/it][A100%|██████████| 1/1 [01:37<00:00, 97.13s/it]
  1%|          | 52/5198 [1:55:19<148:04:29, 103.59s/it]
100%|██████████| 1/1 [01:37<00:00, 97.11s/it][A100%|██████████| 1/1 [01:37<00:00, 97.11s/it]
  1%|          | 52/5198 [1:55:19<148:03:11, 103.57s/it]
100%|██████████| 1/1 [01:37<00:00, 97.15s/it][A100%|██████████| 1/1 [01:37<00:00, 97.15s/it]
  1%|          | 52/5198 [1:55:19<148:03:22, 103.58s/it]
100%|██████████| 1/1 [01:37<00:00, 97.07s/it][A100%|██████████| 1/1 [01:37<00:00, 97.07s/it]
  1%|          | 52/5198 [1:55:19<148:03:07, 103.57s/it]
100%|██████████| 1/1 [01:37<00:00, 97.08s/it][A100%|██████████| 1/1 [01:37<00:00, 97.08s/it]
  1%|          | 52/5198 [1:55:21<148:02:53, 103.57s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_49

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.62s/it][A100%|██████████| 1/1 [01:39<00:00, 99.62s/it]
  1%|          | 53/5198 [1:56:58<146:35:40, 102.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 21:22:03,851] [INFO] [logging.py:96:log_dist] [Rank 0] step=53, skipped=0, lr=[1.589072958839174e-05], mom=[(0.9, 0.999)]
steps: 53 loss: 0.7312 iter time (s): 99.134 samples/sec: 1.291

100%|██████████| 1/1 [01:39<00:00, 99.86s/it][A100%|██████████| 1/1 [01:39<00:00, 99.86s/it]
  1%|          | 53/5198 [1:56:58<146:29:40, 102.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.97s/it][A100%|██████████| 1/1 [01:39<00:00, 99.97s/it]
  1%|          | 53/5198 [1:56:58<146:30:00, 102.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.70s/it][A100%|██████████| 1/1 [01:39<00:00, 99.70s/it]
  1%|          | 53/5198 [1:56:58<146:28:54, 102.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.73s/it][A100%|██████████| 1/1 [01:39<00:00, 99.74s/it]
  1%|          | 53/5198 [1:56:59<146:28:24, 102.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.80s/it][A100%|██████████| 1/1 [01:39<00:00, 99.80s/it]
  1%|          | 53/5198 [1:56:59<146:28:44, 102.49s/it]
100%|██████████| 1/1 [01:39<00:00, 99.88s/it][A100%|██████████| 1/1 [01:39<00:00, 99.88s/it]
  1%|          | 53/5198 [1:56:59<146:29:04, 102.50s/it]
100%|██████████| 1/1 [01:39<00:00, 99.90s/it][A100%|██████████| 1/1 [01:39<00:00, 99.90s/it]
  1%|          | 53/5198 [1:57:01<146:29:19, 102.50s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_50

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.


  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:18<00:00, 138.40s/it][A100%|██████████| 1/1 [02:18<00:00, 138.40s/it]
  1%|          | 54/5198 [1:59:16<162:07:05, 113.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 21:24:23,959] [INFO] [logging.py:96:log_dist] [Rank 0] step=54, skipped=0, lr=[1.5956127138686665e-05], mom=[(0.9, 0.999)]
steps: 54 loss: 0.6726 iter time (s): 139.257 samples/sec: 0.919

100%|██████████| 1/1 [02:20<00:00, 140.02s/it][A100%|██████████| 1/1 [02:20<00:00, 140.02s/it]
  1%|          | 54/5198 [1:59:18<162:33:50, 113.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:20<00:00, 140.00s/it][A100%|██████████| 1/1 [02:20<00:00, 140.00s/it]
  1%|          | 54/5198 [1:59:18<162:34:57, 113.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:20<00:00, 140.06s/it][A100%|██████████| 1/1 [02:20<00:00, 140.07s/it]
  1%|          | 54/5198 [1:59:19<162:33:22, 113.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:20<00:00, 140.10s/it][A100%|██████████| 1/1 [02:20<00:00, 140.10s/it]
  1%|          | 54/5198 [1:59:19<162:35:14, 113.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:19<00:00, 139.99s/it][A100%|██████████| 1/1 [02:19<00:00, 139.99s/it]
  1%|          | 54/5198 [1:59:19<162:33:44, 113.77s/it]
100%|██████████| 1/1 [02:20<00:00, 140.02s/it][A100%|██████████| 1/1 [02:20<00:00, 140.02s/it]
  1%|          | 54/5198 [1:59:19<162:34:03, 113.77s/it]
100%|██████████| 1/1 [02:20<00:00, 140.03s/it][A100%|██████████| 1/1 [02:20<00:00, 140.03s/it]
  1%|          | 54/5198 [1:59:21<162:33:56, 113.77s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_51
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.31s/it][A100%|██████████| 1/1 [01:44<00:00, 104.31s/it]
  1%|          | 55/5198 [2:01:01<158:25:02, 110.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 21:26:07,892] [INFO] [logging.py:96:log_dist] [Rank 0] step=55, skipped=0, lr=[1.6020324665964146e-05], mom=[(0.9, 0.999)]
steps: 55 loss: 0.6984 iter time (s): 103.145 samples/sec: 1.241

100%|██████████| 1/1 [01:43<00:00, 103.85s/it][A100%|██████████| 1/1 [01:43<00:00, 103.85s/it]
  1%|          | 55/5198 [2:01:02<158:18:31, 110.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.84s/it][A100%|██████████| 1/1 [01:43<00:00, 103.84s/it]
  1%|          | 55/5198 [2:01:02<158:20:27, 110.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.95s/it][A100%|██████████| 1/1 [01:43<00:00, 103.95s/it]
  1%|          | 55/5198 [2:01:03<158:20:35, 110.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.99s/it][A100%|██████████| 1/1 [01:43<00:00, 103.99s/it]
  1%|          | 55/5198 [2:01:03<158:20:25, 110.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.86s/it][A100%|██████████| 1/1 [01:43<00:00, 103.86s/it]
  1%|          | 55/5198 [2:01:03<158:19:50, 110.83s/it]
100%|██████████| 1/1 [01:43<00:00, 103.93s/it][A100%|██████████| 1/1 [01:43<00:00, 103.93s/it]
  1%|          | 55/5198 [2:01:03<158:20:17, 110.83s/it]
100%|██████████| 1/1 [01:43<00:00, 103.93s/it][A100%|██████████| 1/1 [01:43<00:00, 103.94s/it]
  1%|          | 55/5198 [2:01:05<158:20:04, 110.83s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_52

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.62s/it][A100%|██████████| 1/1 [01:29<00:00, 89.62s/it]
  1%|          | 56/5198 [2:02:32<149:30:04, 104.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 21:27:37,701] [INFO] [logging.py:96:log_dist] [Rank 0] step=56, skipped=0, lr=[1.6083365417872165e-05], mom=[(0.9, 0.999)]
steps: 56 loss: 0.6856 iter time (s): 88.929 samples/sec: 1.439

100%|██████████| 1/1 [01:29<00:00, 89.81s/it][A100%|██████████| 1/1 [01:29<00:00, 89.81s/it]
  1%|          | 56/5198 [2:02:32<149:18:52, 104.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.63s/it][A100%|██████████| 1/1 [01:29<00:00, 89.63s/it]
  1%|          | 56/5198 [2:02:32<149:17:04, 104.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.71s/it][A100%|██████████| 1/1 [01:29<00:00, 89.71s/it]
  1%|          | 56/5198 [2:02:32<149:16:04, 104.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.88s/it][A100%|██████████| 1/1 [01:29<00:00, 89.88s/it]
  1%|          | 56/5198 [2:02:32<149:19:53, 104.55s/it]
100%|██████████| 1/1 [01:29<00:00, 89.75s/it][A100%|██████████| 1/1 [01:29<00:00, 89.75s/it]
  1%|          | 56/5198 [2:02:33<149:18:32, 104.53s/it]
100%|██████████| 1/1 [01:29<00:00, 89.74s/it][A100%|██████████| 1/1 [01:29<00:00, 89.74s/it]
  1%|          | 56/5198 [2:02:33<149:18:08, 104.53s/it]
100%|██████████| 1/1 [01:29<00:00, 89.75s/it][A100%|██████████| 1/1 [01:29<00:00, 89.75s/it]
  1%|          | 56/5198 [2:02:35<149:17:57, 104.53s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_53

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.92s/it][A100%|██████████| 1/1 [01:20<00:00, 80.92s/it]
  1%|          | 57/5198 [2:03:53<139:24:51, 97.63s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 21:28:58,615] [INFO] [logging.py:96:log_dist] [Rank 0] step=57, skipped=0, lr=[1.6145290345476972e-05], mom=[(0.9, 0.999)]
steps: 57 loss: 0.6815 iter time (s): 80.115 samples/sec: 1.598

100%|██████████| 1/1 [01:20<00:00, 80.82s/it][A100%|██████████| 1/1 [01:20<00:00, 80.82s/it]
  1%|          | 57/5198 [2:03:53<139:08:46, 97.44s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.97s/it][A100%|██████████| 1/1 [01:20<00:00, 80.97s/it]
  1%|          | 57/5198 [2:03:53<139:10:21, 97.46s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.91s/it][A100%|██████████| 1/1 [01:20<00:00, 80.91s/it]
  1%|          | 57/5198 [2:03:53<139:09:45, 97.45s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.78s/it][A100%|██████████| 1/1 [01:20<00:00, 80.78s/it]
  1%|          | 57/5198 [2:03:53<139:09:57, 97.45s/it] 
100%|██████████| 1/1 [01:20<00:00, 80.80s/it][A100%|██████████| 1/1 [01:20<00:00, 80.80s/it]
  1%|          | 57/5198 [2:03:53<139:08:57, 97.44s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.88s/it][A100%|██████████| 1/1 [01:20<00:00, 80.88s/it]
  1%|          | 57/5198 [2:03:54<139:09:55, 97.45s/it] 
100%|██████████| 1/1 [01:20<00:00, 80.88s/it][A100%|██████████| 1/1 [01:20<00:00, 80.88s/it]
  1%|          | 57/5198 [2:03:56<139:09:42, 97.45s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_54
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.88s/it][A100%|██████████| 1/1 [01:37<00:00, 97.88s/it]
  1%|          | 58/5198 [2:05:31<139:42:49, 97.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 21:30:37,480] [INFO] [logging.py:96:log_dist] [Rank 0] step=58, skipped=0, lr=[1.6206138263046164e-05], mom=[(0.9, 0.999)]
steps: 58 loss: 0.6487 iter time (s): 98.044 samples/sec: 1.306

100%|██████████| 1/1 [01:38<00:00, 98.88s/it][A100%|██████████| 1/1 [01:38<00:00, 98.88s/it]
  1%|          | 58/5198 [2:05:32<139:44:42, 97.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.75s/it][A100%|██████████| 1/1 [01:38<00:00, 98.75s/it]
  1%|          | 58/5198 [2:05:32<139:43:20, 97.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.82s/it][A100%|██████████| 1/1 [01:38<00:00, 98.82s/it]
  1%|          | 58/5198 [2:05:32<139:43:32, 97.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.80s/it][A100%|██████████| 1/1 [01:38<00:00, 98.80s/it]
  1%|          | 58/5198 [2:05:32<139:44:59, 97.88s/it]
100%|██████████| 1/1 [01:38<00:00, 98.86s/it][A100%|██████████| 1/1 [01:38<00:00, 98.86s/it]
  1%|          | 58/5198 [2:05:32<139:45:12, 97.88s/it]
100%|██████████| 1/1 [01:38<00:00, 98.81s/it][A100%|██████████| 1/1 [01:38<00:00, 98.81s/it]
  1%|          | 58/5198 [2:05:32<139:43:34, 97.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.84s/it][A100%|██████████| 1/1 [01:38<00:00, 98.84s/it]
  1%|          | 58/5198 [2:05:35<139:44:12, 97.87s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_55
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.55s/it][A100%|██████████| 1/1 [01:25<00:00, 85.55s/it]
  1%|          | 59/5198 [2:06:57<134:34:40, 94.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 21:32:03,075] [INFO] [logging.py:96:log_dist] [Rank 0] step=59, skipped=0, lr=[1.6265945994173015e-05], mom=[(0.9, 0.999)]
steps: 59 loss: 0.6792 iter time (s): 84.767 samples/sec: 1.510

100%|██████████| 1/1 [01:25<00:00, 85.54s/it][A100%|██████████| 1/1 [01:25<00:00, 85.54s/it]
  1%|          | 59/5198 [2:06:57<134:26:22, 94.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.57s/it][A100%|██████████| 1/1 [01:25<00:00, 85.57s/it]
  1%|          | 59/5198 [2:06:57<134:28:14, 94.20s/it]
100%|██████████| 1/1 [01:25<00:00, 85.57s/it][A100%|██████████| 1/1 [01:25<00:00, 85.57s/it]
  1%|          | 59/5198 [2:06:58<134:26:20, 94.18s/it]
100%|██████████| 1/1 [01:25<00:00, 85.45s/it][A100%|██████████| 1/1 [01:25<00:00, 85.45s/it]
  1%|          | 59/5198 [2:06:58<134:25:59, 94.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.56s/it][A100%|██████████| 1/1 [01:25<00:00, 85.56s/it]
  1%|          | 59/5198 [2:06:58<134:26:25, 94.18s/it]
100%|██████████| 1/1 [01:25<00:00, 85.56s/it][A100%|██████████| 1/1 [01:25<00:00, 85.56s/it]
  1%|          | 59/5198 [2:06:58<134:27:38, 94.19s/it]
100%|██████████| 1/1 [01:25<00:00, 85.60s/it][A100%|██████████| 1/1 [01:25<00:00, 85.60s/it]
  1%|          | 59/5198 [2:07:00<134:27:20, 94.19s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_56
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:01<00:00, 121.58s/it][A100%|██████████| 1/1 [02:01<00:00, 121.58s/it]
  1%|          | 60/5198 [2:08:59<146:22:57, 102.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 21:34:06,038] [INFO] [logging.py:96:log_dist] [Rank 0] step=60, skipped=0, lr=[1.6324748505619602e-05], mom=[(0.9, 0.999)]
steps: 60 loss: 0.6944 iter time (s): 122.090 samples/sec: 1.048

100%|██████████| 1/1 [02:02<00:00, 122.89s/it][A100%|██████████| 1/1 [02:02<00:00, 122.89s/it]
  1%|          | 60/5198 [2:09:00<146:44:46, 102.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:02<00:00, 122.75s/it][A100%|██████████| 1/1 [02:02<00:00, 122.75s/it]
  1%|          | 60/5198 [2:09:00<146:43:44, 102.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:02<00:00, 122.92s/it][A100%|██████████| 1/1 [02:02<00:00, 122.92s/it]
  1%|          | 60/5198 [2:09:01<146:45:26, 102.83s/it]
100%|██████████| 1/1 [02:02<00:00, 122.98s/it][A100%|██████████| 1/1 [02:02<00:00, 122.98s/it]
  1%|          | 60/5198 [2:09:01<146:45:08, 102.82s/it]
100%|██████████| 1/1 [02:02<00:00, 122.80s/it][A100%|██████████| 1/1 [02:02<00:00, 122.80s/it]
  1%|          | 60/5198 [2:09:01<146:43:55, 102.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:02<00:00, 122.87s/it][A100%|██████████| 1/1 [02:02<00:00, 122.87s/it]
  1%|          | 60/5198 [2:09:01<146:44:55, 102.82s/it]
100%|██████████| 1/1 [02:02<00:00, 122.87s/it][A100%|██████████| 1/1 [02:02<00:00, 122.87s/it]
  1%|          | 60/5198 [2:09:03<146:44:23, 102.82s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_57
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:02<00:00, 122.08s/it][A100%|██████████| 1/1 [02:02<00:00, 122.08s/it]
  1%|          | 61/5198 [2:11:01<154:54:42, 108.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 21:36:08,532] [INFO] [logging.py:96:log_dist] [Rank 0] step=61, skipped=0, lr=[1.6382579030097016e-05], mom=[(0.9, 0.999)]
steps: 61 loss: 0.6434 iter time (s): 121.554 samples/sec: 1.053

100%|██████████| 1/1 [02:02<00:00, 122.50s/it][A100%|██████████| 1/1 [02:02<00:00, 122.50s/it]
  1%|          | 61/5198 [2:11:03<155:08:48, 108.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:02<00:00, 122.50s/it][A100%|██████████| 1/1 [02:02<00:00, 122.50s/it]
  1%|          | 61/5198 [2:11:03<155:09:30, 108.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:02<00:00, 122.43s/it][A100%|██████████| 1/1 [02:02<00:00, 122.43s/it]
  1%|          | 61/5198 [2:11:03<155:09:57, 108.74s/it]
100%|██████████| 1/1 [02:02<00:00, 122.54s/it][A100%|██████████| 1/1 [02:02<00:00, 122.54s/it]
  1%|          | 61/5198 [2:11:03<155:09:45, 108.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:02<00:00, 122.58s/it][A100%|██████████| 1/1 [02:02<00:00, 122.58s/it]
  1%|          | 61/5198 [2:11:03<155:12:07, 108.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:02<00:00, 122.44s/it][A100%|██████████| 1/1 [02:02<00:00, 122.44s/it]
  1%|          | 61/5198 [2:11:04<155:11:02, 108.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:02<00:00, 122.93s/it][A100%|██████████| 1/1 [02:02<00:00, 122.93s/it]
  1%|          | 61/5198 [2:11:06<155:23:04, 108.89s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_58
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.38s/it][A100%|██████████| 1/1 [01:29<00:00, 89.38s/it]
  1%|          | 62/5198 [2:12:31<146:55:21, 102.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 21:37:37,589] [INFO] [logging.py:96:log_dist] [Rank 0] step=62, skipped=0, lr=[1.643946917906196e-05], mom=[(0.9, 0.999)]
steps: 62 loss: 0.7090 iter time (s): 87.575 samples/sec: 1.462

100%|██████████| 1/1 [01:29<00:00, 89.02s/it][A100%|██████████| 1/1 [01:29<00:00, 89.02s/it]
  1%|          | 62/5198 [2:12:32<146:42:26, 102.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.02s/it][A100%|██████████| 1/1 [01:29<00:00, 89.02s/it]
  1%|          | 62/5198 [2:12:32<146:43:17, 102.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 89.00s/it][A100%|██████████| 1/1 [01:28<00:00, 89.00s/it]
  1%|          | 62/5198 [2:12:32<146:44:57, 102.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.05s/it][A100%|██████████| 1/1 [01:29<00:00, 89.05s/it]
  1%|          | 62/5198 [2:12:32<146:44:20, 102.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.15s/it][A100%|██████████| 1/1 [01:29<00:00, 89.15s/it]
  1%|          | 62/5198 [2:12:33<146:45:47, 102.87s/it]
100%|██████████| 1/1 [01:29<00:00, 89.03s/it][A100%|██████████| 1/1 [01:29<00:00, 89.03s/it]
  1%|          | 62/5198 [2:12:33<146:45:01, 102.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.56s/it][A100%|██████████| 1/1 [01:28<00:00, 88.56s/it]
  1%|          | 62/5198 [2:12:35<146:41:27, 102.82s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_59
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.94s/it][A100%|██████████| 1/1 [01:27<00:00, 87.94s/it]
  1%|          | 63/5198 [2:14:00<140:39:46, 98.61s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 21:39:06,027] [INFO] [logging.py:96:log_dist] [Rank 0] step=63, skipped=0, lr=[1.6495449046488518e-05], mom=[(0.9, 0.999)]
steps: 63 loss: 0.6965 iter time (s): 87.397 samples/sec: 1.465

100%|██████████| 1/1 [01:28<00:00, 88.36s/it][A100%|██████████| 1/1 [01:28<00:00, 88.36s/it]
  1%|          | 63/5198 [2:14:00<140:29:40, 98.50s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.28s/it][A100%|██████████| 1/1 [01:28<00:00, 88.28s/it]
  1%|          | 63/5198 [2:14:00<140:28:50, 98.49s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.26s/it][A100%|██████████| 1/1 [01:28<00:00, 88.26s/it]
  1%|          | 63/5198 [2:14:01<140:30:07, 98.50s/it] 
100%|██████████| 1/1 [01:28<00:00, 88.24s/it][A100%|██████████| 1/1 [01:28<00:00, 88.24s/it]
  1%|          | 63/5198 [2:14:01<140:27:30, 98.47s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.17s/it][A100%|██████████| 1/1 [01:28<00:00, 88.17s/it]
  1%|          | 63/5198 [2:14:01<140:27:51, 98.48s/it] 
100%|██████████| 1/1 [01:28<00:00, 88.11s/it][A100%|██████████| 1/1 [01:28<00:00, 88.11s/it]
  1%|          | 63/5198 [2:14:01<140:26:40, 98.46s/it] 
100%|██████████| 1/1 [01:28<00:00, 88.15s/it][A100%|██████████| 1/1 [01:28<00:00, 88.15s/it]
  1%|          | 63/5198 [2:14:03<140:24:28, 98.44s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_3
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.44s/it][A100%|██████████| 1/1 [01:58<00:00, 118.44s/it]
  1%|          | 64/5198 [2:15:59<149:13:45, 104.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 21:41:05,359] [INFO] [logging.py:96:log_dist] [Rank 0] step=64, skipped=0, lr=[1.655054730446778e-05], mom=[(0.9, 0.999)]
steps: 64 loss: 0.8717 iter time (s): 118.777 samples/sec: 1.078

100%|██████████| 1/1 [01:59<00:00, 119.76s/it][A100%|██████████| 1/1 [01:59<00:00, 119.76s/it]
  1%|          | 64/5198 [2:16:00<149:33:24, 104.87s/it]
100%|██████████| 1/1 [01:59<00:00, 119.81s/it][A100%|██████████| 1/1 [01:59<00:00, 119.81s/it]
  1%|          | 64/5198 [2:16:00<149:37:23, 104.92s/it]
100%|██████████| 1/1 [01:59<00:00, 119.67s/it][A100%|██████████| 1/1 [01:59<00:00, 119.67s/it]
  1%|          | 64/5198 [2:16:00<149:32:10, 104.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.71s/it][A100%|██████████| 1/1 [01:59<00:00, 119.71s/it]
  1%|          | 64/5198 [2:16:00<149:31:10, 104.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.63s/it][A100%|██████████| 1/1 [01:59<00:00, 119.63s/it]
  1%|          | 64/5198 [2:16:01<149:32:21, 104.86s/it]
100%|██████████| 1/1 [01:59<00:00, 119.70s/it][A100%|██████████| 1/1 [01:59<00:00, 119.70s/it]
  1%|          | 64/5198 [2:16:01<149:33:14, 104.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.71s/it][A100%|██████████| 1/1 [01:59<00:00, 119.71s/it]
  1%|          | 64/5198 [2:16:03<149:31:07, 104.84s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_60
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.85s/it][A100%|██████████| 1/1 [01:35<00:00, 95.85s/it]
  1%|▏         | 65/5198 [2:17:35<145:35:20, 102.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 21:42:41,016] [INFO] [logging.py:96:log_dist] [Rank 0] step=65, skipped=0, lr=[1.6604791291395783e-05], mom=[(0.9, 0.999)]
steps: 65 loss: 0.6717 iter time (s): 94.473 samples/sec: 1.355

100%|██████████| 1/1 [01:35<00:00, 95.08s/it][A100%|██████████| 1/1 [01:35<00:00, 95.08s/it]
  1%|▏         | 65/5198 [2:17:35<145:25:57, 102.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.21s/it][A100%|██████████| 1/1 [01:35<00:00, 95.22s/it]
  1%|▏         | 65/5198 [2:17:35<145:26:53, 102.01s/it]
100%|██████████| 1/1 [01:35<00:00, 95.30s/it][A100%|██████████| 1/1 [01:35<00:00, 95.30s/it]
  1%|▏         | 65/5198 [2:17:36<145:25:35, 101.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.40s/it][A100%|██████████| 1/1 [01:35<00:00, 95.40s/it]
  1%|▏         | 65/5198 [2:17:36<145:27:12, 102.01s/it]
100%|██████████| 1/1 [01:35<00:00, 95.28s/it][A100%|██████████| 1/1 [01:35<00:00, 95.28s/it]
  1%|▏         | 65/5198 [2:17:36<145:26:39, 102.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.30s/it][A100%|██████████| 1/1 [01:35<00:00, 95.30s/it]
  1%|▏         | 65/5198 [2:17:36<145:26:25, 102.00s/it]
100%|██████████| 1/1 [01:35<00:00, 95.31s/it][A100%|██████████| 1/1 [01:35<00:00, 95.31s/it]
  1%|▏         | 65/5198 [2:17:38<145:25:03, 101.99s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_61
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.65s/it][A100%|██████████| 1/1 [01:39<00:00, 99.65s/it]
  1%|▏         | 66/5198 [2:19:15<144:37:38, 101.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 21:44:21,175] [INFO] [logging.py:96:log_dist] [Rank 0] step=66, skipped=0, lr=[1.6658207093428674e-05], mom=[(0.9, 0.999)]
steps: 66 loss: 0.7363 iter time (s): 99.253 samples/sec: 1.290

100%|██████████| 1/1 [01:39<00:00, 99.95s/it][A100%|██████████| 1/1 [01:39<00:00, 99.96s/it]
  1%|▏         | 66/5198 [2:19:15<144:33:29, 101.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.89s/it][A100%|██████████| 1/1 [01:39<00:00, 99.89s/it]
  1%|▏         | 66/5198 [2:19:15<144:34:12, 101.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.98s/it][A100%|██████████| 1/1 [01:39<00:00, 99.98s/it]
  1%|▏         | 66/5198 [2:19:16<144:33:32, 101.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.93s/it][A100%|██████████| 1/1 [01:39<00:00, 99.93s/it]
  1%|▏         | 66/5198 [2:19:16<144:33:31, 101.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.92s/it][A100%|██████████| 1/1 [01:39<00:00, 99.92s/it]
  1%|▏         | 66/5198 [2:19:16<144:33:42, 101.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.95s/it][A100%|██████████| 1/1 [01:39<00:00, 99.95s/it]
  1%|▏         | 66/5198 [2:19:16<144:33:31, 101.41s/it]
100%|██████████| 1/1 [01:39<00:00, 99.98s/it][A100%|██████████| 1/1 [01:39<00:00, 99.98s/it]
  1%|▏         | 66/5198 [2:19:18<144:32:50, 101.40s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_62

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.79s/it][A100%|██████████| 1/1 [01:36<00:00, 96.79s/it]
  1%|▏         | 67/5198 [2:20:52<142:47:35, 100.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 21:45:58,317] [INFO] [logging.py:96:log_dist] [Rank 0] step=67, skipped=0, lr=[1.6710819619812745e-05], mom=[(0.9, 0.999)]
steps: 67 loss: 0.6371 iter time (s): 96.302 samples/sec: 1.329

100%|██████████| 1/1 [01:37<00:00, 97.12s/it][A100%|██████████| 1/1 [01:37<00:00, 97.12s/it]
  1%|▏         | 67/5198 [2:20:52<142:43:52, 100.14s/it]
100%|██████████| 1/1 [01:37<00:00, 97.11s/it][A100%|██████████| 1/1 [01:37<00:00, 97.11s/it]
  1%|▏         | 67/5198 [2:20:53<142:42:48, 100.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.04s/it][A100%|██████████| 1/1 [01:37<00:00, 97.04s/it]
  1%|▏         | 67/5198 [2:20:53<142:41:49, 100.12s/it]
100%|██████████| 1/1 [01:37<00:00, 97.09s/it][A100%|██████████| 1/1 [01:37<00:00, 97.09s/it]
  1%|▏         | 67/5198 [2:20:53<142:42:10, 100.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.17s/it][A100%|██████████| 1/1 [01:37<00:00, 97.17s/it]
  1%|▏         | 67/5198 [2:20:53<142:43:31, 100.14s/it]
100%|██████████| 1/1 [01:37<00:00, 97.04s/it][A100%|██████████| 1/1 [01:37<00:00, 97.04s/it]
  1%|▏         | 67/5198 [2:20:53<142:43:06, 100.13s/it]
100%|██████████| 1/1 [01:37<00:00, 97.05s/it][A100%|██████████| 1/1 [01:37<00:00, 97.05s/it]
  1%|▏         | 67/5198 [2:20:55<142:42:24, 100.13s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_63
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.79s/it][A100%|██████████| 1/1 [01:42<00:00, 102.79s/it]
  1%|▏         | 68/5198 [2:22:35<144:04:27, 101.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 21:47:41,557] [INFO] [logging.py:96:log_dist] [Rank 0] step=68, skipped=0, lr=[1.676265267263382e-05], mom=[(0.9, 0.999)]
steps: 68 loss: 0.6503 iter time (s): 102.471 samples/sec: 1.249

100%|██████████| 1/1 [01:43<00:00, 103.25s/it][A100%|██████████| 1/1 [01:43<00:00, 103.25s/it]
  1%|▏         | 68/5198 [2:22:36<144:04:43, 101.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.33s/it][A100%|██████████| 1/1 [01:43<00:00, 103.33s/it]
  1%|▏         | 68/5198 [2:22:36<144:04:17, 101.10s/it]
100%|██████████| 1/1 [01:43<00:00, 103.22s/it][A100%|██████████| 1/1 [01:43<00:00, 103.22s/it]
  1%|▏         | 68/5198 [2:22:36<144:03:14, 101.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.32s/it][A100%|██████████| 1/1 [01:43<00:00, 103.32s/it]
  1%|▏         | 68/5198 [2:22:36<144:04:17, 101.10s/it]
100%|██████████| 1/1 [01:43<00:00, 103.26s/it][A100%|██████████| 1/1 [01:43<00:00, 103.26s/it]
  1%|▏         | 68/5198 [2:22:36<144:03:52, 101.10s/it]
100%|██████████| 1/1 [01:43<00:00, 103.27s/it][A100%|██████████| 1/1 [01:43<00:00, 103.27s/it]
  1%|▏         | 68/5198 [2:22:36<144:03:21, 101.09s/it]
100%|██████████| 1/1 [01:43<00:00, 103.28s/it][A100%|██████████| 1/1 [01:43<00:00, 103.28s/it]
  1%|▏         | 68/5198 [2:22:39<144:02:34, 101.08s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_64

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.28s/it][A100%|██████████| 1/1 [01:35<00:00, 95.28s/it]
  1%|▏         | 69/5198 [2:24:11<141:47:47, 99.53s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 21:49:17,121] [INFO] [logging.py:96:log_dist] [Rank 0] step=69, skipped=0, lr=[1.6813729011474854e-05], mom=[(0.9, 0.999)]
steps: 69 loss: 0.6699 iter time (s): 94.708 samples/sec: 1.352

100%|██████████| 1/1 [01:35<00:00, 95.49s/it][A100%|██████████| 1/1 [01:35<00:00, 95.49s/it]
  1%|▏         | 69/5198 [2:24:11<141:39:15, 99.43s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.47s/it][A100%|██████████| 1/1 [01:35<00:00, 95.47s/it]
  1%|▏         | 69/5198 [2:24:11<141:40:03, 99.44s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.50s/it][A100%|██████████| 1/1 [01:35<00:00, 95.50s/it]
  1%|▏         | 69/5198 [2:24:12<141:39:14, 99.43s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.46s/it][A100%|██████████| 1/1 [01:35<00:00, 95.46s/it]
  1%|▏         | 69/5198 [2:24:12<141:40:20, 99.44s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.46s/it][A100%|██████████| 1/1 [01:35<00:00, 95.46s/it]
  1%|▏         | 69/5198 [2:24:12<141:39:17, 99.43s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.51s/it][A100%|██████████| 1/1 [01:35<00:00, 95.51s/it]
  1%|▏         | 69/5198 [2:24:12<141:39:47, 99.43s/it] 
100%|██████████| 1/1 [01:35<00:00, 95.52s/it][A100%|██████████| 1/1 [01:35<00:00, 95.52s/it]
  1%|▏         | 69/5198 [2:24:14<141:39:30, 99.43s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_65
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.18s/it][A100%|██████████| 1/1 [01:29<00:00, 89.18s/it]
  1%|▏         | 70/5198 [2:25:41<137:33:53, 96.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 21:50:46,854] [INFO] [logging.py:96:log_dist] [Rank 0] step=70, skipped=0, lr=[1.686407041342146e-05], mom=[(0.9, 0.999)]
steps: 70 loss: 0.6650 iter time (s): 88.803 samples/sec: 1.441

100%|██████████| 1/1 [01:29<00:00, 89.75s/it][A100%|██████████| 1/1 [01:29<00:00, 89.75s/it]
  1%|▏         | 70/5198 [2:25:41<137:29:48, 96.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.75s/it][A100%|██████████| 1/1 [01:29<00:00, 89.75s/it]
  1%|▏         | 70/5198 [2:25:41<137:30:56, 96.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.72s/it][A100%|██████████| 1/1 [01:29<00:00, 89.72s/it]
  1%|▏         | 70/5198 [2:25:42<137:30:30, 96.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.76s/it][A100%|██████████| 1/1 [01:29<00:00, 89.76s/it]
  1%|▏         | 70/5198 [2:25:42<137:29:57, 96.53s/it]
100%|██████████| 1/1 [01:29<00:00, 89.81s/it][A100%|██████████| 1/1 [01:29<00:00, 89.81s/it]
  1%|▏         | 70/5198 [2:25:42<137:32:06, 96.55s/it]
100%|██████████| 1/1 [01:29<00:00, 89.64s/it][A100%|██████████| 1/1 [01:29<00:00, 89.64s/it]
  1%|▏         | 70/5198 [2:25:42<137:29:52, 96.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A

  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.67s/it][A100%|██████████| 1/1 [01:29<00:00, 89.67s/it]
  1%|▏         | 70/5198 [2:25:44<137:30:12, 96.53s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_66
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.31s/it][A100%|██████████| 1/1 [01:25<00:00, 85.31s/it]
  1%|▏         | 71/5198 [2:27:07<132:57:17, 93.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 21:52:12,252] [INFO] [logging.py:96:log_dist] [Rank 0] step=71, skipped=0, lr=[1.6913697728811226e-05], mom=[(0.9, 0.999)]
steps: 71 loss: 0.6533 iter time (s): 84.514 samples/sec: 1.515

100%|██████████| 1/1 [01:25<00:00, 85.27s/it][A100%|██████████| 1/1 [01:25<00:00, 85.27s/it]
  1%|▏         | 71/5198 [2:27:06<132:40:07, 93.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.20s/it][A100%|██████████| 1/1 [01:25<00:00, 85.20s/it]
  1%|▏         | 71/5198 [2:27:06<132:40:15, 93.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.28s/it][A100%|██████████| 1/1 [01:25<00:00, 85.28s/it]
  1%|▏         | 71/5198 [2:27:07<132:40:35, 93.16s/it]
100%|██████████| 1/1 [01:25<00:00, 85.18s/it][A100%|██████████| 1/1 [01:25<00:00, 85.18s/it]
  1%|▏         | 71/5198 [2:27:07<132:39:53, 93.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.25s/it][A100%|██████████| 1/1 [01:25<00:00, 85.26s/it]
  1%|▏         | 71/5198 [2:27:07<132:40:29, 93.16s/it]
100%|██████████| 1/1 [01:25<00:00, 85.27s/it][A100%|██████████| 1/1 [01:25<00:00, 85.27s/it]
  1%|▏         | 71/5198 [2:27:07<132:40:21, 93.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.29s/it][A100%|██████████| 1/1 [01:25<00:00, 85.29s/it]
  1%|▏         | 71/5198 [2:27:09<132:40:27, 93.16s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_67
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.82s/it][A100%|██████████| 1/1 [01:27<00:00, 87.83s/it]
  1%|▏         | 72/5198 [2:28:35<130:48:10, 91.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 21:53:41,073] [INFO] [logging.py:96:log_dist] [Rank 0] step=72, skipped=0, lr=[1.6962630933084134e-05], mom=[(0.9, 0.999)]
steps: 72 loss: 0.6799 iter time (s): 87.975 samples/sec: 1.455

100%|██████████| 1/1 [01:28<00:00, 88.75s/it][A100%|██████████| 1/1 [01:28<00:00, 88.75s/it]
  1%|▏         | 72/5198 [2:28:35<130:48:00, 91.86s/it]
100%|██████████| 1/1 [01:28<00:00, 88.77s/it][A100%|██████████| 1/1 [01:28<00:00, 88.77s/it]
  1%|▏         | 72/5198 [2:28:35<130:46:32, 91.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.73s/it][A100%|██████████| 1/1 [01:28<00:00, 88.73s/it]
  1%|▏         | 72/5198 [2:28:36<130:48:07, 91.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.80s/it][A100%|██████████| 1/1 [01:28<00:00, 88.80s/it]
  1%|▏         | 72/5198 [2:28:36<130:47:02, 91.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.76s/it][A100%|██████████| 1/1 [01:28<00:00, 88.76s/it]
  1%|▏         | 72/5198 [2:28:36<130:47:34, 91.86s/it]
100%|██████████| 1/1 [01:28<00:00, 88.71s/it][A100%|██████████| 1/1 [01:28<00:00, 88.71s/it]
  1%|▏         | 72/5198 [2:28:36<130:47:46, 91.86s/it]
100%|██████████| 1/1 [01:28<00:00, 88.74s/it][A100%|██████████| 1/1 [01:28<00:00, 88.74s/it]
  1%|▏         | 72/5198 [2:28:38<130:47:34, 91.86s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_68

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.44s/it][A100%|██████████| 1/1 [01:28<00:00, 88.44s/it]
  1%|▏         | 73/5198 [2:30:04<129:30:19, 90.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 21:55:09,986] [INFO] [logging.py:96:log_dist] [Rank 0] step=73, skipped=0, lr=[1.7010889175056685e-05], mom=[(0.9, 0.999)]
steps: 73 loss: 0.7082 iter time (s): 88.120 samples/sec: 1.453

100%|██████████| 1/1 [01:29<00:00, 89.18s/it][A100%|██████████| 1/1 [01:29<00:00, 89.18s/it]
  1%|▏         | 73/5198 [2:30:04<129:37:03, 91.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.32s/it][A100%|██████████| 1/1 [01:29<00:00, 89.32s/it]
  1%|▏         | 73/5198 [2:30:05<129:43:19, 91.12s/it]
100%|██████████| 1/1 [01:29<00:00, 89.21s/it][A100%|██████████| 1/1 [01:29<00:00, 89.21s/it]
  1%|▏         | 73/5198 [2:30:05<129:37:59, 91.06s/it]
100%|██████████| 1/1 [01:29<00:00, 89.28s/it][A100%|██████████| 1/1 [01:29<00:00, 89.28s/it]
  1%|▏         | 73/5198 [2:30:05<129:41:38, 91.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.19s/it][A100%|██████████| 1/1 [01:29<00:00, 89.19s/it]
  1%|▏         | 73/5198 [2:30:05<129:40:42, 91.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.53s/it][A100%|██████████| 1/1 [01:29<00:00, 89.53s/it]
  1%|▏         | 73/5198 [2:30:08<129:48:18, 91.18s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_69
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.62s/it][A100%|██████████| 1/1 [01:29<00:00, 89.62s/it]
  1%|▏         | 73/5198 [2:30:06<129:50:15, 91.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.43s/it][A100%|██████████| 1/1 [01:39<00:00, 99.43s/it]
  1%|▏         | 74/5198 [2:31:44<133:18:49, 93.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 21:56:50,149] [INFO] [logging.py:96:log_dist] [Rank 0] step=74, skipped=0, lr=[1.7058490821911785e-05], mom=[(0.9, 0.999)]
steps: 74 loss: 0.6972 iter time (s): 98.686 samples/sec: 1.297

100%|██████████| 1/1 [01:39<00:00, 99.76s/it][A100%|██████████| 1/1 [01:39<00:00, 99.76s/it]
  1%|▏         | 74/5198 [2:31:45<133:27:13, 93.76s/it]
100%|██████████| 1/1 [01:40<00:00, 100.03s/it][A100%|██████████| 1/1 [01:40<00:00, 100.03s/it]
  1%|▏         | 74/5198 [2:31:45<133:27:47, 93.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.86s/it][A100%|██████████| 1/1 [01:39<00:00, 99.86s/it]
  1%|▏         | 74/5198 [2:31:45<133:24:54, 93.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.91s/it][A100%|██████████| 1/1 [01:39<00:00, 99.91s/it]
  1%|▏         | 74/5198 [2:31:45<133:24:18, 93.73s/it]
100%|██████████| 1/1 [01:39<00:00, 99.79s/it][A100%|██████████| 1/1 [01:39<00:00, 99.79s/it]
  1%|▏         | 74/5198 [2:31:45<133:24:40, 93.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.47s/it][A100%|██████████| 1/1 [01:39<00:00, 99.47s/it]
  1%|▏         | 74/5198 [2:31:45<133:22:01, 93.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.57s/it][A100%|██████████| 1/1 [01:39<00:00, 99.57s/it]
  1%|▏         | 74/5198 [2:31:47<133:22:15, 93.70s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_70
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.25s/it][A100%|██████████| 1/1 [01:33<00:00, 93.25s/it]
  1%|▏         | 75/5198 [2:33:17<133:18:31, 93.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 21:58:23,701] [INFO] [logging.py:96:log_dist] [Rank 0] step=75, skipped=0, lr=[1.7105453501168896e-05], mom=[(0.9, 0.999)]
steps: 75 loss: 0.6334 iter time (s): 92.666 samples/sec: 1.381

100%|██████████| 1/1 [01:33<00:00, 93.24s/it][A100%|██████████| 1/1 [01:33<00:00, 93.24s/it]
  1%|▏         | 75/5198 [2:33:18<133:14:08, 93.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.36s/it][A100%|██████████| 1/1 [01:33<00:00, 93.36s/it]
  1%|▏         | 75/5198 [2:33:18<133:16:20, 93.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.42s/it][A100%|██████████| 1/1 [01:33<00:00, 93.42s/it]
  1%|▏         | 75/5198 [2:33:18<133:15:24, 93.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.38s/it][A100%|██████████| 1/1 [01:33<00:00, 93.38s/it]
  1%|▏         | 75/5198 [2:33:18<133:17:18, 93.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.43s/it][A100%|██████████| 1/1 [01:33<00:00, 93.43s/it]
  1%|▏         | 75/5198 [2:33:19<133:16:32, 93.65s/it]
100%|██████████| 1/1 [01:33<00:00, 93.45s/it][A100%|██████████| 1/1 [01:33<00:00, 93.45s/it]
  1%|▏         | 75/5198 [2:33:19<133:14:15, 93.63s/it]
100%|██████████| 1/1 [01:33<00:00, 93.45s/it][A100%|██████████| 1/1 [01:33<00:00, 93.45s/it]
  1%|▏         | 75/5198 [2:33:21<133:14:25, 93.63s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_71

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.66s/it][A100%|██████████| 1/1 [01:49<00:00, 109.66s/it]
  1%|▏         | 76/5198 [2:35:08<140:18:42, 98.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 22:00:14,280] [INFO] [logging.py:96:log_dist] [Rank 0] step=76, skipped=0, lr=[1.715179413987444e-05], mom=[(0.9, 0.999)]
steps: 76 loss: 0.6695 iter time (s): 109.702 samples/sec: 1.167

100%|██████████| 1/1 [01:50<00:00, 110.49s/it][A100%|██████████| 1/1 [01:50<00:00, 110.49s/it]
  1%|▏         | 76/5198 [2:35:08<140:26:48, 98.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.66s/it][A100%|██████████| 1/1 [01:50<00:00, 110.66s/it]
  1%|▏         | 76/5198 [2:35:09<140:30:29, 98.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.56s/it][A100%|██████████| 1/1 [01:50<00:00, 110.56s/it]
  1%|▏         | 76/5198 [2:35:09<140:29:51, 98.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.55s/it][A100%|██████████| 1/1 [01:50<00:00, 110.55s/it]
  1%|▏         | 76/5198 [2:35:09<140:28:28, 98.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.52s/it][A100%|██████████| 1/1 [01:50<00:00, 110.52s/it]
  1%|▏         | 76/5198 [2:35:09<140:29:10, 98.74s/it]
100%|██████████| 1/1 [01:50<00:00, 110.56s/it][A100%|██████████| 1/1 [01:50<00:00, 110.56s/it]
  1%|▏         | 76/5198 [2:35:09<140:28:18, 98.73s/it]
100%|██████████| 1/1 [01:50<00:00, 110.53s/it][A100%|██████████| 1/1 [01:50<00:00, 110.53s/it]
  1%|▏         | 76/5198 [2:35:11<140:28:13, 98.73s/it]Shard 76 in [76, 158, 182, 242, 293, 363, 418, 421, 752, 814, 842, 991, 1266, 1366, 1425, 1464, 1574, 1728, 2166, 2441, 2563, 2739, 2854, 2894, 3089, 3181, 3395, 3576, 3831, 4300, 4589, 4947, 4950]: file /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_72 skipped to avoid exceeding cuda memory
Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_73
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.85s/it][A100%|██████████| 1/1 [01:35<00:00, 95.85s/it]
  2%|▏         | 78/5198 [2:36:44<107:07:57, 75.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 22:01:50,153] [INFO] [logging.py:96:log_dist] [Rank 0] step=77, skipped=0, lr=[1.719752900123053e-05], mom=[(0.9, 0.999)]
steps: 77 loss: 0.7080 iter time (s): 94.981 samples/sec: 1.348

100%|██████████| 1/1 [01:35<00:00, 95.87s/it][A100%|██████████| 1/1 [01:35<00:00, 95.87s/it]
  2%|▏         | 78/5198 [2:36:44<107:04:33, 75.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.86s/it][A100%|██████████| 1/1 [01:35<00:00, 95.86s/it]
  2%|▏         | 78/5198 [2:36:45<107:05:59, 75.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.90s/it][A100%|██████████| 1/1 [01:35<00:00, 95.90s/it]
  2%|▏         | 78/5198 [2:36:45<107:05:21, 75.30s/it]
100%|██████████| 1/1 [01:35<00:00, 95.93s/it][A100%|██████████| 1/1 [01:35<00:00, 95.93s/it]
  2%|▏         | 78/5198 [2:36:45<107:06:54, 75.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.77s/it][A100%|██████████| 1/1 [01:35<00:00, 95.77s/it]
  2%|▏         | 78/5198 [2:36:45<107:05:25, 75.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.81s/it][A100%|██████████| 1/1 [01:35<00:00, 95.81s/it]
  2%|▏         | 78/5198 [2:36:47<107:04:32, 75.29s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_74

100%|██████████| 1/1 [01:35<00:00, 95.81s/it][A100%|██████████| 1/1 [01:35<00:00, 95.81s/it]
  2%|▏         | 78/5198 [2:36:45<107:04:43, 75.29s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.23s/it][A100%|██████████| 1/1 [01:55<00:00, 115.23s/it]
  2%|▏         | 79/5198 [2:38:40<121:20:04, 85.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 22:03:46,351] [INFO] [logging.py:96:log_dist] [Rank 0] step=78, skipped=0, lr=[1.7242673718860318e-05], mom=[(0.9, 0.999)]
steps: 78 loss: 0.6414 iter time (s): 115.346 samples/sec: 1.110

100%|██████████| 1/1 [01:56<00:00, 116.21s/it][A100%|██████████| 1/1 [01:56<00:00, 116.21s/it]
  2%|▏         | 79/5198 [2:38:41<121:29:22, 85.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.14s/it][A100%|██████████| 1/1 [01:56<00:00, 116.14s/it]
  2%|▏         | 79/5198 [2:38:41<121:28:44, 85.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.04s/it][A100%|██████████| 1/1 [01:56<00:00, 116.04s/it]
  2%|▏         | 79/5198 [2:38:41<121:27:25, 85.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.15s/it][A100%|██████████| 1/1 [01:56<00:00, 116.15s/it]
  2%|▏         | 79/5198 [2:38:41<121:28:32, 85.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.10s/it][A100%|██████████| 1/1 [01:56<00:00, 116.10s/it]
  2%|▏         | 79/5198 [2:38:41<121:27:27, 85.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.16s/it][A100%|██████████| 1/1 [01:56<00:00, 116.16s/it]
  2%|▏         | 79/5198 [2:38:41<121:28:09, 85.42s/it]
100%|██████████| 1/1 [01:56<00:00, 116.17s/it][A100%|██████████| 1/1 [01:56<00:00, 116.17s/it]
  2%|▏         | 79/5198 [2:38:43<121:28:13, 85.43s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_4

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.08s/it][A100%|██████████| 1/1 [01:59<00:00, 119.08s/it]
  2%|▏         | 80/5198 [2:40:39<134:00:22, 94.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 22:05:45,909] [INFO] [logging.py:96:log_dist] [Rank 0] step=79, skipped=0, lr=[1.7287243328890707e-05], mom=[(0.9, 0.999)]
steps: 79 loss: 0.8721 iter time (s): 118.996 samples/sec: 1.076

100%|██████████| 1/1 [01:59<00:00, 119.91s/it][A100%|██████████| 1/1 [01:59<00:00, 119.91s/it]
  2%|▏         | 80/5198 [2:40:40<134:17:10, 94.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.94s/it][A100%|██████████| 1/1 [01:59<00:00, 119.94s/it]
  2%|▏         | 80/5198 [2:40:41<134:17:32, 94.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.02s/it][A100%|██████████| 1/1 [02:00<00:00, 120.02s/it]
  2%|▏         | 80/5198 [2:40:41<134:18:18, 94.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.95s/it][A100%|██████████| 1/1 [01:59<00:00, 119.95s/it]
  2%|▏         | 80/5198 [2:40:41<134:17:29, 94.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 120.00s/it][A100%|██████████| 1/1 [01:59<00:00, 120.00s/it]
  2%|▏         | 80/5198 [2:40:41<134:17:49, 94.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.96s/it][A100%|██████████| 1/1 [01:59<00:00, 119.96s/it]
  2%|▏         | 80/5198 [2:40:41<134:17:25, 94.46s/it]
100%|██████████| 1/1 [01:59<00:00, 119.96s/it][A100%|██████████| 1/1 [01:59<00:00, 119.96s/it]
  2%|▏         | 80/5198 [2:40:43<134:17:28, 94.46s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_75

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.09s/it][A100%|██████████| 1/1 [01:21<00:00, 81.09s/it]
  2%|▏         | 81/5198 [2:42:00<128:57:35, 90.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 22:07:06,372] [INFO] [logging.py:96:log_dist] [Rank 0] step=80, skipped=0, lr=[1.733125230001707e-05], mom=[(0.9, 0.999)]
steps: 80 loss: 0.6642 iter time (s): 79.227 samples/sec: 1.616

100%|██████████| 1/1 [01:20<00:00, 80.02s/it][A100%|██████████| 1/1 [01:20<00:00, 80.02s/it]
  2%|▏         | 81/5198 [2:42:01<128:40:54, 90.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.97s/it][A100%|██████████| 1/1 [01:19<00:00, 79.97s/it]
  2%|▏         | 81/5198 [2:42:01<128:39:54, 90.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.93s/it][A100%|██████████| 1/1 [01:19<00:00, 79.93s/it]
  2%|▏         | 81/5198 [2:42:01<128:39:37, 90.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.99s/it][A100%|██████████| 1/1 [01:19<00:00, 79.99s/it]
  2%|▏         | 81/5198 [2:42:01<128:40:32, 90.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.95s/it][A100%|██████████| 1/1 [01:19<00:00, 79.95s/it]
  2%|▏         | 81/5198 [2:42:01<128:39:48, 90.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.96s/it][A100%|██████████| 1/1 [01:19<00:00, 79.96s/it]
  2%|▏         | 81/5198 [2:42:01<128:39:42, 90.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.98s/it][A100%|██████████| 1/1 [01:19<00:00, 79.98s/it]
  2%|▏         | 81/5198 [2:42:03<128:40:07, 90.52s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_76
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.15s/it][A100%|██████████| 1/1 [01:30<00:00, 90.15s/it]
  2%|▏         | 82/5198 [2:43:31<128:47:47, 90.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 22:08:37,001] [INFO] [logging.py:96:log_dist] [Rank 0] step=81, skipped=0, lr=[1.737471456170049e-05], mom=[(0.9, 0.999)]
steps: 81 loss: 0.6694 iter time (s): 89.862 samples/sec: 1.424

100%|██████████| 1/1 [01:30<00:00, 90.63s/it][A100%|██████████| 1/1 [01:30<00:00, 90.63s/it]
  2%|▏         | 82/5198 [2:43:31<128:42:10, 90.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.76s/it][A100%|██████████| 1/1 [01:30<00:00, 90.76s/it]
  2%|▏         | 82/5198 [2:43:31<128:44:16, 90.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.69s/it][A100%|██████████| 1/1 [01:30<00:00, 90.69s/it]
  2%|▏         | 82/5198 [2:43:32<128:42:31, 90.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.70s/it][A100%|██████████| 1/1 [01:30<00:00, 90.70s/it]
  2%|▏         | 82/5198 [2:43:32<128:43:16, 90.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.70s/it][A100%|██████████| 1/1 [01:30<00:00, 90.70s/it]
  2%|▏         | 82/5198 [2:43:32<128:42:47, 90.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.70s/it][A100%|██████████| 1/1 [01:30<00:00, 90.70s/it]
  2%|▏         | 82/5198 [2:43:32<128:42:42, 90.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.69s/it][A100%|██████████| 1/1 [01:30<00:00, 90.69s/it]
  2%|▏         | 82/5198 [2:43:34<128:42:39, 90.57s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_77
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.08s/it][A100%|██████████| 1/1 [01:22<00:00, 82.08s/it]
  2%|▏         | 83/5198 [2:44:53<125:24:54, 88.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 22:09:59,142] [INFO] [logging.py:96:log_dist] [Rank 0] step=82, skipped=0, lr=[1.74176435306349e-05], mom=[(0.9, 0.999)]
steps: 82 loss: 0.6904 iter time (s): 81.314 samples/sec: 1.574

100%|██████████| 1/1 [01:22<00:00, 82.13s/it][A100%|██████████| 1/1 [01:22<00:00, 82.13s/it]
  2%|▏         | 83/5198 [2:44:53<125:15:32, 88.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.00s/it][A100%|██████████| 1/1 [01:22<00:00, 82.00s/it]
  2%|▏         | 83/5198 [2:44:53<125:13:54, 88.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.04s/it][A100%|██████████| 1/1 [01:22<00:00, 82.04s/it]
  2%|▏         | 83/5198 [2:44:54<125:13:29, 88.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.04s/it][A100%|██████████| 1/1 [01:22<00:00, 82.04s/it]
  2%|▏         | 83/5198 [2:44:54<125:14:00, 88.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.05s/it][A100%|██████████| 1/1 [01:22<00:00, 82.05s/it]
  2%|▏         | 83/5198 [2:44:54<125:14:07, 88.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.04s/it][A100%|██████████| 1/1 [01:22<00:00, 82.04s/it]
  2%|▏         | 83/5198 [2:44:54<125:13:43, 88.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.05s/it][A100%|██████████| 1/1 [01:22<00:00, 82.05s/it]
  2%|▏         | 83/5198 [2:44:56<125:13:48, 88.14s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_78
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.91s/it][A100%|██████████| 1/1 [01:32<00:00, 92.91s/it]
  2%|▏         | 84/5198 [2:46:26<127:22:57, 89.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 22:11:32,519] [INFO] [logging.py:96:log_dist] [Rank 0] step=83, skipped=0, lr=[1.746005213561014e-05], mom=[(0.9, 0.999)]
steps: 83 loss: 0.6475 iter time (s): 92.632 samples/sec: 1.382

100%|██████████| 1/1 [01:33<00:00, 93.37s/it][A100%|██████████| 1/1 [01:33<00:00, 93.37s/it]
  2%|▏         | 84/5198 [2:46:27<127:22:55, 89.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.39s/it][A100%|██████████| 1/1 [01:33<00:00, 93.39s/it]
  2%|▏         | 84/5198 [2:46:27<127:22:27, 89.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.43s/it][A100%|██████████| 1/1 [01:33<00:00, 93.43s/it]
  2%|▏         | 84/5198 [2:46:27<127:23:05, 89.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.39s/it][A100%|██████████| 1/1 [01:33<00:00, 93.39s/it]
  2%|▏         | 84/5198 [2:46:27<127:22:15, 89.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.41s/it][A100%|██████████| 1/1 [01:33<00:00, 93.41s/it]
  2%|▏         | 84/5198 [2:46:27<127:23:01, 89.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.41s/it][A100%|██████████| 1/1 [01:33<00:00, 93.41s/it]
  2%|▏         | 84/5198 [2:46:27<127:22:38, 89.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.40s/it][A100%|██████████| 1/1 [01:33<00:00, 93.40s/it]
  2%|▏         | 84/5198 [2:46:30<127:22:34, 89.67s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_79
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.14s/it][A100%|██████████| 1/1 [01:29<00:00, 89.14s/it]
  2%|▏         | 85/5198 [2:47:56<127:13:22, 89.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 22:13:01,780] [INFO] [logging.py:96:log_dist] [Rank 0] step=84, skipped=0, lr=[1.7501952840885987e-05], mom=[(0.9, 0.999)]
steps: 84 loss: 0.6416 iter time (s): 88.482 samples/sec: 1.447

100%|██████████| 1/1 [01:29<00:00, 89.21s/it][A100%|██████████| 1/1 [01:29<00:00, 89.21s/it]
  2%|▏         | 85/5198 [2:47:56<127:10:12, 89.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.22s/it][A100%|██████████| 1/1 [01:29<00:00, 89.22s/it]
  2%|▏         | 85/5198 [2:47:56<127:10:11, 89.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.22s/it][A100%|██████████| 1/1 [01:29<00:00, 89.22s/it]
  2%|▏         | 85/5198 [2:47:56<127:10:39, 89.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.32s/it][A100%|██████████| 1/1 [01:29<00:00, 89.32s/it]
  2%|▏         | 85/5198 [2:47:56<127:12:26, 89.57s/it]
100%|██████████| 1/1 [01:29<00:00, 89.24s/it][A100%|██████████| 1/1 [01:29<00:00, 89.24s/it]
  2%|▏         | 85/5198 [2:47:57<127:10:50, 89.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.23s/it][A100%|██████████| 1/1 [01:29<00:00, 89.23s/it]
  2%|▏         | 85/5198 [2:47:57<127:10:19, 89.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.23s/it][A100%|██████████| 1/1 [01:29<00:00, 89.23s/it]
  2%|▏         | 85/5198 [2:47:59<127:10:30, 89.54s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_80
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.71s/it][A100%|██████████| 1/1 [01:40<00:00, 100.71s/it]
  2%|▏         | 86/5198 [2:49:36<131:55:10, 92.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 22:14:42,988] [INFO] [logging.py:96:log_dist] [Rank 0] step=85, skipped=0, lr=[1.754335766818311e-05], mom=[(0.9, 0.999)]
steps: 85 loss: 0.6116 iter time (s): 100.449 samples/sec: 1.274

100%|██████████| 1/1 [01:41<00:00, 101.17s/it][A100%|██████████| 1/1 [01:41<00:00, 101.17s/it]
  2%|▏         | 86/5198 [2:49:37<132:01:14, 92.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.18s/it][A100%|██████████| 1/1 [01:41<00:00, 101.18s/it]
  2%|▏         | 86/5198 [2:49:37<132:01:18, 92.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.23s/it][A100%|██████████| 1/1 [01:41<00:00, 101.23s/it]
  2%|▏         | 86/5198 [2:49:38<132:03:04, 92.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.14s/it][A100%|██████████| 1/1 [01:41<00:00, 101.14s/it]
  2%|▏         | 86/5198 [2:49:38<132:01:57, 92.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.18s/it][A100%|██████████| 1/1 [01:41<00:00, 101.18s/it]
  2%|▏         | 86/5198 [2:49:38<132:02:02, 92.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.22s/it][A100%|██████████| 1/1 [01:41<00:00, 101.22s/it]
  2%|▏         | 86/5198 [2:49:40<132:02:28, 92.99s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_81

100%|██████████| 1/1 [01:41<00:00, 101.24s/it][A100%|██████████| 1/1 [01:41<00:00, 101.24s/it]
  2%|▏         | 86/5198 [2:49:38<132:02:54, 92.99s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.46s/it][A100%|██████████| 1/1 [01:48<00:00, 108.46s/it]
  2%|▏         | 87/5198 [2:51:25<138:30:45, 97.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 22:16:31,810] [INFO] [logging.py:96:log_dist] [Rank 0] step=86, skipped=0, lr=[1.7584278217387818e-05], mom=[(0.9, 0.999)]
steps: 86 loss: 0.6130 iter time (s): 108.050 samples/sec: 1.185

100%|██████████| 1/1 [01:48<00:00, 108.78s/it][A100%|██████████| 1/1 [01:48<00:00, 108.78s/it]
  2%|▏         | 87/5198 [2:51:26<138:39:19, 97.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.82s/it][A100%|██████████| 1/1 [01:48<00:00, 108.82s/it]
  2%|▏         | 87/5198 [2:51:26<138:40:02, 97.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.76s/it][A100%|██████████| 1/1 [01:48<00:00, 108.76s/it]
  2%|▏         | 87/5198 [2:51:26<138:39:48, 97.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.79s/it][A100%|██████████| 1/1 [01:48<00:00, 108.79s/it]
  2%|▏         | 87/5198 [2:51:26<138:39:56, 97.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.79s/it][A100%|██████████| 1/1 [01:48<00:00, 108.79s/it]
  2%|▏         | 87/5198 [2:51:27<138:39:58, 97.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.76s/it][A100%|██████████| 1/1 [01:48<00:00, 108.76s/it]
  2%|▏         | 87/5198 [2:51:27<138:39:40, 97.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.78s/it][A100%|██████████| 1/1 [01:48<00:00, 108.78s/it]
  2%|▏         | 87/5198 [2:51:29<138:39:54, 97.67s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_82
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.99s/it][A100%|██████████| 1/1 [01:52<00:00, 112.99s/it]
  2%|▏         | 88/5198 [2:53:18<145:04:11, 102.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 22:18:25,070] [INFO] [logging.py:96:log_dist] [Rank 0] step=87, skipped=0, lr=[1.7624725686059993e-05], mom=[(0.9, 0.999)]
steps: 87 loss: 0.6450 iter time (s): 112.518 samples/sec: 1.138

100%|██████████| 1/1 [01:53<00:00, 113.39s/it][A100%|██████████| 1/1 [01:53<00:00, 113.39s/it]
  2%|▏         | 88/5198 [2:53:19<145:16:18, 102.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.38s/it][A100%|██████████| 1/1 [01:53<00:00, 113.38s/it]
  2%|▏         | 88/5198 [2:53:19<145:16:36, 102.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.41s/it][A100%|██████████| 1/1 [01:53<00:00, 113.41s/it]
  2%|▏         | 88/5198 [2:53:20<145:17:14, 102.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.38s/it][A100%|██████████| 1/1 [01:53<00:00, 113.38s/it]
  2%|▏         | 88/5198 [2:53:20<145:16:24, 102.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.43s/it][A100%|██████████| 1/1 [01:53<00:00, 113.43s/it]
  2%|▏         | 88/5198 [2:53:20<145:17:42, 102.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.39s/it][A100%|██████████| 1/1 [01:53<00:00, 113.39s/it]
  2%|▏         | 88/5198 [2:53:20<145:16:33, 102.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.38s/it][A100%|██████████| 1/1 [01:53<00:00, 113.38s/it]
  2%|▏         | 88/5198 [2:53:22<145:16:34, 102.35s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_83
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.47s/it][A100%|██████████| 1/1 [01:22<00:00, 82.47s/it]
  2%|▏         | 89/5198 [2:54:41<136:45:45, 96.37s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 22:19:46,857] [INFO] [logging.py:96:log_dist] [Rank 0] step=88, skipped=0, lr=[1.766471088782615e-05], mom=[(0.9, 0.999)]
steps: 88 loss: 0.6299 iter time (s): 80.916 samples/sec: 1.582

100%|██████████| 1/1 [01:21<00:00, 81.65s/it][A100%|██████████| 1/1 [01:21<00:00, 81.65s/it]
  2%|▏         | 89/5198 [2:54:41<136:29:49, 96.18s/it] 
100%|██████████| 1/1 [01:21<00:00, 81.80s/it][A100%|██████████| 1/1 [01:21<00:00, 81.80s/it]
  2%|▏         | 89/5198 [2:54:41<136:33:07, 96.22s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.63s/it][A100%|██████████| 1/1 [01:21<00:00, 81.63s/it]
  2%|▏         | 89/5198 [2:54:41<136:29:37, 96.18s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.67s/it][A100%|██████████| 1/1 [01:21<00:00, 81.67s/it]
  2%|▏         | 89/5198 [2:54:42<136:30:47, 96.19s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.82s/it][A100%|██████████| 1/1 [01:21<00:00, 81.82s/it]
  2%|▏         | 89/5198 [2:54:42<136:33:43, 96.23s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.75s/it][A100%|██████████| 1/1 [01:21<00:00, 81.75s/it]
  2%|▏         | 89/5198 [2:54:42<136:32:01, 96.21s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.75s/it][A100%|██████████| 1/1 [01:21<00:00, 81.75s/it]
  2%|▏         | 89/5198 [2:54:44<136:32:01, 96.21s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_84
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.35s/it][A100%|██████████| 1/1 [01:28<00:00, 88.35s/it]
  2%|▏         | 90/5198 [2:56:09<133:24:54, 94.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 22:21:15,597] [INFO] [logging.py:96:log_dist] [Rank 0] step=89, skipped=0, lr=[1.770424426973334e-05], mom=[(0.9, 0.999)]
steps: 89 loss: 0.6063 iter time (s): 87.895 samples/sec: 1.456

100%|██████████| 1/1 [01:28<00:00, 88.70s/it][A100%|██████████| 1/1 [01:28<00:00, 88.70s/it]
  2%|▏         | 90/5198 [2:56:10<133:20:27, 93.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.82s/it][A100%|██████████| 1/1 [01:28<00:00, 88.82s/it]
  2%|▏         | 90/5198 [2:56:10<133:21:26, 93.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.80s/it][A100%|██████████| 1/1 [01:28<00:00, 88.80s/it]
  2%|▏         | 90/5198 [2:56:10<133:20:39, 93.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.68s/it][A100%|██████████| 1/1 [01:28<00:00, 88.68s/it]
  2%|▏         | 90/5198 [2:56:10<133:20:28, 93.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.78s/it][A100%|██████████| 1/1 [01:28<00:00, 88.78s/it]
  2%|▏         | 90/5198 [2:56:10<133:20:58, 93.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.77s/it][A100%|██████████| 1/1 [01:28<00:00, 88.77s/it]
  2%|▏         | 90/5198 [2:56:11<133:21:23, 93.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.77s/it][A100%|██████████| 1/1 [01:28<00:00, 88.77s/it]
  2%|▏         | 90/5198 [2:56:13<133:21:26, 93.99s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_85
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.72s/it][A100%|██████████| 1/1 [01:41<00:00, 101.72s/it]
  2%|▏         | 91/5198 [2:57:51<136:42:57, 96.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 22:22:57,826] [INFO] [logging.py:96:log_dist] [Rank 0] step=90, skipped=0, lr=[1.7743335928633427e-05], mom=[(0.9, 0.999)]
steps: 90 loss: 0.6379 iter time (s): 101.349 samples/sec: 1.263

100%|██████████| 1/1 [01:42<00:00, 102.34s/it][A100%|██████████| 1/1 [01:42<00:00, 102.34s/it]
  2%|▏         | 91/5198 [2:57:52<136:52:15, 96.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.26s/it][A100%|██████████| 1/1 [01:42<00:00, 102.26s/it]
  2%|▏         | 91/5198 [2:57:52<136:50:51, 96.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.23s/it][A100%|██████████| 1/1 [01:42<00:00, 102.23s/it]
  2%|▏         | 91/5198 [2:57:53<136:49:47, 96.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.24s/it][A100%|██████████| 1/1 [01:42<00:00, 102.24s/it]
  2%|▏         | 91/5198 [2:57:53<136:49:34, 96.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.28s/it][A100%|██████████| 1/1 [01:42<00:00, 102.28s/it]
  2%|▏         | 91/5198 [2:57:53<136:50:49, 96.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A

100%|██████████| 1/1 [01:42<00:00, 102.27s/it][A100%|██████████| 1/1 [01:42<00:00, 102.27s/it]
100%|██████████| 1/1 [01:42<00:00, 102.25s/it][A  2%|▏         | 91/5198 [2:57:53<136:50:50, 96.47s/it]100%|██████████| 1/1 [01:42<00:00, 102.25s/it]
  2%|▏         | 91/5198 [2:57:55<136:50:34, 96.46s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_86

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.98s/it][A100%|██████████| 1/1 [01:28<00:00, 88.98s/it]
  2%|▏         | 92/5198 [2:59:20<133:37:15, 94.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 22:24:26,629] [INFO] [logging.py:96:log_dist] [Rank 0] step=91, skipped=0, lr=[1.778199562666217e-05], mom=[(0.9, 0.999)]
steps: 91 loss: 0.6155 iter time (s): 87.889 samples/sec: 1.456

100%|██████████| 1/1 [01:28<00:00, 88.60s/it][A100%|██████████| 1/1 [01:28<00:00, 88.60s/it]
  2%|▏         | 92/5198 [2:59:21<133:30:03, 94.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.68s/it][A100%|██████████| 1/1 [01:28<00:00, 88.68s/it]
  2%|▏         | 92/5198 [2:59:21<133:31:17, 94.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.66s/it][A100%|██████████| 1/1 [01:28<00:00, 88.66s/it]
  2%|▏         | 92/5198 [2:59:21<133:29:55, 94.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.66s/it][A100%|██████████| 1/1 [01:28<00:00, 88.66s/it]
  2%|▏         | 92/5198 [2:59:21<133:29:41, 94.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.65s/it][A100%|██████████| 1/1 [01:28<00:00, 88.65s/it]
  2%|▏         | 92/5198 [2:59:21<133:30:24, 94.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.61s/it][A100%|██████████| 1/1 [01:28<00:00, 88.61s/it]
  2%|▏         | 92/5198 [2:59:21<133:29:21, 94.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.64s/it][A100%|██████████| 1/1 [01:28<00:00, 88.64s/it]
  2%|▏         | 92/5198 [2:59:24<133:29:46, 94.12s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_87
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.45s/it][A100%|██████████| 1/1 [01:18<00:00, 78.45s/it]
  2%|▏         | 93/5198 [3:00:39<126:58:18, 89.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 22:25:44,934] [INFO] [logging.py:96:log_dist] [Rank 0] step=92, skipped=0, lr=[1.7820232805872323e-05], mom=[(0.9, 0.999)]
steps: 92 loss: 0.6519 iter time (s): 77.550 samples/sec: 1.651

100%|██████████| 1/1 [01:18<00:00, 78.29s/it][A100%|██████████| 1/1 [01:18<00:00, 78.29s/it]
  2%|▏         | 93/5198 [3:00:39<126:45:07, 89.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.34s/it][A100%|██████████| 1/1 [01:18<00:00, 78.34s/it]
  2%|▏         | 93/5198 [3:00:39<126:47:07, 89.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.37s/it][A100%|██████████| 1/1 [01:18<00:00, 78.37s/it]
  2%|▏         | 93/5198 [3:00:40<126:47:11, 89.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.32s/it][A100%|██████████| 1/1 [01:18<00:00, 78.32s/it]
  2%|▏         | 93/5198 [3:00:40<126:45:37, 89.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.32s/it][A100%|██████████| 1/1 [01:18<00:00, 78.32s/it]
  2%|▏         | 93/5198 [3:00:40<126:46:19, 89.40s/it]
100%|██████████| 1/1 [01:18<00:00, 78.31s/it][A100%|██████████| 1/1 [01:18<00:00, 78.31s/it]
  2%|▏         | 93/5198 [3:00:40<126:45:05, 89.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.32s/it][A100%|██████████| 1/1 [01:18<00:00, 78.32s/it]
  2%|▏         | 93/5198 [3:00:42<126:45:32, 89.39s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_88
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.23s/it][A100%|██████████| 1/1 [01:29<00:00, 89.23s/it]
  2%|▏         | 94/5198 [3:02:08<126:52:42, 89.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 22:27:14,637] [INFO] [logging.py:96:log_dist] [Rank 0] step=93, skipped=0, lr=[1.7858056602075787e-05], mom=[(0.9, 0.999)]
steps: 93 loss: 0.6634 iter time (s): 88.928 samples/sec: 1.439

100%|██████████| 1/1 [01:29<00:00, 89.67s/it][A100%|██████████| 1/1 [01:29<00:00, 89.67s/it]
  2%|▏         | 94/5198 [3:02:09<126:50:59, 89.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.59s/it][A100%|██████████| 1/1 [01:29<00:00, 89.59s/it]
  2%|▏         | 94/5198 [3:02:09<126:50:26, 89.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.66s/it][A100%|██████████| 1/1 [01:29<00:00, 89.66s/it]
  2%|▏         | 94/5198 [3:02:09<126:52:21, 89.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.71s/it][A100%|██████████| 1/1 [01:29<00:00, 89.71s/it]
  2%|▏         | 94/5198 [3:02:09<126:52:25, 89.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.65s/it][A100%|██████████| 1/1 [01:29<00:00, 89.65s/it]
  2%|▏         | 94/5198 [3:02:09<126:51:32, 89.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.73s/it][A100%|██████████| 1/1 [01:29<00:00, 89.73s/it]
  2%|▏         | 94/5198 [3:02:09<126:52:35, 89.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.71s/it][A100%|██████████| 1/1 [01:29<00:00, 89.71s/it]
  2%|▏         | 94/5198 [3:02:12<126:52:25, 89.49s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_89
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.84s/it][A100%|██████████| 1/1 [01:30<00:00, 90.84s/it]
  2%|▏         | 95/5198 [3:03:39<127:29:01, 89.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 22:28:45,646] [INFO] [logging.py:96:log_dist] [Rank 0] step=94, skipped=0, lr=[1.7895475857945435e-05], mom=[(0.9, 0.999)]
steps: 94 loss: 0.6550 iter time (s): 90.219 samples/sec: 1.419

100%|██████████| 1/1 [01:31<00:00, 91.04s/it][A100%|██████████| 1/1 [01:31<00:00, 91.04s/it]
  2%|▏         | 95/5198 [3:03:40<127:29:46, 89.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.06s/it][A100%|██████████| 1/1 [01:31<00:00, 91.06s/it]
  2%|▏         | 95/5198 [3:03:40<127:29:54, 89.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.05s/it][A100%|██████████| 1/1 [01:31<00:00, 91.05s/it]
  2%|▏         | 95/5198 [3:03:40<127:31:05, 89.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.00s/it][A100%|██████████| 1/1 [01:31<00:00, 91.01s/it]
  2%|▏         | 95/5198 [3:03:40<127:29:12, 89.94s/it]
100%|██████████| 1/1 [01:31<00:00, 91.04s/it][A100%|██████████| 1/1 [01:31<00:00, 91.04s/it]
  2%|▏         | 95/5198 [3:03:40<127:30:44, 89.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.01s/it][A100%|██████████| 1/1 [01:31<00:00, 91.01s/it]
  2%|▏         | 95/5198 [3:03:41<127:30:05, 89.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.02s/it][A100%|██████████| 1/1 [01:31<00:00, 91.02s/it]
  2%|▏         | 95/5198 [3:03:43<127:30:06, 89.95s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_5
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:57<00:00, 117.44s/it][A100%|██████████| 1/1 [01:57<00:00, 117.44s/it]
  2%|▏         | 96/5198 [3:05:37<139:13:33, 98.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 22:30:43,756] [INFO] [logging.py:96:log_dist] [Rank 0] step=95, skipped=0, lr=[1.7932499135423735e-05], mom=[(0.9, 0.999)]
steps: 95 loss: 0.8323 iter time (s): 117.586 samples/sec: 1.089

100%|██████████| 1/1 [01:58<00:00, 118.42s/it][A100%|██████████| 1/1 [01:58<00:00, 118.42s/it]
  2%|▏         | 96/5198 [3:05:38<139:34:25, 98.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.52s/it][A100%|██████████| 1/1 [01:58<00:00, 118.52s/it]
  2%|▏         | 96/5198 [3:05:38<139:37:06, 98.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.52s/it][A100%|██████████| 1/1 [01:58<00:00, 118.52s/it]
  2%|▏         | 96/5198 [3:05:39<139:38:07, 98.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.48s/it][A100%|██████████| 1/1 [01:58<00:00, 118.48s/it]
  2%|▏         | 96/5198 [3:05:39<139:36:48, 98.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.52s/it][A100%|██████████| 1/1 [01:58<00:00, 118.52s/it]
  2%|▏         | 96/5198 [3:05:39<139:36:37, 98.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.49s/it][A100%|██████████| 1/1 [01:58<00:00, 118.49s/it]
  2%|▏         | 96/5198 [3:05:39<139:36:29, 98.51s/it]
100%|██████████| 1/1 [01:58<00:00, 118.47s/it][A100%|██████████| 1/1 [01:58<00:00, 118.47s/it]
  2%|▏         | 96/5198 [3:05:41<139:36:06, 98.50s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_90

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.42s/it][A100%|██████████| 1/1 [01:21<00:00, 81.42s/it]
  2%|▏         | 97/5198 [3:06:59<132:06:25, 93.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 22:32:04,489] [INFO] [logging.py:96:log_dist] [Rank 0] step=96, skipped=0, lr=[1.7969134727481606e-05], mom=[(0.9, 0.999)]
steps: 96 loss: 0.6856 iter time (s): 79.564 samples/sec: 1.609

100%|██████████| 1/1 [01:20<00:00, 80.40s/it][A100%|██████████| 1/1 [01:20<00:00, 80.40s/it]
  2%|▏         | 97/5198 [3:06:59<131:52:00, 93.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.35s/it][A100%|██████████| 1/1 [01:20<00:00, 80.35s/it]
  2%|▏         | 97/5198 [3:06:59<131:52:27, 93.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.24s/it][A100%|██████████| 1/1 [01:20<00:00, 80.25s/it]
  2%|▏         | 97/5198 [3:06:59<131:50:33, 93.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.27s/it][A100%|██████████| 1/1 [01:20<00:00, 80.27s/it]
  2%|▏         | 97/5198 [3:06:59<131:50:22, 93.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.28s/it][A100%|██████████| 1/1 [01:20<00:00, 80.28s/it]
  2%|▏         | 97/5198 [3:06:59<131:50:38, 93.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.29s/it][A100%|██████████| 1/1 [01:20<00:00, 80.29s/it]
  2%|▏         | 97/5198 [3:06:59<131:50:34, 93.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.31s/it][A100%|██████████| 1/1 [01:20<00:00, 80.31s/it]
  2%|▏         | 97/5198 [3:07:02<131:50:43, 93.05s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_91
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.85s/it][A100%|██████████| 1/1 [01:37<00:00, 97.85s/it]
  2%|▏         | 98/5198 [3:08:36<134:05:29, 94.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 22:33:42,987] [INFO] [logging.py:96:log_dist] [Rank 0] step=97, skipped=0, lr=[1.8005390669268035e-05], mom=[(0.9, 0.999)]
steps: 97 loss: 0.6491 iter time (s): 97.740 samples/sec: 1.310

100%|██████████| 1/1 [01:38<00:00, 98.52s/it][A100%|██████████| 1/1 [01:38<00:00, 98.52s/it]
  2%|▏         | 98/5198 [3:08:37<134:09:43, 94.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.46s/it][A100%|██████████| 1/1 [01:38<00:00, 98.46s/it]
  2%|▏         | 98/5198 [3:08:37<134:08:33, 94.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.51s/it][A100%|██████████| 1/1 [01:38<00:00, 98.51s/it]
  2%|▏         | 98/5198 [3:08:38<134:08:32, 94.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.54s/it][A100%|██████████| 1/1 [01:38<00:00, 98.54s/it]
  2%|▏         | 98/5198 [3:08:38<134:09:12, 94.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.55s/it][A100%|██████████| 1/1 [01:38<00:00, 98.55s/it]
  2%|▏         | 98/5198 [3:08:38<134:09:30, 94.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.52s/it][A100%|██████████| 1/1 [01:38<00:00, 98.52s/it]
  2%|▏         | 98/5198 [3:08:38<134:08:49, 94.69s/it]
100%|██████████| 1/1 [01:38<00:00, 98.51s/it][A100%|██████████| 1/1 [01:38<00:00, 98.51s/it]
  2%|▏         | 98/5198 [3:08:40<134:08:37, 94.69s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_92

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.56s/it][A100%|██████████| 1/1 [01:41<00:00, 101.56s/it]
  2%|▏         | 99/5198 [3:10:18<137:04:27, 96.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 22:35:24,833] [INFO] [logging.py:96:log_dist] [Rank 0] step=98, skipped=0, lr=[1.8041274748687843e-05], mom=[(0.9, 0.999)]
steps: 98 loss: 0.6448 iter time (s): 101.071 samples/sec: 1.266

100%|██████████| 1/1 [01:41<00:00, 101.83s/it][A100%|██████████| 1/1 [01:41<00:00, 101.83s/it]
  2%|▏         | 99/5198 [3:10:19<137:09:59, 96.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.85s/it][A100%|██████████| 1/1 [01:41<00:00, 101.85s/it]
  2%|▏         | 99/5198 [3:10:19<137:09:43, 96.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.86s/it][A100%|██████████| 1/1 [01:41<00:00, 101.86s/it]
  2%|▏         | 99/5198 [3:10:19<137:10:09, 96.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.81s/it][A100%|██████████| 1/1 [01:41<00:00, 101.81s/it]
  2%|▏         | 99/5198 [3:10:20<137:09:08, 96.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.82s/it][A100%|██████████| 1/1 [01:41<00:00, 101.82s/it]
  2%|▏         | 99/5198 [3:10:20<137:09:46, 96.84s/it]
100%|██████████| 1/1 [01:41<00:00, 101.80s/it][A100%|██████████| 1/1 [01:41<00:00, 101.80s/it]
  2%|▏         | 99/5198 [3:10:20<137:08:33, 96.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.83s/it][A100%|██████████| 1/1 [01:41<00:00, 101.83s/it]
  2%|▏         | 99/5198 [3:10:22<137:09:13, 96.83s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_93
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.54s/it][A100%|██████████| 1/1 [01:40<00:00, 100.54s/it]
[2024-06-29 22:37:05,434] [INFO] [logging.py:96:log_dist] [Rank 0] step=99, skipped=0, lr=[1.8076794516442503e-05], mom=[(0.9, 0.999)]
steps: 99 loss: 0.6355 iter time (s): 99.883 samples/sec: 1.282

100%|██████████| 1/1 [01:40<00:00, 100.59s/it][A100%|██████████| 1/1 [01:40<00:00, 100.59s/it]

100%|██████████| 1/1 [01:40<00:00, 100.67s/it][A100%|██████████| 1/1 [01:40<00:00, 100.67s/it]

100%|██████████| 1/1 [01:40<00:00, 100.57s/it][A100%|██████████| 1/1 [01:40<00:00, 100.57s/it]

100%|██████████| 1/1 [01:40<00:00, 100.61s/it][A100%|██████████| 1/1 [01:40<00:00, 100.61s/it]

100%|██████████| 1/1 [01:40<00:00, 100.62s/it][A100%|██████████| 1/1 [01:40<00:00, 100.62s/it]

100%|██████████| 1/1 [01:40<00:00, 100.66s/it][A100%|██████████| 1/1 [01:40<00:00, 100.66s/it]

100%|██████████| 1/1 [01:40<00:00, 100.63s/it][A100%|██████████| 1/1 [01:40<00:00, 100.63s/it]
Checkpointing at shard 99
[2024-06-29 22:37:12,043] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step99 is about to be saved!
[2024-06-29 22:37:13,155] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step99/layer_00-model_states.pt...
[2024-06-29 22:37:16,657] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step99/layer_02-model_states.pt...
[2024-06-29 22:37:17,769] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step99/layer_06-model_states.pt...
[2024-06-29 22:37:17,770] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step99/layer_05-model_states.pt...
[2024-06-29 22:37:17,911] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step99/layer_07-model_states.pt...
[2024-06-29 22:37:18,590] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step99/layer_08-model_states.pt...
[2024-06-29 22:37:31,794] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step99/layer_04-model_states.pt...
[2024-06-29 22:37:31,922] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step99/layer_03-model_states.pt...
[2024-06-29 22:40:13,093] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step99/layer_00-model_states.pt.
[2024-06-29 22:40:16,782] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step99/layer_01-model_states.pt...
[2024-06-29 22:42:06,216] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step99/layer_06-model_states.pt.
[2024-06-29 22:42:06,279] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step99/mp_rank_05_model_states.pt...
[2024-06-29 22:42:06,804] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step99/mp_rank_05_model_states.pt.
[2024-06-29 22:42:06,804] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step99 is ready now!
[2024-06-29 22:42:10,578] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step99/layer_07-model_states.pt.
[2024-06-29 22:42:10,614] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step99/mp_rank_06_model_states.pt...
[2024-06-29 22:42:10,769] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step99/mp_rank_06_model_states.pt.
[2024-06-29 22:42:10,769] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step99 is ready now!
[2024-06-29 22:42:12,477] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step99/layer_05-model_states.pt.
[2024-06-29 22:42:12,480] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step99/layer_02-model_states.pt.
[2024-06-29 22:42:12,513] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step99/layer_08-model_states.pt.
[2024-06-29 22:42:12,525] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step99/mp_rank_04_model_states.pt...
[2024-06-29 22:42:12,533] [INFO] [logging.py:96:log_dist] [Rank 1] Saving model checkpoint: /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step99/mp_rank_01_model_states.pt
[2024-06-29 22:42:12,533] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step99/mp_rank_01_model_states.pt...
[2024-06-29 22:42:12,639] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step99/layer_09-model_states.pt...
[2024-06-29 22:42:13,026] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step99/mp_rank_04_model_states.pt.
[2024-06-29 22:42:13,026] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step99 is ready now!
[2024-06-29 22:42:13,060] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step99/mp_rank_01_model_states.pt.
[2024-06-29 22:42:13,060] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step99 is ready now!
[2024-06-29 22:42:15,364] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step99/layer_09-model_states.pt.
[2024-06-29 22:42:15,367] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step99/mp_rank_07_model_states.pt...
[2024-06-29 22:42:15,580] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step99/mp_rank_07_model_states.pt.
[2024-06-29 22:42:15,580] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step99 is ready now!
[2024-06-29 22:44:22,869] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step99/layer_03-model_states.pt.
[2024-06-29 22:44:22,912] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step99/mp_rank_02_model_states.pt...
[2024-06-29 22:44:22,979] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step99/mp_rank_02_model_states.pt.
[2024-06-29 22:44:22,979] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step99 is ready now!
[2024-06-29 22:44:23,045] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step99/layer_01-model_states.pt.
[2024-06-29 22:44:23,076] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step99/layer_04-model_states.pt.
[2024-06-29 22:44:23,088] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step99/mp_rank_00_model_states.pt
[2024-06-29 22:44:23,088] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step99/mp_rank_00_model_states.pt...
[2024-06-29 22:44:23,118] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step99/mp_rank_03_model_states.pt...
[2024-06-29 22:44:23,164] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step99/mp_rank_03_model_states.pt.
[2024-06-29 22:44:23,165] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step99 is ready now!
[2024-06-29 22:44:23,315] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step99/mp_rank_00_model_states.pt.
[2024-06-29 22:44:23,315] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step99 is ready now!
Checkpoint saved using --- 437.0905165672302 seconds ---
  2%|▏         | 100/5198 [3:19:17<324:26:09, 229.10s/it]  2%|▏         | 100/5198 [3:19:17<324:27:24, 229.12s/it]  2%|▏         | 100/5198 [3:19:20<324:24:42, 229.09s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_94
  2%|▏         | 100/5198 [3:19:19<325:43:05, 230.01s/it]  2%|▏         | 100/5198 [3:19:17<324:25:11, 229.09s/it]  2%|▏         | 100/5198 [3:19:17<324:31:55, 229.17s/it]  2%|▏         | 100/5198 [3:19:17<324:28:59, 229.14s/it]  2%|▏         | 100/5198 [3:19:17<324:35:23, 229.21s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.93s/it][A100%|██████████| 1/1 [01:26<00:00, 86.93s/it]
  2%|▏         | 101/5198 [3:20:46<264:57:00, 187.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 22:45:52,502] [INFO] [logging.py:96:log_dist] [Rank 0] step=100, skipped=0, lr=[1.8111957295566368e-05], mom=[(0.9, 0.999)]
steps: 100 loss: 0.6376 iter time (s): 89.043 samples/sec: 1.438

100%|██████████| 1/1 [01:29<00:00, 89.42s/it][A100%|██████████| 1/1 [01:29<00:00, 89.42s/it]
  2%|▏         | 101/5198 [3:20:47<265:12:59, 187.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.77s/it][A100%|██████████| 1/1 [01:29<00:00, 89.77s/it]
  2%|▏         | 101/5198 [3:20:47<265:19:33, 187.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.86s/it][A100%|██████████| 1/1 [01:29<00:00, 89.86s/it]
  2%|▏         | 101/5198 [3:20:47<265:19:50, 187.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.93s/it][A100%|██████████| 1/1 [01:29<00:00, 89.93s/it]
  2%|▏         | 101/5198 [3:20:47<265:20:31, 187.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.97s/it][A100%|██████████| 1/1 [01:29<00:00, 89.97s/it]
  2%|▏         | 101/5198 [3:20:48<265:20:33, 187.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.06s/it][A100%|██████████| 1/1 [01:30<00:00, 90.06s/it]
  2%|▏         | 101/5198 [3:20:48<265:22:07, 187.43s/it]
100%|██████████| 1/1 [01:30<00:00, 90.06s/it][A100%|██████████| 1/1 [01:30<00:00, 90.06s/it]
  2%|▏         | 101/5198 [3:20:50<265:21:52, 187.43s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_95

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.37s/it][A100%|██████████| 1/1 [01:45<00:00, 105.37s/it]
  2%|▏         | 102/5198 [3:22:32<230:13:52, 162.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 22:47:38,417] [INFO] [logging.py:96:log_dist] [Rank 0] step=101, skipped=0, lr=[1.8146770190488428e-05], mom=[(0.9, 0.999)]
steps: 101 loss: 0.6486 iter time (s): 104.882 samples/sec: 1.220

100%|██████████| 1/1 [01:45<00:00, 105.96s/it][A100%|██████████| 1/1 [01:45<00:00, 105.96s/it]
  2%|▏         | 102/5198 [3:22:33<230:38:17, 162.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.78s/it][A100%|██████████| 1/1 [01:45<00:00, 105.78s/it]
  2%|▏         | 102/5198 [3:22:33<230:37:15, 162.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.89s/it][A100%|██████████| 1/1 [01:45<00:00, 105.89s/it]
  2%|▏         | 102/5198 [3:22:33<230:40:08, 162.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.75s/it][A100%|██████████| 1/1 [01:45<00:00, 105.75s/it]
  2%|▏         | 102/5198 [3:22:33<230:36:59, 162.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.75s/it][A100%|██████████| 1/1 [01:45<00:00, 105.75s/it]
  2%|▏         | 102/5198 [3:22:33<230:37:10, 162.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.75s/it][A100%|██████████| 1/1 [01:45<00:00, 105.75s/it]
  2%|▏         | 102/5198 [3:22:36<230:37:54, 162.93s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_96
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.76s/it][A100%|██████████| 1/1 [01:45<00:00, 105.76s/it]
  2%|▏         | 102/5198 [3:22:33<230:38:23, 162.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:19<00:00, 139.01s/it][A100%|██████████| 1/1 [02:19<00:00, 139.01s/it]
  2%|▏         | 103/5198 [3:24:51<220:13:17, 155.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 22:49:58,473] [INFO] [logging.py:96:log_dist] [Rank 0] step=102, skipped=0, lr=[1.8181240095647642e-05], mom=[(0.9, 0.999)]
steps: 102 loss: 0.6538 iter time (s): 139.180 samples/sec: 0.920

100%|██████████| 1/1 [02:19<00:00, 139.94s/it][A100%|██████████| 1/1 [02:19<00:00, 139.94s/it]
  2%|▏         | 103/5198 [3:24:53<220:50:05, 156.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:19<00:00, 139.80s/it][A100%|██████████| 1/1 [02:19<00:00, 139.80s/it]
  2%|▏         | 103/5198 [3:24:53<220:47:46, 156.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:19<00:00, 139.93s/it][A100%|██████████| 1/1 [02:19<00:00, 139.93s/it]
  2%|▏         | 103/5198 [3:24:53<220:48:57, 156.02s/it]
100%|██████████| 1/1 [02:19<00:00, 139.98s/it][A100%|██████████| 1/1 [02:19<00:00, 139.98s/it]
  2%|▏         | 103/5198 [3:24:53<220:50:20, 156.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:19<00:00, 139.95s/it][A100%|██████████| 1/1 [02:19<00:00, 139.95s/it]
  2%|▏         | 103/5198 [3:24:53<220:49:28, 156.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:19<00:00, 139.91s/it][A100%|██████████| 1/1 [02:19<00:00, 139.91s/it]
  2%|▏         | 103/5198 [3:24:53<220:49:23, 156.03s/it]
100%|██████████| 1/1 [02:19<00:00, 139.93s/it][A100%|██████████| 1/1 [02:19<00:00, 139.93s/it]
  2%|▏         | 103/5198 [3:24:56<220:49:27, 156.03s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_97

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.45s/it][A100%|██████████| 1/1 [01:45<00:00, 105.45s/it]
  2%|▏         | 104/5198 [3:26:36<198:56:45, 140.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 22:51:43,046] [INFO] [logging.py:96:log_dist] [Rank 0] step=103, skipped=0, lr=[1.821537370368803e-05], mom=[(0.9, 0.999)]
steps: 103 loss: 0.6070 iter time (s): 103.820 samples/sec: 1.233

100%|██████████| 1/1 [01:44<00:00, 104.52s/it][A100%|██████████| 1/1 [01:44<00:00, 104.52s/it]
  2%|▏         | 104/5198 [3:26:37<198:55:36, 140.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.63s/it][A100%|██████████| 1/1 [01:44<00:00, 104.63s/it]
  2%|▏         | 104/5198 [3:26:37<198:56:47, 140.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.56s/it][A100%|██████████| 1/1 [01:44<00:00, 104.56s/it]
  2%|▏         | 104/5198 [3:26:38<198:56:53, 140.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.70s/it][A100%|██████████| 1/1 [01:44<00:00, 104.70s/it]
  2%|▏         | 104/5198 [3:26:38<198:59:29, 140.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.69s/it][A100%|██████████| 1/1 [01:44<00:00, 104.69s/it]
  2%|▏         | 104/5198 [3:26:38<198:59:33, 140.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.69s/it][A100%|██████████| 1/1 [01:44<00:00, 104.69s/it]
  2%|▏         | 104/5198 [3:26:38<198:59:32, 140.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.70s/it][A100%|██████████| 1/1 [01:44<00:00, 104.70s/it]
  2%|▏         | 104/5198 [3:26:40<198:59:44, 140.63s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_98
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.29s/it][A100%|██████████| 1/1 [01:21<00:00, 81.29s/it]
  2%|▏         | 105/5198 [3:27:58<173:48:08, 122.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 22:53:03,956] [INFO] [logging.py:96:log_dist] [Rank 0] step=104, skipped=0, lr=[1.8249177513257787e-05], mom=[(0.9, 0.999)]
steps: 104 loss: 0.6617 iter time (s): 80.020 samples/sec: 1.600

100%|██████████| 1/1 [01:20<00:00, 80.98s/it][A100%|██████████| 1/1 [01:20<00:00, 80.98s/it]
  2%|▏         | 105/5198 [3:27:58<173:35:36, 122.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.82s/it][A100%|██████████| 1/1 [01:20<00:00, 80.82s/it]
  2%|▏         | 105/5198 [3:27:58<173:32:32, 122.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.90s/it][A100%|██████████| 1/1 [01:20<00:00, 80.90s/it]
  2%|▏         | 105/5198 [3:27:59<173:34:47, 122.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.86s/it][A100%|██████████| 1/1 [01:20<00:00, 80.86s/it]
  2%|▏         | 105/5198 [3:27:59<173:35:23, 122.70s/it]
100%|██████████| 1/1 [01:20<00:00, 80.91s/it][A100%|██████████| 1/1 [01:20<00:00, 80.91s/it]
  2%|▏         | 105/5198 [3:27:59<173:36:36, 122.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.87s/it][A100%|██████████| 1/1 [01:20<00:00, 80.87s/it]
  2%|▏         | 105/5198 [3:27:59<173:35:39, 122.71s/it]
100%|██████████| 1/1 [01:20<00:00, 80.86s/it][A100%|██████████| 1/1 [01:20<00:00, 80.86s/it]
  2%|▏         | 105/5198 [3:28:01<173:35:30, 122.70s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_99
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.39s/it][A100%|██████████| 1/1 [01:34<00:00, 94.39s/it]
  2%|▏         | 106/5198 [3:29:32<161:44:19, 114.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 22:54:38,813] [INFO] [logging.py:96:log_dist] [Rank 0] step=105, skipped=0, lr=[1.828265783643528e-05], mom=[(0.9, 0.999)]
steps: 105 loss: 0.6771 iter time (s): 94.014 samples/sec: 1.362

100%|██████████| 1/1 [01:34<00:00, 94.81s/it][A100%|██████████| 1/1 [01:34<00:00, 94.81s/it]
  2%|▏         | 106/5198 [3:29:33<161:43:31, 114.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.89s/it][A100%|██████████| 1/1 [01:34<00:00, 94.89s/it]
  2%|▏         | 106/5198 [3:29:33<161:43:26, 114.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.81s/it][A100%|██████████| 1/1 [01:34<00:00, 94.81s/it]
  2%|▏         | 106/5198 [3:29:33<161:42:52, 114.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.77s/it][A100%|██████████| 1/1 [01:34<00:00, 94.78s/it]
  2%|▏         | 106/5198 [3:29:34<161:43:20, 114.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.82s/it][A100%|██████████| 1/1 [01:34<00:00, 94.82s/it]
  2%|▏         | 106/5198 [3:29:34<161:43:45, 114.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.79s/it][A100%|██████████| 1/1 [01:34<00:00, 94.79s/it]
  2%|▏         | 106/5198 [3:29:34<161:43:05, 114.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.82s/it][A100%|██████████| 1/1 [01:34<00:00, 94.82s/it]
  2%|▏         | 106/5198 [3:29:36<161:43:39, 114.34s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_100
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.72s/it][A100%|██████████| 1/1 [01:24<00:00, 84.72s/it]
  2%|▏         | 107/5198 [3:30:57<149:11:24, 105.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 22:56:03,413] [INFO] [logging.py:96:log_dist] [Rank 0] step=106, skipped=0, lr=[1.8315820805803032e-05], mom=[(0.9, 0.999)]
steps: 106 loss: 0.6597 iter time (s): 83.784 samples/sec: 1.528

100%|██████████| 1/1 [01:24<00:00, 84.67s/it][A100%|██████████| 1/1 [01:24<00:00, 84.67s/it]
  2%|▏         | 107/5198 [3:30:58<149:06:42, 105.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.67s/it][A100%|██████████| 1/1 [01:24<00:00, 84.67s/it]
  2%|▏         | 107/5198 [3:30:58<149:06:38, 105.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.70s/it][A100%|██████████| 1/1 [01:24<00:00, 84.70s/it]
  2%|▏         | 107/5198 [3:30:58<149:07:01, 105.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.67s/it][A100%|██████████| 1/1 [01:24<00:00, 84.68s/it]
  2%|▏         | 107/5198 [3:30:58<149:06:41, 105.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.67s/it][A100%|██████████| 1/1 [01:24<00:00, 84.67s/it]
  2%|▏         | 107/5198 [3:30:58<149:06:44, 105.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.67s/it][A100%|██████████| 1/1 [01:24<00:00, 84.67s/it]
  2%|▏         | 107/5198 [3:30:58<149:06:12, 105.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.65s/it][A100%|██████████| 1/1 [01:24<00:00, 84.65s/it]
  2%|▏         | 107/5198 [3:31:01<149:06:12, 105.44s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_101
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.21s/it][A100%|██████████| 1/1 [01:42<00:00, 102.21s/it]
  2%|▏         | 108/5198 [3:32:40<147:49:37, 104.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 22:57:46,248] [INFO] [logging.py:96:log_dist] [Rank 0] step=107, skipped=0, lr=[1.8348672381189623e-05], mom=[(0.9, 0.999)]
steps: 107 loss: 0.6486 iter time (s): 101.964 samples/sec: 1.255

100%|██████████| 1/1 [01:42<00:00, 102.86s/it][A100%|██████████| 1/1 [01:42<00:00, 102.86s/it]
  2%|▏         | 108/5198 [3:32:41<147:59:20, 104.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.02s/it][A100%|██████████| 1/1 [01:43<00:00, 103.02s/it]
  2%|▏         | 108/5198 [3:32:41<148:03:35, 104.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.89s/it][A100%|██████████| 1/1 [01:42<00:00, 102.89s/it]
  2%|▏         | 108/5198 [3:32:41<148:00:19, 104.68s/it]
100%|██████████| 1/1 [01:42<00:00, 102.98s/it][A100%|██████████| 1/1 [01:42<00:00, 102.98s/it]
  2%|▏         | 108/5198 [3:32:41<148:02:43, 104.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.93s/it][A100%|██████████| 1/1 [01:42<00:00, 102.93s/it]
  2%|▏         | 108/5198 [3:32:41<148:01:27, 104.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.96s/it][A100%|██████████| 1/1 [01:42<00:00, 102.96s/it]
  2%|▏         | 108/5198 [3:32:41<148:01:42, 104.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.96s/it][A100%|██████████| 1/1 [01:42<00:00, 102.96s/it]
  2%|▏         | 108/5198 [3:32:44<148:01:41, 104.70s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_102
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.19s/it][A100%|██████████| 1/1 [01:52<00:00, 112.19s/it]
  2%|▏         | 109/5198 [3:34:32<151:08:15, 106.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 22:59:38,939] [INFO] [logging.py:96:log_dist] [Rank 0] step=108, skipped=0, lr=[1.8381218356097962e-05], mom=[(0.9, 0.999)]
steps: 108 loss: 0.6794 iter time (s): 111.685 samples/sec: 1.146

100%|██████████| 1/1 [01:52<00:00, 112.33s/it][A100%|██████████| 1/1 [01:52<00:00, 112.33s/it]
  2%|▏         | 109/5198 [3:34:33<151:15:38, 107.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.53s/it][A100%|██████████| 1/1 [01:52<00:00, 112.53s/it]
  2%|▏         | 109/5198 [3:34:33<151:17:56, 107.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.41s/it][A100%|██████████| 1/1 [01:52<00:00, 112.41s/it]
  2%|▏         | 109/5198 [3:34:34<151:17:10, 107.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.49s/it][A100%|██████████| 1/1 [01:52<00:00, 112.49s/it]
  2%|▏         | 109/5198 [3:34:34<151:17:32, 107.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.47s/it][A100%|██████████| 1/1 [01:52<00:00, 112.47s/it]
  2%|▏         | 109/5198 [3:34:34<151:17:48, 107.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.46s/it][A100%|██████████| 1/1 [01:52<00:00, 112.46s/it]
  2%|▏         | 109/5198 [3:34:36<151:17:34, 107.03s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_103

100%|██████████| 1/1 [01:52<00:00, 112.47s/it][A100%|██████████| 1/1 [01:52<00:00, 112.47s/it]
  2%|▏         | 109/5198 [3:34:34<151:17:54, 107.03s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.48s/it][A100%|██████████| 1/1 [01:22<00:00, 82.48s/it]
  2%|▏         | 110/5198 [3:35:55<140:48:10, 99.62s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 23:01:00,705] [INFO] [logging.py:96:log_dist] [Rank 0] step=109, skipped=0, lr=[1.841346436383733e-05], mom=[(0.9, 0.999)]
steps: 109 loss: 0.6402 iter time (s): 80.988 samples/sec: 1.580

100%|██████████| 1/1 [01:21<00:00, 81.81s/it][A100%|██████████| 1/1 [01:21<00:00, 81.81s/it]
  2%|▏         | 110/5198 [3:35:55<140:33:17, 99.45s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.78s/it][A100%|██████████| 1/1 [01:21<00:00, 81.78s/it]
  2%|▏         | 110/5198 [3:35:55<140:34:07, 99.46s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.77s/it][A100%|██████████| 1/1 [01:21<00:00, 81.77s/it]
  2%|▏         | 110/5198 [3:35:55<140:33:07, 99.45s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.78s/it][A100%|██████████| 1/1 [01:21<00:00, 81.78s/it]
  2%|▏         | 110/5198 [3:35:55<140:33:35, 99.45s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.81s/it][A100%|██████████| 1/1 [01:21<00:00, 81.81s/it]
  2%|▏         | 110/5198 [3:35:56<140:34:34, 99.46s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.81s/it][A100%|██████████| 1/1 [01:21<00:00, 81.81s/it]
  2%|▏         | 110/5198 [3:35:56<140:34:37, 99.46s/it] 
100%|██████████| 1/1 [01:21<00:00, 81.81s/it][A100%|██████████| 1/1 [01:21<00:00, 81.81s/it]
  2%|▏         | 110/5198 [3:35:58<140:34:29, 99.46s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_104

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.05s/it][A100%|██████████| 1/1 [01:32<00:00, 92.05s/it]
  2%|▏         | 111/5198 [3:37:27<137:37:54, 97.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 23:02:33,222] [INFO] [logging.py:96:log_dist] [Rank 0] step=110, skipped=0, lr=[1.844541588337544e-05], mom=[(0.9, 0.999)]
steps: 110 loss: 0.6271 iter time (s): 91.690 samples/sec: 1.396

100%|██████████| 1/1 [01:32<00:00, 92.46s/it][A100%|██████████| 1/1 [01:32<00:00, 92.46s/it]
  2%|▏         | 111/5198 [3:37:27<137:34:07, 97.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.45s/it][A100%|██████████| 1/1 [01:32<00:00, 92.45s/it]
  2%|▏         | 111/5198 [3:37:27<137:34:29, 97.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.45s/it][A100%|██████████| 1/1 [01:32<00:00, 92.45s/it]
  2%|▏         | 111/5198 [3:37:28<137:33:49, 97.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.40s/it][A100%|██████████| 1/1 [01:32<00:00, 92.40s/it]
  2%|▏         | 111/5198 [3:37:28<137:33:33, 97.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.51s/it][A100%|██████████| 1/1 [01:32<00:00, 92.51s/it]
  2%|▏         | 111/5198 [3:37:28<137:35:29, 97.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.42s/it][A100%|██████████| 1/1 [01:32<00:00, 92.42s/it]
  2%|▏         | 111/5198 [3:37:28<137:33:50, 97.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.44s/it][A100%|██████████| 1/1 [01:32<00:00, 92.44s/it]
  2%|▏         | 111/5198 [3:37:30<137:34:23, 97.36s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_6
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.15s/it][A100%|██████████| 1/1 [01:59<00:00, 119.15s/it]
  2%|▏         | 112/5198 [3:39:26<146:53:18, 103.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 23:04:32,986] [INFO] [logging.py:96:log_dist] [Rank 0] step=111, skipped=0, lr=[1.847707824492561e-05], mom=[(0.9, 0.999)]
steps: 111 loss: 0.8446 iter time (s): 119.231 samples/sec: 1.074

100%|██████████| 1/1 [02:00<00:00, 120.11s/it][A100%|██████████| 1/1 [02:00<00:00, 120.11s/it]
  2%|▏         | 112/5198 [3:39:27<147:11:19, 104.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.04s/it][A100%|██████████| 1/1 [02:00<00:00, 120.04s/it]
  2%|▏         | 112/5198 [3:39:28<147:10:01, 104.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.12s/it][A100%|██████████| 1/1 [02:00<00:00, 120.12s/it]
  2%|▏         | 112/5198 [3:39:28<147:11:24, 104.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.07s/it][A100%|██████████| 1/1 [02:00<00:00, 120.07s/it]
  2%|▏         | 112/5198 [3:39:28<147:11:22, 104.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.15s/it][A100%|██████████| 1/1 [02:00<00:00, 120.15s/it]
  2%|▏         | 112/5198 [3:39:28<147:11:59, 104.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.12s/it][A100%|██████████| 1/1 [02:00<00:00, 120.12s/it]
  2%|▏         | 112/5198 [3:39:28<147:11:25, 104.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.11s/it][A100%|██████████| 1/1 [02:00<00:00, 120.11s/it]
  2%|▏         | 112/5198 [3:39:30<147:11:33, 104.19s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_105
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.73s/it][A100%|██████████| 1/1 [01:26<00:00, 86.73s/it]
  2%|▏         | 113/5198 [3:40:53<139:36:15, 98.83s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 23:05:59,186] [INFO] [logging.py:96:log_dist] [Rank 0] step=112, skipped=0, lr=[1.850845663528346e-05], mom=[(0.9, 0.999)]
steps: 112 loss: 0.6939 iter time (s): 85.091 samples/sec: 1.504

100%|██████████| 1/1 [01:25<00:00, 85.96s/it][A100%|██████████| 1/1 [01:25<00:00, 85.96s/it]
  2%|▏         | 113/5198 [3:40:53<139:26:20, 98.72s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.93s/it][A100%|██████████| 1/1 [01:25<00:00, 85.93s/it]
  2%|▏         | 113/5198 [3:40:53<139:24:51, 98.70s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.88s/it][A100%|██████████| 1/1 [01:25<00:00, 85.88s/it]
  2%|▏         | 113/5198 [3:40:54<139:24:40, 98.70s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.87s/it][A100%|██████████| 1/1 [01:25<00:00, 85.87s/it]
  2%|▏         | 113/5198 [3:40:54<139:24:05, 98.69s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.84s/it][A100%|██████████| 1/1 [01:25<00:00, 85.84s/it]
  2%|▏         | 113/5198 [3:40:54<139:23:52, 98.69s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.88s/it][A100%|██████████| 1/1 [01:25<00:00, 85.88s/it]
  2%|▏         | 113/5198 [3:40:54<139:24:27, 98.70s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.88s/it][A100%|██████████| 1/1 [01:25<00:00, 85.88s/it]
  2%|▏         | 113/5198 [3:40:56<139:24:38, 98.70s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_106
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.69s/it][A100%|██████████| 1/1 [01:44<00:00, 104.70s/it]
  2%|▏         | 114/5198 [3:42:38<142:07:14, 100.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 23:07:44,571] [INFO] [logging.py:96:log_dist] [Rank 0] step=113, skipped=0, lr=[1.8539556102926362e-05], mom=[(0.9, 0.999)]
steps: 113 loss: 0.6307 iter time (s): 104.581 samples/sec: 1.224

100%|██████████| 1/1 [01:45<00:00, 105.32s/it][A100%|██████████| 1/1 [01:45<00:00, 105.32s/it]
  2%|▏         | 114/5198 [3:42:39<142:12:46, 100.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.37s/it][A100%|██████████| 1/1 [01:45<00:00, 105.37s/it]
  2%|▏         | 114/5198 [3:42:39<142:12:57, 100.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.34s/it][A100%|██████████| 1/1 [01:45<00:00, 105.35s/it]
  2%|▏         | 114/5198 [3:42:39<142:12:13, 100.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.32s/it][A100%|██████████| 1/1 [01:45<00:00, 105.32s/it]
  2%|▏         | 114/5198 [3:42:39<142:10:56, 100.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.37s/it][A100%|██████████| 1/1 [01:45<00:00, 105.37s/it]
  2%|▏         | 114/5198 [3:42:39<142:12:22, 100.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.34s/it][A100%|██████████| 1/1 [01:45<00:00, 105.35s/it]
  2%|▏         | 114/5198 [3:42:39<142:12:03, 100.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.33s/it][A100%|██████████| 1/1 [01:45<00:00, 105.33s/it]
  2%|▏         | 114/5198 [3:42:42<142:11:52, 100.69s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_107
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.56s/it][A100%|██████████| 1/1 [01:43<00:00, 103.56s/it]
  2%|▏         | 115/5198 [3:44:22<143:24:04, 101.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 23:09:28,244] [INFO] [logging.py:96:log_dist] [Rank 0] step=114, skipped=0, lr=[1.857038156288827e-05], mom=[(0.9, 0.999)]
steps: 114 loss: 0.6408 iter time (s): 102.914 samples/sec: 1.244

100%|██████████| 1/1 [01:43<00:00, 103.64s/it][A100%|██████████| 1/1 [01:43<00:00, 103.64s/it]
  2%|▏         | 115/5198 [3:44:22<143:26:09, 101.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.71s/it][A100%|██████████| 1/1 [01:43<00:00, 103.72s/it]
  2%|▏         | 115/5198 [3:44:23<143:28:01, 101.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.68s/it][A100%|██████████| 1/1 [01:43<00:00, 103.68s/it]
  2%|▏         | 115/5198 [3:44:23<143:26:40, 101.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.74s/it][A100%|██████████| 1/1 [01:43<00:00, 103.74s/it]
  2%|▏         | 115/5198 [3:44:23<143:27:19, 101.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.76s/it][A100%|██████████| 1/1 [01:43<00:00, 103.76s/it]
  2%|▏         | 115/5198 [3:44:23<143:28:36, 101.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.77s/it][A100%|██████████| 1/1 [01:43<00:00, 103.77s/it]
  2%|▏         | 115/5198 [3:44:25<143:28:37, 101.62s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_108

100%|██████████| 1/1 [01:43<00:00, 103.78s/it][A100%|██████████| 1/1 [01:43<00:00, 103.78s/it]
  2%|▏         | 115/5198 [3:44:23<143:29:02, 101.62s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.66s/it][A100%|██████████| 1/1 [01:22<00:00, 82.66s/it]
  2%|▏         | 116/5198 [3:45:44<135:26:09, 95.94s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 23:10:50,454] [INFO] [logging.py:96:log_dist] [Rank 0] step=115, skipped=0, lr=[1.8600937801421617e-05], mom=[(0.9, 0.999)]
steps: 115 loss: 0.6577 iter time (s): 81.343 samples/sec: 1.574

100%|██████████| 1/1 [01:22<00:00, 82.23s/it][A100%|██████████| 1/1 [01:22<00:00, 82.23s/it]
  2%|▏         | 116/5198 [3:45:45<135:12:47, 95.78s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.15s/it][A100%|██████████| 1/1 [01:22<00:00, 82.15s/it]
  2%|▏         | 116/5198 [3:45:45<135:12:03, 95.77s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.28s/it][A100%|██████████| 1/1 [01:22<00:00, 82.28s/it]
  2%|▏         | 116/5198 [3:45:45<135:14:31, 95.80s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.15s/it][A100%|██████████| 1/1 [01:22<00:00, 82.15s/it]
  2%|▏         | 116/5198 [3:45:45<135:12:31, 95.78s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.21s/it][A100%|██████████| 1/1 [01:22<00:00, 82.21s/it]
  2%|▏         | 116/5198 [3:45:45<135:13:07, 95.79s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.15s/it][A100%|██████████| 1/1 [01:22<00:00, 82.15s/it]
  2%|▏         | 116/5198 [3:45:48<135:12:23, 95.78s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_109

100%|██████████| 1/1 [01:22<00:00, 82.15s/it][A100%|██████████| 1/1 [01:22<00:00, 82.15s/it]
  2%|▏         | 116/5198 [3:45:45<135:12:46, 95.78s/it] Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.85s/it][A100%|██████████| 1/1 [01:26<00:00, 86.85s/it]
  2%|▏         | 117/5198 [3:47:11<131:37:03, 93.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 23:12:17,598] [INFO] [logging.py:96:log_dist] [Rank 0] step=116, skipped=0, lr=[1.8631229480457462e-05], mom=[(0.9, 0.999)]
steps: 116 loss: 0.6029 iter time (s): 86.335 samples/sec: 1.483

100%|██████████| 1/1 [01:27<00:00, 87.08s/it][A100%|██████████| 1/1 [01:27<00:00, 87.08s/it]
  2%|▏         | 117/5198 [3:47:12<131:30:13, 93.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.12s/it][A100%|██████████| 1/1 [01:27<00:00, 87.13s/it]
  2%|▏         | 117/5198 [3:47:12<131:30:57, 93.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.09s/it][A100%|██████████| 1/1 [01:27<00:00, 87.09s/it]
  2%|▏         | 117/5198 [3:47:12<131:31:47, 93.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.09s/it][A100%|██████████| 1/1 [01:27<00:00, 87.09s/it]
  2%|▏         | 117/5198 [3:47:12<131:30:16, 93.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.11s/it][A100%|██████████| 1/1 [01:27<00:00, 87.11s/it]
  2%|▏         | 117/5198 [3:47:12<131:31:15, 93.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.09s/it][A100%|██████████| 1/1 [01:27<00:00, 87.09s/it]
  2%|▏         | 117/5198 [3:47:15<131:30:21, 93.17s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_110

100%|██████████| 1/1 [01:27<00:00, 87.09s/it][A100%|██████████| 1/1 [01:27<00:00, 87.09s/it]
  2%|▏         | 117/5198 [3:47:12<131:30:30, 93.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.73s/it][A100%|██████████| 1/1 [01:44<00:00, 104.73s/it]
  2%|▏         | 118/5198 [3:48:56<136:30:58, 96.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 23:14:02,943] [INFO] [logging.py:96:log_dist] [Rank 0] step=117, skipped=0, lr=[1.8661261141874143e-05], mom=[(0.9, 0.999)]
steps: 117 loss: 0.6422 iter time (s): 104.578 samples/sec: 1.224

100%|██████████| 1/1 [01:45<00:00, 105.38s/it][A100%|██████████| 1/1 [01:45<00:00, 105.38s/it]
  2%|▏         | 118/5198 [3:48:57<136:38:55, 96.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.35s/it][A100%|██████████| 1/1 [01:45<00:00, 105.35s/it]
  2%|▏         | 118/5198 [3:48:57<136:38:38, 96.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.28s/it][A100%|██████████| 1/1 [01:45<00:00, 105.28s/it]
  2%|▏         | 118/5198 [3:48:58<136:37:47, 96.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.39s/it][A100%|██████████| 1/1 [01:45<00:00, 105.39s/it]
  2%|▏         | 118/5198 [3:48:58<136:39:10, 96.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.37s/it][A100%|██████████| 1/1 [01:45<00:00, 105.37s/it]
  2%|▏         | 118/5198 [3:48:58<136:39:27, 96.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.35s/it][A100%|██████████| 1/1 [01:45<00:00, 105.35s/it]
  2%|▏         | 118/5198 [3:48:58<136:38:21, 96.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.36s/it][A100%|██████████| 1/1 [01:45<00:00, 105.36s/it]
  2%|▏         | 118/5198 [3:49:00<136:38:29, 96.83s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_111
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.29s/it][A100%|██████████| 1/1 [01:20<00:00, 80.29s/it]
  2%|▏         | 119/5198 [3:50:17<129:35:17, 91.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 23:15:22,698] [INFO] [logging.py:96:log_dist] [Rank 0] step=118, skipped=0, lr=[1.869103721158431e-05], mom=[(0.9, 0.999)]
steps: 118 loss: 0.6847 iter time (s): 78.967 samples/sec: 1.621

100%|██████████| 1/1 [01:19<00:00, 79.66s/it][A100%|██████████| 1/1 [01:19<00:00, 79.66s/it]
  2%|▏         | 119/5198 [3:50:17<129:21:20, 91.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.76s/it][A100%|██████████| 1/1 [01:19<00:00, 79.76s/it]
  2%|▏         | 119/5198 [3:50:17<129:23:39, 91.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.75s/it][A100%|██████████| 1/1 [01:19<00:00, 79.75s/it]
  2%|▏         | 119/5198 [3:50:17<129:23:07, 91.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.73s/it][A100%|██████████| 1/1 [01:19<00:00, 79.74s/it]
  2%|▏         | 119/5198 [3:50:17<129:23:20, 91.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.71s/it][A100%|██████████| 1/1 [01:19<00:00, 79.71s/it]
  2%|▏         | 119/5198 [3:50:17<129:22:50, 91.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.69s/it][A100%|██████████| 1/1 [01:19<00:00, 79.69s/it]
  2%|▏         | 119/5198 [3:50:18<129:21:45, 91.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.73s/it][A100%|██████████| 1/1 [01:19<00:00, 79.73s/it]
  2%|▏         | 119/5198 [3:50:20<129:22:43, 91.70s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_112
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.87s/it][A100%|██████████| 1/1 [01:46<00:00, 106.87s/it]
  2%|▏         | 120/5198 [3:52:04<135:58:50, 96.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 23:17:10,359] [INFO] [logging.py:96:log_dist] [Rank 0] step=119, skipped=0, lr=[1.8720562003449495e-05], mom=[(0.9, 0.999)]
steps: 119 loss: 0.6475 iter time (s): 106.894 samples/sec: 1.197

100%|██████████| 1/1 [01:47<00:00, 107.70s/it][A
100%|██████████| 1/1 [01:47<00:00, 107.70s/it]
100%|██████████| 1/1 [01:47<00:00, 107.91s/it][A100%|██████████| 1/1 [01:47<00:00, 107.91s/it]
  2%|▏         | 120/5198 [3:52:05<136:08:09, 96.51s/it]  2%|▏         | 120/5198 [3:52:05<136:11:56, 96.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.75s/it][A100%|██████████| 1/1 [01:47<00:00, 107.75s/it]
  2%|▏         | 120/5198 [3:52:05<136:09:08, 96.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.85s/it][A100%|██████████| 1/1 [01:47<00:00, 107.85s/it]
  2%|▏         | 120/5198 [3:52:05<136:11:51, 96.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.89s/it][A100%|██████████| 1/1 [01:47<00:00, 107.89s/it]
  2%|▏         | 120/5198 [3:52:05<136:12:26, 96.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.85s/it][A100%|██████████| 1/1 [01:47<00:00, 107.85s/it]
  2%|▏         | 120/5198 [3:52:08<136:11:22, 96.55s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_113
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.90s/it][A100%|██████████| 1/1 [01:47<00:00, 107.90s/it]
  2%|▏         | 120/5198 [3:52:05<136:12:03, 96.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.54s/it][A100%|██████████| 1/1 [01:47<00:00, 107.54s/it]
  2%|▏         | 121/5198 [3:53:52<140:46:47, 99.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 23:18:57,810] [INFO] [logging.py:96:log_dist] [Rank 0] step=120, skipped=0, lr=[1.87498397230309e-05], mom=[(0.9, 0.999)]
steps: 120 loss: 0.6594 iter time (s): 106.510 samples/sec: 1.202

100%|██████████| 1/1 [01:47<00:00, 107.23s/it][A100%|██████████| 1/1 [01:47<00:00, 107.23s/it]
  2%|▏         | 121/5198 [3:53:52<140:41:25, 99.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.34s/it][A100%|██████████| 1/1 [01:47<00:00, 107.34s/it]
  2%|▏         | 121/5198 [3:53:52<140:41:45, 99.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.36s/it][A100%|██████████| 1/1 [01:47<00:00, 107.36s/it]
  2%|▏         | 121/5198 [3:53:52<140:42:50, 99.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.23s/it][A100%|██████████| 1/1 [01:47<00:00, 107.23s/it]
  2%|▏         | 121/5198 [3:53:53<140:41:31, 99.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.22s/it][A100%|██████████| 1/1 [01:47<00:00, 107.22s/it]
  2%|▏         | 121/5198 [3:53:53<140:41:37, 99.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.25s/it][A100%|██████████| 1/1 [01:47<00:00, 107.25s/it]
  2%|▏         | 121/5198 [3:53:53<140:42:06, 99.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.28s/it][A100%|██████████| 1/1 [01:47<00:00, 107.28s/it]
  2%|▏         | 121/5198 [3:53:55<140:42:16, 99.77s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_114
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.70s/it][A100%|██████████| 1/1 [01:40<00:00, 100.70s/it]
  2%|▏         | 122/5198 [3:55:33<141:14:29, 100.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 23:20:38,689] [INFO] [logging.py:96:log_dist] [Rank 0] step=121, skipped=0, lr=[1.8778874471184513e-05], mom=[(0.9, 0.999)]
steps: 121 loss: 0.6232 iter time (s): 100.075 samples/sec: 1.279

100%|██████████| 1/1 [01:40<00:00, 100.89s/it][A100%|██████████| 1/1 [01:40<00:00, 100.89s/it]
  2%|▏         | 122/5198 [3:55:33<141:08:43, 100.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.89s/it][A100%|██████████| 1/1 [01:40<00:00, 100.89s/it]
  2%|▏         | 122/5198 [3:55:33<141:08:50, 100.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.81s/it][A100%|██████████| 1/1 [01:40<00:00, 100.81s/it]
  2%|▏         | 122/5198 [3:55:33<141:07:28, 100.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.84s/it][A100%|██████████| 1/1 [01:40<00:00, 100.85s/it]
  2%|▏         | 122/5198 [3:55:33<141:07:32, 100.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.87s/it][A100%|██████████| 1/1 [01:40<00:00, 100.87s/it]
  2%|▏         | 122/5198 [3:55:33<141:08:16, 100.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.86s/it][A100%|██████████| 1/1 [01:40<00:00, 100.86s/it]
  2%|▏         | 122/5198 [3:55:34<141:08:19, 100.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.86s/it][A100%|██████████| 1/1 [01:40<00:00, 100.86s/it]
  2%|▏         | 122/5198 [3:55:36<141:08:33, 100.10s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_115
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.44s/it][A100%|██████████| 1/1 [01:26<00:00, 86.44s/it]
  2%|▏         | 123/5198 [3:56:59<135:33:55, 96.16s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 23:22:05,527] [INFO] [logging.py:96:log_dist] [Rank 0] step=122, skipped=0, lr=[1.880767024750831e-05], mom=[(0.9, 0.999)]
steps: 122 loss: 0.6564 iter time (s): 86.041 samples/sec: 1.488

100%|██████████| 1/1 [01:26<00:00, 86.80s/it][A100%|██████████| 1/1 [01:26<00:00, 86.80s/it]
  2%|▏         | 123/5198 [3:57:00<135:30:02, 96.12s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.79s/it][A100%|██████████| 1/1 [01:26<00:00, 86.79s/it]
  2%|▏         | 123/5198 [3:57:00<135:29:34, 96.11s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.84s/it][A100%|██████████| 1/1 [01:26<00:00, 86.84s/it]
  2%|▏         | 123/5198 [3:57:00<135:29:55, 96.12s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.77s/it][A100%|██████████| 1/1 [01:26<00:00, 86.77s/it]
  2%|▏         | 123/5198 [3:57:00<135:28:25, 96.10s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.78s/it][A100%|██████████| 1/1 [01:26<00:00, 86.78s/it]
  2%|▏         | 123/5198 [3:57:00<135:28:55, 96.11s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.75s/it][A100%|██████████| 1/1 [01:26<00:00, 86.75s/it]
  2%|▏         | 123/5198 [3:57:00<135:28:15, 96.10s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.76s/it][A100%|██████████| 1/1 [01:26<00:00, 86.76s/it]
  2%|▏         | 123/5198 [3:57:03<135:28:33, 96.10s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_116
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.46s/it][A100%|██████████| 1/1 [01:28<00:00, 88.46s/it]
  2%|▏         | 124/5198 [3:58:28<132:21:28, 93.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 23:23:34,221] [INFO] [logging.py:96:log_dist] [Rank 0] step=123, skipped=0, lr=[1.8836230953648723e-05], mom=[(0.9, 0.999)]
steps: 123 loss: 0.6634 iter time (s): 87.970 samples/sec: 1.455

100%|██████████| 1/1 [01:28<00:00, 88.68s/it][A100%|██████████| 1/1 [01:28<00:00, 88.68s/it]
  2%|▏         | 124/5198 [3:58:28<132:20:10, 93.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.75s/it][A100%|██████████| 1/1 [01:28<00:00, 88.75s/it]
  2%|▏         | 124/5198 [3:58:28<132:21:35, 93.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.73s/it][A100%|██████████| 1/1 [01:28<00:00, 88.73s/it]
  2%|▏         | 124/5198 [3:58:29<132:21:05, 93.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.74s/it][A100%|██████████| 1/1 [01:28<00:00, 88.74s/it]
  2%|▏         | 124/5198 [3:58:29<132:20:23, 93.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.76s/it][A100%|██████████| 1/1 [01:28<00:00, 88.76s/it]
  2%|▏         | 124/5198 [3:58:29<132:21:07, 93.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.79s/it][A100%|██████████| 1/1 [01:28<00:00, 88.79s/it]
  2%|▏         | 124/5198 [3:58:29<132:21:18, 93.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.77s/it][A100%|██████████| 1/1 [01:28<00:00, 88.77s/it]
  2%|▏         | 124/5198 [3:58:31<132:21:10, 93.90s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_117
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.68s/it][A100%|██████████| 1/1 [02:03<00:00, 123.68s/it]
  2%|▏         | 125/5198 [4:00:32<144:59:11, 102.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 23:25:39,046] [INFO] [logging.py:96:log_dist] [Rank 0] step=124, skipped=0, lr=[1.8864560396473256e-05], mom=[(0.9, 0.999)]
steps: 124 loss: 0.6174 iter time (s): 124.016 samples/sec: 1.032

100%|██████████| 1/1 [02:04<00:00, 124.83s/it][A100%|██████████| 1/1 [02:04<00:00, 124.83s/it]
  2%|▏         | 125/5198 [4:00:33<145:23:36, 103.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:04<00:00, 124.83s/it][A100%|██████████| 1/1 [02:04<00:00, 124.83s/it]
  2%|▏         | 125/5198 [4:00:33<145:24:40, 103.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:04<00:00, 124.88s/it][A100%|██████████| 1/1 [02:04<00:00, 124.88s/it]
  2%|▏         | 125/5198 [4:00:34<145:25:24, 103.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:04<00:00, 124.85s/it][A100%|██████████| 1/1 [02:04<00:00, 124.85s/it]
  2%|▏         | 125/5198 [4:00:34<145:24:09, 103.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:04<00:00, 124.88s/it][A100%|██████████| 1/1 [02:04<00:00, 124.88s/it]
  2%|▏         | 125/5198 [4:00:34<145:25:24, 103.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:04<00:00, 124.84s/it][A100%|██████████| 1/1 [02:04<00:00, 124.84s/it]
  2%|▏         | 125/5198 [4:00:34<145:24:31, 103.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:04<00:00, 124.83s/it][A100%|██████████| 1/1 [02:04<00:00, 124.83s/it]
  2%|▏         | 125/5198 [4:00:36<145:24:20, 103.19s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_118
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.12s/it][A100%|██████████| 1/1 [01:50<00:00, 110.12s/it]
  2%|▏         | 126/5198 [4:02:22<148:04:17, 105.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 23:27:28,900] [INFO] [logging.py:96:log_dist] [Rank 0] step=125, skipped=0, lr=[1.889266229111566e-05], mom=[(0.9, 0.999)]
steps: 125 loss: 0.6041 iter time (s): 109.027 samples/sec: 1.174

100%|██████████| 1/1 [01:49<00:00, 109.91s/it][A100%|██████████| 1/1 [01:49<00:00, 109.91s/it]
  2%|▏         | 126/5198 [4:02:23<148:12:59, 105.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.93s/it][A100%|██████████| 1/1 [01:49<00:00, 109.94s/it]
  2%|▏         | 126/5198 [4:02:23<148:14:14, 105.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.91s/it][A100%|██████████| 1/1 [01:49<00:00, 109.91s/it]
  2%|▏         | 126/5198 [4:02:24<148:14:03, 105.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.01s/it][A100%|██████████| 1/1 [01:50<00:00, 110.01s/it]
  2%|▏         | 126/5198 [4:02:24<148:15:49, 105.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.91s/it][A100%|██████████| 1/1 [01:49<00:00, 109.91s/it]
  2%|▏         | 126/5198 [4:02:24<148:14:06, 105.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.94s/it][A100%|██████████| 1/1 [01:49<00:00, 109.94s/it]
  2%|▏         | 126/5198 [4:02:26<148:14:08, 105.21s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_119

100%|██████████| 1/1 [01:49<00:00, 109.95s/it][A100%|██████████| 1/1 [01:49<00:00, 109.95s/it]
  2%|▏         | 126/5198 [4:02:24<148:14:34, 105.22s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.23s/it][A100%|██████████| 1/1 [01:38<00:00, 98.23s/it]
  2%|▏         | 127/5198 [4:04:00<145:12:22, 103.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 23:29:06,957] [INFO] [logging.py:96:log_dist] [Rank 0] step=126, skipped=0, lr=[1.8920540263899815e-05], mom=[(0.9, 0.999)]
steps: 126 loss: 0.6330 iter time (s): 97.134 samples/sec: 1.318

100%|██████████| 1/1 [01:37<00:00, 97.99s/it][A100%|██████████| 1/1 [01:37<00:00, 97.99s/it]
  2%|▏         | 127/5198 [4:04:01<145:08:33, 103.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.01s/it][A100%|██████████| 1/1 [01:38<00:00, 98.01s/it]
  2%|▏         | 127/5198 [4:04:01<145:09:57, 103.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.98s/it][A100%|██████████| 1/1 [01:37<00:00, 97.99s/it]
  2%|▏         | 127/5198 [4:04:02<145:09:13, 103.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.88s/it][A100%|██████████| 1/1 [01:37<00:00, 97.88s/it]
  2%|▏         | 127/5198 [4:04:02<145:07:49, 103.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.92s/it][A100%|██████████| 1/1 [01:37<00:00, 97.93s/it]
  2%|▏         | 127/5198 [4:04:02<145:07:45, 103.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.92s/it][A100%|██████████| 1/1 [01:37<00:00, 97.92s/it]
  2%|▏         | 127/5198 [4:04:02<145:07:47, 103.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.94s/it][A100%|██████████| 1/1 [01:37<00:00, 97.94s/it]
  2%|▏         | 127/5198 [4:04:04<145:08:10, 103.04s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_7
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.48s/it][A100%|██████████| 1/1 [02:00<00:00, 120.48s/it]
  2%|▏         | 128/5198 [4:06:01<152:34:16, 108.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 23:31:07,887] [INFO] [logging.py:96:log_dist] [Rank 0] step=127, skipped=0, lr=[1.8948197855148e-05], mom=[(0.9, 0.999)]
steps: 127 loss: 0.8008 iter time (s): 120.347 samples/sec: 1.064

100%|██████████| 1/1 [02:01<00:00, 121.14s/it][A100%|██████████| 1/1 [02:01<00:00, 121.14s/it]
  2%|▏         | 128/5198 [4:06:02<152:45:47, 108.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:01<00:00, 121.07s/it][A100%|██████████| 1/1 [02:01<00:00, 121.07s/it]
  2%|▏         | 128/5198 [4:06:02<152:45:16, 108.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:01<00:00, 121.03s/it][A100%|██████████| 1/1 [02:01<00:00, 121.03s/it]
  2%|▏         | 128/5198 [4:06:03<152:43:36, 108.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:01<00:00, 121.17s/it][A100%|██████████| 1/1 [02:01<00:00, 121.17s/it]
  2%|▏         | 128/5198 [4:06:03<152:46:11, 108.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:01<00:00, 121.15s/it][A100%|██████████| 1/1 [02:01<00:00, 121.15s/it]
  2%|▏         | 128/5198 [4:06:03<152:45:34, 108.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:01<00:00, 121.17s/it][A100%|██████████| 1/1 [02:01<00:00, 121.17s/it]
  2%|▏         | 128/5198 [4:06:03<152:46:04, 108.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:01<00:00, 121.17s/it][A100%|██████████| 1/1 [02:01<00:00, 121.17s/it]
  2%|▏         | 128/5198 [4:06:05<152:46:13, 108.48s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_120
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.09s/it][A100%|██████████| 1/1 [01:31<00:00, 91.09s/it]
  2%|▏         | 129/5198 [4:07:32<145:20:40, 103.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 23:32:38,655] [INFO] [logging.py:96:log_dist] [Rank 0] step=128, skipped=0, lr=[1.8975638521879078e-05], mom=[(0.9, 0.999)]
steps: 128 loss: 0.6049 iter time (s): 89.719 samples/sec: 1.427

100%|██████████| 1/1 [01:30<00:00, 90.58s/it][A100%|██████████| 1/1 [01:30<00:00, 90.58s/it]
  2%|▏         | 129/5198 [4:07:33<145:10:58, 103.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.55s/it][A100%|██████████| 1/1 [01:30<00:00, 90.55s/it]
  2%|▏         | 129/5198 [4:07:33<145:09:33, 103.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.70s/it][A100%|██████████| 1/1 [01:30<00:00, 90.70s/it]
  2%|▏         | 129/5198 [4:07:33<145:12:31, 103.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.62s/it][A100%|██████████| 1/1 [01:30<00:00, 90.63s/it]
  2%|▏         | 129/5198 [4:07:33<145:12:11, 103.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.61s/it][A100%|██████████| 1/1 [01:30<00:00, 90.61s/it]
  2%|▏         | 129/5198 [4:07:34<145:11:22, 103.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.58s/it][A100%|██████████| 1/1 [01:30<00:00, 90.58s/it]
  2%|▏         | 129/5198 [4:07:36<145:11:04, 103.11s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_121

100%|██████████| 1/1 [01:30<00:00, 90.60s/it][A100%|██████████| 1/1 [01:30<00:00, 90.60s/it]
  2%|▏         | 129/5198 [4:07:34<145:11:29, 103.11s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.09s/it][A100%|██████████| 1/1 [01:24<00:00, 84.09s/it]
  3%|▎         | 130/5198 [4:08:57<137:19:45, 97.55s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 23:34:02,788] [INFO] [logging.py:96:log_dist] [Rank 0] step=129, skipped=0, lr=[1.9002865640401647e-05], mom=[(0.9, 0.999)]
steps: 129 loss: 0.6700 iter time (s): 83.255 samples/sec: 1.537

100%|██████████| 1/1 [01:24<00:00, 84.03s/it][A100%|██████████| 1/1 [01:24<00:00, 84.03s/it]
  3%|▎         | 130/5198 [4:08:57<137:06:03, 97.39s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.07s/it][A100%|██████████| 1/1 [01:24<00:00, 84.07s/it]
  3%|▎         | 130/5198 [4:08:57<137:06:09, 97.39s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.97s/it][A100%|██████████| 1/1 [01:23<00:00, 83.97s/it]
  3%|▎         | 130/5198 [4:08:57<137:05:35, 97.38s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.03s/it][A100%|██████████| 1/1 [01:24<00:00, 84.03s/it]
  3%|▎         | 130/5198 [4:08:58<137:06:48, 97.40s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.06s/it][A100%|██████████| 1/1 [01:24<00:00, 84.06s/it]
  3%|▎         | 130/5198 [4:08:58<137:06:58, 97.40s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.04s/it][A100%|██████████| 1/1 [01:24<00:00, 84.04s/it]
  3%|▎         | 130/5198 [4:09:00<137:06:20, 97.39s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_122

100%|██████████| 1/1 [01:24<00:00, 84.04s/it][A100%|██████████| 1/1 [01:24<00:00, 84.04s/it]
  3%|▎         | 130/5198 [4:08:58<137:06:39, 97.40s/it] Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.15s/it][A100%|██████████| 1/1 [01:52<00:00, 112.15s/it]
  3%|▎         | 131/5198 [4:10:49<143:32:09, 101.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 23:35:55,912] [INFO] [logging.py:96:log_dist] [Rank 0] step=130, skipped=0, lr=[1.902988250880708e-05], mom=[(0.9, 0.999)]
steps: 130 loss: 0.6178 iter time (s): 112.332 samples/sec: 1.139

100%|██████████| 1/1 [01:53<00:00, 113.19s/it][A100%|██████████| 1/1 [01:53<00:00, 113.19s/it]
  3%|▎         | 131/5198 [4:10:50<143:45:02, 102.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.12s/it][A100%|██████████| 1/1 [01:53<00:00, 113.12s/it]
  3%|▎         | 131/5198 [4:10:50<143:43:16, 102.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.17s/it][A100%|██████████| 1/1 [01:53<00:00, 113.17s/it]
  3%|▎         | 131/5198 [4:10:51<143:44:12, 102.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.09s/it][A100%|██████████| 1/1 [01:53<00:00, 113.09s/it]
  3%|▎         | 131/5198 [4:10:51<143:43:01, 102.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.08s/it][A100%|██████████| 1/1 [01:53<00:00, 113.08s/it]
  3%|▎         | 131/5198 [4:10:51<143:42:59, 102.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.10s/it][A100%|██████████| 1/1 [01:53<00:00, 113.10s/it]
  3%|▎         | 131/5198 [4:10:51<143:43:00, 102.11s/it]
100%|██████████| 1/1 [01:53<00:00, 113.10s/it][A100%|██████████| 1/1 [01:53<00:00, 113.10s/it]
  3%|▎         | 131/5198 [4:10:53<143:42:53, 102.11s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_123
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.38s/it][A100%|██████████| 1/1 [01:52<00:00, 112.38s/it]
  3%|▎         | 132/5198 [4:12:42<147:57:46, 105.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 23:37:48,424] [INFO] [logging.py:96:log_dist] [Rank 0] step=131, skipped=0, lr=[1.9056692349367072e-05], mom=[(0.9, 0.999)]
steps: 131 loss: 0.5854 iter time (s): 111.737 samples/sec: 1.146

100%|██████████| 1/1 [01:52<00:00, 112.57s/it][A100%|██████████| 1/1 [01:52<00:00, 112.57s/it]
  3%|▎         | 132/5198 [4:12:43<148:07:50, 105.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.56s/it][A100%|██████████| 1/1 [01:52<00:00, 112.56s/it]
  3%|▎         | 132/5198 [4:12:43<148:06:34, 105.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.52s/it][A100%|██████████| 1/1 [01:52<00:00, 112.52s/it]
  3%|▎         | 132/5198 [4:12:43<148:06:07, 105.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.58s/it][A100%|██████████| 1/1 [01:52<00:00, 112.58s/it]
  3%|▎         | 132/5198 [4:12:43<148:06:49, 105.25s/it]
100%|██████████| 1/1 [01:52<00:00, 112.55s/it][A100%|██████████| 1/1 [01:52<00:00, 112.55s/it]
  3%|▎         | 132/5198 [4:12:43<148:06:00, 105.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.54s/it][A100%|██████████| 1/1 [01:52<00:00, 112.54s/it]
  3%|▎         | 132/5198 [4:12:43<148:05:42, 105.24s/it]
100%|██████████| 1/1 [01:52<00:00, 112.55s/it][A100%|██████████| 1/1 [01:52<00:00, 112.55s/it]
  3%|▎         | 132/5198 [4:12:46<148:05:45, 105.24s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_124

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.54s/it][A100%|██████████| 1/1 [01:28<00:00, 88.54s/it]
  3%|▎         | 133/5198 [4:14:10<140:59:11, 100.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 23:39:16,448] [INFO] [logging.py:96:log_dist] [Rank 0] step=132, skipped=0, lr=[1.9083298310839972e-05], mom=[(0.9, 0.999)]
steps: 132 loss: 0.6606 iter time (s): 87.208 samples/sec: 1.468

100%|██████████| 1/1 [01:27<00:00, 87.95s/it][A100%|██████████| 1/1 [01:27<00:00, 87.95s/it]
  3%|▎         | 133/5198 [4:14:11<140:47:54, 100.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.01s/it][A100%|██████████| 1/1 [01:28<00:00, 88.01s/it]
  3%|▎         | 133/5198 [4:14:11<140:48:29, 100.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 88.00s/it][A100%|██████████| 1/1 [01:27<00:00, 88.00s/it]
  3%|▎         | 133/5198 [4:14:11<140:47:56, 100.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.01s/it][A100%|██████████| 1/1 [01:28<00:00, 88.01s/it]
  3%|▎         | 133/5198 [4:14:11<140:48:36, 100.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.04s/it][A100%|██████████| 1/1 [01:28<00:00, 88.04s/it]
  3%|▎         | 133/5198 [4:14:11<140:48:52, 100.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.06s/it][A100%|██████████| 1/1 [01:28<00:00, 88.06s/it]
  3%|▎         | 133/5198 [4:14:14<140:49:13, 100.09s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_125
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.09s/it][A100%|██████████| 1/1 [01:28<00:00, 88.09s/it]
  3%|▎         | 133/5198 [4:14:11<140:49:55, 100.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.70s/it][A100%|██████████| 1/1 [01:31<00:00, 91.70s/it]
  3%|▎         | 134/5198 [4:15:42<137:24:39, 97.69s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 23:40:48,356] [INFO] [logging.py:96:log_dist] [Rank 0] step=133, skipped=0, lr=[1.910970347069012e-05], mom=[(0.9, 0.999)]
steps: 133 loss: 0.5792 iter time (s): 91.047 samples/sec: 1.406

100%|██████████| 1/1 [01:31<00:00, 91.83s/it][A100%|██████████| 1/1 [01:31<00:00, 91.83s/it]
  3%|▎         | 134/5198 [4:15:42<137:17:42, 97.60s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.88s/it][A100%|██████████| 1/1 [01:31<00:00, 91.88s/it]
  3%|▎         | 134/5198 [4:15:43<137:19:27, 97.62s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.89s/it][A100%|██████████| 1/1 [01:31<00:00, 91.89s/it]
  3%|▎         | 134/5198 [4:15:43<137:19:28, 97.62s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.84s/it][A100%|██████████| 1/1 [01:31<00:00, 91.84s/it]
  3%|▎         | 134/5198 [4:15:43<137:18:22, 97.61s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.83s/it][A100%|██████████| 1/1 [01:31<00:00, 91.83s/it]
  3%|▎         | 134/5198 [4:15:43<137:18:35, 97.61s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.81s/it][A100%|██████████| 1/1 [01:31<00:00, 91.81s/it]
  3%|▎         | 134/5198 [4:15:43<137:18:38, 97.61s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.86s/it][A100%|██████████| 1/1 [01:31<00:00, 91.86s/it]
  3%|▎         | 134/5198 [4:15:45<137:19:17, 97.62s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_126
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.30s/it][A100%|██████████| 1/1 [01:42<00:00, 102.30s/it]
  3%|▎         | 135/5198 [4:17:24<139:23:53, 99.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 23:42:31,052] [INFO] [logging.py:96:log_dist] [Rank 0] step=134, skipped=0, lr=[1.9135910837224043e-05], mom=[(0.9, 0.999)]
steps: 134 loss: 0.5762 iter time (s): 101.877 samples/sec: 1.256

100%|██████████| 1/1 [01:42<00:00, 102.73s/it][A100%|██████████| 1/1 [01:42<00:00, 102.73s/it]
  3%|▎         | 135/5198 [4:17:25<139:26:10, 99.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.74s/it][A100%|██████████| 1/1 [01:42<00:00, 102.74s/it]
  3%|▎         | 135/5198 [4:17:25<139:27:30, 99.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.74s/it][A100%|██████████| 1/1 [01:42<00:00, 102.74s/it]
  3%|▎         | 135/5198 [4:17:26<139:27:29, 99.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.67s/it][A100%|██████████| 1/1 [01:42<00:00, 102.67s/it]
  3%|▎         | 135/5198 [4:17:26<139:25:13, 99.13s/it]
100%|██████████| 1/1 [01:42<00:00, 102.72s/it][A100%|██████████| 1/1 [01:42<00:00, 102.72s/it]
  3%|▎         | 135/5198 [4:17:26<139:26:16, 99.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.72s/it][A100%|██████████| 1/1 [01:42<00:00, 102.72s/it]
  3%|▎         | 135/5198 [4:17:26<139:26:22, 99.15s/it]
100%|██████████| 1/1 [01:42<00:00, 102.70s/it][A100%|██████████| 1/1 [01:42<00:00, 102.70s/it]
  3%|▎         | 135/5198 [4:17:28<139:26:23, 99.15s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_127

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.66s/it][A100%|██████████| 1/1 [01:21<00:00, 81.66s/it]
  3%|▎         | 136/5198 [4:18:46<132:03:49, 93.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 23:43:52,282] [INFO] [logging.py:96:log_dist] [Rank 0] step=135, skipped=0, lr=[1.9161923351647253e-05], mom=[(0.9, 0.999)]
steps: 135 loss: 0.6017 iter time (s): 80.401 samples/sec: 1.592

100%|██████████| 1/1 [01:21<00:00, 81.15s/it][A100%|██████████| 1/1 [01:21<00:00, 81.15s/it]
  3%|▎         | 136/5198 [4:18:46<131:49:18, 93.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.09s/it][A100%|██████████| 1/1 [01:21<00:00, 81.09s/it]
  3%|▎         | 136/5198 [4:18:46<131:48:46, 93.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.04s/it][A100%|██████████| 1/1 [01:21<00:00, 81.04s/it]
  3%|▎         | 136/5198 [4:18:47<131:47:30, 93.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.16s/it][A100%|██████████| 1/1 [01:21<00:00, 81.16s/it]
  3%|▎         | 136/5198 [4:18:47<131:49:27, 93.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.19s/it][A100%|██████████| 1/1 [01:21<00:00, 81.19s/it]
  3%|▎         | 136/5198 [4:18:47<131:49:44, 93.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.16s/it][A100%|██████████| 1/1 [01:21<00:00, 81.16s/it]
  3%|▎         | 136/5198 [4:18:47<131:49:37, 93.75s/it]
100%|██████████| 1/1 [01:21<00:00, 81.16s/it][A100%|██████████| 1/1 [01:21<00:00, 81.16s/it]
  3%|▎         | 136/5198 [4:18:49<131:49:38, 93.75s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_128

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.41s/it][A100%|██████████| 1/1 [01:30<00:00, 90.41s/it]
  3%|▎         | 137/5198 [4:20:17<130:36:42, 92.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 23:45:23,099] [INFO] [logging.py:96:log_dist] [Rank 0] step=136, skipped=0, lr=[1.9187743890045118e-05], mom=[(0.9, 0.999)]
steps: 136 loss: 0.6087 iter time (s): 90.046 samples/sec: 1.421

100%|██████████| 1/1 [01:30<00:00, 90.89s/it][A100%|██████████| 1/1 [01:30<00:00, 90.89s/it]
  3%|▎         | 137/5198 [4:20:17<130:35:36, 92.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.87s/it][A100%|██████████| 1/1 [01:30<00:00, 90.87s/it]
  3%|▎         | 137/5198 [4:20:17<130:34:55, 92.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.98s/it][A100%|██████████| 1/1 [01:30<00:00, 90.98s/it]
  3%|▎         | 137/5198 [4:20:18<130:36:50, 92.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.86s/it][A100%|██████████| 1/1 [01:30<00:00, 90.86s/it]
  3%|▎         | 137/5198 [4:20:18<130:34:50, 92.88s/it]
100%|██████████| 1/1 [01:30<00:00, 90.83s/it][A100%|██████████| 1/1 [01:30<00:00, 90.83s/it]
  3%|▎         | 137/5198 [4:20:18<130:34:20, 92.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.82s/it][A100%|██████████| 1/1 [01:30<00:00, 90.82s/it]
  3%|▎         | 137/5198 [4:20:18<130:33:53, 92.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.82s/it][A100%|██████████| 1/1 [01:30<00:00, 90.82s/it]
  3%|▎         | 137/5198 [4:20:20<130:34:08, 92.88s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_129
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.31s/it][A100%|██████████| 1/1 [01:40<00:00, 100.31s/it]
  3%|▎         | 138/5198 [4:21:57<133:45:44, 95.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 23:47:03,795] [INFO] [logging.py:96:log_dist] [Rank 0] step=137, skipped=0, lr=[1.921337526529119e-05], mom=[(0.9, 0.999)]
steps: 137 loss: 0.6924 iter time (s): 99.916 samples/sec: 1.281

100%|██████████| 1/1 [01:40<00:00, 100.72s/it][A100%|██████████| 1/1 [01:40<00:00, 100.72s/it]
  3%|▎         | 138/5198 [4:21:58<133:52:21, 95.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.72s/it][A100%|██████████| 1/1 [01:40<00:00, 100.72s/it]
  3%|▎         | 138/5198 [4:21:58<133:51:50, 95.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.64s/it][A100%|██████████| 1/1 [01:40<00:00, 100.64s/it]
  3%|▎         | 138/5198 [4:21:58<133:51:08, 95.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.70s/it][A100%|██████████| 1/1 [01:40<00:00, 100.70s/it]
  3%|▎         | 138/5198 [4:21:59<133:51:16, 95.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.77s/it][A100%|██████████| 1/1 [01:40<00:00, 100.77s/it]
  3%|▎         | 138/5198 [4:21:59<133:52:32, 95.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.72s/it][A100%|██████████| 1/1 [01:40<00:00, 100.72s/it]
  3%|▎         | 138/5198 [4:22:01<133:51:05, 95.23s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_130
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.74s/it][A100%|██████████| 1/1 [01:40<00:00, 100.74s/it]
  3%|▎         | 138/5198 [4:21:59<133:51:34, 95.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.28s/it][A100%|██████████| 1/1 [01:32<00:00, 92.28s/it]
  3%|▎         | 139/5198 [4:23:30<132:34:39, 94.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 23:48:36,001] [INFO] [logging.py:96:log_dist] [Rank 0] step=138, skipped=0, lr=[1.923882022888615e-05], mom=[(0.9, 0.999)]
steps: 138 loss: 0.6206 iter time (s): 91.399 samples/sec: 1.400

100%|██████████| 1/1 [01:32<00:00, 92.14s/it][A100%|██████████| 1/1 [01:32<00:00, 92.14s/it]
  3%|▎         | 139/5198 [4:23:30<132:32:21, 94.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.10s/it][A100%|██████████| 1/1 [01:32<00:00, 92.10s/it]
  3%|▎         | 139/5198 [4:23:30<132:31:13, 94.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.14s/it][A100%|██████████| 1/1 [01:32<00:00, 92.14s/it]
  3%|▎         | 139/5198 [4:23:31<132:31:42, 94.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.22s/it][A100%|██████████| 1/1 [01:32<00:00, 92.22s/it]
  3%|▎         | 139/5198 [4:23:31<132:33:42, 94.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.18s/it][A100%|██████████| 1/1 [01:32<00:00, 92.18s/it]
  3%|▎         | 139/5198 [4:23:31<132:33:32, 94.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.18s/it][A100%|██████████| 1/1 [01:32<00:00, 92.18s/it]
  3%|▎         | 139/5198 [4:23:31<132:32:48, 94.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.22s/it][A100%|██████████| 1/1 [01:32<00:00, 92.22s/it]
  3%|▎         | 139/5198 [4:23:33<132:33:24, 94.33s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_131
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.97s/it][A100%|██████████| 1/1 [01:19<00:00, 79.97s/it]
  3%|▎         | 140/5198 [4:24:50<126:33:47, 90.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 23:49:55,720] [INFO] [logging.py:96:log_dist] [Rank 0] step=139, skipped=0, lr=[1.9264081472730333e-05], mom=[(0.9, 0.999)]
steps: 139 loss: 0.6369 iter time (s): 78.894 samples/sec: 1.622

100%|██████████| 1/1 [01:19<00:00, 79.65s/it][A100%|██████████| 1/1 [01:19<00:00, 79.65s/it]
  3%|▎         | 140/5198 [4:24:50<126:20:08, 89.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.73s/it][A100%|██████████| 1/1 [01:19<00:00, 79.73s/it]
  3%|▎         | 140/5198 [4:24:50<126:21:15, 89.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.67s/it][A100%|██████████| 1/1 [01:19<00:00, 79.67s/it]
  3%|▎         | 140/5198 [4:24:50<126:20:04, 89.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.59s/it][A100%|██████████| 1/1 [01:19<00:00, 79.59s/it]
  3%|▎         | 140/5198 [4:24:50<126:19:31, 89.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.60s/it][A100%|██████████| 1/1 [01:19<00:00, 79.60s/it]
  3%|▎         | 140/5198 [4:24:50<126:19:44, 89.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.61s/it][A100%|██████████| 1/1 [01:19<00:00, 79.61s/it]
  3%|▎         | 140/5198 [4:24:50<126:19:24, 89.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.62s/it][A100%|██████████| 1/1 [01:19<00:00, 79.62s/it]
  3%|▎         | 140/5198 [4:24:53<126:20:01, 89.92s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_132
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.75s/it][A100%|██████████| 1/1 [01:31<00:00, 91.75s/it]
  3%|▎         | 141/5198 [4:26:22<127:18:03, 90.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 23:51:28,020] [INFO] [logging.py:96:log_dist] [Rank 0] step=140, skipped=0, lr=[1.9289161630832753e-05], mom=[(0.9, 0.999)]
steps: 140 loss: 0.6265 iter time (s): 91.571 samples/sec: 1.398

100%|██████████| 1/1 [01:32<00:00, 92.40s/it][A100%|██████████| 1/1 [01:32<00:00, 92.40s/it]
  3%|▎         | 141/5198 [4:26:22<127:21:38, 90.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.37s/it][A100%|██████████| 1/1 [01:32<00:00, 92.37s/it]
  3%|▎         | 141/5198 [4:26:22<127:21:38, 90.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.39s/it][A100%|██████████| 1/1 [01:32<00:00, 92.39s/it]
  3%|▎         | 141/5198 [4:26:23<127:20:49, 90.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.48s/it][A100%|██████████| 1/1 [01:32<00:00, 92.48s/it]
  3%|▎         | 141/5198 [4:26:23<127:23:41, 90.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.40s/it][A100%|██████████| 1/1 [01:32<00:00, 92.40s/it]
  3%|▎         | 141/5198 [4:26:23<127:21:24, 90.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.43s/it][A100%|██████████| 1/1 [01:32<00:00, 92.43s/it]
  3%|▎         | 141/5198 [4:26:23<127:21:42, 90.67s/it]
100%|██████████| 1/1 [01:32<00:00, 92.40s/it][A100%|██████████| 1/1 [01:32<00:00, 92.40s/it]
  3%|▎         | 141/5198 [4:26:25<127:21:27, 90.66s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_133

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.54s/it][A100%|██████████| 1/1 [01:51<00:00, 111.54s/it]
  3%|▎         | 142/5198 [4:28:13<136:08:05, 96.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 23:53:20,210] [INFO] [logging.py:96:log_dist] [Rank 0] step=141, skipped=0, lr=[1.9314063280959264e-05], mom=[(0.9, 0.999)]
steps: 141 loss: 0.6531 iter time (s): 111.352 samples/sec: 1.150

100%|██████████| 1/1 [01:52<00:00, 112.17s/it][A100%|██████████| 1/1 [01:52<00:00, 112.17s/it]
  3%|▎         | 142/5198 [4:28:14<136:23:56, 97.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.20s/it][A100%|██████████| 1/1 [01:52<00:00, 112.20s/it]
  3%|▎         | 142/5198 [4:28:15<136:24:45, 97.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.08s/it][A100%|██████████| 1/1 [01:52<00:00, 112.08s/it]
  3%|▎         | 142/5198 [4:28:15<136:23:17, 97.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.16s/it][A100%|██████████| 1/1 [01:52<00:00, 112.16s/it]
  3%|▎         | 142/5198 [4:28:15<136:23:14, 97.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.13s/it][A100%|██████████| 1/1 [01:52<00:00, 112.13s/it]
  3%|▎         | 142/5198 [4:28:15<136:22:47, 97.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.17s/it][A100%|██████████| 1/1 [01:52<00:00, 112.17s/it]
  3%|▎         | 142/5198 [4:28:15<136:23:50, 97.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.17s/it][A100%|██████████| 1/1 [01:52<00:00, 112.17s/it]
  3%|▎         | 142/5198 [4:28:17<136:23:46, 97.12s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_134
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.84s/it][A100%|██████████| 1/1 [01:25<00:00, 85.84s/it]
  3%|▎         | 143/5198 [4:29:39<131:30:51, 93.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 23:54:45,480] [INFO] [logging.py:96:log_dist] [Rank 0] step=142, skipped=0, lr=[1.933878894622252e-05], mom=[(0.9, 0.999)]
steps: 142 loss: 0.6056 iter time (s): 84.448 samples/sec: 1.516

100%|██████████| 1/1 [01:25<00:00, 85.32s/it][A100%|██████████| 1/1 [01:25<00:00, 85.32s/it]
  3%|▎         | 143/5198 [4:29:40<131:24:22, 93.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.26s/it][A100%|██████████| 1/1 [01:25<00:00, 85.26s/it]
  3%|▎         | 143/5198 [4:29:40<131:23:31, 93.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.26s/it][A100%|██████████| 1/1 [01:25<00:00, 85.26s/it]
  3%|▎         | 143/5198 [4:29:40<131:22:19, 93.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.28s/it][A100%|██████████| 1/1 [01:25<00:00, 85.28s/it]
  3%|▎         | 143/5198 [4:29:40<131:22:41, 93.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.28s/it][A100%|██████████| 1/1 [01:25<00:00, 85.28s/it]
  3%|▎         | 143/5198 [4:29:40<131:22:29, 93.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.26s/it][A100%|██████████| 1/1 [01:25<00:00, 85.26s/it]
  3%|▎         | 143/5198 [4:29:40<131:22:39, 93.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.26s/it][A100%|██████████| 1/1 [01:25<00:00, 85.26s/it]
  3%|▎         | 143/5198 [4:29:43<131:22:42, 93.56s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_8
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:05<00:00, 125.03s/it][A100%|██████████| 1/1 [02:05<00:00, 125.03s/it]
  3%|▎         | 144/5198 [4:31:45<144:45:36, 103.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 23:56:51,504] [INFO] [logging.py:96:log_dist] [Rank 0] step=143, skipped=0, lr=[1.9363341096616153e-05], mom=[(0.9, 0.999)]
steps: 143 loss: 0.8358 iter time (s): 125.510 samples/sec: 1.020

100%|██████████| 1/1 [02:06<00:00, 126.31s/it][A100%|██████████| 1/1 [02:06<00:00, 126.31s/it]
  3%|▎         | 144/5198 [4:31:46<145:10:03, 103.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:06<00:00, 126.23s/it][A100%|██████████| 1/1 [02:06<00:00, 126.23s/it]
  3%|▎         | 144/5198 [4:31:46<145:07:24, 103.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:06<00:00, 126.28s/it][A100%|██████████| 1/1 [02:06<00:00, 126.28s/it]
  3%|▎         | 144/5198 [4:31:46<145:07:45, 103.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:06<00:00, 126.29s/it][A100%|██████████| 1/1 [02:06<00:00, 126.29s/it]
  3%|▎         | 144/5198 [4:31:47<145:08:15, 103.38s/it]
100%|██████████| 1/1 [02:06<00:00, 126.33s/it][A100%|██████████| 1/1 [02:06<00:00, 126.33s/it]
  3%|▎         | 144/5198 [4:31:47<145:09:14, 103.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:06<00:00, 126.25s/it][A100%|██████████| 1/1 [02:06<00:00, 126.25s/it]
  3%|▎         | 144/5198 [4:31:47<145:07:10, 103.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:06<00:00, 126.28s/it][A100%|██████████| 1/1 [02:06<00:00, 126.28s/it]
  3%|▎         | 144/5198 [4:31:49<145:08:02, 103.38s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_135
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.21s/it][A100%|██████████| 1/1 [01:28<00:00, 88.21s/it]
  3%|▎         | 145/5198 [4:33:13<138:31:20, 98.69s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 23:58:19,091] [INFO] [logging.py:96:log_dist] [Rank 0] step=144, skipped=0, lr=[1.9387722150495435e-05], mom=[(0.9, 0.999)]
steps: 144 loss: 0.6061 iter time (s): 86.506 samples/sec: 1.480

100%|██████████| 1/1 [01:27<00:00, 87.24s/it][A100%|██████████| 1/1 [01:27<00:00, 87.24s/it]
  3%|▎         | 145/5198 [4:33:13<138:20:17, 98.56s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.34s/it][A100%|██████████| 1/1 [01:27<00:00, 87.34s/it]
  3%|▎         | 145/5198 [4:33:13<138:20:52, 98.57s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.30s/it][A100%|██████████| 1/1 [01:27<00:00, 87.30s/it]
  3%|▎         | 145/5198 [4:33:14<138:20:11, 98.56s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.25s/it][A100%|██████████| 1/1 [01:27<00:00, 87.25s/it]
  3%|▎         | 145/5198 [4:33:14<138:19:52, 98.55s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.33s/it][A100%|██████████| 1/1 [01:27<00:00, 87.33s/it]
  3%|▎         | 145/5198 [4:33:14<138:21:12, 98.57s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.43s/it][A100%|██████████| 1/1 [01:27<00:00, 87.43s/it]
  3%|▎         | 145/5198 [4:33:14<138:22:48, 98.59s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.39s/it][A100%|██████████| 1/1 [01:27<00:00, 87.39s/it]
  3%|▎         | 145/5198 [4:33:16<138:22:30, 98.59s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_136
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.03s/it][A100%|██████████| 1/1 [01:25<00:00, 85.03s/it]
  3%|▎         | 146/5198 [4:34:38<132:48:44, 94.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-29 23:59:44,254] [INFO] [logging.py:96:log_dist] [Rank 0] step=145, skipped=0, lr=[1.9411934476006756e-05], mom=[(0.9, 0.999)]
steps: 145 loss: 0.6431 iter time (s): 84.269 samples/sec: 1.519

100%|██████████| 1/1 [01:25<00:00, 85.13s/it][A100%|██████████| 1/1 [01:25<00:00, 85.13s/it]
  3%|▎         | 146/5198 [4:34:38<132:39:47, 94.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.16s/it][A100%|██████████| 1/1 [01:25<00:00, 85.16s/it]
  3%|▎         | 146/5198 [4:34:39<132:40:48, 94.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.15s/it][A100%|██████████| 1/1 [01:25<00:00, 85.15s/it]
  3%|▎         | 146/5198 [4:34:39<132:40:03, 94.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.18s/it][A100%|██████████| 1/1 [01:25<00:00, 85.18s/it]
  3%|▎         | 146/5198 [4:34:39<132:40:41, 94.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.14s/it][A100%|██████████| 1/1 [01:25<00:00, 85.14s/it]
  3%|▎         | 146/5198 [4:34:39<132:40:50, 94.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.10s/it][A100%|██████████| 1/1 [01:25<00:00, 85.10s/it]
  3%|▎         | 146/5198 [4:34:39<132:40:43, 94.55s/it]
100%|██████████| 1/1 [01:25<00:00, 85.10s/it][A100%|██████████| 1/1 [01:25<00:00, 85.10s/it]
  3%|▎         | 146/5198 [4:34:41<132:40:19, 94.54s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_137

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.35s/it][A100%|██████████| 1/1 [01:48<00:00, 108.35s/it]
  3%|▎         | 147/5198 [4:36:27<138:36:37, 98.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 00:01:33,321] [INFO] [logging.py:96:log_dist] [Rank 0] step=146, skipped=0, lr=[1.943598039246798e-05], mom=[(0.9, 0.999)]
steps: 146 loss: 0.6166 iter time (s): 108.234 samples/sec: 1.183

100%|██████████| 1/1 [01:49<00:00, 109.00s/it][A100%|██████████| 1/1 [01:49<00:00, 109.00s/it]
  3%|▎         | 147/5198 [4:36:27<138:43:51, 98.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.01s/it][A100%|██████████| 1/1 [01:49<00:00, 109.01s/it]
  3%|▎         | 147/5198 [4:36:28<138:44:55, 98.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.00s/it][A100%|██████████| 1/1 [01:49<00:00, 109.00s/it]
  3%|▎         | 147/5198 [4:36:28<138:44:07, 98.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.98s/it][A100%|██████████| 1/1 [01:48<00:00, 108.98s/it]
  3%|▎         | 147/5198 [4:36:28<138:44:01, 98.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.97s/it][A100%|██████████| 1/1 [01:48<00:00, 108.97s/it]
  3%|▎         | 147/5198 [4:36:28<138:43:45, 98.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.96s/it][A100%|██████████| 1/1 [01:48<00:00, 108.96s/it]
  3%|▎         | 147/5198 [4:36:28<138:43:23, 98.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.99s/it][A100%|██████████| 1/1 [01:48<00:00, 108.99s/it]
  3%|▎         | 147/5198 [4:36:30<138:43:45, 98.88s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_138
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.13s/it][A100%|██████████| 1/1 [01:29<00:00, 89.13s/it]
  3%|▎         | 148/5198 [4:37:56<134:33:59, 95.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 00:03:02,069] [INFO] [logging.py:96:log_dist] [Rank 0] step=147, skipped=0, lr=[1.9459862171701665e-05], mom=[(0.9, 0.999)]
steps: 147 loss: 0.6191 iter time (s): 87.986 samples/sec: 1.455

100%|██████████| 1/1 [01:28<00:00, 88.77s/it][A100%|██████████| 1/1 [01:28<00:00, 88.77s/it]
  3%|▎         | 148/5198 [4:37:56<134:27:19, 95.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.78s/it][A100%|██████████| 1/1 [01:28<00:00, 88.78s/it]
  3%|▎         | 148/5198 [4:37:56<134:28:13, 95.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.74s/it][A100%|██████████| 1/1 [01:28<00:00, 88.74s/it]
  3%|▎         | 148/5198 [4:37:57<134:26:53, 95.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.75s/it][A100%|██████████| 1/1 [01:28<00:00, 88.75s/it]
  3%|▎         | 148/5198 [4:37:57<134:26:43, 95.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.78s/it][A100%|██████████| 1/1 [01:28<00:00, 88.78s/it]
  3%|▎         | 148/5198 [4:37:57<134:27:28, 95.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.79s/it][A100%|██████████| 1/1 [01:28<00:00, 88.79s/it]
  3%|▎         | 148/5198 [4:37:57<134:27:19, 95.85s/it]
100%|██████████| 1/1 [01:28<00:00, 88.76s/it][A100%|██████████| 1/1 [01:28<00:00, 88.76s/it]
  3%|▎         | 148/5198 [4:37:59<134:26:53, 95.84s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_139

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.63s/it][A100%|██████████| 1/1 [01:30<00:00, 90.63s/it]
  3%|▎         | 149/5198 [4:39:27<132:21:00, 94.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 00:04:32,823] [INFO] [logging.py:96:log_dist] [Rank 0] step=148, skipped=0, lr=[1.948358203932308e-05], mom=[(0.9, 0.999)]
steps: 148 loss: 0.6568 iter time (s): 89.971 samples/sec: 1.423

100%|██████████| 1/1 [01:30<00:00, 90.71s/it][A100%|██████████| 1/1 [01:30<00:00, 90.71s/it]
  3%|▎         | 149/5198 [4:39:27<132:16:15, 94.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.69s/it][A100%|██████████| 1/1 [01:30<00:00, 90.69s/it]
  3%|▎         | 149/5198 [4:39:27<132:16:24, 94.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.78s/it][A100%|██████████| 1/1 [01:30<00:00, 90.78s/it]
  3%|▎         | 149/5198 [4:39:27<132:17:42, 94.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.81s/it][A100%|██████████| 1/1 [01:30<00:00, 90.81s/it]
  3%|▎         | 149/5198 [4:39:28<132:18:16, 94.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.77s/it][A100%|██████████| 1/1 [01:30<00:00, 90.77s/it]
  3%|▎         | 149/5198 [4:39:28<132:17:42, 94.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.78s/it][A100%|██████████| 1/1 [01:30<00:00, 90.78s/it]
  3%|▎         | 149/5198 [4:39:28<132:17:51, 94.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.79s/it][A100%|██████████| 1/1 [01:30<00:00, 90.79s/it]
  3%|▎         | 149/5198 [4:39:30<132:17:53, 94.33s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_140
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.86s/it][A100%|██████████| 1/1 [01:40<00:00, 100.86s/it]
  3%|▎         | 150/5198 [4:41:08<135:06:48, 96.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 00:06:14,105] [INFO] [logging.py:96:log_dist] [Rank 0] step=149, skipped=0, lr=[1.9507142175984895e-05], mom=[(0.9, 0.999)]
steps: 149 loss: 0.6859 iter time (s): 100.456 samples/sec: 1.274

100%|██████████| 1/1 [01:41<00:00, 101.27s/it][A100%|██████████| 1/1 [01:41<00:00, 101.27s/it]
  3%|▎         | 150/5198 [4:41:08<135:10:34, 96.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.18s/it][A100%|██████████| 1/1 [01:41<00:00, 101.18s/it]
  3%|▎         | 150/5198 [4:41:08<135:08:18, 96.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.31s/it][A100%|██████████| 1/1 [01:41<00:00, 101.31s/it]
  3%|▎         | 150/5198 [4:41:09<135:12:27, 96.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.24s/it][A100%|██████████| 1/1 [01:41<00:00, 101.24s/it]
  3%|▎         | 150/5198 [4:41:09<135:11:09, 96.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.28s/it][A100%|██████████| 1/1 [01:41<00:00, 101.28s/it]
  3%|▎         | 150/5198 [4:41:09<135:11:50, 96.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.25s/it][A100%|██████████| 1/1 [01:41<00:00, 101.25s/it]
  3%|▎         | 150/5198 [4:41:09<135:11:03, 96.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.26s/it][A100%|██████████| 1/1 [01:41<00:00, 101.26s/it]
  3%|▎         | 150/5198 [4:41:11<135:11:16, 96.41s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_141
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.79s/it][A100%|██████████| 1/1 [01:29<00:00, 89.79s/it]
  3%|▎         | 151/5198 [4:42:38<132:23:42, 94.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 00:07:43,755] [INFO] [logging.py:96:log_dist] [Rank 0] step=150, skipped=0, lr=[1.953054471858019e-05], mom=[(0.9, 0.999)]
steps: 150 loss: 0.6539 iter time (s): 88.844 samples/sec: 1.441

100%|██████████| 1/1 [01:29<00:00, 89.65s/it][A100%|██████████| 1/1 [01:29<00:00, 89.65s/it]
  3%|▎         | 151/5198 [4:42:38<132:18:51, 94.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.71s/it][A100%|██████████| 1/1 [01:29<00:00, 89.71s/it]
  3%|▎         | 151/5198 [4:42:38<132:18:40, 94.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.59s/it][A100%|██████████| 1/1 [01:29<00:00, 89.59s/it]
  3%|▎         | 151/5198 [4:42:38<132:18:49, 94.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.61s/it][A100%|██████████| 1/1 [01:29<00:00, 89.62s/it]
  3%|▎         | 151/5198 [4:42:38<132:18:19, 94.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.59s/it][A100%|██████████| 1/1 [01:29<00:00, 89.59s/it]
  3%|▎         | 151/5198 [4:42:39<132:18:09, 94.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.60s/it][A100%|██████████| 1/1 [01:29<00:00, 89.61s/it]
  3%|▎         | 151/5198 [4:42:39<132:17:58, 94.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.61s/it][A100%|██████████| 1/1 [01:29<00:00, 89.61s/it]
  3%|▎         | 151/5198 [4:42:41<132:18:12, 94.37s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_142
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.40s/it][A100%|██████████| 1/1 [01:41<00:00, 101.40s/it]
  3%|▎         | 152/5198 [4:44:19<135:21:30, 96.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 00:09:25,633] [INFO] [logging.py:96:log_dist] [Rank 0] step=151, skipped=0, lr=[1.9553791761405558e-05], mom=[(0.9, 0.999)]
steps: 151 loss: 0.6420 iter time (s): 101.106 samples/sec: 1.266

100%|██████████| 1/1 [01:41<00:00, 101.85s/it][A100%|██████████| 1/1 [01:41<00:00, 101.85s/it]
  3%|▎         | 152/5198 [4:44:20<135:25:54, 96.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.91s/it][A100%|██████████| 1/1 [01:41<00:00, 101.91s/it]
  3%|▎         | 152/5198 [4:44:20<135:27:19, 96.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.86s/it][A100%|██████████| 1/1 [01:41<00:00, 101.86s/it]
  3%|▎         | 152/5198 [4:44:20<135:26:14, 96.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.82s/it][A100%|██████████| 1/1 [01:41<00:00, 101.82s/it]
  3%|▎         | 152/5198 [4:44:20<135:24:47, 96.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.91s/it][A100%|██████████| 1/1 [01:41<00:00, 101.91s/it]
  3%|▎         | 152/5198 [4:44:20<135:27:07, 96.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A

100%|██████████| 1/1 [01:41<00:00, 101.86s/it][A100%|██████████| 1/1 [01:41<00:00, 101.89s/it][A100%|██████████| 1/1 [01:41<00:00, 101.86s/it]
  3%|▎         | 152/5198 [4:44:23<135:25:47, 96.62s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_143
100%|██████████| 1/1 [01:41<00:00, 101.89s/it]
  3%|▎         | 152/5198 [4:44:20<135:26:18, 96.63s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.91s/it][A100%|██████████| 1/1 [01:54<00:00, 114.91s/it]
  3%|▎         | 153/5198 [4:46:14<143:07:21, 102.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 00:11:21,092] [INFO] [logging.py:96:log_dist] [Rank 0] step=152, skipped=0, lr=[1.957688535728574e-05], mom=[(0.9, 0.999)]
steps: 152 loss: 0.6375 iter time (s): 114.698 samples/sec: 1.116

100%|██████████| 1/1 [01:55<00:00, 115.50s/it][A100%|██████████| 1/1 [01:55<00:00, 115.50s/it]
  3%|▎         | 153/5198 [4:46:15<143:20:53, 102.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.54s/it][A100%|██████████| 1/1 [01:55<00:00, 115.54s/it]
  3%|▎         | 153/5198 [4:46:15<143:22:48, 102.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.62s/it][A100%|██████████| 1/1 [01:55<00:00, 115.62s/it]
  3%|▎         | 153/5198 [4:46:16<143:24:01, 102.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.58s/it][A100%|██████████| 1/1 [01:55<00:00, 115.58s/it]
  3%|▎         | 153/5198 [4:46:16<143:23:36, 102.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.70s/it][A100%|██████████| 1/1 [01:55<00:00, 115.70s/it]
  3%|▎         | 153/5198 [4:46:16<143:24:54, 102.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.64s/it][A100%|██████████| 1/1 [01:55<00:00, 115.64s/it]
  3%|▎         | 153/5198 [4:46:18<143:24:01, 102.33s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_144
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.64s/it][A100%|██████████| 1/1 [01:55<00:00, 115.64s/it]
  3%|▎         | 153/5198 [4:46:16<143:24:34, 102.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.41s/it][A100%|██████████| 1/1 [01:24<00:00, 84.41s/it]
  3%|▎         | 154/5198 [4:47:39<135:41:47, 96.85s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 00:12:44,773] [INFO] [logging.py:96:log_dist] [Rank 0] step=153, skipped=0, lr=[1.959982751866147e-05], mom=[(0.9, 0.999)]
steps: 153 loss: 0.6413 iter time (s): 82.734 samples/sec: 1.547

100%|██████████| 1/1 [01:23<00:00, 83.65s/it][A100%|██████████| 1/1 [01:23<00:00, 83.65s/it]
  3%|▎         | 154/5198 [4:47:39<135:29:29, 96.70s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.59s/it][A100%|██████████| 1/1 [01:23<00:00, 83.59s/it]
  3%|▎         | 154/5198 [4:47:39<135:29:03, 96.70s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.44s/it][A100%|██████████| 1/1 [01:23<00:00, 83.44s/it]
  3%|▎         | 154/5198 [4:47:39<135:26:21, 96.67s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.49s/it][A100%|██████████| 1/1 [01:23<00:00, 83.49s/it]
  3%|▎         | 154/5198 [4:47:39<135:27:09, 96.68s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.49s/it][A100%|██████████| 1/1 [01:23<00:00, 83.49s/it]
  3%|▎         | 154/5198 [4:47:42<135:27:23, 96.68s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_145

100%|██████████| 1/1 [01:23<00:00, 83.53s/it][A100%|██████████| 1/1 [01:23<00:00, 83.53s/it]
  3%|▎         | 154/5198 [4:47:40<135:29:03, 96.70s/it] Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.49s/it][A100%|██████████| 1/1 [01:23<00:00, 83.49s/it]
  3%|▎         | 154/5198 [4:47:40<135:27:51, 96.68s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.07s/it][A100%|██████████| 1/1 [01:24<00:00, 84.07s/it]
  3%|▎         | 155/5198 [4:49:03<130:22:35, 93.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 00:14:09,050] [INFO] [logging.py:96:log_dist] [Rank 0] step=154, skipped=0, lr=[1.962262021864183e-05], mom=[(0.9, 0.999)]
steps: 154 loss: 0.6316 iter time (s): 83.516 samples/sec: 1.533

100%|██████████| 1/1 [01:24<00:00, 84.45s/it][A100%|██████████| 1/1 [01:24<00:00, 84.45s/it]
  3%|▎         | 155/5198 [4:49:03<130:19:04, 93.03s/it]
100%|██████████| 1/1 [01:24<00:00, 84.31s/it][A100%|██████████| 1/1 [01:24<00:00, 84.32s/it]
  3%|▎         | 155/5198 [4:49:03<130:15:25, 92.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.42s/it][A100%|██████████| 1/1 [01:24<00:00, 84.42s/it]
  3%|▎         | 155/5198 [4:49:04<130:16:14, 93.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.50s/it][A100%|██████████| 1/1 [01:24<00:00, 84.50s/it]
  3%|▎         | 155/5198 [4:49:04<130:18:38, 93.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.42s/it][A100%|██████████| 1/1 [01:24<00:00, 84.42s/it]
  3%|▎         | 155/5198 [4:49:04<130:18:02, 93.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.91s/it][A100%|██████████| 1/1 [01:24<00:00, 84.91s/it]
  3%|▎         | 155/5198 [4:49:05<130:29:37, 93.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.48s/it][A100%|██████████| 1/1 [01:25<00:00, 85.48s/it]
  3%|▎         | 155/5198 [4:49:07<130:43:30, 93.32s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_146
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.52s/it][A100%|██████████| 1/1 [01:33<00:00, 93.52s/it]
  3%|▎         | 156/5198 [4:50:37<130:36:17, 93.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 00:15:42,941] [INFO] [logging.py:96:log_dist] [Rank 0] step=155, skipped=0, lr=[1.964526539202255e-05], mom=[(0.9, 0.999)]
steps: 155 loss: 0.5734 iter time (s): 91.920 samples/sec: 1.393

100%|██████████| 1/1 [01:33<00:00, 93.71s/it][A100%|██████████| 1/1 [01:33<00:00, 93.71s/it]
  3%|▎         | 156/5198 [4:50:37<130:34:53, 93.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.86s/it][A100%|██████████| 1/1 [01:33<00:00, 93.86s/it]
  3%|▎         | 156/5198 [4:50:37<130:36:14, 93.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.86s/it][A100%|██████████| 1/1 [01:33<00:00, 93.86s/it]
  3%|▎         | 156/5198 [4:50:38<130:36:41, 93.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.74s/it][A100%|██████████| 1/1 [01:33<00:00, 93.74s/it]
  3%|▎         | 156/5198 [4:50:38<130:34:53, 93.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.79s/it][A100%|██████████| 1/1 [01:33<00:00, 93.79s/it]
  3%|▎         | 156/5198 [4:50:38<130:36:36, 93.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.26s/it][A100%|██████████| 1/1 [01:33<00:00, 93.26s/it]
  3%|▎         | 156/5198 [4:50:38<130:31:11, 93.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.75s/it][A100%|██████████| 1/1 [01:32<00:00, 92.75s/it]
  3%|▎         | 156/5198 [4:50:40<130:27:56, 93.15s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_147
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.16s/it][A100%|██████████| 1/1 [01:24<00:00, 84.16s/it]
  3%|▎         | 157/5198 [4:52:01<126:49:59, 90.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 00:17:07,038] [INFO] [logging.py:96:log_dist] [Rank 0] step=156, skipped=0, lr=[1.9667764936271615e-05], mom=[(0.9, 0.999)]
steps: 156 loss: 0.5960 iter time (s): 83.258 samples/sec: 1.537

100%|██████████| 1/1 [01:24<00:00, 84.11s/it][A100%|██████████| 1/1 [01:24<00:00, 84.11s/it]
  3%|▎         | 157/5198 [4:52:01<126:43:31, 90.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.10s/it][A100%|██████████| 1/1 [01:24<00:00, 84.10s/it]
  3%|▎         | 157/5198 [4:52:01<126:44:07, 90.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.02s/it][A100%|██████████| 1/1 [01:24<00:00, 84.02s/it]
  3%|▎         | 157/5198 [4:52:02<126:42:25, 90.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.97s/it][A100%|██████████| 1/1 [01:23<00:00, 83.97s/it]
  3%|▎         | 157/5198 [4:52:02<126:41:11, 90.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.06s/it][A100%|██████████| 1/1 [01:24<00:00, 84.06s/it]
  3%|▎         | 157/5198 [4:52:02<126:42:25, 90.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.05s/it][A100%|██████████| 1/1 [01:24<00:00, 84.05s/it]
  3%|▎         | 157/5198 [4:52:04<126:37:05, 90.42s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_148
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.10s/it][A100%|██████████| 1/1 [01:24<00:00, 84.10s/it]
  3%|▎         | 157/5198 [4:52:02<126:40:34, 90.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.29s/it][A100%|██████████| 1/1 [01:46<00:00, 106.29s/it]
  3%|▎         | 158/5198 [4:53:47<133:28:28, 95.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 00:18:54,110] [INFO] [logging.py:96:log_dist] [Rank 0] step=157, skipped=0, lr=[1.9690120712483303e-05], mom=[(0.9, 0.999)]
steps: 157 loss: 0.6156 iter time (s): 106.273 samples/sec: 1.204

100%|██████████| 1/1 [01:47<00:00, 107.00s/it][A100%|██████████| 1/1 [01:47<00:00, 107.00s/it]
  3%|▎         | 158/5198 [4:53:48<133:38:11, 95.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.97s/it][A100%|██████████| 1/1 [01:46<00:00, 106.97s/it]
  3%|▎         | 158/5198 [4:53:48<133:37:52, 95.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.08s/it][A100%|██████████| 1/1 [01:47<00:00, 107.08s/it]
  3%|▎         | 158/5198 [4:53:49<133:39:28, 95.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.11s/it][A100%|██████████| 1/1 [01:47<00:00, 107.11s/it]
  3%|▎         | 158/5198 [4:53:49<133:39:10, 95.47s/it]
100%|██████████| 1/1 [01:47<00:00, 107.04s/it][A100%|██████████| 1/1 [01:47<00:00, 107.04s/it]
  3%|▎         | 158/5198 [4:53:49<133:38:09, 95.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.05s/it][A100%|██████████| 1/1 [01:47<00:00, 107.05s/it]
  3%|▎         | 158/5198 [4:53:49<133:37:14, 95.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.09s/it][A100%|██████████| 1/1 [01:47<00:00, 107.09s/it]
  3%|▎         | 158/5198 [4:53:51<133:35:38, 95.42s/it]Shard 158 in [76, 158, 182, 242, 293, 363, 418, 421, 752, 814, 842, 991, 1266, 1366, 1425, 1464, 1574, 1728, 2166, 2441, 2563, 2739, 2854, 2894, 3089, 3181, 3395, 3576, 3831, 4300, 4589, 4947, 4950]: file /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_149 skipped to avoid exceeding cuda memory
Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_9
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.88s/it][A100%|██████████| 1/1 [01:59<00:00, 119.88s/it]
  3%|▎         | 160/5198 [4:55:47<110:37:24, 79.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 00:20:54,262] [INFO] [logging.py:96:log_dist] [Rank 0] step=158, skipped=0, lr=[1.9712334546302004e-05], mom=[(0.9, 0.999)]
steps: 158 loss: 0.8581 iter time (s): 119.621 samples/sec: 1.070

100%|██████████| 1/1 [02:00<00:00, 120.53s/it][A100%|██████████| 1/1 [02:00<00:00, 120.53s/it]
  3%|▎         | 160/5198 [4:55:49<110:51:33, 79.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.55s/it][A100%|██████████| 1/1 [02:00<00:00, 120.55s/it]
  3%|▎         | 160/5198 [4:55:49<110:51:42, 79.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.65s/it][A100%|██████████| 1/1 [02:00<00:00, 120.65s/it]
  3%|▎         | 160/5198 [4:55:49<110:54:30, 79.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.63s/it][A100%|██████████| 1/1 [02:00<00:00, 120.63s/it]
  3%|▎         | 160/5198 [4:55:50<110:53:24, 79.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.65s/it][A100%|██████████| 1/1 [02:00<00:00, 120.65s/it]
  3%|▎         | 160/5198 [4:55:49<110:54:20, 79.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.62s/it][A100%|██████████| 1/1 [02:00<00:00, 120.62s/it]
  3%|▎         | 160/5198 [4:55:52<110:51:52, 79.22s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_150
Training on 128 of 128 sentences.

100%|██████████| 1/1 [02:00<00:00, 120.65s/it][A100%|██████████| 1/1 [02:00<00:00, 120.65s/it]

  0%|          | 0/1 [00:00<?, ?it/s]  3%|▎         | 160/5198 [4:55:50<110:53:20, 79.24s/it][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.17s/it][A100%|██████████| 1/1 [01:42<00:00, 102.17s/it]
  3%|▎         | 161/5198 [4:57:30<118:41:46, 84.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 00:22:36,422] [INFO] [logging.py:96:log_dist] [Rank 0] step=159, skipped=0, lr=[1.973440822881686e-05], mom=[(0.9, 0.999)]
steps: 159 loss: 0.6299 iter time (s): 100.865 samples/sec: 1.269

100%|██████████| 1/1 [01:41<00:00, 101.71s/it][A100%|██████████| 1/1 [01:41<00:00, 101.71s/it]
  3%|▎         | 161/5198 [4:57:30<118:38:38, 84.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.70s/it][A100%|██████████| 1/1 [01:41<00:00, 101.71s/it]
  3%|▎         | 161/5198 [4:57:31<118:38:42, 84.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.61s/it][A100%|██████████| 1/1 [01:41<00:00, 101.61s/it]
  3%|▎         | 161/5198 [4:57:31<118:38:42, 84.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.57s/it][A100%|██████████| 1/1 [01:41<00:00, 101.57s/it]
  3%|▎         | 161/5198 [4:57:31<118:37:43, 84.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.61s/it][A100%|██████████| 1/1 [01:41<00:00, 101.61s/it]
  3%|▎         | 161/5198 [4:57:31<118:37:53, 84.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.58s/it][A100%|██████████| 1/1 [01:41<00:00, 101.58s/it]
  3%|▎         | 161/5198 [4:57:31<118:37:11, 84.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.60s/it][A100%|██████████| 1/1 [01:41<00:00, 101.60s/it]
  3%|▎         | 161/5198 [4:57:33<118:36:37, 84.77s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_151
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.53s/it][A100%|██████████| 1/1 [01:55<00:00, 115.53s/it]
  3%|▎         | 162/5198 [4:59:26<129:57:38, 92.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 00:24:31,843] [INFO] [logging.py:96:log_dist] [Rank 0] step=160, skipped=0, lr=[1.9756343517428372e-05], mom=[(0.9, 0.999)]
steps: 160 loss: 0.6262 iter time (s): 114.707 samples/sec: 1.116

100%|██████████| 1/1 [01:55<00:00, 115.42s/it][A100%|██████████| 1/1 [01:55<00:00, 115.42s/it]
  3%|▎         | 162/5198 [4:59:26<129:49:41, 92.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.56s/it][A100%|██████████| 1/1 [01:55<00:00, 115.56s/it]
  3%|▎         | 162/5198 [4:59:26<129:52:52, 92.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.55s/it][A100%|██████████| 1/1 [01:55<00:00, 115.55s/it]
  3%|▎         | 162/5198 [4:59:27<129:52:33, 92.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.57s/it][A100%|██████████| 1/1 [01:55<00:00, 115.57s/it]
  3%|▎         | 162/5198 [4:59:27<129:52:24, 92.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.57s/it][A100%|██████████| 1/1 [01:55<00:00, 115.57s/it]
  3%|▎         | 162/5198 [4:59:27<129:52:32, 92.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.58s/it][A100%|██████████| 1/1 [01:55<00:00, 115.58s/it]
  3%|▎         | 162/5198 [4:59:27<129:52:05, 92.84s/it]
100%|██████████| 1/1 [01:55<00:00, 115.57s/it][A100%|██████████| 1/1 [01:55<00:00, 115.57s/it]
  3%|▎         | 162/5198 [4:59:29<129:51:24, 92.83s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_152

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:18<00:00, 138.83s/it][A100%|██████████| 1/1 [02:18<00:00, 138.83s/it]
  3%|▎         | 163/5198 [5:01:45<147:28:32, 105.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 00:26:51,966] [INFO] [logging.py:96:log_dist] [Rank 0] step=161, skipped=0, lr=[1.9778142136688e-05], mom=[(0.9, 0.999)]
steps: 161 loss: 0.6056 iter time (s): 139.217 samples/sec: 0.919

100%|██████████| 1/1 [02:20<00:00, 140.17s/it][A100%|██████████| 1/1 [02:20<00:00, 140.17s/it]
  3%|▎         | 163/5198 [5:01:46<147:49:27, 105.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:20<00:00, 140.05s/it][A100%|██████████| 1/1 [02:20<00:00, 140.05s/it]
  3%|▎         | 163/5198 [5:01:46<147:48:55, 105.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:19<00:00, 139.92s/it][A100%|██████████| 1/1 [02:19<00:00, 139.92s/it]
  3%|▎         | 163/5198 [5:01:47<147:45:34, 105.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:20<00:00, 140.01s/it][A100%|██████████| 1/1 [02:20<00:00, 140.01s/it]
  3%|▎         | 163/5198 [5:01:47<147:47:53, 105.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:20<00:00, 140.01s/it][A100%|██████████| 1/1 [02:20<00:00, 140.01s/it]
  3%|▎         | 163/5198 [5:01:47<147:47:57, 105.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:19<00:00, 139.98s/it][A100%|██████████| 1/1 [02:19<00:00, 139.99s/it]
  3%|▎         | 163/5198 [5:01:47<147:46:54, 105.66s/it]
100%|██████████| 1/1 [02:19<00:00, 139.98s/it][A100%|██████████| 1/1 [02:19<00:00, 139.98s/it]
  3%|▎         | 163/5198 [5:01:49<147:46:20, 105.66s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_153

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.04s/it][A100%|██████████| 1/1 [01:27<00:00, 87.04s/it]
  3%|▎         | 164/5198 [5:03:12<140:19:20, 100.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 00:28:17,945] [INFO] [logging.py:96:log_dist] [Rank 0] step=162, skipped=0, lr=[1.9799805779111784e-05], mom=[(0.9, 0.999)]
steps: 162 loss: 0.5798 iter time (s): 85.209 samples/sec: 1.502

100%|██████████| 1/1 [01:25<00:00, 85.93s/it][A100%|██████████| 1/1 [01:25<00:00, 85.93s/it]
  3%|▎         | 164/5198 [5:03:12<140:03:54, 100.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.98s/it][A100%|██████████| 1/1 [01:25<00:00, 85.98s/it]
  3%|▎         | 164/5198 [5:03:12<140:04:37, 100.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.90s/it][A100%|██████████| 1/1 [01:25<00:00, 85.90s/it]
  3%|▎         | 164/5198 [5:03:13<140:02:05, 100.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.01s/it][A100%|██████████| 1/1 [01:26<00:00, 86.01s/it]
  3%|▎         | 164/5198 [5:03:13<140:03:05, 100.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.93s/it][A100%|██████████| 1/1 [01:25<00:00, 85.93s/it]
  3%|▎         | 164/5198 [5:03:13<140:02:45, 100.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.97s/it][A100%|██████████| 1/1 [01:25<00:00, 85.97s/it]
  3%|▎         | 164/5198 [5:03:13<140:03:00, 100.16s/it]
100%|██████████| 1/1 [01:25<00:00, 85.97s/it][A100%|██████████| 1/1 [01:25<00:00, 85.97s/it]
  3%|▎         | 164/5198 [5:03:15<140:02:34, 100.15s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_154
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.09s/it][A100%|██████████| 1/1 [01:36<00:00, 96.09s/it]
  3%|▎         | 165/5198 [5:04:48<138:38:11, 99.16s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 00:29:54,432] [INFO] [logging.py:96:log_dist] [Rank 0] step=163, skipped=0, lr=[1.9821336105968915e-05], mom=[(0.9, 0.999)]
steps: 163 loss: 0.6983 iter time (s): 95.718 samples/sec: 1.337

100%|██████████| 1/1 [01:36<00:00, 96.54s/it][A100%|██████████| 1/1 [01:36<00:00, 96.54s/it]
  3%|▎         | 165/5198 [5:04:49<138:35:42, 99.13s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.43s/it][A100%|██████████| 1/1 [01:36<00:00, 96.43s/it]
  3%|▎         | 165/5198 [5:04:49<138:33:28, 99.11s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.51s/it][A100%|██████████| 1/1 [01:36<00:00, 96.51s/it]
  3%|▎         | 165/5198 [5:04:49<138:33:38, 99.11s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.53s/it][A100%|██████████| 1/1 [01:36<00:00, 96.53s/it]
  3%|▎         | 165/5198 [5:04:49<138:34:40, 99.12s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.60s/it][A100%|██████████| 1/1 [01:36<00:00, 96.60s/it]
  3%|▎         | 165/5198 [5:04:49<138:36:19, 99.14s/it] 
100%|██████████| 1/1 [01:36<00:00, 96.53s/it][A100%|██████████| 1/1 [01:36<00:00, 96.53s/it]
  3%|▎         | 165/5198 [5:04:49<138:34:34, 99.12s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.54s/it][A100%|██████████| 1/1 [01:36<00:00, 96.54s/it]
  3%|▎         | 165/5198 [5:04:52<138:34:26, 99.12s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_155
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.32s/it][A100%|██████████| 1/1 [01:18<00:00, 78.32s/it]
  3%|▎         | 166/5198 [5:06:06<130:14:08, 93.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 00:31:12,101] [INFO] [logging.py:96:log_dist] [Rank 0] step=164, skipped=0, lr=[1.98427347480462e-05], mom=[(0.9, 0.999)]
steps: 164 loss: 0.6570 iter time (s): 76.846 samples/sec: 1.666

100%|██████████| 1/1 [01:17<00:00, 77.55s/it][A100%|██████████| 1/1 [01:17<00:00, 77.55s/it]
  3%|▎         | 166/5198 [5:06:06<129:49:41, 92.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:17<00:00, 77.66s/it][A100%|██████████| 1/1 [01:17<00:00, 77.66s/it]
  3%|▎         | 166/5198 [5:06:06<129:50:51, 92.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:17<00:00, 77.66s/it][A100%|██████████| 1/1 [01:17<00:00, 77.66s/it]
  3%|▎         | 166/5198 [5:06:07<129:51:00, 92.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:17<00:00, 77.59s/it][A100%|██████████| 1/1 [01:17<00:00, 77.59s/it]
  3%|▎         | 166/5198 [5:06:07<129:50:01, 92.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:17<00:00, 77.50s/it][A100%|██████████| 1/1 [01:17<00:00, 77.50s/it]
  3%|▎         | 166/5198 [5:06:07<129:49:01, 92.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:17<00:00, 77.56s/it][A100%|██████████| 1/1 [01:17<00:00, 77.56s/it]
  3%|▎         | 166/5198 [5:06:07<129:49:09, 92.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:17<00:00, 77.57s/it][A100%|██████████| 1/1 [01:17<00:00, 77.57s/it]
  3%|▎         | 166/5198 [5:06:09<129:49:08, 92.88s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_156
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:07<00:00, 127.27s/it][A100%|██████████| 1/1 [02:07<00:00, 127.27s/it]
  3%|▎         | 167/5198 [5:08:14<144:20:09, 103.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 00:33:20,754] [INFO] [logging.py:96:log_dist] [Rank 0] step=165, skipped=0, lr=[1.9864003306389262e-05], mom=[(0.9, 0.999)]
steps: 165 loss: 0.6481 iter time (s): 128.035 samples/sec: 1.000

100%|██████████| 1/1 [02:08<00:00, 128.82s/it][A100%|██████████| 1/1 [02:08<00:00, 128.82s/it]
  3%|▎         | 167/5198 [5:08:15<144:30:38, 103.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:08<00:00, 128.80s/it][A100%|██████████| 1/1 [02:08<00:00, 128.80s/it]
  3%|▎         | 167/5198 [5:08:15<144:30:54, 103.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:08<00:00, 128.80s/it][A100%|██████████| 1/1 [02:08<00:00, 128.80s/it]
  3%|▎         | 167/5198 [5:08:16<144:31:04, 103.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:08<00:00, 128.85s/it][A100%|██████████| 1/1 [02:08<00:00, 128.85s/it]
  3%|▎         | 167/5198 [5:08:16<144:31:34, 103.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:08<00:00, 128.88s/it][A100%|██████████| 1/1 [02:08<00:00, 128.88s/it]
  3%|▎         | 167/5198 [5:08:16<144:31:29, 103.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:08<00:00, 128.85s/it][A100%|██████████| 1/1 [02:08<00:00, 128.85s/it]
  3%|▎         | 167/5198 [5:08:16<144:30:58, 103.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:08<00:00, 128.88s/it][A100%|██████████| 1/1 [02:08<00:00, 128.88s/it]
  3%|▎         | 167/5198 [5:08:18<144:31:39, 103.42s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_157
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:29<00:00, 149.62s/it][A100%|██████████| 1/1 [02:29<00:00, 149.62s/it]
  3%|▎         | 168/5198 [5:10:44<163:31:28, 117.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 00:35:51,241] [INFO] [logging.py:96:log_dist] [Rank 0] step=166, skipped=0, lr=[1.9885143353021433e-05], mom=[(0.9, 0.999)]
steps: 166 loss: 0.6528 iter time (s): 149.553 samples/sec: 0.856

100%|██████████| 1/1 [02:30<00:00, 150.43s/it][A100%|██████████| 1/1 [02:30<00:00, 150.43s/it]
  3%|▎         | 168/5198 [5:10:45<163:51:42, 117.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:30<00:00, 150.52s/it][A100%|██████████| 1/1 [02:30<00:00, 150.52s/it]
  3%|▎         | 168/5198 [5:10:46<163:54:10, 117.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:30<00:00, 150.46s/it][A100%|██████████| 1/1 [02:30<00:00, 150.46s/it]
  3%|▎         | 168/5198 [5:10:46<163:52:47, 117.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:30<00:00, 150.42s/it][A100%|██████████| 1/1 [02:30<00:00, 150.42s/it]
  3%|▎         | 168/5198 [5:10:46<163:52:03, 117.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:30<00:00, 150.40s/it][A100%|██████████| 1/1 [02:30<00:00, 150.40s/it]
  3%|▎         | 168/5198 [5:10:46<163:51:35, 117.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:30<00:00, 150.43s/it][A100%|██████████| 1/1 [02:30<00:00, 150.43s/it]
  3%|▎         | 168/5198 [5:10:46<163:51:54, 117.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:30<00:00, 150.41s/it][A100%|██████████| 1/1 [02:30<00:00, 150.41s/it]
  3%|▎         | 168/5198 [5:10:48<163:51:44, 117.28s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_158
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.87s/it][A100%|██████████| 1/1 [01:31<00:00, 91.87s/it]
  3%|▎         | 169/5198 [5:12:16<153:16:26, 109.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 00:37:22,495] [INFO] [logging.py:96:log_dist] [Rank 0] step=167, skipped=0, lr=[1.990615643164092e-05], mom=[(0.9, 0.999)]
steps: 167 loss: 0.5775 iter time (s): 90.366 samples/sec: 1.416

100%|██████████| 1/1 [01:31<00:00, 91.29s/it][A100%|██████████| 1/1 [01:31<00:00, 91.29s/it]
  3%|▎         | 169/5198 [5:12:17<153:04:20, 109.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.12s/it][A100%|██████████| 1/1 [01:31<00:00, 91.12s/it]
  3%|▎         | 169/5198 [5:12:17<153:01:46, 109.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.19s/it][A100%|██████████| 1/1 [01:31<00:00, 91.19s/it]
  3%|▎         | 169/5198 [5:12:17<153:02:44, 109.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.22s/it][A100%|██████████| 1/1 [01:31<00:00, 91.22s/it]
  3%|▎         | 169/5198 [5:12:17<153:02:49, 109.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.19s/it][A100%|██████████| 1/1 [01:31<00:00, 91.19s/it]
  3%|▎         | 169/5198 [5:12:17<153:01:50, 109.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.19s/it][A100%|██████████| 1/1 [01:31<00:00, 91.19s/it]
  3%|▎         | 169/5198 [5:12:17<153:01:55, 109.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.19s/it][A100%|██████████| 1/1 [01:31<00:00, 91.19s/it]
  3%|▎         | 169/5198 [5:12:20<153:01:54, 109.55s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_159
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.88s/it][A100%|██████████| 1/1 [01:28<00:00, 88.88s/it]
  3%|▎         | 170/5198 [5:13:46<144:39:08, 103.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 00:38:51,788] [INFO] [logging.py:96:log_dist] [Rank 0] step=168, skipped=0, lr=[1.9927044058297284e-05], mom=[(0.9, 0.999)]
steps: 168 loss: 0.6659 iter time (s): 88.460 samples/sec: 1.447

100%|██████████| 1/1 [01:29<00:00, 89.21s/it][A100%|██████████| 1/1 [01:29<00:00, 89.21s/it]
  3%|▎         | 170/5198 [5:13:46<144:35:01, 103.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.26s/it][A100%|██████████| 1/1 [01:29<00:00, 89.26s/it]
  3%|▎         | 170/5198 [5:13:46<144:34:36, 103.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.17s/it][A100%|██████████| 1/1 [01:29<00:00, 89.18s/it]
  3%|▎         | 170/5198 [5:13:46<144:32:59, 103.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.26s/it][A100%|██████████| 1/1 [01:29<00:00, 89.26s/it]
  3%|▎         | 170/5198 [5:13:47<144:35:05, 103.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.26s/it][A100%|██████████| 1/1 [01:29<00:00, 89.26s/it]
  3%|▎         | 170/5198 [5:13:47<144:34:27, 103.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.26s/it][A100%|██████████| 1/1 [01:29<00:00, 89.26s/it]
  3%|▎         | 170/5198 [5:13:47<144:34:35, 103.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.26s/it][A100%|██████████| 1/1 [01:29<00:00, 89.26s/it]
  3%|▎         | 170/5198 [5:13:49<144:34:26, 103.51s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_160
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:04<00:00, 124.24s/it][A100%|██████████| 1/1 [02:04<00:00, 124.24s/it]
  3%|▎         | 171/5198 [5:15:50<153:19:00, 109.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 00:40:57,183] [INFO] [logging.py:96:log_dist] [Rank 0] step=169, skipped=0, lr=[1.9947807722047796e-05], mom=[(0.9, 0.999)]
steps: 169 loss: 0.5911 iter time (s): 124.591 samples/sec: 1.027

100%|██████████| 1/1 [02:05<00:00, 125.43s/it][A100%|██████████| 1/1 [02:05<00:00, 125.43s/it]
  3%|▎         | 171/5198 [5:15:51<153:40:56, 110.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:05<00:00, 125.37s/it][A100%|██████████| 1/1 [02:05<00:00, 125.37s/it]
  3%|▎         | 171/5198 [5:15:51<153:39:24, 110.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:05<00:00, 125.48s/it][A100%|██████████| 1/1 [02:05<00:00, 125.48s/it]
  3%|▎         | 171/5198 [5:15:52<153:40:52, 110.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:05<00:00, 125.36s/it][A100%|██████████| 1/1 [02:05<00:00, 125.36s/it]
  3%|▎         | 171/5198 [5:15:52<153:39:08, 110.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:05<00:00, 125.39s/it][A100%|██████████| 1/1 [02:05<00:00, 125.39s/it]
  3%|▎         | 171/5198 [5:15:52<153:39:29, 110.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:05<00:00, 125.41s/it][A100%|██████████| 1/1 [02:05<00:00, 125.41s/it]
  3%|▎         | 171/5198 [5:15:52<153:40:02, 110.05s/it]
100%|██████████| 1/1 [02:05<00:00, 125.40s/it][A100%|██████████| 1/1 [02:05<00:00, 125.40s/it]
  3%|▎         | 171/5198 [5:15:54<153:39:45, 110.04s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_161

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.53s/it][A100%|██████████| 1/1 [01:32<00:00, 92.53s/it]
  3%|▎         | 172/5198 [5:17:23<146:09:23, 104.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 00:42:28,972] [INFO] [logging.py:96:log_dist] [Rank 0] step=170, skipped=0, lr=[1.9968448885594408e-05], mom=[(0.9, 0.999)]
steps: 170 loss: 0.6324 iter time (s): 90.970 samples/sec: 1.407

100%|██████████| 1/1 [01:31<00:00, 91.69s/it][A100%|██████████| 1/1 [01:31<00:00, 91.69s/it]
  3%|▎         | 172/5198 [5:17:23<145:59:44, 104.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.76s/it][A100%|██████████| 1/1 [01:31<00:00, 91.76s/it]
  3%|▎         | 172/5198 [5:17:23<146:00:14, 104.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.67s/it][A100%|██████████| 1/1 [01:31<00:00, 91.67s/it]
  3%|▎         | 172/5198 [5:17:24<145:59:13, 104.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.73s/it][A100%|██████████| 1/1 [01:31<00:00, 91.73s/it]
  3%|▎         | 172/5198 [5:17:24<145:59:30, 104.57s/it]

100%|██████████| 1/1 [01:31<00:00, 91.70s/it][A  0%|          | 0/1 [00:00<?, ?it/s][A100%|██████████| 1/1 [01:31<00:00, 91.70s/it]
  3%|▎         | 172/5198 [5:17:24<145:58:50, 104.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.72s/it][A100%|██████████| 1/1 [01:31<00:00, 91.72s/it]
  3%|▎         | 172/5198 [5:17:24<145:59:41, 104.57s/it]
100%|██████████| 1/1 [01:31<00:00, 91.71s/it][A100%|██████████| 1/1 [01:31<00:00, 91.71s/it]
  3%|▎         | 172/5198 [5:17:26<145:59:26, 104.57s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_162

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.74s/it][A100%|██████████| 1/1 [01:25<00:00, 85.74s/it]
  3%|▎         | 173/5198 [5:18:49<138:17:01, 99.07s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 00:43:54,745] [INFO] [logging.py:96:log_dist] [Rank 0] step=171, skipped=0, lr=[1.9988968985902092e-05], mom=[(0.9, 0.999)]
steps: 171 loss: 0.6099 iter time (s): 85.025 samples/sec: 1.505

100%|██████████| 1/1 [01:25<00:00, 85.83s/it][A100%|██████████| 1/1 [01:25<00:00, 85.84s/it]
  3%|▎         | 173/5198 [5:18:49<138:08:54, 98.97s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.80s/it][A100%|██████████| 1/1 [01:25<00:00, 85.80s/it]
  3%|▎         | 173/5198 [5:18:49<138:08:11, 98.96s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.79s/it][A100%|██████████| 1/1 [01:25<00:00, 85.79s/it]
  3%|▎         | 173/5198 [5:18:49<138:07:16, 98.95s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.85s/it][A100%|██████████| 1/1 [01:25<00:00, 85.85s/it]
  3%|▎         | 173/5198 [5:18:49<138:09:02, 98.97s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.87s/it][A100%|██████████| 1/1 [01:25<00:00, 85.87s/it]
  3%|▎         | 173/5198 [5:18:50<138:08:57, 98.97s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.82s/it][A100%|██████████| 1/1 [01:25<00:00, 85.82s/it]
  3%|▎         | 173/5198 [5:18:50<138:08:12, 98.96s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.83s/it][A100%|██████████| 1/1 [01:25<00:00, 85.83s/it]
  3%|▎         | 173/5198 [5:18:52<138:08:26, 98.97s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_163
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.96s/it][A100%|██████████| 1/1 [01:30<00:00, 90.96s/it]
  3%|▎         | 174/5198 [5:20:20<134:58:20, 96.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 00:45:26,084] [INFO] [logging.py:96:log_dist] [Rank 0] step=172, skipped=0, lr=[2.000936943479912e-05], mom=[(0.9, 0.999)]
steps: 172 loss: 0.6505 iter time (s): 90.524 samples/sec: 1.414

100%|██████████| 1/1 [01:31<00:00, 91.48s/it][A100%|██████████| 1/1 [01:31<00:00, 91.48s/it]
  3%|▎         | 174/5198 [5:20:20<134:59:36, 96.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.43s/it][A100%|██████████| 1/1 [01:31<00:00, 91.43s/it]
  3%|▎         | 174/5198 [5:20:20<134:58:01, 96.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.55s/it][A100%|██████████| 1/1 [01:31<00:00, 91.55s/it]
  3%|▎         | 174/5198 [5:20:21<135:00:14, 96.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.47s/it][A100%|██████████| 1/1 [01:31<00:00, 91.47s/it]
  3%|▎         | 174/5198 [5:20:21<134:59:28, 96.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.51s/it][A100%|██████████| 1/1 [01:31<00:00, 91.51s/it]
  3%|▎         | 174/5198 [5:20:21<135:00:35, 96.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.55s/it][A100%|██████████| 1/1 [01:31<00:00, 91.55s/it]
  3%|▎         | 174/5198 [5:20:21<135:00:58, 96.75s/it]
100%|██████████| 1/1 [01:31<00:00, 91.54s/it][A100%|██████████| 1/1 [01:31<00:00, 91.54s/it]
  3%|▎         | 174/5198 [5:20:23<135:00:48, 96.75s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_164

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.18s/it][A100%|██████████| 1/1 [01:47<00:00, 107.18s/it]
  3%|▎         | 175/5198 [5:22:07<139:22:41, 99.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 00:47:13,410] [INFO] [logging.py:96:log_dist] [Rank 0] step=173, skipped=0, lr=[1.9999996580991077e-05], mom=[(0.9, 0.999)]
steps: 173 loss: 0.6392 iter time (s): 106.301 samples/sec: 1.204

100%|██████████| 1/1 [01:47<00:00, 107.12s/it][A100%|██████████| 1/1 [01:47<00:00, 107.12s/it]
  3%|▎         | 175/5198 [5:22:08<139:18:47, 99.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.18s/it][A100%|██████████| 1/1 [01:47<00:00, 107.18s/it]
  3%|▎         | 175/5198 [5:22:08<139:19:11, 99.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.12s/it][A100%|██████████| 1/1 [01:47<00:00, 107.12s/it]
  3%|▎         | 175/5198 [5:22:08<139:19:07, 99.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.14s/it][A100%|██████████| 1/1 [01:47<00:00, 107.14s/it]
  3%|▎         | 175/5198 [5:22:08<139:19:13, 99.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.14s/it][A100%|██████████| 1/1 [01:47<00:00, 107.14s/it]
  3%|▎         | 175/5198 [5:22:08<139:19:52, 99.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.08s/it][A100%|██████████| 1/1 [01:47<00:00, 107.08s/it]
  3%|▎         | 175/5198 [5:22:08<139:18:41, 99.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.10s/it][A100%|██████████| 1/1 [01:47<00:00, 107.10s/it]
  3%|▎         | 175/5198 [5:22:11<139:19:01, 99.85s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_10
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:06<00:00, 126.01s/it][A100%|██████████| 1/1 [02:06<00:00, 126.01s/it]
  3%|▎         | 176/5198 [5:24:13<150:19:19, 107.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 00:49:20,152] [INFO] [logging.py:96:log_dist] [Rank 0] step=174, skipped=0, lr=[1.9999990293454576e-05], mom=[(0.9, 0.999)]
steps: 174 loss: 0.8556 iter time (s): 126.244 samples/sec: 1.014

100%|██████████| 1/1 [02:07<00:00, 127.13s/it][A100%|██████████| 1/1 [02:07<00:00, 127.13s/it]
  3%|▎         | 176/5198 [5:24:15<150:41:36, 108.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:07<00:00, 127.16s/it][A100%|██████████| 1/1 [02:07<00:00, 127.16s/it]
  3%|▎         | 176/5198 [5:24:15<150:42:46, 108.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:07<00:00, 127.08s/it][A100%|██████████| 1/1 [02:07<00:00, 127.08s/it]
  3%|▎         | 176/5198 [5:24:15<150:40:44, 108.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:07<00:00, 127.15s/it][A100%|██████████| 1/1 [02:07<00:00, 127.15s/it]
  3%|▎         | 176/5198 [5:24:15<150:42:39, 108.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:07<00:00, 127.15s/it][A100%|██████████| 1/1 [02:07<00:00, 127.15s/it]
  3%|▎         | 176/5198 [5:24:15<150:43:03, 108.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:07<00:00, 127.13s/it][A100%|██████████| 1/1 [02:07<00:00, 127.13s/it]
  3%|▎         | 176/5198 [5:24:18<150:41:58, 108.03s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_165
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:07<00:00, 127.17s/it][A100%|██████████| 1/1 [02:07<00:00, 127.17s/it]
  3%|▎         | 176/5198 [5:24:15<150:42:49, 108.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.36s/it][A100%|██████████| 1/1 [01:45<00:00, 105.36s/it]
  3%|▎         | 177/5198 [5:25:59<149:22:12, 107.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 00:51:04,746] [INFO] [logging.py:96:log_dist] [Rank 0] step=175, skipped=0, lr=[1.999998079799378e-05], mom=[(0.9, 0.999)]
steps: 175 loss: 0.6145 iter time (s): 103.396 samples/sec: 1.238

100%|██████████| 1/1 [01:44<00:00, 104.23s/it][A100%|██████████| 1/1 [01:44<00:00, 104.23s/it]
  3%|▎         | 177/5198 [5:25:59<149:04:48, 106.89s/it]
100%|██████████| 1/1 [01:44<00:00, 104.06s/it][A100%|██████████| 1/1 [01:44<00:00, 104.06s/it]
  3%|▎         | 177/5198 [5:25:59<149:01:28, 106.85s/it]

  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.14s/it][A100%|██████████| 1/1 [01:44<00:00, 104.14s/it]
  3%|▎         | 177/5198 [5:25:59<149:02:01, 106.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.04s/it][A100%|██████████| 1/1 [01:44<00:00, 104.04s/it]
  3%|▎         | 177/5198 [5:25:59<149:01:10, 106.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.12s/it][A100%|██████████| 1/1 [01:44<00:00, 104.12s/it]
  3%|▎         | 177/5198 [5:25:59<149:02:45, 106.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.06s/it][A100%|██████████| 1/1 [01:44<00:00, 104.06s/it]
  3%|▎         | 177/5198 [5:26:00<149:01:23, 106.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.10s/it][A100%|██████████| 1/1 [01:44<00:00, 104.10s/it]
  3%|▎         | 177/5198 [5:26:02<149:01:54, 106.85s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_166
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.90s/it][A100%|██████████| 1/1 [01:48<00:00, 108.90s/it]
  3%|▎         | 178/5198 [5:27:48<150:14:39, 107.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 00:52:54,820] [INFO] [logging.py:96:log_dist] [Rank 0] step=176, skipped=0, lr=[1.9999968094611738e-05], mom=[(0.9, 0.999)]
steps: 176 loss: 0.6303 iter time (s): 109.353 samples/sec: 1.171

100%|██████████| 1/1 [01:50<00:00, 110.00s/it][A100%|██████████| 1/1 [01:50<00:00, 110.00s/it]
  3%|▎         | 178/5198 [5:27:49<150:21:23, 107.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.21s/it][A100%|██████████| 1/1 [01:50<00:00, 110.21s/it]
  3%|▎         | 178/5198 [5:27:49<150:24:08, 107.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.22s/it][A100%|██████████| 1/1 [01:50<00:00, 110.22s/it]
  3%|▎         | 178/5198 [5:27:50<150:24:52, 107.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.12s/it][A100%|██████████| 1/1 [01:50<00:00, 110.12s/it]
  3%|▎         | 178/5198 [5:27:50<150:22:59, 107.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.22s/it][A100%|██████████| 1/1 [01:50<00:00, 110.22s/it]
  3%|▎         | 178/5198 [5:27:50<150:24:15, 107.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.21s/it][A100%|██████████| 1/1 [01:50<00:00, 110.22s/it]
  3%|▎         | 178/5198 [5:27:50<150:24:16, 107.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.20s/it][A100%|██████████| 1/1 [01:50<00:00, 110.20s/it]
  3%|▎         | 178/5198 [5:27:52<150:24:12, 107.86s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_167
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.88s/it][A100%|██████████| 1/1 [01:36<00:00, 96.88s/it]
  3%|▎         | 179/5198 [5:29:25<145:44:48, 104.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 00:54:31,549] [INFO] [logging.py:96:log_dist] [Rank 0] step=177, skipped=0, lr=[1.9999952183312533e-05], mom=[(0.9, 0.999)]
steps: 177 loss: 0.6244 iter time (s): 95.878 samples/sec: 1.335

100%|██████████| 1/1 [01:36<00:00, 96.79s/it][A100%|██████████| 1/1 [01:36<00:00, 96.79s/it]
  3%|▎         | 179/5198 [5:29:26<145:43:03, 104.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.66s/it][A100%|██████████| 1/1 [01:36<00:00, 96.66s/it]
  3%|▎         | 179/5198 [5:29:26<145:41:52, 104.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.64s/it][A100%|██████████| 1/1 [01:36<00:00, 96.64s/it]
  3%|▎         | 179/5198 [5:29:26<145:41:41, 104.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.61s/it][A100%|██████████| 1/1 [01:36<00:00, 96.61s/it]
  3%|▎         | 179/5198 [5:29:26<145:40:29, 104.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.71s/it][A100%|██████████| 1/1 [01:36<00:00, 96.71s/it]
  3%|▎         | 179/5198 [5:29:26<145:42:10, 104.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.65s/it][A100%|██████████| 1/1 [01:36<00:00, 96.66s/it]
  3%|▎         | 179/5198 [5:29:26<145:41:34, 104.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.66s/it][A100%|██████████| 1/1 [01:36<00:00, 96.66s/it]
  3%|▎         | 179/5198 [5:29:29<145:41:33, 104.50s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_168
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.73s/it][A100%|██████████| 1/1 [01:31<00:00, 91.73s/it]
  3%|▎         | 180/5198 [5:30:57<140:24:41, 100.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 00:56:03,266] [INFO] [logging.py:96:log_dist] [Rank 0] step=178, skipped=0, lr=[1.9999933064101263e-05], mom=[(0.9, 0.999)]
steps: 178 loss: 0.6005 iter time (s): 90.932 samples/sec: 1.408

100%|██████████| 1/1 [01:31<00:00, 91.64s/it][A100%|██████████| 1/1 [01:31<00:00, 91.64s/it]
  3%|▎         | 180/5198 [5:30:57<140:18:28, 100.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.67s/it][A100%|██████████| 1/1 [01:31<00:00, 91.67s/it]
  3%|▎         | 180/5198 [5:30:57<140:18:35, 100.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.65s/it][A100%|██████████| 1/1 [01:31<00:00, 91.66s/it]
  3%|▎         | 180/5198 [5:30:58<140:17:53, 100.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.66s/it][A100%|██████████| 1/1 [01:31<00:00, 91.66s/it]
  3%|▎         | 180/5198 [5:30:58<140:18:12, 100.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.76s/it][A100%|██████████| 1/1 [01:31<00:00, 91.76s/it]
  3%|▎         | 180/5198 [5:30:58<140:19:43, 100.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.69s/it][A100%|██████████| 1/1 [01:31<00:00, 91.69s/it]
  3%|▎         | 180/5198 [5:30:58<140:18:40, 100.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.71s/it][A100%|██████████| 1/1 [01:31<00:00, 91.71s/it]
  3%|▎         | 180/5198 [5:31:00<140:19:04, 100.67s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_169
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.88s/it][A100%|██████████| 1/1 [01:49<00:00, 109.88s/it]
  3%|▎         | 181/5198 [5:32:47<144:16:08, 103.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 00:57:53,799] [INFO] [logging.py:96:log_dist] [Rank 0] step=179, skipped=0, lr=[1.9999910736984064e-05], mom=[(0.9, 0.999)]
steps: 179 loss: 0.6426 iter time (s): 109.749 samples/sec: 1.166

100%|██████████| 1/1 [01:50<00:00, 110.57s/it][A100%|██████████| 1/1 [01:50<00:00, 110.57s/it]
  3%|▎         | 181/5198 [5:32:48<144:25:39, 103.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.58s/it][A100%|██████████| 1/1 [01:50<00:00, 110.58s/it]
  3%|▎         | 181/5198 [5:32:48<144:25:56, 103.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.63s/it][A100%|██████████| 1/1 [01:50<00:00, 110.63s/it]
  3%|▎         | 181/5198 [5:32:48<144:26:38, 103.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.61s/it][A100%|██████████| 1/1 [01:50<00:00, 110.61s/it]
  3%|▎         | 181/5198 [5:32:49<144:26:21, 103.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.55s/it][A100%|██████████| 1/1 [01:50<00:00, 110.55s/it]
  3%|▎         | 181/5198 [5:32:49<144:26:07, 103.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.60s/it][A100%|██████████| 1/1 [01:50<00:00, 110.60s/it]
  3%|▎         | 181/5198 [5:32:49<144:26:23, 103.64s/it]
100%|██████████| 1/1 [01:50<00:00, 110.57s/it][A100%|██████████| 1/1 [01:50<00:00, 110.58s/it]
  3%|▎         | 181/5198 [5:32:51<144:26:04, 103.64s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_170
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.82s/it][A100%|██████████| 1/1 [01:31<00:00, 91.82s/it]
  4%|▎         | 182/5198 [5:34:19<139:24:00, 100.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 00:59:25,219] [INFO] [logging.py:96:log_dist] [Rank 0] step=180, skipped=0, lr=[1.9999885201968098e-05], mom=[(0.9, 0.999)]
steps: 180 loss: 0.6020 iter time (s): 90.589 samples/sec: 1.413

100%|██████████| 1/1 [01:31<00:00, 91.42s/it][A100%|██████████| 1/1 [01:31<00:00, 91.42s/it]
  4%|▎         | 182/5198 [5:34:19<139:17:40, 99.97s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.42s/it][A100%|██████████| 1/1 [01:31<00:00, 91.42s/it]
  4%|▎         | 182/5198 [5:34:20<139:18:06, 99.98s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.45s/it][A100%|██████████| 1/1 [01:31<00:00, 91.45s/it]
  4%|▎         | 182/5198 [5:34:20<139:19:10, 99.99s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.43s/it][A100%|██████████| 1/1 [01:31<00:00, 91.43s/it]
  4%|▎         | 182/5198 [5:34:20<139:18:31, 99.98s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.46s/it][A100%|██████████| 1/1 [01:31<00:00, 91.46s/it]
  4%|▎         | 182/5198 [5:34:20<139:19:02, 99.99s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.43s/it][A100%|██████████| 1/1 [01:31<00:00, 91.43s/it]
  4%|▎         | 182/5198 [5:34:20<139:18:29, 99.98s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.44s/it][A100%|██████████| 1/1 [01:31<00:00, 91.44s/it]
  4%|▎         | 182/5198 [5:34:22<139:18:38, 99.98s/it] Shard 182 in [76, 158, 182, 242, 293, 363, 418, 421, 752, 814, 842, 991, 1266, 1366, 1425, 1464, 1574, 1728, 2166, 2441, 2563, 2739, 2854, 2894, 3089, 3181, 3395, 3576, 3831, 4300, 4589, 4947, 4950]: file /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_171 skipped to avoid exceeding cuda memory
Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_172
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.94s/it][A100%|██████████| 1/1 [01:41<00:00, 101.94s/it]
  4%|▎         | 184/5198 [5:36:01<107:50:15, 77.43s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 01:01:07,589] [INFO] [logging.py:96:log_dist] [Rank 0] step=181, skipped=0, lr=[1.999985645906156e-05], mom=[(0.9, 0.999)]
steps: 181 loss: 0.5889 iter time (s): 101.507 samples/sec: 1.261

100%|██████████| 1/1 [01:42<00:00, 102.31s/it][A100%|██████████| 1/1 [01:42<00:00, 102.31s/it]
  4%|▎         | 184/5198 [5:36:02<107:51:50, 77.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.35s/it][A100%|██████████| 1/1 [01:42<00:00, 102.35s/it]
  4%|▎         | 184/5198 [5:36:02<107:52:59, 77.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.31s/it][A100%|██████████| 1/1 [01:42<00:00, 102.31s/it]
  4%|▎         | 184/5198 [5:36:02<107:52:33, 77.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.33s/it][A100%|██████████| 1/1 [01:42<00:00, 102.33s/it]
  4%|▎         | 184/5198 [5:36:02<107:52:33, 77.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.30s/it][A100%|██████████| 1/1 [01:42<00:00, 102.30s/it]
  4%|▎         | 184/5198 [5:36:02<107:52:21, 77.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.29s/it][A100%|██████████| 1/1 [01:42<00:00, 102.29s/it]
  4%|▎         | 184/5198 [5:36:05<107:51:58, 77.45s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_173
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.32s/it][A100%|██████████| 1/1 [01:42<00:00, 102.32s/it]
  4%|▎         | 184/5198 [5:36:02<107:52:22, 77.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.56s/it][A100%|██████████| 1/1 [01:32<00:00, 92.56s/it]
  4%|▎         | 185/5198 [5:37:34<113:05:17, 81.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 01:02:39,998] [INFO] [logging.py:96:log_dist] [Rank 0] step=182, skipped=0, lr=[1.9999824508273667e-05], mom=[(0.9, 0.999)]
steps: 182 loss: 0.6612 iter time (s): 91.616 samples/sec: 1.397

100%|██████████| 1/1 [01:32<00:00, 92.34s/it][A100%|██████████| 1/1 [01:32<00:00, 92.34s/it]
  4%|▎         | 185/5198 [5:37:34<112:59:21, 81.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.39s/it][A100%|██████████| 1/1 [01:32<00:00, 92.39s/it]
  4%|▎         | 185/5198 [5:37:34<113:01:14, 81.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.36s/it][A100%|██████████| 1/1 [01:32<00:00, 92.36s/it]
  4%|▎         | 185/5198 [5:37:35<113:00:07, 81.15s/it]
100%|██████████| 1/1 [01:32<00:00, 92.44s/it][A100%|██████████| 1/1 [01:32<00:00, 92.44s/it]
  4%|▎         | 185/5198 [5:37:35<113:01:59, 81.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.35s/it][A100%|██████████| 1/1 [01:32<00:00, 92.35s/it]
  4%|▎         | 185/5198 [5:37:35<112:59:48, 81.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.37s/it][A100%|██████████| 1/1 [01:32<00:00, 92.37s/it]
  4%|▎         | 185/5198 [5:37:35<113:00:08, 81.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.39s/it][A100%|██████████| 1/1 [01:32<00:00, 92.39s/it]
  4%|▎         | 185/5198 [5:37:37<113:00:25, 81.15s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_174
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.48s/it][A100%|██████████| 1/1 [01:27<00:00, 87.48s/it]
  4%|▎         | 186/5198 [5:39:01<115:23:50, 82.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 01:04:07,315] [INFO] [logging.py:96:log_dist] [Rank 0] step=183, skipped=0, lr=[1.999978934961467e-05], mom=[(0.9, 0.999)]
steps: 183 loss: 0.5921 iter time (s): 86.543 samples/sec: 1.479

100%|██████████| 1/1 [01:27<00:00, 87.44s/it][A100%|██████████| 1/1 [01:27<00:00, 87.44s/it]
  4%|▎         | 186/5198 [5:39:02<115:15:55, 82.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.31s/it][A100%|██████████| 1/1 [01:27<00:00, 87.31s/it]
  4%|▎         | 186/5198 [5:39:02<115:14:25, 82.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.26s/it][A100%|██████████| 1/1 [01:27<00:00, 87.26s/it]
  4%|▎         | 186/5198 [5:39:02<115:13:56, 82.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.34s/it][A100%|██████████| 1/1 [01:27<00:00, 87.34s/it]
  4%|▎         | 186/5198 [5:39:02<115:13:56, 82.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.42s/it][A100%|██████████| 1/1 [01:27<00:00, 87.42s/it]
  4%|▎         | 186/5198 [5:39:02<115:15:54, 82.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.37s/it][A100%|██████████| 1/1 [01:27<00:00, 87.37s/it]
  4%|▎         | 186/5198 [5:39:02<115:14:53, 82.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.36s/it][A100%|██████████| 1/1 [01:27<00:00, 87.36s/it]
  4%|▎         | 186/5198 [5:39:04<115:14:52, 82.78s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_175
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.83s/it][A100%|██████████| 1/1 [01:34<00:00, 94.83s/it]
  4%|▎         | 187/5198 [5:40:36<120:00:34, 86.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 01:05:42,351] [INFO] [logging.py:96:log_dist] [Rank 0] step=184, skipped=0, lr=[1.9999750983095852e-05], mom=[(0.9, 0.999)]
steps: 184 loss: 0.5879 iter time (s): 94.199 samples/sec: 1.359

100%|██████████| 1/1 [01:35<00:00, 95.07s/it][A100%|██████████| 1/1 [01:35<00:00, 95.07s/it]
  4%|▎         | 187/5198 [5:40:37<119:53:39, 86.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.01s/it][A100%|██████████| 1/1 [01:35<00:00, 95.01s/it]
  4%|▎         | 187/5198 [5:40:37<119:51:26, 86.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.08s/it][A100%|██████████| 1/1 [01:35<00:00, 95.08s/it]
  4%|▎         | 187/5198 [5:40:37<119:52:23, 86.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.94s/it][A100%|██████████| 1/1 [01:34<00:00, 94.94s/it]
  4%|▎         | 187/5198 [5:40:37<119:50:43, 86.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.01s/it][A100%|██████████| 1/1 [01:35<00:00, 95.01s/it]
  4%|▎         | 187/5198 [5:40:39<119:51:27, 86.11s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_176

100%|██████████| 1/1 [01:35<00:00, 95.12s/it][A100%|██████████| 1/1 [01:35<00:00, 95.12s/it]
  4%|▎         | 187/5198 [5:40:37<119:53:21, 86.13s/it]
100%|██████████| 1/1 [01:35<00:00, 95.02s/it][A100%|██████████| 1/1 [01:35<00:00, 95.02s/it]
  4%|▎         | 187/5198 [5:40:37<119:51:48, 86.11s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.82s/it][A100%|██████████| 1/1 [01:21<00:00, 81.82s/it]
  4%|▎         | 188/5198 [5:41:58<118:20:19, 85.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 01:07:04,436] [INFO] [logging.py:96:log_dist] [Rank 0] step=185, skipped=0, lr=[1.9999709408729524e-05], mom=[(0.9, 0.999)]
steps: 185 loss: 0.6033 iter time (s): 81.267 samples/sec: 1.575

100%|██████████| 1/1 [01:21<00:00, 81.91s/it][A100%|██████████| 1/1 [01:21<00:00, 81.91s/it]
  4%|▎         | 188/5198 [5:41:59<118:12:06, 84.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.96s/it][A100%|██████████| 1/1 [01:21<00:00, 81.96s/it]
  4%|▎         | 188/5198 [5:41:59<118:15:07, 84.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 82.00s/it][A100%|██████████| 1/1 [01:21<00:00, 82.00s/it]
  4%|▎         | 188/5198 [5:41:59<118:14:48, 84.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.03s/it][A100%|██████████| 1/1 [01:22<00:00, 82.03s/it]
  4%|▎         | 188/5198 [5:41:59<118:14:33, 84.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.94s/it][A100%|██████████| 1/1 [01:21<00:00, 81.94s/it]
  4%|▎         | 188/5198 [5:41:59<118:14:16, 84.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.02s/it][A100%|██████████| 1/1 [01:22<00:00, 82.02s/it]
  4%|▎         | 188/5198 [5:41:59<118:14:52, 84.97s/it]
100%|██████████| 1/1 [01:22<00:00, 82.02s/it][A100%|██████████| 1/1 [01:22<00:00, 82.02s/it]
  4%|▎         | 188/5198 [5:42:02<118:14:46, 84.97s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_177

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:15<00:00, 135.59s/it][A100%|██████████| 1/1 [02:15<00:00, 135.59s/it]
  4%|▎         | 189/5198 [5:44:14<138:27:37, 99.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 01:09:21,661] [INFO] [logging.py:96:log_dist] [Rank 0] step=186, skipped=0, lr=[1.999966462652902e-05], mom=[(0.9, 0.999)]
steps: 186 loss: 0.6233 iter time (s): 136.461 samples/sec: 0.938

100%|██████████| 1/1 [02:17<00:00, 137.19s/it][A100%|██████████| 1/1 [02:17<00:00, 137.19s/it]
  4%|▎         | 189/5198 [5:44:16<138:59:00, 99.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:17<00:00, 137.38s/it][A100%|██████████| 1/1 [02:17<00:00, 137.38s/it]
  4%|▎         | 189/5198 [5:44:16<139:01:13, 99.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:17<00:00, 137.25s/it][A100%|██████████| 1/1 [02:17<00:00, 137.25s/it]
  4%|▎         | 189/5198 [5:44:16<139:00:20, 99.90s/it]
100%|██████████| 1/1 [02:17<00:00, 137.29s/it][A100%|██████████| 1/1 [02:17<00:00, 137.29s/it]
  4%|▎         | 189/5198 [5:44:16<139:00:55, 99.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:17<00:00, 137.31s/it][A100%|██████████| 1/1 [02:17<00:00, 137.31s/it]
  4%|▎         | 189/5198 [5:44:17<139:01:08, 99.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:17<00:00, 137.31s/it][A100%|██████████| 1/1 [02:17<00:00, 137.31s/it]
  4%|▎         | 189/5198 [5:44:17<139:01:37, 99.92s/it]
100%|██████████| 1/1 [02:17<00:00, 137.32s/it][A100%|██████████| 1/1 [02:17<00:00, 137.32s/it]
  4%|▎         | 189/5198 [5:44:19<139:01:42, 99.92s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_178
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.26s/it][A100%|██████████| 1/1 [01:23<00:00, 83.26s/it]
  4%|▎         | 190/5198 [5:45:38<132:02:23, 94.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 01:10:43,775] [INFO] [logging.py:96:log_dist] [Rank 0] step=187, skipped=0, lr=[1.9999616636508703e-05], mom=[(0.9, 0.999)]
steps: 187 loss: 0.5895 iter time (s): 81.162 samples/sec: 1.577

100%|██████████| 1/1 [01:22<00:00, 82.06s/it][A100%|██████████| 1/1 [01:22<00:00, 82.06s/it]
  4%|▎         | 190/5198 [5:45:38<131:47:37, 94.74s/it]
100%|██████████| 1/1 [01:21<00:00, 81.94s/it][A100%|██████████| 1/1 [01:21<00:00, 81.94s/it]
  4%|▎         | 190/5198 [5:45:38<131:46:43, 94.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.90s/it][A100%|██████████| 1/1 [01:21<00:00, 81.90s/it]
  4%|▎         | 190/5198 [5:45:38<131:46:32, 94.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.98s/it][A100%|██████████| 1/1 [01:21<00:00, 81.98s/it]
  4%|▎         | 190/5198 [5:45:38<131:46:46, 94.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.03s/it][A100%|██████████| 1/1 [01:22<00:00, 82.03s/it]
  4%|▎         | 190/5198 [5:45:39<131:47:09, 94.73s/it]
100%|██████████| 1/1 [01:21<00:00, 81.89s/it][A100%|██████████| 1/1 [01:21<00:00, 81.90s/it]
  4%|▎         | 190/5198 [5:45:41<131:46:44, 94.73s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_179

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.90s/it][A100%|██████████| 1/1 [01:21<00:00, 81.90s/it]
  4%|▎         | 190/5198 [5:45:39<131:47:00, 94.73s/it]Training on 128 of 128 sentences.


  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.77s/it][A100%|██████████| 1/1 [01:36<00:00, 96.77s/it]
  4%|▎         | 191/5198 [5:47:15<132:52:42, 95.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 01:12:21,195] [INFO] [logging.py:96:log_dist] [Rank 0] step=188, skipped=0, lr=[1.999956543868398e-05], mom=[(0.9, 0.999)]
steps: 188 loss: 0.6180 iter time (s): 96.616 samples/sec: 1.325

100%|██████████| 1/1 [01:37<00:00, 97.38s/it][A100%|██████████| 1/1 [01:37<00:00, 97.38s/it]
  4%|▎         | 191/5198 [5:47:15<132:52:59, 95.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.50s/it][A100%|██████████| 1/1 [01:37<00:00, 97.50s/it]
  4%|▎         | 191/5198 [5:47:15<132:53:31, 95.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.47s/it][A100%|██████████| 1/1 [01:37<00:00, 97.47s/it]
  4%|▎         | 191/5198 [5:47:16<132:53:41, 95.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.53s/it][A100%|██████████| 1/1 [01:37<00:00, 97.53s/it]
  4%|▎         | 191/5198 [5:47:16<132:53:48, 95.55s/it]
100%|██████████| 1/1 [01:37<00:00, 97.49s/it][A100%|██████████| 1/1 [01:37<00:00, 97.49s/it]
  4%|▎         | 191/5198 [5:47:16<132:54:12, 95.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.44s/it][A100%|██████████| 1/1 [01:37<00:00, 97.44s/it]
  4%|▎         | 191/5198 [5:47:16<132:53:14, 95.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.44s/it][A100%|██████████| 1/1 [01:37<00:00, 97.44s/it]
  4%|▎         | 191/5198 [5:47:18<132:53:16, 95.55s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_11

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.78s/it][A100%|██████████| 1/1 [01:58<00:00, 118.78s/it]
  4%|▎         | 192/5198 [5:49:14<142:27:23, 102.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 01:14:20,572] [INFO] [logging.py:96:log_dist] [Rank 0] step=189, skipped=0, lr=[1.9999511033071267e-05], mom=[(0.9, 0.999)]
steps: 189 loss: 0.8169 iter time (s): 118.754 samples/sec: 1.078

100%|██████████| 1/1 [01:59<00:00, 119.54s/it][A100%|██████████| 1/1 [01:59<00:00, 119.54s/it]
  4%|▎         | 192/5198 [5:49:15<142:42:42, 102.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.54s/it][A100%|██████████| 1/1 [01:59<00:00, 119.54s/it]
  4%|▎         | 192/5198 [5:49:15<142:45:12, 102.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.47s/it][A100%|██████████| 1/1 [01:59<00:00, 119.47s/it]
  4%|▎         | 192/5198 [5:49:15<142:41:31, 102.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.53s/it][A100%|██████████| 1/1 [01:59<00:00, 119.53s/it]
  4%|▎         | 192/5198 [5:49:16<142:44:23, 102.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.56s/it][A100%|██████████| 1/1 [01:59<00:00, 119.56s/it]
  4%|▎         | 192/5198 [5:49:16<142:43:46, 102.64s/it]
100%|██████████| 1/1 [01:59<00:00, 119.58s/it][A100%|██████████| 1/1 [01:59<00:00, 119.58s/it]
  4%|▎         | 192/5198 [5:49:16<142:43:08, 102.63s/it]
100%|██████████| 1/1 [01:59<00:00, 119.59s/it][A100%|██████████| 1/1 [01:59<00:00, 119.59s/it]
  4%|▎         | 192/5198 [5:49:18<142:43:22, 102.64s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_180
Training on 128 of 128 sentences.


  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.70s/it][A100%|██████████| 1/1 [01:30<00:00, 90.70s/it]
  4%|▎         | 193/5198 [5:50:45<137:40:32, 99.03s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 01:15:50,929] [INFO] [logging.py:96:log_dist] [Rank 0] step=190, skipped=0, lr=[1.9999453419688026e-05], mom=[(0.9, 0.999)]
steps: 190 loss: 0.6124 iter time (s): 89.185 samples/sec: 1.435

100%|██████████| 1/1 [01:30<00:00, 90.20s/it][A100%|██████████| 1/1 [01:30<00:00, 90.20s/it]
  4%|▎         | 193/5198 [5:50:45<137:33:58, 98.95s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.08s/it][A100%|██████████| 1/1 [01:30<00:00, 90.08s/it]
  4%|▎         | 193/5198 [5:50:45<137:32:55, 98.94s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.14s/it][A100%|██████████| 1/1 [01:30<00:00, 90.14s/it]
  4%|▎         | 193/5198 [5:50:46<137:31:34, 98.92s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.05s/it][A100%|██████████| 1/1 [01:30<00:00, 90.06s/it]
  4%|▎         | 193/5198 [5:50:46<137:31:34, 98.92s/it] 
100%|██████████| 1/1 [01:29<00:00, 89.89s/it][A100%|██████████| 1/1 [01:29<00:00, 89.89s/it]
  4%|▎         | 193/5198 [5:50:46<137:30:27, 98.91s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.96s/it][A100%|██████████| 1/1 [01:29<00:00, 89.96s/it]
  4%|▎         | 193/5198 [5:50:46<137:31:12, 98.92s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.98s/it][A100%|██████████| 1/1 [01:29<00:00, 89.98s/it]
  4%|▎         | 193/5198 [5:50:48<137:31:34, 98.92s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_181
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:05<00:00, 125.42s/it][A100%|██████████| 1/1 [02:05<00:00, 125.42s/it]
  4%|▎         | 194/5198 [5:52:50<148:39:11, 106.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 01:17:57,588] [INFO] [logging.py:96:log_dist] [Rank 0] step=191, skipped=0, lr=[1.9999392598552734e-05], mom=[(0.9, 0.999)]
steps: 191 loss: 0.6647 iter time (s): 125.877 samples/sec: 1.017

100%|██████████| 1/1 [02:06<00:00, 126.48s/it][A100%|██████████| 1/1 [02:06<00:00, 126.48s/it]
  4%|▎         | 194/5198 [5:52:52<148:57:27, 107.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:06<00:00, 126.59s/it][A100%|██████████| 1/1 [02:06<00:00, 126.59s/it]
  4%|▎         | 194/5198 [5:52:52<148:58:18, 107.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:06<00:00, 126.64s/it][A100%|██████████| 1/1 [02:06<00:00, 126.64s/it]
  4%|▎         | 194/5198 [5:52:52<148:57:43, 107.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:06<00:00, 126.56s/it][A100%|██████████| 1/1 [02:06<00:00, 126.56s/it]
  4%|▎         | 194/5198 [5:52:52<148:57:16, 107.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:06<00:00, 126.59s/it][A100%|██████████| 1/1 [02:06<00:00, 126.59s/it]
  4%|▎         | 194/5198 [5:52:52<148:57:22, 107.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:06<00:00, 126.64s/it][A100%|██████████| 1/1 [02:06<00:00, 126.64s/it]
  4%|▎         | 194/5198 [5:52:52<148:57:39, 107.17s/it]
100%|██████████| 1/1 [02:06<00:00, 126.63s/it][A100%|██████████| 1/1 [02:06<00:00, 126.63s/it]
  4%|▎         | 194/5198 [5:52:55<148:57:39, 107.17s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_182

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.59s/it][A100%|██████████| 1/1 [01:44<00:00, 104.59s/it]
  4%|▍         | 195/5198 [5:54:35<147:46:01, 106.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 01:19:41,831] [INFO] [logging.py:96:log_dist] [Rank 0] step=192, skipped=0, lr=[1.9999328569684907e-05], mom=[(0.9, 0.999)]
steps: 192 loss: 0.5885 iter time (s): 103.403 samples/sec: 1.238

100%|██████████| 1/1 [01:44<00:00, 104.21s/it][A100%|██████████| 1/1 [01:44<00:00, 104.21s/it]
  4%|▍         | 195/5198 [5:54:36<147:44:50, 106.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.25s/it][A100%|██████████| 1/1 [01:44<00:00, 104.25s/it]
  4%|▍         | 195/5198 [5:54:36<147:44:05, 106.31s/it]
100%|██████████| 1/1 [01:44<00:00, 104.23s/it][A100%|██████████| 1/1 [01:44<00:00, 104.23s/it]
  4%|▍         | 195/5198 [5:54:36<147:44:32, 106.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.26s/it][A100%|██████████| 1/1 [01:44<00:00, 104.26s/it]
  4%|▍         | 195/5198 [5:54:37<147:43:48, 106.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.34s/it][A100%|██████████| 1/1 [01:44<00:00, 104.34s/it]
  4%|▍         | 195/5198 [5:54:37<147:45:33, 106.32s/it]
100%|██████████| 1/1 [01:44<00:00, 104.22s/it][A100%|██████████| 1/1 [01:44<00:00, 104.22s/it]
  4%|▍         | 195/5198 [5:54:37<147:44:36, 106.31s/it]
100%|██████████| 1/1 [01:44<00:00, 104.23s/it][A100%|██████████| 1/1 [01:44<00:00, 104.23s/it]
  4%|▍         | 195/5198 [5:54:39<147:45:00, 106.32s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_183

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:01<00:00, 121.09s/it][A100%|██████████| 1/1 [02:01<00:00, 121.09s/it]
  4%|▍         | 196/5198 [5:56:37<153:58:49, 110.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 01:21:43,693] [INFO] [logging.py:96:log_dist] [Rank 0] step=193, skipped=0, lr=[1.9999261333105092e-05], mom=[(0.9, 0.999)]
steps: 193 loss: 0.5870 iter time (s): 121.027 samples/sec: 1.058

100%|██████████| 1/1 [02:01<00:00, 121.79s/it][A100%|██████████| 1/1 [02:01<00:00, 121.79s/it]
  4%|▍         | 196/5198 [5:56:38<154:09:35, 110.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:01<00:00, 121.70s/it][A100%|██████████| 1/1 [02:01<00:00, 121.70s/it]
  4%|▍         | 196/5198 [5:56:38<154:09:33, 110.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:01<00:00, 121.77s/it][A100%|██████████| 1/1 [02:01<00:00, 121.77s/it]
  4%|▍         | 196/5198 [5:56:38<154:08:34, 110.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:01<00:00, 121.84s/it][A100%|██████████| 1/1 [02:01<00:00, 121.84s/it]
  4%|▍         | 196/5198 [5:56:38<154:09:34, 110.95s/it]
100%|██████████| 1/1 [02:01<00:00, 121.74s/it][A100%|██████████| 1/1 [02:01<00:00, 121.74s/it]
  4%|▍         | 196/5198 [5:56:39<154:08:54, 110.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:01<00:00, 121.80s/it][A100%|██████████| 1/1 [02:01<00:00, 121.80s/it]
  4%|▍         | 196/5198 [5:56:39<154:09:20, 110.95s/it]
100%|██████████| 1/1 [02:01<00:00, 121.81s/it][A100%|██████████| 1/1 [02:01<00:00, 121.81s/it]
  4%|▍         | 196/5198 [5:56:41<154:09:15, 110.95s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_184

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.87s/it][A100%|██████████| 1/1 [01:27<00:00, 87.87s/it]
  4%|▍         | 197/5198 [5:58:05<144:30:47, 104.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 01:23:10,821] [INFO] [logging.py:96:log_dist] [Rank 0] step=194, skipped=0, lr=[1.9999190888834852e-05], mom=[(0.9, 0.999)]
steps: 194 loss: 0.6161 iter time (s): 86.186 samples/sec: 1.485

100%|██████████| 1/1 [01:27<00:00, 87.08s/it][A100%|██████████| 1/1 [01:27<00:00, 87.08s/it]
  4%|▍         | 197/5198 [5:58:05<144:12:45, 103.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.99s/it][A100%|██████████| 1/1 [01:26<00:00, 86.99s/it]
  4%|▍         | 197/5198 [5:58:05<144:11:23, 103.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.07s/it][A100%|██████████| 1/1 [01:27<00:00, 87.07s/it]
  4%|▍         | 197/5198 [5:58:05<144:11:58, 103.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.98s/it][A100%|██████████| 1/1 [01:26<00:00, 86.98s/it]
  4%|▍         | 197/5198 [5:58:05<144:11:29, 103.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.04s/it][A100%|██████████| 1/1 [01:27<00:00, 87.04s/it]
  4%|▍         | 197/5198 [5:58:06<144:11:35, 103.80s/it]
100%|██████████| 1/1 [01:26<00:00, 86.90s/it][A100%|██████████| 1/1 [01:26<00:00, 86.90s/it]
  4%|▍         | 197/5198 [5:58:06<144:11:18, 103.80s/it]
100%|██████████| 1/1 [01:26<00:00, 86.91s/it][A100%|██████████| 1/1 [01:26<00:00, 86.91s/it]
  4%|▍         | 197/5198 [5:58:08<144:11:24, 103.80s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_185

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.63s/it][A100%|██████████| 1/1 [01:22<00:00, 82.63s/it]
  4%|▍         | 198/5198 [5:59:28<135:42:45, 97.71s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 01:24:33,692] [INFO] [logging.py:96:log_dist] [Rank 0] step=195, skipped=0, lr=[1.999911723689679e-05], mom=[(0.9, 0.999)]
steps: 195 loss: 0.6003 iter time (s): 82.108 samples/sec: 1.559

100%|██████████| 1/1 [01:22<00:00, 82.81s/it][A100%|██████████| 1/1 [01:22<00:00, 82.81s/it]
  4%|▍         | 198/5198 [5:59:28<135:28:05, 97.54s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.94s/it][A100%|██████████| 1/1 [01:22<00:00, 82.94s/it]
  4%|▍         | 198/5198 [5:59:28<135:29:40, 97.56s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.95s/it][A100%|██████████| 1/1 [01:22<00:00, 82.96s/it]
  4%|▍         | 198/5198 [5:59:28<135:31:33, 97.58s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.99s/it][A100%|██████████| 1/1 [01:22<00:00, 82.99s/it]
  4%|▍         | 198/5198 [5:59:28<135:30:51, 97.57s/it] 
100%|██████████| 1/1 [01:22<00:00, 82.85s/it][A100%|██████████| 1/1 [01:22<00:00, 82.85s/it]
  4%|▍         | 198/5198 [5:59:29<135:29:44, 97.56s/it] 
100%|██████████| 1/1 [01:22<00:00, 82.90s/it][A100%|██████████| 1/1 [01:22<00:00, 82.90s/it]
  4%|▍         | 198/5198 [5:59:29<135:30:03, 97.56s/it] 
100%|██████████| 1/1 [01:22<00:00, 82.92s/it][A100%|██████████| 1/1 [01:22<00:00, 82.92s/it]
  4%|▍         | 198/5198 [5:59:31<135:30:03, 97.56s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_186

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.55s/it][A100%|██████████| 1/1 [01:29<00:00, 89.55s/it]
  4%|▍         | 199/5198 [6:00:57<132:24:42, 95.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 01:26:03,672] [INFO] [logging.py:96:log_dist] [Rank 0] step=196, skipped=0, lr=[1.999904037731454e-05], mom=[(0.9, 0.999)]
steps: 196 loss: 0.5889 iter time (s): 89.124 samples/sec: 1.436

100%|██████████| 1/1 [01:29<00:00, 89.93s/it][A100%|██████████| 1/1 [01:29<00:00, 89.93s/it]
  4%|▍         | 199/5198 [6:00:58<132:18:58, 95.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.87s/it][A100%|██████████| 1/1 [01:29<00:00, 89.87s/it]
  4%|▍         | 199/5198 [6:00:58<132:18:14, 95.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.88s/it][A100%|██████████| 1/1 [01:29<00:00, 89.88s/it]
  4%|▍         | 199/5198 [6:00:58<132:18:13, 95.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.83s/it][A100%|██████████| 1/1 [01:29<00:00, 89.83s/it]
  4%|▍         | 199/5198 [6:00:58<132:18:33, 95.28s/it]
100%|██████████| 1/1 [01:29<00:00, 89.88s/it][A100%|██████████| 1/1 [01:29<00:00, 89.88s/it]
  4%|▍         | 199/5198 [6:00:59<132:18:54, 95.29s/it]
100%|██████████| 1/1 [01:29<00:00, 89.92s/it][A100%|██████████| 1/1 [01:29<00:00, 89.92s/it]
  4%|▍         | 199/5198 [6:00:59<132:18:31, 95.28s/it]
100%|██████████| 1/1 [01:29<00:00, 89.92s/it][A100%|██████████| 1/1 [01:29<00:00, 89.92s/it]
  4%|▍         | 199/5198 [6:01:01<132:18:34, 95.28s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_187

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.19s/it][A100%|██████████| 1/1 [01:43<00:00, 103.20s/it]
[2024-06-30 01:27:47,660] [INFO] [logging.py:96:log_dist] [Rank 0] step=197, skipped=0, lr=[1.9998960310112755e-05], mom=[(0.9, 0.999)]
steps: 197 loss: 0.6025 iter time (s): 103.195 samples/sec: 1.240

100%|██████████| 1/1 [01:43<00:00, 103.99s/it][A100%|██████████| 1/1 [01:43<00:00, 103.99s/it]

100%|██████████| 1/1 [01:44<00:00, 104.08s/it][A100%|██████████| 1/1 [01:44<00:00, 104.08s/it]

100%|██████████| 1/1 [01:44<00:00, 104.10s/it][A100%|██████████| 1/1 [01:44<00:00, 104.10s/it]

100%|██████████| 1/1 [01:43<00:00, 103.97s/it][A100%|██████████| 1/1 [01:43<00:00, 103.97s/it]

100%|██████████| 1/1 [01:44<00:00, 104.01s/it][A100%|██████████| 1/1 [01:44<00:00, 104.02s/it]

100%|██████████| 1/1 [01:44<00:00, 104.10s/it][A100%|██████████| 1/1 [01:44<00:00, 104.10s/it]
Checkpointing at shard 199

100%|██████████| 1/1 [01:44<00:00, 104.10s/it][A100%|██████████| 1/1 [01:44<00:00, 104.10s/it]
[2024-06-30 01:27:48,581] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step197 is about to be saved!
[2024-06-30 01:27:49,458] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step197/layer_00-model_states.pt...
[2024-06-30 01:27:52,971] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step197/layer_02-model_states.pt...
[2024-06-30 01:27:54,183] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step197/layer_06-model_states.pt...
[2024-06-30 01:27:54,185] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step197/layer_05-model_states.pt...
[2024-06-30 01:27:54,251] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step197/layer_07-model_states.pt...
[2024-06-30 01:27:54,957] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step197/layer_08-model_states.pt...
[2024-06-30 01:28:08,187] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step197/layer_04-model_states.pt...
[2024-06-30 01:28:08,344] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step197/layer_03-model_states.pt...
[2024-06-30 01:28:57,224] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step197/layer_00-model_states.pt.
[2024-06-30 01:29:04,312] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step197/layer_01-model_states.pt...
[2024-06-30 01:36:17,618] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step197/layer_07-model_states.pt.
[2024-06-30 01:36:17,680] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step197/mp_rank_06_model_states.pt...
[2024-06-30 01:36:18,028] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step197/mp_rank_06_model_states.pt.
[2024-06-30 01:36:18,028] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step197 is ready now!
[2024-06-30 01:36:51,430] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step197/layer_02-model_states.pt.
[2024-06-30 01:36:51,432] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step197/layer_05-model_states.pt.
[2024-06-30 01:36:51,473] [INFO] [logging.py:96:log_dist] [Rank 1] Saving model checkpoint: /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step197/mp_rank_01_model_states.pt
[2024-06-30 01:36:51,473] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step197/mp_rank_01_model_states.pt...
[2024-06-30 01:36:51,477] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step197/mp_rank_04_model_states.pt...
[2024-06-30 01:36:51,491] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step197/layer_08-model_states.pt.
[2024-06-30 01:36:51,582] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step197/layer_03-model_states.pt.
[2024-06-30 01:36:51,585] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step197/layer_06-model_states.pt.
[2024-06-30 01:36:51,586] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step197/layer_01-model_states.pt.
[2024-06-30 01:36:51,604] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step197/layer_04-model_states.pt.
[2024-06-30 01:36:51,605] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step197/layer_09-model_states.pt...
[2024-06-30 01:36:51,630] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step197/mp_rank_01_model_states.pt.
[2024-06-30 01:36:51,631] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step197 is ready now!
[2024-06-30 01:36:51,636] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step197/mp_rank_05_model_states.pt...
[2024-06-30 01:36:51,638] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step197/mp_rank_02_model_states.pt...
[2024-06-30 01:36:51,726] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step197/mp_rank_03_model_states.pt...
[2024-06-30 01:36:51,771] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step197/mp_rank_04_model_states.pt.
[2024-06-30 01:36:51,771] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step197 is ready now!
[2024-06-30 01:36:51,994] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step197/mp_rank_03_model_states.pt.
[2024-06-30 01:36:51,994] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step197 is ready now!
[2024-06-30 01:36:52,003] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step197/mp_rank_05_model_states.pt.
[2024-06-30 01:36:52,003] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step197 is ready now!
[2024-06-30 01:36:52,020] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step197/mp_rank_02_model_states.pt.
[2024-06-30 01:36:52,020] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step197 is ready now!
[2024-06-30 01:36:52,129] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step197/mp_rank_00_model_states.pt
[2024-06-30 01:36:52,129] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step197/mp_rank_00_model_states.pt...
[2024-06-30 01:36:56,724] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step197/mp_rank_00_model_states.pt.
[2024-06-30 01:36:56,724] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step197 is ready now!
[2024-06-30 01:36:58,358] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step197/layer_09-model_states.pt.
[2024-06-30 01:36:58,362] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step197/mp_rank_07_model_states.pt...
[2024-06-30 01:37:00,759] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step197/mp_rank_07_model_states.pt.
[2024-06-30 01:37:00,759] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step197 is ready now!
Checkpoint saved using --- 552.1803784370422 seconds ---
  4%|▍         | 200/5198 [6:11:57<366:57:18, 264.31s/it]  4%|▍         | 200/5198 [6:11:57<365:42:46, 263.42s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_188
  4%|▍         | 200/5198 [6:11:55<365:45:21, 263.45s/it]  4%|▍         | 200/5198 [6:11:55<365:47:39, 263.48s/it]  4%|▍         | 200/5198 [6:11:55<365:44:16, 263.44s/it]  4%|▍         | 200/5198 [6:11:55<365:53:36, 263.55s/it]  4%|▍         | 200/5198 [6:11:55<365:50:42, 263.51s/it]  4%|▍         | 200/5198 [6:11:55<365:43:09, 263.42s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.41s/it][A100%|██████████| 1/1 [01:45<00:00, 105.41s/it]
  4%|▍         | 201/5198 [6:13:43<301:10:29, 216.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 01:38:49,616] [INFO] [logging.py:96:log_dist] [Rank 0] step=198, skipped=0, lr=[1.999887703531712e-05], mom=[(0.9, 0.999)]
steps: 198 loss: 0.5955 iter time (s): 107.918 samples/sec: 1.186

100%|██████████| 1/1 [01:48<00:00, 108.23s/it][A100%|██████████| 1/1 [01:48<00:00, 108.23s/it]
  4%|▍         | 201/5198 [6:13:44<301:36:05, 217.28s/it]
100%|██████████| 1/1 [01:48<00:00, 108.34s/it][A100%|██████████| 1/1 [01:48<00:00, 108.34s/it]
  4%|▍         | 201/5198 [6:13:44<301:36:53, 217.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.44s/it][A100%|██████████| 1/1 [01:48<00:00, 108.44s/it]
  4%|▍         | 201/5198 [6:13:44<301:37:09, 217.30s/it]
100%|██████████| 1/1 [01:48<00:00, 108.53s/it][A100%|██████████| 1/1 [01:48<00:00, 108.53s/it]
  4%|▍         | 201/5198 [6:13:44<301:37:55, 217.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.57s/it][A100%|██████████| 1/1 [01:48<00:00, 108.57s/it]
  4%|▍         | 201/5198 [6:13:44<301:38:17, 217.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.62s/it][A100%|██████████| 1/1 [01:48<00:00, 108.62s/it]
  4%|▍         | 201/5198 [6:13:44<301:38:44, 217.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.66s/it][A100%|██████████| 1/1 [01:48<00:00, 108.66s/it]
  4%|▍         | 201/5198 [6:13:47<301:39:17, 217.32s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_189
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.41s/it][A100%|██████████| 1/1 [01:42<00:00, 102.41s/it]
  4%|▍         | 202/5198 [6:15:26<253:34:40, 182.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 01:40:32,218] [INFO] [logging.py:96:log_dist] [Rank 0] step=199, skipped=0, lr=[1.9998790552954358e-05], mom=[(0.9, 0.999)]
steps: 199 loss: 0.5946 iter time (s): 101.728 samples/sec: 1.258

100%|██████████| 1/1 [01:42<00:00, 102.45s/it][A100%|██████████| 1/1 [01:42<00:00, 102.45s/it]
  4%|▍         | 202/5198 [6:15:26<253:48:53, 182.89s/it]
100%|██████████| 1/1 [01:42<00:00, 102.50s/it][A100%|██████████| 1/1 [01:42<00:00, 102.50s/it]
  4%|▍         | 202/5198 [6:15:26<253:47:49, 182.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.53s/it][A100%|██████████| 1/1 [01:42<00:00, 102.53s/it]
  4%|▍         | 202/5198 [6:15:27<253:50:31, 182.91s/it]
100%|██████████| 1/1 [01:42<00:00, 102.57s/it][A100%|██████████| 1/1 [01:42<00:00, 102.57s/it]
  4%|▍         | 202/5198 [6:15:27<253:50:46, 182.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.59s/it][A100%|██████████| 1/1 [01:42<00:00, 102.59s/it]

  4%|▍         | 202/5198 [6:15:27<253:50:50, 182.92s/it]  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.58s/it][A100%|██████████| 1/1 [01:42<00:00, 102.58s/it]
  4%|▍         | 202/5198 [6:15:27<253:50:41, 182.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.48s/it][A100%|██████████| 1/1 [01:42<00:00, 102.48s/it]
  4%|▍         | 202/5198 [6:15:29<253:50:37, 182.91s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_190
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.05s/it][A100%|██████████| 1/1 [01:35<00:00, 95.05s/it]
  4%|▍         | 203/5198 [6:17:01<217:11:24, 156.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 01:42:07,438] [INFO] [logging.py:96:log_dist] [Rank 0] step=200, skipped=0, lr=[1.9998700863052213e-05], mom=[(0.9, 0.999)]
steps: 200 loss: 0.5711 iter time (s): 94.483 samples/sec: 1.355

100%|██████████| 1/1 [01:35<00:00, 95.21s/it][A100%|██████████| 1/1 [01:35<00:00, 95.21s/it]
  4%|▍         | 203/5198 [6:17:02<217:18:22, 156.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.26s/it][A100%|██████████| 1/1 [01:35<00:00, 95.26s/it]
  4%|▍         | 203/5198 [6:17:02<217:19:16, 156.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.14s/it][A100%|██████████| 1/1 [01:35<00:00, 95.14s/it]
  4%|▍         | 203/5198 [6:17:02<217:18:09, 156.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.25s/it][A100%|██████████| 1/1 [01:35<00:00, 95.25s/it]
  4%|▍         | 203/5198 [6:17:02<217:20:04, 156.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.28s/it][A100%|██████████| 1/1 [01:35<00:00, 95.28s/it]
  4%|▍         | 203/5198 [6:17:02<217:20:02, 156.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.29s/it][A100%|██████████| 1/1 [01:35<00:00, 95.29s/it]
  4%|▍         | 203/5198 [6:17:02<217:20:13, 156.64s/it]
100%|██████████| 1/1 [01:35<00:00, 95.29s/it][A100%|██████████| 1/1 [01:35<00:00, 95.29s/it]
  4%|▍         | 203/5198 [6:17:05<217:20:08, 156.64s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_191

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.53s/it][A100%|██████████| 1/1 [01:42<00:00, 102.53s/it]
  4%|▍         | 204/5198 [6:18:44<194:50:32, 140.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 01:43:50,134] [INFO] [logging.py:96:log_dist] [Rank 0] step=201, skipped=0, lr=[1.9998607965639462e-05], mom=[(0.9, 0.999)]
steps: 201 loss: 0.6256 iter time (s): 102.505 samples/sec: 1.249

100%|██████████| 1/1 [01:43<00:00, 103.23s/it][A100%|██████████| 1/1 [01:43<00:00, 103.23s/it]
  4%|▍         | 204/5198 [6:18:45<195:04:04, 140.62s/it]
100%|██████████| 1/1 [01:43<00:00, 103.25s/it][A100%|██████████| 1/1 [01:43<00:00, 103.25s/it]
  4%|▍         | 204/5198 [6:18:45<195:04:41, 140.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.33s/it][A100%|██████████| 1/1 [01:43<00:00, 103.33s/it]
  4%|▍         | 204/5198 [6:18:45<195:06:02, 140.64s/it]
100%|██████████| 1/1 [01:43<00:00, 103.21s/it][A100%|██████████| 1/1 [01:43<00:00, 103.21s/it]
  4%|▍         | 204/5198 [6:18:45<195:04:20, 140.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.19s/it][A100%|██████████| 1/1 [01:43<00:00, 103.19s/it]
  4%|▍         | 204/5198 [6:18:46<195:04:10, 140.62s/it]
100%|██████████| 1/1 [01:43<00:00, 103.18s/it][A100%|██████████| 1/1 [01:43<00:00, 103.18s/it]
  4%|▍         | 204/5198 [6:18:46<195:03:59, 140.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.28s/it][A100%|██████████| 1/1 [01:43<00:00, 103.28s/it]
  4%|▍         | 204/5198 [6:18:48<195:06:26, 140.65s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_192
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.33s/it][A100%|██████████| 1/1 [01:55<00:00, 115.33s/it]
  4%|▍         | 205/5198 [6:20:41<185:00:31, 133.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 01:45:47,112] [INFO] [logging.py:96:log_dist] [Rank 0] step=202, skipped=0, lr=[1.9998511860745904e-05], mom=[(0.9, 0.999)]
steps: 202 loss: 0.5977 iter time (s): 115.496 samples/sec: 1.108

100%|██████████| 1/1 [01:56<00:00, 116.18s/it][A100%|██████████| 1/1 [01:56<00:00, 116.18s/it]
  4%|▍         | 205/5198 [6:20:41<184:55:45, 133.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.34s/it][A100%|██████████| 1/1 [01:56<00:00, 116.34s/it]
  4%|▍         | 205/5198 [6:20:41<184:57:29, 133.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.29s/it][A100%|██████████| 1/1 [01:56<00:00, 116.29s/it]
  4%|▍         | 205/5198 [6:20:42<184:56:45, 133.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.31s/it][A100%|██████████| 1/1 [01:56<00:00, 116.31s/it]
  4%|▍         | 205/5198 [6:20:42<184:56:46, 133.35s/it]
100%|██████████| 1/1 [01:56<00:00, 116.34s/it][A100%|██████████| 1/1 [01:56<00:00, 116.34s/it]
  4%|▍         | 205/5198 [6:20:42<184:56:43, 133.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.30s/it][A100%|██████████| 1/1 [01:56<00:00, 116.30s/it]
  4%|▍         | 205/5198 [6:20:42<184:56:54, 133.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.27s/it][A100%|██████████| 1/1 [01:56<00:00, 116.27s/it]
  4%|▍         | 205/5198 [6:20:44<184:56:21, 133.34s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_193
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.76s/it][A100%|██████████| 1/1 [01:28<00:00, 88.76s/it]
  4%|▍         | 206/5198 [6:22:10<166:31:27, 120.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 01:47:16,018] [INFO] [logging.py:96:log_dist] [Rank 0] step=203, skipped=0, lr=[1.9998412548402372e-05], mom=[(0.9, 0.999)]
steps: 203 loss: 0.6345 iter time (s): 88.088 samples/sec: 1.453

100%|██████████| 1/1 [01:28<00:00, 88.92s/it][A100%|██████████| 1/1 [01:28<00:00, 88.92s/it]
  4%|▍         | 206/5198 [6:22:10<166:25:18, 120.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.87s/it][A100%|██████████| 1/1 [01:28<00:00, 88.87s/it]
  4%|▍         | 206/5198 [6:22:10<166:25:25, 120.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.85s/it][A100%|██████████| 1/1 [01:28<00:00, 88.85s/it]
  4%|▍         | 206/5198 [6:22:11<166:25:23, 120.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.92s/it][A100%|██████████| 1/1 [01:28<00:00, 88.92s/it]
  4%|▍         | 206/5198 [6:22:11<166:26:46, 120.03s/it]
100%|██████████| 1/1 [01:28<00:00, 88.91s/it][A100%|██████████| 1/1 [01:28<00:00, 88.91s/it]
  4%|▍         | 206/5198 [6:22:11<166:26:00, 120.02s/it]
100%|██████████| 1/1 [01:28<00:00, 88.95s/it][A100%|██████████| 1/1 [01:28<00:00, 88.95s/it]
  4%|▍         | 206/5198 [6:22:11<166:26:54, 120.03s/it]
100%|██████████| 1/1 [01:28<00:00, 88.89s/it][A100%|██████████| 1/1 [01:28<00:00, 88.89s/it]
  4%|▍         | 206/5198 [6:22:13<166:26:14, 120.03s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_194
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.05s/it][A100%|██████████| 1/1 [01:30<00:00, 90.05s/it]
  4%|▍         | 207/5198 [6:23:41<154:13:29, 111.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 01:48:46,658] [INFO] [logging.py:96:log_dist] [Rank 0] step=204, skipped=0, lr=[1.9998310028640734e-05], mom=[(0.9, 0.999)]
steps: 204 loss: 0.6038 iter time (s): 89.766 samples/sec: 1.426

100%|██████████| 1/1 [01:30<00:00, 90.53s/it][A100%|██████████| 1/1 [01:30<00:00, 90.53s/it]
  4%|▍         | 207/5198 [6:23:41<154:09:42, 111.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.60s/it][A100%|██████████| 1/1 [01:30<00:00, 90.61s/it]
  4%|▍         | 207/5198 [6:23:41<154:09:46, 111.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.57s/it][A100%|██████████| 1/1 [01:30<00:00, 90.57s/it]
  4%|▍         | 207/5198 [6:23:41<154:10:35, 111.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.44s/it][A100%|██████████| 1/1 [01:30<00:00, 90.44s/it]
  4%|▍         | 207/5198 [6:23:41<154:09:47, 111.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.49s/it][A100%|██████████| 1/1 [01:30<00:00, 90.49s/it]
  4%|▍         | 207/5198 [6:23:41<154:10:27, 111.21s/it]
100%|██████████| 1/1 [01:30<00:00, 90.56s/it][A100%|██████████| 1/1 [01:30<00:00, 90.56s/it]
  4%|▍         | 207/5198 [6:23:42<154:10:56, 111.21s/it]
100%|██████████| 1/1 [01:30<00:00, 90.59s/it][A100%|██████████| 1/1 [01:30<00:00, 90.59s/it]
  4%|▍         | 207/5198 [6:23:44<154:10:51, 111.21s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_12
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.12s/it][A100%|██████████| 1/1 [01:58<00:00, 118.13s/it]
  4%|▍         | 208/5198 [6:25:39<157:14:37, 113.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 01:50:45,965] [INFO] [logging.py:96:log_dist] [Rank 0] step=205, skipped=0, lr=[1.999820430149387e-05], mom=[(0.9, 0.999)]
steps: 205 loss: 0.8310 iter time (s): 118.722 samples/sec: 1.078

100%|██████████| 1/1 [01:59<00:00, 119.54s/it][A100%|██████████| 1/1 [01:59<00:00, 119.54s/it]
  4%|▍         | 208/5198 [6:25:40<157:38:41, 113.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.62s/it][A100%|██████████| 1/1 [01:59<00:00, 119.62s/it]
  4%|▍         | 208/5198 [6:25:41<157:38:19, 113.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.59s/it][A100%|██████████| 1/1 [01:59<00:00, 119.59s/it]
  4%|▍         | 208/5198 [6:25:41<157:38:41, 113.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.63s/it][A100%|██████████| 1/1 [01:59<00:00, 119.63s/it]
  4%|▍         | 208/5198 [6:25:41<157:38:30, 113.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.54s/it][A100%|██████████| 1/1 [01:59<00:00, 119.54s/it]
  4%|▍         | 208/5198 [6:25:41<157:39:14, 113.74s/it]
100%|██████████| 1/1 [01:59<00:00, 119.59s/it][A100%|██████████| 1/1 [01:59<00:00, 119.59s/it]
  4%|▍         | 208/5198 [6:25:41<157:39:07, 113.74s/it]
100%|██████████| 1/1 [01:59<00:00, 119.62s/it][A100%|██████████| 1/1 [01:59<00:00, 119.62s/it]
  4%|▍         | 208/5198 [6:25:43<157:39:17, 113.74s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_195


  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.06s/it][A100%|██████████| 1/1 [01:43<00:00, 103.06s/it]
  4%|▍         | 209/5198 [6:27:23<153:02:34, 110.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 01:52:29,080] [INFO] [logging.py:96:log_dist] [Rank 0] step=206, skipped=0, lr=[1.999809536699571e-05], mom=[(0.9, 0.999)]
steps: 206 loss: 0.6374 iter time (s): 101.926 samples/sec: 1.256

100%|██████████| 1/1 [01:42<00:00, 102.72s/it][A100%|██████████| 1/1 [01:42<00:00, 102.72s/it]
  4%|▍         | 209/5198 [6:27:23<153:04:10, 110.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.85s/it][A100%|██████████| 1/1 [01:42<00:00, 102.85s/it]
  4%|▍         | 209/5198 [6:27:23<153:05:26, 110.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.69s/it][A100%|██████████| 1/1 [01:42<00:00, 102.69s/it]
  4%|▍         | 209/5198 [6:27:24<153:03:10, 110.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.84s/it][A100%|██████████| 1/1 [01:42<00:00, 102.84s/it]
  4%|▍         | 209/5198 [6:27:24<153:05:07, 110.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.70s/it][A100%|██████████| 1/1 [01:42<00:00, 102.70s/it]
  4%|▍         | 209/5198 [6:27:24<153:04:30, 110.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.75s/it][A100%|██████████| 1/1 [01:42<00:00, 102.75s/it]
  4%|▍         | 209/5198 [6:27:24<153:04:19, 110.45s/it]
100%|██████████| 1/1 [01:42<00:00, 102.71s/it][A100%|██████████| 1/1 [01:42<00:00, 102.71s/it]
  4%|▍         | 209/5198 [6:27:26<153:03:52, 110.45s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_196
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.65s/it][A100%|██████████| 1/1 [01:42<00:00, 102.65s/it]
  4%|▍         | 210/5198 [6:29:06<149:56:13, 108.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 01:54:11,582] [INFO] [logging.py:96:log_dist] [Rank 0] step=207, skipped=0, lr=[1.9997983225181203e-05], mom=[(0.9, 0.999)]
steps: 207 loss: 0.6049 iter time (s): 101.588 samples/sec: 1.260

100%|██████████| 1/1 [01:42<00:00, 102.43s/it][A100%|██████████| 1/1 [01:42<00:00, 102.43s/it]
  4%|▍         | 210/5198 [6:29:06<149:45:21, 108.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.50s/it][A100%|██████████| 1/1 [01:42<00:00, 102.50s/it]
  4%|▍         | 210/5198 [6:29:06<149:45:03, 108.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.40s/it][A100%|██████████| 1/1 [01:42<00:00, 102.40s/it]
  4%|▍         | 210/5198 [6:29:06<149:44:10, 108.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.45s/it][A100%|██████████| 1/1 [01:42<00:00, 102.45s/it]
  4%|▍         | 210/5198 [6:29:06<149:43:13, 108.06s/it]
100%|██████████| 1/1 [01:42<00:00, 102.48s/it][A100%|██████████| 1/1 [01:42<00:00, 102.48s/it]
  4%|▍         | 210/5198 [6:29:06<149:44:29, 108.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.43s/it][A100%|██████████| 1/1 [01:42<00:00, 102.43s/it]
  4%|▍         | 210/5198 [6:29:09<149:44:10, 108.07s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_197

100%|██████████| 1/1 [01:42<00:00, 102.43s/it][A100%|██████████| 1/1 [01:42<00:00, 102.43s/it]
  4%|▍         | 210/5198 [6:29:07<149:44:51, 108.08s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.22s/it][A100%|██████████| 1/1 [01:39<00:00, 99.22s/it]
  4%|▍         | 211/5198 [6:30:45<146:20:11, 105.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 01:55:51,744] [INFO] [logging.py:96:log_dist] [Rank 0] step=208, skipped=0, lr=[1.999786787608632e-05], mom=[(0.9, 0.999)]
steps: 208 loss: 0.6835 iter time (s): 99.318 samples/sec: 1.289

100%|██████████| 1/1 [01:40<00:00, 100.06s/it][A100%|██████████| 1/1 [01:40<00:00, 100.06s/it]
  4%|▍         | 211/5198 [6:30:46<146:23:53, 105.68s/it]
100%|██████████| 1/1 [01:39<00:00, 99.95s/it][A100%|██████████| 1/1 [01:39<00:00, 99.95s/it]
  4%|▍         | 211/5198 [6:30:46<146:21:57, 105.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.13s/it][A100%|██████████| 1/1 [01:40<00:00, 100.13s/it]
  4%|▍         | 211/5198 [6:30:46<146:24:37, 105.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.99s/it][A100%|██████████| 1/1 [01:39<00:00, 99.99s/it]
  4%|▍         | 211/5198 [6:30:46<146:22:20, 105.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.08s/it][A100%|██████████| 1/1 [01:40<00:00, 100.08s/it]
  4%|▍         | 211/5198 [6:30:47<146:24:12, 105.69s/it]
100%|██████████| 1/1 [01:40<00:00, 100.05s/it][A100%|██████████| 1/1 [01:40<00:00, 100.05s/it]
  4%|▍         | 211/5198 [6:30:47<146:22:55, 105.67s/it]
100%|██████████| 1/1 [01:40<00:00, 100.08s/it][A100%|██████████| 1/1 [01:40<00:00, 100.08s/it]
  4%|▍         | 211/5198 [6:30:49<146:23:14, 105.67s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_198
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.15s/it][A100%|██████████| 1/1 [01:22<00:00, 82.15s/it]
  4%|▍         | 212/5198 [6:32:08<136:41:14, 98.69s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 01:57:13,731] [INFO] [logging.py:96:log_dist] [Rank 0] step=209, skipped=0, lr=[1.999774931974807e-05], mom=[(0.9, 0.999)]
steps: 209 loss: 0.6115 iter time (s): 81.206 samples/sec: 1.576

100%|██████████| 1/1 [01:21<00:00, 81.97s/it][A100%|██████████| 1/1 [01:21<00:00, 81.97s/it]
  4%|▍         | 212/5198 [6:32:08<136:32:19, 98.58s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.08s/it][A100%|██████████| 1/1 [01:22<00:00, 82.08s/it]
  4%|▍         | 212/5198 [6:32:08<136:32:39, 98.59s/it] 
100%|██████████| 1/1 [01:21<00:00, 81.97s/it][A100%|██████████| 1/1 [01:21<00:00, 81.97s/it]
  4%|▍         | 212/5198 [6:32:08<136:31:59, 98.58s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.01s/it][A100%|██████████| 1/1 [01:22<00:00, 82.01s/it]
  4%|▍         | 212/5198 [6:32:08<136:31:06, 98.57s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.93s/it][A100%|██████████| 1/1 [01:21<00:00, 81.93s/it]
  4%|▍         | 212/5198 [6:32:09<136:32:24, 98.58s/it] 
100%|██████████| 1/1 [01:21<00:00, 81.97s/it][A100%|██████████| 1/1 [01:21<00:00, 81.97s/it]
  4%|▍         | 212/5198 [6:32:09<136:31:56, 98.58s/it] 
100%|██████████| 1/1 [01:21<00:00, 81.99s/it][A100%|██████████| 1/1 [01:21<00:00, 81.99s/it]
  4%|▍         | 212/5198 [6:32:11<136:31:46, 98.58s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_199
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.60s/it][A100%|██████████| 1/1 [01:22<00:00, 82.60s/it]
  4%|▍         | 213/5198 [6:33:31<130:05:00, 93.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 01:58:36,566] [INFO] [logging.py:96:log_dist] [Rank 0] step=210, skipped=0, lr=[1.999762755620449e-05], mom=[(0.9, 0.999)]
steps: 210 loss: 0.6200 iter time (s): 82.067 samples/sec: 1.560

100%|██████████| 1/1 [01:22<00:00, 82.79s/it][A100%|██████████| 1/1 [01:22<00:00, 82.79s/it]
  4%|▍         | 213/5198 [6:33:31<129:58:16, 93.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.70s/it][A100%|██████████| 1/1 [01:22<00:00, 82.70s/it]
  4%|▍         | 213/5198 [6:33:31<129:57:31, 93.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.79s/it][A100%|██████████| 1/1 [01:22<00:00, 82.79s/it]
  4%|▍         | 213/5198 [6:33:31<129:57:47, 93.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.90s/it][A100%|██████████| 1/1 [01:22<00:00, 82.90s/it]
  4%|▍         | 213/5198 [6:33:31<129:59:08, 93.87s/it]
100%|██████████| 1/1 [01:22<00:00, 82.78s/it][A100%|██████████| 1/1 [01:22<00:00, 82.78s/it]
  4%|▍         | 213/5198 [6:33:31<129:58:36, 93.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.83s/it][A100%|██████████| 1/1 [01:22<00:00, 82.83s/it]
  4%|▍         | 213/5198 [6:33:31<129:58:35, 93.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.85s/it][A100%|██████████| 1/1 [01:22<00:00, 82.85s/it]
  4%|▍         | 213/5198 [6:33:34<129:58:41, 93.87s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_200
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.11s/it][A100%|██████████| 1/1 [01:54<00:00, 114.11s/it]
  4%|▍         | 214/5198 [6:35:25<138:33:52, 100.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 02:00:31,956] [INFO] [logging.py:96:log_dist] [Rank 0] step=211, skipped=0, lr=[1.9997502585494647e-05], mom=[(0.9, 0.999)]
steps: 211 loss: 0.5802 iter time (s): 114.515 samples/sec: 1.118

100%|██████████| 1/1 [01:55<00:00, 115.43s/it][A100%|██████████| 1/1 [01:55<00:00, 115.44s/it]
  4%|▍         | 214/5198 [6:35:26<138:54:32, 100.34s/it]
100%|██████████| 1/1 [01:55<00:00, 115.35s/it][A100%|██████████| 1/1 [01:55<00:00, 115.35s/it]
  4%|▍         | 214/5198 [6:35:26<138:54:12, 100.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.49s/it][A100%|██████████| 1/1 [01:55<00:00, 115.49s/it]
  4%|▍         | 214/5198 [6:35:27<138:55:33, 100.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.38s/it][A100%|██████████| 1/1 [01:55<00:00, 115.38s/it]
  4%|▍         | 214/5198 [6:35:27<138:54:40, 100.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.40s/it][A100%|██████████| 1/1 [01:55<00:00, 115.40s/it]
  4%|▍         | 214/5198 [6:35:27<138:54:15, 100.33s/it]
100%|██████████| 1/1 [01:55<00:00, 115.30s/it][A
100%|██████████| 1/1 [01:55<00:00, 115.30s/it]
  4%|▍         | 214/5198 [6:35:29<138:53:52, 100.33s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_201
100%|██████████| 1/1 [01:55<00:00, 115.42s/it][A100%|██████████| 1/1 [01:55<00:00, 115.42s/it]
  4%|▍         | 214/5198 [6:35:27<138:54:23, 100.33s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.31s/it][A100%|██████████| 1/1 [01:35<00:00, 95.31s/it]
  4%|▍         | 215/5198 [6:37:01<136:39:59, 98.74s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 02:02:06,939] [INFO] [logging.py:96:log_dist] [Rank 0] step=212, skipped=0, lr=[1.9997374407658633e-05], mom=[(0.9, 0.999)]
steps: 212 loss: 0.6208 iter time (s): 94.109 samples/sec: 1.360

100%|██████████| 1/1 [01:34<00:00, 94.89s/it][A100%|██████████| 1/1 [01:34<00:00, 94.89s/it]
  4%|▍         | 215/5198 [6:37:01<136:39:24, 98.73s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.99s/it][A100%|██████████| 1/1 [01:34<00:00, 94.99s/it]
  4%|▍         | 215/5198 [6:37:01<136:39:49, 98.73s/it] 
100%|██████████| 1/1 [01:34<00:00, 94.90s/it][A100%|██████████| 1/1 [01:34<00:00, 94.90s/it]
  4%|▍         | 215/5198 [6:37:02<136:39:05, 98.72s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.91s/it][A100%|██████████| 1/1 [01:34<00:00, 94.91s/it]
  4%|▍         | 215/5198 [6:37:02<136:38:02, 98.71s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.82s/it][A100%|██████████| 1/1 [01:34<00:00, 94.82s/it]
  4%|▍         | 215/5198 [6:37:02<136:38:01, 98.71s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.88s/it][A100%|██████████| 1/1 [01:34<00:00, 94.88s/it]
  4%|▍         | 215/5198 [6:37:02<136:38:55, 98.72s/it] 
100%|██████████| 1/1 [01:34<00:00, 94.92s/it][A100%|██████████| 1/1 [01:34<00:00, 94.92s/it]
  4%|▍         | 215/5198 [6:37:04<136:38:43, 98.72s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_202

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.75s/it][A100%|██████████| 1/1 [01:31<00:00, 91.75s/it]
  4%|▍         | 216/5198 [6:38:33<133:53:55, 96.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 02:03:39,003] [INFO] [logging.py:96:log_dist] [Rank 0] step=213, skipped=0, lr=[1.9997243022737566e-05], mom=[(0.9, 0.999)]
steps: 213 loss: 0.5885 iter time (s): 91.216 samples/sec: 1.403

100%|██████████| 1/1 [01:32<00:00, 92.02s/it][A100%|██████████| 1/1 [01:32<00:00, 92.02s/it]
  4%|▍         | 216/5198 [6:38:33<133:53:40, 96.75s/it]
100%|██████████| 1/1 [01:32<00:00, 92.22s/it][A100%|██████████| 1/1 [01:32<00:00, 92.22s/it]
  4%|▍         | 216/5198 [6:38:33<133:57:13, 96.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.21s/it][A100%|██████████| 1/1 [01:32<00:00, 92.21s/it]
  4%|▍         | 216/5198 [6:38:34<133:56:04, 96.78s/it]
100%|██████████| 1/1 [01:32<00:00, 92.23s/it][A100%|██████████| 1/1 [01:32<00:00, 92.23s/it]
  4%|▍         | 216/5198 [6:38:34<133:55:03, 96.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.22s/it][A100%|██████████| 1/1 [01:32<00:00, 92.22s/it]
  4%|▍         | 216/5198 [6:38:34<133:54:53, 96.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.14s/it][A100%|██████████| 1/1 [01:32<00:00, 92.14s/it]
  4%|▍         | 216/5198 [6:38:36<133:54:41, 96.76s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_203

100%|██████████| 1/1 [01:32<00:00, 92.16s/it][A100%|██████████| 1/1 [01:32<00:00, 92.16s/it]
  4%|▍         | 216/5198 [6:38:34<133:55:08, 96.77s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.75s/it][A100%|██████████| 1/1 [01:24<00:00, 84.75s/it]
  4%|▍         | 217/5198 [6:39:58<129:00:43, 93.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 02:05:03,864] [INFO] [logging.py:96:log_dist] [Rank 0] step=214, skipped=0, lr=[1.9997108430773605e-05], mom=[(0.9, 0.999)]
steps: 214 loss: 0.5899 iter time (s): 83.780 samples/sec: 1.528

100%|██████████| 1/1 [01:24<00:00, 84.56s/it][A100%|██████████| 1/1 [01:24<00:00, 84.56s/it]
  4%|▍         | 217/5198 [6:39:58<128:51:38, 93.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.66s/it][A100%|██████████| 1/1 [01:24<00:00, 84.66s/it]
  4%|▍         | 217/5198 [6:39:58<128:52:17, 93.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.60s/it][A100%|██████████| 1/1 [01:24<00:00, 84.60s/it]
  4%|▍         | 217/5198 [6:39:59<128:51:07, 93.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.64s/it][A100%|██████████| 1/1 [01:24<00:00, 84.64s/it]
  4%|▍         | 217/5198 [6:39:59<128:53:17, 93.15s/it]
100%|██████████| 1/1 [01:24<00:00, 84.67s/it][A100%|██████████| 1/1 [01:24<00:00, 84.67s/it]
  4%|▍         | 217/5198 [6:39:59<128:52:07, 93.14s/it]
100%|██████████| 1/1 [01:24<00:00, 84.56s/it][A100%|██████████| 1/1 [01:24<00:00, 84.56s/it]
  4%|▍         | 217/5198 [6:39:59<128:52:05, 93.14s/it]
100%|██████████| 1/1 [01:24<00:00, 84.57s/it][A100%|██████████| 1/1 [01:24<00:00, 84.57s/it]
  4%|▍         | 217/5198 [6:40:01<128:52:07, 93.14s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_204
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.71s/it][A100%|██████████| 1/1 [01:30<00:00, 90.71s/it]
  4%|▍         | 218/5198 [6:41:29<128:03:24, 92.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 02:06:34,918] [INFO] [logging.py:96:log_dist] [Rank 0] step=215, skipped=0, lr=[1.9996970631809925e-05], mom=[(0.9, 0.999)]
steps: 215 loss: 0.6694 iter time (s): 90.282 samples/sec: 1.418

100%|██████████| 1/1 [01:31<00:00, 91.02s/it][A100%|██████████| 1/1 [01:31<00:00, 91.02s/it]
  4%|▍         | 218/5198 [6:41:29<127:57:46, 92.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.95s/it][A100%|██████████| 1/1 [01:30<00:00, 90.95s/it]
  4%|▍         | 218/5198 [6:41:29<127:59:10, 92.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.88s/it][A100%|██████████| 1/1 [01:30<00:00, 90.89s/it]
  4%|▍         | 218/5198 [6:41:30<127:58:36, 92.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.13s/it][A100%|██████████| 1/1 [01:31<00:00, 91.13s/it]
  4%|▍         | 218/5198 [6:41:30<127:59:55, 92.53s/it]
100%|██████████| 1/1 [01:30<00:00, 90.97s/it][A100%|██████████| 1/1 [01:30<00:00, 90.97s/it]
  4%|▍         | 218/5198 [6:41:30<127:58:43, 92.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.05s/it][A100%|██████████| 1/1 [01:31<00:00, 91.05s/it]
  4%|▍         | 218/5198 [6:41:30<127:59:00, 92.52s/it]
100%|██████████| 1/1 [01:31<00:00, 91.05s/it][A100%|██████████| 1/1 [01:31<00:00, 91.05s/it]
  4%|▍         | 218/5198 [6:41:32<127:58:58, 92.52s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_205
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.06s/it][A100%|██████████| 1/1 [01:48<00:00, 108.06s/it]
  4%|▍         | 219/5198 [6:43:17<134:35:50, 97.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 02:08:23,229] [INFO] [logging.py:96:log_dist] [Rank 0] step=216, skipped=0, lr=[1.9996829625890738e-05], mom=[(0.9, 0.999)]
steps: 216 loss: 0.6169 iter time (s): 107.574 samples/sec: 1.190

100%|██████████| 1/1 [01:48<00:00, 108.29s/it][A100%|██████████| 1/1 [01:48<00:00, 108.29s/it]
  4%|▍         | 219/5198 [6:43:17<134:29:40, 97.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.37s/it][A100%|██████████| 1/1 [01:48<00:00, 108.37s/it]
  4%|▍         | 219/5198 [6:43:18<134:32:53, 97.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.34s/it][A100%|██████████| 1/1 [01:48<00:00, 108.34s/it]
  4%|▍         | 219/5198 [6:43:18<134:31:46, 97.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.35s/it][A100%|██████████| 1/1 [01:48<00:00, 108.35s/it]
  4%|▍         | 219/5198 [6:43:18<134:32:57, 97.28s/it]
100%|██████████| 1/1 [01:48<00:00, 108.37s/it][A100%|██████████| 1/1 [01:48<00:00, 108.37s/it]
  4%|▍         | 219/5198 [6:43:18<134:32:29, 97.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.37s/it][A100%|██████████| 1/1 [01:48<00:00, 108.37s/it]
  4%|▍         | 219/5198 [6:43:18<134:32:34, 97.28s/it]
100%|██████████| 1/1 [01:48<00:00, 108.39s/it][A100%|██████████| 1/1 [01:48<00:00, 108.39s/it]
  4%|▍         | 219/5198 [6:43:20<134:32:51, 97.28s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_206

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.47s/it][A100%|██████████| 1/1 [01:39<00:00, 99.47s/it]
  4%|▍         | 220/5198 [6:44:57<135:36:50, 98.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 02:10:03,204] [INFO] [logging.py:96:log_dist] [Rank 0] step=217, skipped=0, lr=[1.9996685413061282e-05], mom=[(0.9, 0.999)]
steps: 217 loss: 0.6514 iter time (s): 99.077 samples/sec: 1.292

100%|██████████| 1/1 [01:39<00:00, 99.97s/it][A100%|██████████| 1/1 [01:39<00:00, 99.97s/it]
  4%|▍         | 220/5198 [6:44:57<135:36:23, 98.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.91s/it][A100%|██████████| 1/1 [01:39<00:00, 99.91s/it]
  4%|▍         | 220/5198 [6:44:58<135:37:36, 98.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.95s/it][A100%|██████████| 1/1 [01:39<00:00, 99.95s/it]
  4%|▍         | 220/5198 [6:44:58<135:37:44, 98.08s/it]
100%|██████████| 1/1 [01:39<00:00, 99.89s/it][A100%|██████████| 1/1 [01:39<00:00, 99.89s/it]
  4%|▍         | 220/5198 [6:44:58<135:37:00, 98.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.93s/it][A100%|██████████| 1/1 [01:39<00:00, 99.93s/it]
  4%|▍         | 220/5198 [6:44:58<135:37:43, 98.08s/it]
100%|██████████| 1/1 [01:39<00:00, 99.92s/it][A100%|██████████| 1/1 [01:39<00:00, 99.92s/it]
  4%|▍         | 220/5198 [6:44:58<135:37:37, 98.08s/it]
100%|██████████| 1/1 [01:39<00:00, 99.91s/it][A100%|██████████| 1/1 [01:39<00:00, 99.91s/it]
  4%|▍         | 220/5198 [6:45:00<135:37:36, 98.08s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_207

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.28s/it][A100%|██████████| 1/1 [01:49<00:00, 109.28s/it]
  4%|▍         | 221/5198 [6:46:47<140:26:58, 101.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 02:11:53,388] [INFO] [logging.py:96:log_dist] [Rank 0] step=218, skipped=0, lr=[1.9996537993367825e-05], mom=[(0.9, 0.999)]
steps: 218 loss: 0.6149 iter time (s): 109.254 samples/sec: 1.172

100%|██████████| 1/1 [01:50<00:00, 110.09s/it][A100%|██████████| 1/1 [01:50<00:00, 110.09s/it]
  4%|▍         | 221/5198 [6:46:47<140:34:04, 101.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.06s/it][A100%|██████████| 1/1 [01:50<00:00, 110.06s/it]
  4%|▍         | 221/5198 [6:46:48<140:34:16, 101.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.00s/it][A100%|██████████| 1/1 [01:50<00:00, 110.00s/it]
  4%|▍         | 221/5198 [6:46:48<140:33:37, 101.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.05s/it][A100%|██████████| 1/1 [01:50<00:00, 110.06s/it]
  4%|▍         | 221/5198 [6:46:48<140:33:57, 101.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 110.00s/it][A100%|██████████| 1/1 [01:49<00:00, 110.00s/it]
  4%|▍         | 221/5198 [6:46:48<140:34:53, 101.69s/it]
100%|██████████| 1/1 [01:50<00:00, 110.00s/it][A100%|██████████| 1/1 [01:50<00:00, 110.00s/it]
  4%|▍         | 221/5198 [6:46:48<140:34:21, 101.68s/it]
100%|██████████| 1/1 [01:50<00:00, 110.02s/it][A100%|██████████| 1/1 [01:50<00:00, 110.02s/it]
  4%|▍         | 221/5198 [6:46:50<140:34:31, 101.68s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_208
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.70s/it][A100%|██████████| 1/1 [01:32<00:00, 92.70s/it]
  4%|▍         | 222/5198 [6:48:20<136:53:19, 99.04s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 02:13:26,105] [INFO] [logging.py:96:log_dist] [Rank 0] step=219, skipped=0, lr=[1.9996387366857655e-05], mom=[(0.9, 0.999)]
steps: 219 loss: 0.6244 iter time (s): 91.918 samples/sec: 1.393

100%|██████████| 1/1 [01:32<00:00, 92.70s/it][A100%|██████████| 1/1 [01:32<00:00, 92.70s/it]
  4%|▍         | 222/5198 [6:48:20<136:51:16, 99.01s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.69s/it][A100%|██████████| 1/1 [01:32<00:00, 92.69s/it]
  4%|▍         | 222/5198 [6:48:20<136:51:15, 99.01s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.76s/it][A100%|██████████| 1/1 [01:32<00:00, 92.76s/it]
  4%|▍         | 222/5198 [6:48:21<136:50:46, 99.00s/it] 
100%|██████████| 1/1 [01:32<00:00, 92.80s/it][A100%|██████████| 1/1 [01:32<00:00, 92.80s/it]
  4%|▍         | 222/5198 [6:48:21<136:52:11, 99.02s/it] 
100%|██████████| 1/1 [01:32<00:00, 92.66s/it][A100%|██████████| 1/1 [01:32<00:00, 92.66s/it]
  4%|▍         | 222/5198 [6:48:21<136:50:57, 99.01s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.71s/it][A100%|██████████| 1/1 [01:32<00:00, 92.71s/it]
  4%|▍         | 222/5198 [6:48:21<136:50:41, 99.00s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.73s/it][A100%|██████████| 1/1 [01:32<00:00, 92.73s/it]
  4%|▍         | 222/5198 [6:48:23<136:50:51, 99.01s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_209
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.05s/it][A100%|██████████| 1/1 [01:46<00:00, 106.05s/it]
  4%|▍         | 223/5198 [6:50:06<139:56:43, 101.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 02:15:12,685] [INFO] [logging.py:96:log_dist] [Rank 0] step=220, skipped=0, lr=[1.999623353357911e-05], mom=[(0.9, 0.999)]
steps: 220 loss: 0.6619 iter time (s): 105.803 samples/sec: 1.210

100%|██████████| 1/1 [01:46<00:00, 106.60s/it][A100%|██████████| 1/1 [01:46<00:00, 106.60s/it]
  4%|▍         | 223/5198 [6:50:07<139:59:04, 101.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.57s/it][A100%|██████████| 1/1 [01:46<00:00, 106.57s/it]
  4%|▍         | 223/5198 [6:50:07<139:59:06, 101.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.46s/it][A100%|██████████| 1/1 [01:46<00:00, 106.46s/it]
  4%|▍         | 223/5198 [6:50:07<139:57:41, 101.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.56s/it][A100%|██████████| 1/1 [01:46<00:00, 106.56s/it]
  4%|▍         | 223/5198 [6:50:07<139:58:52, 101.29s/it]
100%|██████████| 1/1 [01:46<00:00, 106.61s/it][A100%|██████████| 1/1 [01:46<00:00, 106.61s/it]
  4%|▍         | 223/5198 [6:50:08<139:59:47, 101.30s/it]
100%|██████████| 1/1 [01:46<00:00, 106.62s/it][A100%|██████████| 1/1 [01:46<00:00, 106.63s/it]
  4%|▍         | 223/5198 [6:50:08<139:58:48, 101.29s/it]
100%|██████████| 1/1 [01:46<00:00, 106.62s/it][A100%|██████████| 1/1 [01:46<00:00, 106.62s/it]
  4%|▍         | 223/5198 [6:50:10<139:58:40, 101.29s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_13
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:08<00:00, 128.96s/it][A100%|██████████| 1/1 [02:08<00:00, 128.96s/it]
  4%|▍         | 224/5198 [6:52:16<151:28:42, 109.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 02:17:22,584] [INFO] [logging.py:96:log_dist] [Rank 0] step=221, skipped=0, lr=[1.9996076493581532e-05], mom=[(0.9, 0.999)]
steps: 221 loss: 0.7997 iter time (s): 129.324 samples/sec: 0.990

100%|██████████| 1/1 [02:10<00:00, 130.19s/it][A100%|██████████| 1/1 [02:10<00:00, 130.19s/it]
  4%|▍         | 224/5198 [6:52:17<151:57:10, 109.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:10<00:00, 130.23s/it][A100%|██████████| 1/1 [02:10<00:00, 130.23s/it]
  4%|▍         | 224/5198 [6:52:17<151:59:20, 110.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:10<00:00, 130.23s/it][A100%|██████████| 1/1 [02:10<00:00, 130.23s/it]
  4%|▍         | 224/5198 [6:52:18<151:56:55, 109.98s/it]
100%|██████████| 1/1 [02:10<00:00, 130.14s/it][A100%|██████████| 1/1 [02:10<00:00, 130.14s/it]
  4%|▍         | 224/5198 [6:52:18<151:58:24, 109.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:10<00:00, 130.22s/it][A100%|██████████| 1/1 [02:10<00:00, 130.22s/it]
  4%|▍         | 224/5198 [6:52:18<151:58:43, 110.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:10<00:00, 130.25s/it][A100%|██████████| 1/1 [02:10<00:00, 130.25s/it]
  4%|▍         | 224/5198 [6:52:20<151:57:52, 109.99s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_210

100%|██████████| 1/1 [02:10<00:00, 130.27s/it][A100%|██████████| 1/1 [02:10<00:00, 130.27s/it]
  4%|▍         | 224/5198 [6:52:18<151:58:44, 110.00s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.45s/it][A100%|██████████| 1/1 [01:39<00:00, 99.45s/it]
  4%|▍         | 225/5198 [6:53:55<147:22:39, 106.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 02:19:01,774] [INFO] [logging.py:96:log_dist] [Rank 0] step=222, skipped=0, lr=[1.999591624691531e-05], mom=[(0.9, 0.999)]
steps: 222 loss: 0.5816 iter time (s): 97.836 samples/sec: 1.308

100%|██████████| 1/1 [01:38<00:00, 98.75s/it][A100%|██████████| 1/1 [01:38<00:00, 98.75s/it]
  4%|▍         | 225/5198 [6:53:56<147:16:20, 106.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.72s/it][A100%|██████████| 1/1 [01:38<00:00, 98.72s/it]
  4%|▍         | 225/5198 [6:53:56<147:17:18, 106.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.74s/it][A100%|██████████| 1/1 [01:38<00:00, 98.74s/it]
  4%|▍         | 225/5198 [6:53:57<147:19:32, 106.65s/it]
100%|██████████| 1/1 [01:38<00:00, 98.81s/it][A100%|██████████| 1/1 [01:38<00:00, 98.81s/it]
  4%|▍         | 225/5198 [6:53:57<147:19:42, 106.65s/it]
100%|██████████| 1/1 [01:38<00:00, 98.78s/it][A100%|██████████| 1/1 [01:38<00:00, 98.78s/it]
  4%|▍         | 225/5198 [6:53:57<147:18:14, 106.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.65s/it][A100%|██████████| 1/1 [01:38<00:00, 98.65s/it]
  4%|▍         | 225/5198 [6:53:57<147:17:58, 106.63s/it]
100%|██████████| 1/1 [01:38<00:00, 98.66s/it][A100%|██████████| 1/1 [01:38<00:00, 98.66s/it]
  4%|▍         | 225/5198 [6:53:59<147:18:06, 106.63s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_211

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.16s/it][A100%|██████████| 1/1 [01:51<00:00, 111.16s/it]
  4%|▍         | 226/5198 [6:55:47<149:19:26, 108.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 02:20:53,620] [INFO] [logging.py:96:log_dist] [Rank 0] step=223, skipped=0, lr=[1.9995752793631858e-05], mom=[(0.9, 0.999)]
steps: 223 loss: 0.6170 iter time (s): 110.991 samples/sec: 1.153

100%|██████████| 1/1 [01:51<00:00, 111.76s/it][A100%|██████████| 1/1 [01:51<00:00, 111.76s/it]
  4%|▍         | 226/5198 [6:55:48<149:25:13, 108.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.63s/it][A100%|██████████| 1/1 [01:51<00:00, 111.63s/it]
  4%|▍         | 226/5198 [6:55:48<149:22:54, 108.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.67s/it][A100%|██████████| 1/1 [01:51<00:00, 111.67s/it]
  4%|▍         | 226/5198 [6:55:48<149:25:11, 108.19s/it]
100%|██████████| 1/1 [01:51<00:00, 111.68s/it][A100%|██████████| 1/1 [01:51<00:00, 111.68s/it]
  4%|▍         | 226/5198 [6:55:48<149:24:09, 108.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.78s/it][A100%|██████████| 1/1 [01:51<00:00, 111.78s/it]
  4%|▍         | 226/5198 [6:55:48<149:24:59, 108.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.81s/it][A100%|██████████| 1/1 [01:51<00:00, 111.81s/it]
  4%|▍         | 226/5198 [6:55:51<149:25:11, 108.19s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_212

100%|██████████| 1/1 [01:51<00:00, 111.81s/it][A100%|██████████| 1/1 [01:51<00:00, 111.81s/it]
  4%|▍         | 226/5198 [6:55:49<149:25:17, 108.19s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.67s/it][A100%|██████████| 1/1 [01:28<00:00, 88.67s/it]
  4%|▍         | 227/5198 [6:57:16<141:21:18, 102.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 02:22:21,866] [INFO] [logging.py:96:log_dist] [Rank 0] step=224, skipped=0, lr=[1.9995586133783606e-05], mom=[(0.9, 0.999)]
steps: 224 loss: 0.6486 iter time (s): 87.398 samples/sec: 1.465

100%|██████████| 1/1 [01:28<00:00, 88.22s/it][A100%|██████████| 1/1 [01:28<00:00, 88.22s/it]
  4%|▍         | 227/5198 [6:57:16<141:08:04, 102.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.24s/it][A100%|██████████| 1/1 [01:28<00:00, 88.24s/it]
  4%|▍         | 227/5198 [6:57:16<141:06:24, 102.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.11s/it][A100%|██████████| 1/1 [01:28<00:00, 88.11s/it]
  4%|▍         | 227/5198 [6:57:16<141:06:34, 102.19s/it]
100%|██████████| 1/1 [01:28<00:00, 88.16s/it][A100%|██████████| 1/1 [01:28<00:00, 88.16s/it]
  4%|▍         | 227/5198 [6:57:17<141:07:03, 102.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.21s/it][A100%|██████████| 1/1 [01:28<00:00, 88.21s/it]
  4%|▍         | 227/5198 [6:57:17<141:07:20, 102.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.22s/it][A100%|██████████| 1/1 [01:28<00:00, 88.22s/it]
  4%|▍         | 227/5198 [6:57:17<141:07:18, 102.20s/it]
100%|██████████| 1/1 [01:28<00:00, 88.24s/it][A100%|██████████| 1/1 [01:28<00:00, 88.24s/it]
  4%|▍         | 227/5198 [6:57:19<141:07:42, 102.21s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_213
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.33s/it][A100%|██████████| 1/1 [02:00<00:00, 120.33s/it]
  4%|▍         | 228/5198 [6:59:17<148:57:46, 107.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 02:24:23,655] [INFO] [logging.py:96:log_dist] [Rank 0] step=225, skipped=0, lr=[1.999541626742403e-05], mom=[(0.9, 0.999)]
steps: 225 loss: 0.5853 iter time (s): 120.885 samples/sec: 1.059

100%|██████████| 1/1 [02:01<00:00, 121.78s/it][A100%|██████████| 1/1 [02:01<00:00, 121.78s/it]
  4%|▍         | 228/5198 [6:59:18<149:13:09, 108.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:01<00:00, 121.81s/it][A100%|██████████| 1/1 [02:01<00:00, 121.81s/it]
  4%|▍         | 228/5198 [6:59:18<149:14:14, 108.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:01<00:00, 121.71s/it][A100%|██████████| 1/1 [02:01<00:00, 121.71s/it]
  4%|▍         | 228/5198 [6:59:18<149:12:54, 108.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:01<00:00, 121.77s/it][A100%|██████████| 1/1 [02:01<00:00, 121.77s/it]
  4%|▍         | 228/5198 [6:59:18<149:12:41, 108.08s/it]
100%|██████████| 1/1 [02:01<00:00, 121.79s/it][A100%|██████████| 1/1 [02:01<00:00, 121.79s/it]
  4%|▍         | 228/5198 [6:59:19<149:12:32, 108.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:01<00:00, 121.70s/it][A100%|██████████| 1/1 [02:01<00:00, 121.70s/it]
  4%|▍         | 228/5198 [6:59:19<149:12:56, 108.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:01<00:00, 121.73s/it][A100%|██████████| 1/1 [02:01<00:00, 121.73s/it]
  4%|▍         | 228/5198 [6:59:21<149:13:13, 108.09s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_214
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.33s/it][A100%|██████████| 1/1 [01:30<00:00, 90.33s/it]
  4%|▍         | 229/5198 [7:00:47<141:48:48, 102.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 02:25:53,478] [INFO] [logging.py:96:log_dist] [Rank 0] step=226, skipped=0, lr=[1.9995243194607624e-05], mom=[(0.9, 0.999)]
steps: 226 loss: 0.5621 iter time (s): 89.039 samples/sec: 1.438

100%|██████████| 1/1 [01:29<00:00, 89.87s/it][A100%|██████████| 1/1 [01:29<00:00, 89.87s/it]
  4%|▍         | 229/5198 [7:00:48<141:39:47, 102.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.82s/it][A100%|██████████| 1/1 [01:29<00:00, 89.82s/it]
  4%|▍         | 229/5198 [7:00:48<141:39:48, 102.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.86s/it][A100%|██████████| 1/1 [01:29<00:00, 89.86s/it]
  4%|▍         | 229/5198 [7:00:48<141:38:38, 102.62s/it]
100%|██████████| 1/1 [01:29<00:00, 89.77s/it][A100%|██████████| 1/1 [01:29<00:00, 89.77s/it]
  4%|▍         | 229/5198 [7:00:48<141:38:03, 102.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.80s/it][A100%|██████████| 1/1 [01:29<00:00, 89.80s/it]
  4%|▍         | 229/5198 [7:00:48<141:37:55, 102.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.82s/it][A100%|██████████| 1/1 [01:29<00:00, 89.82s/it]
  4%|▍         | 229/5198 [7:00:48<141:37:38, 102.61s/it]
100%|██████████| 1/1 [01:29<00:00, 89.83s/it][A100%|██████████| 1/1 [01:29<00:00, 89.83s/it]
  4%|▍         | 229/5198 [7:00:51<141:37:51, 102.61s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_215
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.20s/it][A100%|██████████| 1/1 [01:35<00:00, 95.20s/it]
  4%|▍         | 230/5198 [7:02:23<138:45:24, 100.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 02:27:28,988] [INFO] [logging.py:96:log_dist] [Rank 0] step=227, skipped=0, lr=[1.999506691538991e-05], mom=[(0.9, 0.999)]
steps: 227 loss: 0.5816 iter time (s): 94.628 samples/sec: 1.353

100%|██████████| 1/1 [01:35<00:00, 95.37s/it][A100%|██████████| 1/1 [01:35<00:00, 95.37s/it]
  4%|▍         | 230/5198 [7:02:23<138:39:47, 100.48s/it]
100%|██████████| 1/1 [01:35<00:00, 95.32s/it][A100%|██████████| 1/1 [01:35<00:00, 95.32s/it]
  4%|▍         | 230/5198 [7:02:23<138:36:36, 100.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.35s/it][A100%|██████████| 1/1 [01:35<00:00, 95.35s/it]
  4%|▍         | 230/5198 [7:02:24<138:37:24, 100.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.45s/it][A100%|██████████| 1/1 [01:35<00:00, 95.45s/it]
  4%|▍         | 230/5198 [7:02:24<138:39:00, 100.47s/it]
100%|██████████| 1/1 [01:35<00:00, 95.42s/it][A100%|██████████| 1/1 [01:35<00:00, 95.42s/it]
  4%|▍         | 230/5198 [7:02:24<138:37:45, 100.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.42s/it][A100%|██████████| 1/1 [01:35<00:00, 95.42s/it]
  4%|▍         | 230/5198 [7:02:26<138:38:24, 100.46s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_216

100%|██████████| 1/1 [01:35<00:00, 95.41s/it][A100%|██████████| 1/1 [01:35<00:00, 95.41s/it]
  4%|▍         | 230/5198 [7:02:24<138:38:46, 100.47s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.90s/it][A100%|██████████| 1/1 [01:50<00:00, 110.90s/it]
  4%|▍         | 231/5198 [7:04:14<143:10:58, 103.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 02:29:20,341] [INFO] [logging.py:96:log_dist] [Rank 0] step=228, skipped=0, lr=[1.9994887429827457e-05], mom=[(0.9, 0.999)]
steps: 228 loss: 0.5837 iter time (s): 110.539 samples/sec: 1.158

100%|██████████| 1/1 [01:51<00:00, 111.32s/it][A100%|██████████| 1/1 [01:51<00:00, 111.32s/it]
  4%|▍         | 231/5198 [7:04:15<143:07:36, 103.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.38s/it][A100%|██████████| 1/1 [01:51<00:00, 111.38s/it]
  4%|▍         | 231/5198 [7:04:15<143:07:00, 103.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.31s/it][A100%|██████████| 1/1 [01:51<00:00, 111.31s/it]
  4%|▍         | 231/5198 [7:04:15<143:06:26, 103.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.28s/it][A100%|██████████| 1/1 [01:51<00:00, 111.28s/it]
  4%|▍         | 231/5198 [7:04:15<143:07:11, 103.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.34s/it][A100%|██████████| 1/1 [01:51<00:00, 111.34s/it]
  4%|▍         | 231/5198 [7:04:15<143:07:36, 103.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.33s/it][A100%|██████████| 1/1 [01:51<00:00, 111.33s/it]
  4%|▍         | 231/5198 [7:04:15<143:07:20, 103.73s/it]
100%|██████████| 1/1 [01:51<00:00, 111.34s/it][A100%|██████████| 1/1 [01:51<00:00, 111.34s/it]
  4%|▍         | 231/5198 [7:04:17<143:07:15, 103.73s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_217

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.78s/it][A100%|██████████| 1/1 [01:59<00:00, 119.78s/it]
  4%|▍         | 232/5198 [7:06:14<149:58:25, 108.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 02:31:20,919] [INFO] [logging.py:96:log_dist] [Rank 0] step=229, skipped=0, lr=[1.9994704737977833e-05], mom=[(0.9, 0.999)]
steps: 229 loss: 0.6255 iter time (s): 119.778 samples/sec: 1.069

100%|██████████| 1/1 [02:00<00:00, 120.57s/it][A100%|██████████| 1/1 [02:00<00:00, 120.57s/it]
  4%|▍         | 232/5198 [7:06:15<150:04:16, 108.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.51s/it][A100%|██████████| 1/1 [02:00<00:00, 120.51s/it]
  4%|▍         | 232/5198 [7:06:15<150:04:08, 108.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.60s/it][A100%|██████████| 1/1 [02:00<00:00, 120.60s/it]
  4%|▍         | 232/5198 [7:06:16<150:04:19, 108.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.57s/it][A100%|██████████| 1/1 [02:00<00:00, 120.57s/it]
  4%|▍         | 232/5198 [7:06:16<150:04:55, 108.80s/it]
100%|██████████| 1/1 [02:00<00:00, 120.58s/it][A100%|██████████| 1/1 [02:00<00:00, 120.58s/it]
  4%|▍         | 232/5198 [7:06:16<150:05:11, 108.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.62s/it][A100%|██████████| 1/1 [02:00<00:00, 120.62s/it]
  4%|▍         | 232/5198 [7:06:16<150:05:05, 108.80s/it]
100%|██████████| 1/1 [02:00<00:00, 120.62s/it][A100%|██████████| 1/1 [02:00<00:00, 120.62s/it]
  4%|▍         | 232/5198 [7:06:18<150:05:01, 108.80s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_218
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:18<00:00, 138.99s/it][A100%|██████████| 1/1 [02:18<00:00, 138.99s/it]
  4%|▍         | 233/5198 [7:08:34<162:36:36, 117.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 02:33:41,127] [INFO] [logging.py:96:log_dist] [Rank 0] step=230, skipped=0, lr=[1.9994518839899658e-05], mom=[(0.9, 0.999)]
steps: 230 loss: 0.6201 iter time (s): 139.301 samples/sec: 0.919

100%|██████████| 1/1 [02:20<00:00, 140.18s/it][A100%|██████████| 1/1 [02:20<00:00, 140.18s/it]
  4%|▍         | 233/5198 [7:08:35<163:02:43, 118.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:20<00:00, 140.31s/it][A100%|██████████| 1/1 [02:20<00:00, 140.31s/it]
  4%|▍         | 233/5198 [7:08:36<163:06:22, 118.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:20<00:00, 140.33s/it][A100%|██████████| 1/1 [02:20<00:00, 140.33s/it]
  4%|▍         | 233/5198 [7:08:36<163:05:34, 118.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:20<00:00, 140.19s/it][A100%|██████████| 1/1 [02:20<00:00, 140.19s/it]
  4%|▍         | 233/5198 [7:08:36<163:03:59, 118.24s/it]
100%|██████████| 1/1 [02:20<00:00, 140.22s/it][A100%|██████████| 1/1 [02:20<00:00, 140.22s/it]
  4%|▍         | 233/5198 [7:08:36<163:03:39, 118.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:20<00:00, 140.10s/it][A100%|██████████| 1/1 [02:20<00:00, 140.10s/it]
  4%|▍         | 233/5198 [7:08:36<163:03:56, 118.23s/it]
100%|██████████| 1/1 [02:20<00:00, 140.13s/it][A100%|██████████| 1/1 [02:20<00:00, 140.13s/it]
  4%|▍         | 233/5198 [7:08:38<163:04:30, 118.24s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_219
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.75s/it][A100%|██████████| 1/1 [01:44<00:00, 104.75s/it]
  5%|▍         | 234/5198 [7:10:19<157:19:33, 114.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 02:35:25,325] [INFO] [logging.py:96:log_dist] [Rank 0] step=231, skipped=0, lr=[1.9994329735652572e-05], mom=[(0.9, 0.999)]
steps: 231 loss: 0.5728 iter time (s): 103.289 samples/sec: 1.239

100%|██████████| 1/1 [01:44<00:00, 104.09s/it][A100%|██████████| 1/1 [01:44<00:00, 104.10s/it]
  5%|▍         | 234/5198 [7:10:20<157:12:50, 114.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.99s/it][A100%|██████████| 1/1 [01:43<00:00, 103.99s/it]
  5%|▍         | 234/5198 [7:10:20<157:11:50, 114.00s/it]
100%|██████████| 1/1 [01:44<00:00, 104.05s/it][A100%|██████████| 1/1 [01:44<00:00, 104.05s/it]
  5%|▍         | 234/5198 [7:10:20<157:11:16, 114.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.08s/it][A100%|██████████| 1/1 [01:44<00:00, 104.08s/it]
  5%|▍         | 234/5198 [7:10:20<157:12:05, 114.01s/it]
100%|██████████| 1/1 [01:44<00:00, 104.12s/it][A100%|██████████| 1/1 [01:44<00:00, 104.12s/it]
  5%|▍         | 234/5198 [7:10:20<157:12:59, 114.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.10s/it][A100%|██████████| 1/1 [01:44<00:00, 104.10s/it]
  5%|▍         | 234/5198 [7:10:20<157:12:15, 114.01s/it]
100%|██████████| 1/1 [01:44<00:00, 104.11s/it][A100%|██████████| 1/1 [01:44<00:00, 104.11s/it]
  5%|▍         | 234/5198 [7:10:22<157:12:13, 114.01s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_220

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.33s/it][A100%|██████████| 1/1 [01:42<00:00, 102.33s/it]
  5%|▍         | 235/5198 [7:12:02<152:36:04, 110.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 02:37:08,110] [INFO] [logging.py:96:log_dist] [Rank 0] step=232, skipped=0, lr=[1.9994137425297242e-05], mom=[(0.9, 0.999)]
steps: 232 loss: 0.6226 iter time (s): 101.973 samples/sec: 1.255

100%|██████████| 1/1 [01:42<00:00, 102.72s/it][A100%|██████████| 1/1 [01:42<00:00, 102.72s/it]
  5%|▍         | 235/5198 [7:12:02<152:31:47, 110.64s/it]
100%|██████████| 1/1 [01:42<00:00, 102.61s/it][A100%|██████████| 1/1 [01:42<00:00, 102.61s/it]
  5%|▍         | 235/5198 [7:12:02<152:30:46, 110.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.77s/it][A100%|██████████| 1/1 [01:42<00:00, 102.77s/it]
  5%|▍         | 235/5198 [7:12:03<152:31:42, 110.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.69s/it][A100%|██████████| 1/1 [01:42<00:00, 102.69s/it]
  5%|▍         | 235/5198 [7:12:03<152:31:56, 110.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.68s/it][A100%|██████████| 1/1 [01:42<00:00, 102.68s/it]
  5%|▍         | 235/5198 [7:12:03<152:30:59, 110.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.75s/it][A100%|██████████| 1/1 [01:42<00:00, 102.75s/it]
  5%|▍         | 235/5198 [7:12:03<152:31:34, 110.64s/it]
100%|██████████| 1/1 [01:42<00:00, 102.75s/it][A100%|██████████| 1/1 [01:42<00:00, 102.75s/it]
  5%|▍         | 235/5198 [7:12:05<152:31:17, 110.63s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_221
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.40s/it][A100%|██████████| 1/1 [01:31<00:00, 91.40s/it]
  5%|▍         | 236/5198 [7:13:33<144:47:23, 105.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 02:38:39,621] [INFO] [logging.py:96:log_dist] [Rank 0] step=233, skipped=0, lr=[1.9993941908895366e-05], mom=[(0.9, 0.999)]
steps: 233 loss: 0.5978 iter time (s): 90.630 samples/sec: 1.412

100%|██████████| 1/1 [01:31<00:00, 91.31s/it][A100%|██████████| 1/1 [01:31<00:00, 91.31s/it]
  5%|▍         | 236/5198 [7:13:34<144:33:24, 104.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.50s/it][A100%|██████████| 1/1 [01:31<00:00, 91.50s/it]
  5%|▍         | 236/5198 [7:13:34<144:35:10, 104.90s/it]
100%|██████████| 1/1 [01:31<00:00, 91.38s/it][A100%|██████████| 1/1 [01:31<00:00, 91.38s/it]
  5%|▍         | 236/5198 [7:13:34<144:33:25, 104.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.51s/it][A100%|██████████| 1/1 [01:31<00:00, 91.51s/it]
  5%|▍         | 236/5198 [7:13:34<144:35:43, 104.91s/it]
100%|██████████| 1/1 [01:31<00:00, 91.51s/it][A100%|██████████| 1/1 [01:31<00:00, 91.51s/it]
  5%|▍         | 236/5198 [7:13:34<144:34:57, 104.90s/it]
100%|██████████| 1/1 [01:31<00:00, 91.40s/it][A100%|██████████| 1/1 [01:31<00:00, 91.40s/it]
  5%|▍         | 236/5198 [7:13:34<144:34:08, 104.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.42s/it][A100%|██████████| 1/1 [01:31<00:00, 91.42s/it]
  5%|▍         | 236/5198 [7:13:37<144:34:21, 104.89s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_222
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.50s/it][A100%|██████████| 1/1 [01:39<00:00, 99.50s/it]
  5%|▍         | 237/5198 [7:15:13<142:36:46, 103.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 02:40:19,761] [INFO] [logging.py:96:log_dist] [Rank 0] step=234, skipped=0, lr=[1.9993743186509674e-05], mom=[(0.9, 0.999)]
steps: 234 loss: 0.6186 iter time (s): 99.361 samples/sec: 1.288

100%|██████████| 1/1 [01:40<00:00, 100.20s/it][A100%|██████████| 1/1 [01:40<00:00, 100.20s/it]
  5%|▍         | 237/5198 [7:15:14<142:36:37, 103.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.06s/it][A100%|██████████| 1/1 [01:40<00:00, 100.06s/it]
  5%|▍         | 237/5198 [7:15:14<142:35:08, 103.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.22s/it][A100%|██████████| 1/1 [01:40<00:00, 100.22s/it]
  5%|▍         | 237/5198 [7:15:14<142:36:57, 103.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.05s/it][A100%|██████████| 1/1 [01:40<00:00, 100.05s/it]
  5%|▍         | 237/5198 [7:15:14<142:34:50, 103.47s/it]
100%|██████████| 1/1 [01:40<00:00, 100.10s/it][A100%|██████████| 1/1 [01:40<00:00, 100.10s/it]
  5%|▍         | 237/5198 [7:15:15<142:34:57, 103.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.18s/it][A100%|██████████| 1/1 [01:40<00:00, 100.18s/it]
  5%|▍         | 237/5198 [7:15:15<142:35:58, 103.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.18s/it][A100%|██████████| 1/1 [01:40<00:00, 100.18s/it]
  5%|▍         | 237/5198 [7:15:17<142:35:56, 103.48s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_223
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.41s/it][A100%|██████████| 1/1 [01:55<00:00, 115.41s/it]
  5%|▍         | 238/5198 [7:17:09<147:38:30, 107.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 02:42:15,947] [INFO] [logging.py:96:log_dist] [Rank 0] step=235, skipped=0, lr=[1.999354125820392e-05], mom=[(0.9, 0.999)]
steps: 235 loss: 0.6010 iter time (s): 115.342 samples/sec: 1.110

100%|██████████| 1/1 [01:56<00:00, 116.12s/it][A100%|██████████| 1/1 [01:56<00:00, 116.12s/it]
  5%|▍         | 238/5198 [7:17:10<147:49:01, 107.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.10s/it][A100%|██████████| 1/1 [01:56<00:00, 116.10s/it]
  5%|▍         | 238/5198 [7:17:10<147:49:54, 107.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.17s/it][A100%|██████████| 1/1 [01:56<00:00, 116.17s/it]
  5%|▍         | 238/5198 [7:17:11<147:49:58, 107.30s/it]
100%|██████████| 1/1 [01:56<00:00, 116.04s/it][A100%|██████████| 1/1 [01:56<00:00, 116.04s/it]
  5%|▍         | 238/5198 [7:17:11<147:48:06, 107.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.20s/it][A100%|██████████| 1/1 [01:56<00:00, 116.20s/it]
  5%|▍         | 238/5198 [7:17:11<147:51:01, 107.31s/it]
100%|██████████| 1/1 [01:56<00:00, 116.19s/it][A100%|██████████| 1/1 [01:56<00:00, 116.19s/it]
  5%|▍         | 238/5198 [7:17:13<147:49:36, 107.29s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_224

100%|██████████| 1/1 [01:56<00:00, 116.21s/it][A100%|██████████| 1/1 [01:56<00:00, 116.21s/it]
  5%|▍         | 238/5198 [7:17:11<147:50:10, 107.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.78s/it][A100%|██████████| 1/1 [01:41<00:00, 101.78s/it]
  5%|▍         | 239/5198 [7:18:51<145:31:46, 105.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 02:43:57,561] [INFO] [logging.py:96:log_dist] [Rank 0] step=236, skipped=0, lr=[1.9993336124042885e-05], mom=[(0.9, 0.999)]
steps: 236 loss: 0.5893 iter time (s): 100.700 samples/sec: 1.271

100%|██████████| 1/1 [01:41<00:00, 101.61s/it][A100%|██████████| 1/1 [01:41<00:00, 101.62s/it]
  5%|▍         | 239/5198 [7:18:52<145:26:55, 105.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.56s/it][A100%|██████████| 1/1 [01:41<00:00, 101.56s/it]
  5%|▍         | 239/5198 [7:18:52<145:27:03, 105.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.62s/it][A100%|██████████| 1/1 [01:41<00:00, 101.62s/it]
  5%|▍         | 239/5198 [7:18:52<145:29:53, 105.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.46s/it][A100%|██████████| 1/1 [01:41<00:00, 101.46s/it]
  5%|▍         | 239/5198 [7:18:52<145:27:45, 105.60s/it]
100%|██████████| 1/1 [01:41<00:00, 101.68s/it][A100%|██████████| 1/1 [01:41<00:00, 101.68s/it]
  5%|▍         | 239/5198 [7:18:52<145:29:53, 105.62s/it]
100%|██████████| 1/1 [01:41<00:00, 101.54s/it][A100%|██████████| 1/1 [01:41<00:00, 101.54s/it]
  5%|▍         | 239/5198 [7:18:53<145:28:00, 105.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.56s/it][A100%|██████████| 1/1 [01:41<00:00, 101.56s/it]
  5%|▍         | 239/5198 [7:18:55<145:28:40, 105.61s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_14

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:05<00:00, 125.06s/it][A100%|██████████| 1/1 [02:05<00:00, 125.06s/it]
  5%|▍         | 240/5198 [7:20:56<153:35:32, 111.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 02:46:03,334] [INFO] [logging.py:96:log_dist] [Rank 0] step=237, skipped=0, lr=[1.9993127784092383e-05], mom=[(0.9, 0.999)]
steps: 237 loss: 0.8140 iter time (s): 125.118 samples/sec: 1.023

100%|██████████| 1/1 [02:06<00:00, 126.04s/it][A100%|██████████| 1/1 [02:06<00:00, 126.04s/it]
  5%|▍         | 240/5198 [7:20:58<153:54:24, 111.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:06<00:00, 126.10s/it][A100%|██████████| 1/1 [02:06<00:00, 126.10s/it]
  5%|▍         | 240/5198 [7:20:58<153:54:15, 111.75s/it]
100%|██████████| 1/1 [02:05<00:00, 125.88s/it][A100%|██████████| 1/1 [02:05<00:00, 125.88s/it]
  5%|▍         | 240/5198 [7:20:58<153:50:45, 111.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:05<00:00, 125.85s/it][A100%|██████████| 1/1 [02:05<00:00, 125.86s/it]
  5%|▍         | 240/5198 [7:20:58<153:49:49, 111.70s/it]
100%|██████████| 1/1 [02:05<00:00, 125.84s/it][A100%|██████████| 1/1 [02:05<00:00, 125.84s/it]
  5%|▍         | 240/5198 [7:20:58<153:51:10, 111.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:05<00:00, 125.87s/it][A100%|██████████| 1/1 [02:05<00:00, 125.87s/it]
  5%|▍         | 240/5198 [7:20:58<153:49:57, 111.70s/it]
100%|██████████| 1/1 [02:05<00:00, 125.88s/it][A100%|██████████| 1/1 [02:05<00:00, 125.88s/it]
  5%|▍         | 240/5198 [7:21:01<153:50:07, 111.70s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_225
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.37s/it][A100%|██████████| 1/1 [01:29<00:00, 89.37s/it]
  5%|▍         | 241/5198 [7:22:26<144:34:15, 104.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 02:47:32,284] [INFO] [logging.py:96:log_dist] [Rank 0] step=238, skipped=0, lr=[1.9992916238419253e-05], mom=[(0.9, 0.999)]
steps: 238 loss: 0.6076 iter time (s): 87.793 samples/sec: 1.458

100%|██████████| 1/1 [01:28<00:00, 88.47s/it][A100%|██████████| 1/1 [01:28<00:00, 88.47s/it]
  5%|▍         | 241/5198 [7:22:26<144:16:42, 104.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.49s/it][A100%|██████████| 1/1 [01:28<00:00, 88.49s/it]
  5%|▍         | 241/5198 [7:22:27<144:17:13, 104.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.55s/it][A100%|██████████| 1/1 [01:28<00:00, 88.55s/it]
  5%|▍         | 241/5198 [7:22:27<144:16:51, 104.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.66s/it][A100%|██████████| 1/1 [01:28<00:00, 88.66s/it]
  5%|▍         | 241/5198 [7:22:27<144:18:12, 104.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.69s/it][A100%|██████████| 1/1 [01:28<00:00, 88.69s/it]
  5%|▍         | 241/5198 [7:22:27<144:18:01, 104.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.56s/it][A100%|██████████| 1/1 [01:28<00:00, 88.56s/it]
  5%|▍         | 241/5198 [7:22:27<144:18:19, 104.80s/it]
100%|██████████| 1/1 [01:28<00:00, 88.56s/it][A100%|██████████| 1/1 [01:28<00:00, 88.56s/it]
  5%|▍         | 241/5198 [7:22:29<144:18:00, 104.80s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_226
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.72s/it][A100%|██████████| 1/1 [01:36<00:00, 96.72s/it]
  5%|▍         | 242/5198 [7:24:03<141:14:25, 102.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 02:49:09,508] [INFO] [logging.py:96:log_dist] [Rank 0] step=239, skipped=0, lr=[1.9992701487091367e-05], mom=[(0.9, 0.999)]
steps: 239 loss: 0.5836 iter time (s): 96.409 samples/sec: 1.328

100%|██████████| 1/1 [01:37<00:00, 97.54s/it][A100%|██████████| 1/1 [01:37<00:00, 97.54s/it]
  5%|▍         | 242/5198 [7:24:04<141:15:46, 102.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.44s/it][A100%|██████████| 1/1 [01:37<00:00, 97.44s/it]
  5%|▍         | 242/5198 [7:24:04<141:14:03, 102.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.45s/it][A100%|██████████| 1/1 [01:37<00:00, 97.45s/it]
  5%|▍         | 242/5198 [7:24:04<141:15:31, 102.61s/it]
100%|██████████| 1/1 [01:37<00:00, 97.34s/it][A100%|██████████| 1/1 [01:37<00:00, 97.34s/it]
  5%|▍         | 242/5198 [7:24:05<141:13:02, 102.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.47s/it][A100%|██████████| 1/1 [01:37<00:00, 97.47s/it]
  5%|▍         | 242/5198 [7:24:04<141:15:08, 102.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.49s/it][A100%|██████████| 1/1 [01:37<00:00, 97.49s/it]
  5%|▍         | 242/5198 [7:24:05<141:17:13, 102.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.22s/it][A100%|██████████| 1/1 [01:38<00:00, 98.22s/it]
  5%|▍         | 242/5198 [7:24:08<141:35:01, 102.85s/it]Shard 242 in [76, 158, 182, 242, 293, 363, 418, 421, 752, 814, 842, 991, 1266, 1366, 1425, 1464, 1574, 1728, 2166, 2441, 2563, 2739, 2854, 2894, 3089, 3181, 3395, 3576, 3831, 4300, 4589, 4947, 4950]: file /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_227 skipped to avoid exceeding cuda memory
Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_228
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.34s/it][A100%|██████████| 1/1 [01:26<00:00, 86.34s/it]
  5%|▍         | 244/5198 [7:25:30<103:38:15, 75.31s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 02:50:36,225] [INFO] [logging.py:96:log_dist] [Rank 0] step=240, skipped=0, lr=[1.999248353017762e-05], mom=[(0.9, 0.999)]
steps: 240 loss: 0.6062 iter time (s): 84.825 samples/sec: 1.509

100%|██████████| 1/1 [01:26<00:00, 86.42s/it][A100%|██████████| 1/1 [01:26<00:00, 86.42s/it]
  5%|▍         | 244/5198 [7:25:30<103:29:23, 75.20s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.38s/it][A100%|██████████| 1/1 [01:26<00:00, 86.38s/it]
  5%|▍         | 244/5198 [7:25:30<103:28:36, 75.20s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.36s/it][A100%|██████████| 1/1 [01:26<00:00, 86.36s/it]
  5%|▍         | 244/5198 [7:25:31<103:28:24, 75.19s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.39s/it][A100%|██████████| 1/1 [01:26<00:00, 86.39s/it]
  5%|▍         | 244/5198 [7:25:31<103:28:07, 75.19s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.44s/it][A100%|██████████| 1/1 [01:26<00:00, 86.44s/it]
  5%|▍         | 244/5198 [7:25:31<103:29:02, 75.20s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.58s/it][A100%|██████████| 1/1 [01:25<00:00, 85.58s/it]
  5%|▍         | 244/5198 [7:25:33<103:23:39, 75.14s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_229

100%|██████████| 1/1 [01:26<00:00, 86.31s/it][A100%|██████████| 1/1 [01:26<00:00, 86.31s/it]
  5%|▍         | 244/5198 [7:25:31<103:28:01, 75.19s/it] Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.73s/it][A100%|██████████| 1/1 [01:27<00:00, 87.73s/it]
  5%|▍         | 245/5198 [7:26:58<107:54:06, 78.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 02:52:04,150] [INFO] [logging.py:96:log_dist] [Rank 0] step=241, skipped=0, lr=[1.9992262367747937e-05], mom=[(0.9, 0.999)]
steps: 241 loss: 0.6414 iter time (s): 87.162 samples/sec: 1.469

100%|██████████| 1/1 [01:27<00:00, 87.88s/it][A100%|██████████| 1/1 [01:27<00:00, 87.88s/it]
  5%|▍         | 245/5198 [7:26:58<107:47:54, 78.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.94s/it][A100%|██████████| 1/1 [01:27<00:00, 87.94s/it]
  5%|▍         | 245/5198 [7:26:58<107:48:32, 78.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.96s/it][A100%|██████████| 1/1 [01:27<00:00, 87.96s/it]
  5%|▍         | 245/5198 [7:26:59<107:48:40, 78.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.91s/it][A100%|██████████| 1/1 [01:27<00:00, 87.91s/it]
  5%|▍         | 245/5198 [7:26:59<107:47:27, 78.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.93s/it][A100%|██████████| 1/1 [01:27<00:00, 87.93s/it]
  5%|▍         | 245/5198 [7:26:59<107:48:39, 78.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.95s/it][A100%|██████████| 1/1 [01:27<00:00, 87.95s/it]
  5%|▍         | 245/5198 [7:26:59<107:48:12, 78.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.98s/it][A100%|██████████| 1/1 [01:27<00:00, 87.98s/it]
  5%|▍         | 245/5198 [7:27:01<107:45:25, 78.32s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_230
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.87s/it][A100%|██████████| 1/1 [01:24<00:00, 84.87s/it]
  5%|▍         | 246/5198 [7:28:23<110:19:18, 80.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 02:53:29,297] [INFO] [logging.py:96:log_dist] [Rank 0] step=242, skipped=0, lr=[1.999203799987328e-05], mom=[(0.9, 0.999)]
steps: 242 loss: 0.5815 iter time (s): 84.322 samples/sec: 1.518

100%|██████████| 1/1 [01:25<00:00, 85.07s/it][A100%|██████████| 1/1 [01:25<00:00, 85.07s/it]
  5%|▍         | 246/5198 [7:28:23<110:12:02, 80.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.02s/it][A100%|██████████| 1/1 [01:25<00:00, 85.02s/it]
  5%|▍         | 246/5198 [7:28:23<110:11:17, 80.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.07s/it][A100%|██████████| 1/1 [01:25<00:00, 85.07s/it]
  5%|▍         | 246/5198 [7:28:24<110:12:21, 80.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.13s/it][A100%|██████████| 1/1 [01:25<00:00, 85.13s/it]
  5%|▍         | 246/5198 [7:28:24<110:12:45, 80.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.12s/it][A100%|██████████| 1/1 [01:25<00:00, 85.12s/it]
  5%|▍         | 246/5198 [7:28:24<110:13:23, 80.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.08s/it][A100%|██████████| 1/1 [01:25<00:00, 85.08s/it]
  5%|▍         | 246/5198 [7:28:24<110:12:18, 80.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.07s/it][A100%|██████████| 1/1 [01:25<00:00, 85.08s/it]
  5%|▍         | 246/5198 [7:28:26<110:10:02, 80.09s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_231
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.12s/it][A100%|██████████| 1/1 [01:43<00:00, 103.12s/it]
  5%|▍         | 247/5198 [7:30:06<118:55:29, 86.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 02:55:12,709] [INFO] [logging.py:96:log_dist] [Rank 0] step=243, skipped=0, lr=[1.999181042662562e-05], mom=[(0.9, 0.999)]
steps: 243 loss: 0.6048 iter time (s): 102.652 samples/sec: 1.247

100%|██████████| 1/1 [01:43<00:00, 103.44s/it][A100%|██████████| 1/1 [01:43<00:00, 103.44s/it]
  5%|▍         | 247/5198 [7:30:07<118:54:34, 86.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.49s/it][A100%|██████████| 1/1 [01:43<00:00, 103.49s/it]
  5%|▍         | 247/5198 [7:30:07<118:55:05, 86.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.36s/it][A100%|██████████| 1/1 [01:43<00:00, 103.36s/it]
  5%|▍         | 247/5198 [7:30:07<118:53:00, 86.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.46s/it][A100%|██████████| 1/1 [01:43<00:00, 103.46s/it]
  5%|▍         | 247/5198 [7:30:07<118:55:21, 86.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.44s/it][A100%|██████████| 1/1 [01:43<00:00, 103.44s/it]
  5%|▍         | 247/5198 [7:30:08<118:55:27, 86.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.43s/it][A100%|██████████| 1/1 [01:43<00:00, 103.43s/it]
  5%|▍         | 247/5198 [7:30:10<118:52:47, 86.44s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_232
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.45s/it][A100%|██████████| 1/1 [01:43<00:00, 103.46s/it]
  5%|▍         | 247/5198 [7:30:08<118:54:58, 86.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.36s/it][A100%|██████████| 1/1 [01:29<00:00, 89.36s/it]
  5%|▍         | 248/5198 [7:31:36<120:04:56, 87.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 02:56:42,201] [INFO] [logging.py:96:log_dist] [Rank 0] step=244, skipped=0, lr=[1.999157964807798e-05], mom=[(0.9, 0.999)]
steps: 244 loss: 0.5962 iter time (s): 88.704 samples/sec: 1.443

100%|██████████| 1/1 [01:29<00:00, 89.50s/it][A100%|██████████| 1/1 [01:29<00:00, 89.50s/it]
  5%|▍         | 248/5198 [7:31:36<120:03:38, 87.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.60s/it][A100%|██████████| 1/1 [01:29<00:00, 89.60s/it]
  5%|▍         | 248/5198 [7:31:37<120:06:19, 87.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.61s/it][A100%|██████████| 1/1 [01:29<00:00, 89.61s/it]
  5%|▍         | 248/5198 [7:31:37<120:04:57, 87.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.48s/it][A100%|██████████| 1/1 [01:29<00:00, 89.48s/it]
  5%|▍         | 248/5198 [7:31:37<120:03:35, 87.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.50s/it][A100%|██████████| 1/1 [01:29<00:00, 89.50s/it]
  5%|▍         | 248/5198 [7:31:37<120:04:12, 87.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.51s/it][A100%|██████████| 1/1 [01:29<00:00, 89.51s/it]
  5%|▍         | 248/5198 [7:31:39<120:02:26, 87.30s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_233
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.52s/it][A100%|██████████| 1/1 [01:29<00:00, 89.52s/it]
  5%|▍         | 248/5198 [7:31:37<120:04:14, 87.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.51s/it][A100%|██████████| 1/1 [01:19<00:00, 79.51s/it]
  5%|▍         | 249/5198 [7:32:56<117:02:06, 85.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 02:58:01,566] [INFO] [logging.py:96:log_dist] [Rank 0] step=245, skipped=0, lr=[1.999134566430439e-05], mom=[(0.9, 0.999)]
steps: 245 loss: 0.5960 iter time (s): 78.553 samples/sec: 1.629

100%|██████████| 1/1 [01:19<00:00, 79.37s/it][A100%|██████████| 1/1 [01:19<00:00, 79.37s/it]
  5%|▍         | 249/5198 [7:32:56<116:55:10, 85.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.27s/it][A100%|██████████| 1/1 [01:19<00:00, 79.27s/it]
  5%|▍         | 249/5198 [7:32:56<116:54:45, 85.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.26s/it][A100%|██████████| 1/1 [01:19<00:00, 79.26s/it]
  5%|▍         | 249/5198 [7:32:56<116:53:35, 85.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.33s/it][A100%|██████████| 1/1 [01:19<00:00, 79.33s/it]
  5%|▍         | 249/5198 [7:32:56<116:54:12, 85.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.30s/it][A100%|██████████| 1/1 [01:19<00:00, 79.30s/it]
  5%|▍         | 249/5198 [7:32:56<116:53:58, 85.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.31s/it][A100%|██████████| 1/1 [01:19<00:00, 79.31s/it]
  5%|▍         | 249/5198 [7:32:59<116:52:50, 85.02s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_234

100%|██████████| 1/1 [01:19<00:00, 79.29s/it][A100%|██████████| 1/1 [01:19<00:00, 79.29s/it]
  5%|▍         | 249/5198 [7:32:56<116:53:43, 85.03s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.17s/it][A100%|██████████| 1/1 [01:53<00:00, 113.17s/it]
  5%|▍         | 250/5198 [7:34:49<128:14:58, 93.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 02:59:55,895] [INFO] [logging.py:96:log_dist] [Rank 0] step=246, skipped=0, lr=[1.9991108475379922e-05], mom=[(0.9, 0.999)]
steps: 246 loss: 0.6025 iter time (s): 113.573 samples/sec: 1.127

100%|██████████| 1/1 [01:54<00:00, 114.33s/it][A100%|██████████| 1/1 [01:54<00:00, 114.33s/it]
  5%|▍         | 250/5198 [7:34:50<128:33:51, 93.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.28s/it][A100%|██████████| 1/1 [01:54<00:00, 114.28s/it]
  5%|▍         | 250/5198 [7:34:50<128:32:28, 93.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.41s/it][A100%|██████████| 1/1 [01:54<00:00, 114.41s/it]
  5%|▍         | 250/5198 [7:34:51<128:34:38, 93.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.40s/it][A100%|██████████| 1/1 [01:54<00:00, 114.40s/it]
  5%|▍         | 250/5198 [7:34:51<128:34:37, 93.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.38s/it][A100%|██████████| 1/1 [01:54<00:00, 114.38s/it]
  5%|▍         | 250/5198 [7:34:51<128:34:07, 93.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.39s/it][A100%|██████████| 1/1 [01:54<00:00, 114.39s/it]
  5%|▍         | 250/5198 [7:34:51<128:34:06, 93.54s/it]
100%|██████████| 1/1 [01:54<00:00, 114.40s/it][A100%|██████████| 1/1 [01:54<00:00, 114.40s/it]
  5%|▍         | 250/5198 [7:34:53<128:33:38, 93.54s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_235
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.33s/it][A100%|██████████| 1/1 [01:27<00:00, 87.33s/it]
  5%|▍         | 251/5198 [7:36:17<125:56:42, 91.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 03:01:22,789] [INFO] [logging.py:96:log_dist] [Rank 0] step=247, skipped=0, lr=[1.9990868081380674e-05], mom=[(0.9, 0.999)]
steps: 247 loss: 0.6062 iter time (s): 86.050 samples/sec: 1.488

100%|██████████| 1/1 [01:26<00:00, 86.79s/it][A100%|██████████| 1/1 [01:26<00:00, 86.79s/it]
  5%|▍         | 251/5198 [7:36:17<125:49:35, 91.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.88s/it][A100%|██████████| 1/1 [01:26<00:00, 86.88s/it]
  5%|▍         | 251/5198 [7:36:17<125:50:57, 91.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.85s/it][A100%|██████████| 1/1 [01:26<00:00, 86.85s/it]
  5%|▍         | 251/5198 [7:36:17<125:51:32, 91.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.78s/it][A100%|██████████| 1/1 [01:26<00:00, 86.78s/it]
  5%|▍         | 251/5198 [7:36:17<125:50:00, 91.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.82s/it][A100%|██████████| 1/1 [01:26<00:00, 86.82s/it]
  5%|▍         | 251/5198 [7:36:18<125:50:38, 91.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.80s/it][A100%|██████████| 1/1 [01:26<00:00, 86.80s/it]
  5%|▍         | 251/5198 [7:36:20<125:49:43, 91.57s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_236

100%|██████████| 1/1 [01:26<00:00, 86.80s/it][A100%|██████████| 1/1 [01:26<00:00, 86.80s/it]
  5%|▍         | 251/5198 [7:36:18<125:50:07, 91.57s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.52s/it][A100%|██████████| 1/1 [01:37<00:00, 97.52s/it]
  5%|▍         | 252/5198 [7:37:54<128:21:24, 93.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 03:03:00,763] [INFO] [logging.py:96:log_dist] [Rank 0] step=248, skipped=0, lr=[1.9990624482383763e-05], mom=[(0.9, 0.999)]
steps: 248 loss: 0.5832 iter time (s): 97.215 samples/sec: 1.317

100%|██████████| 1/1 [01:38<00:00, 98.02s/it][A100%|██████████| 1/1 [01:38<00:00, 98.02s/it]
  5%|▍         | 252/5198 [7:37:55<128:25:12, 93.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.88s/it][A100%|██████████| 1/1 [01:37<00:00, 97.88s/it]
  5%|▍         | 252/5198 [7:37:55<128:22:39, 93.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.99s/it][A100%|██████████| 1/1 [01:37<00:00, 97.99s/it]
  5%|▍         | 252/5198 [7:37:55<128:25:45, 93.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.99s/it][A100%|██████████| 1/1 [01:37<00:00, 97.99s/it]
  5%|▍         | 252/5198 [7:37:55<128:24:40, 93.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.95s/it][A100%|██████████| 1/1 [01:37<00:00, 97.95s/it]
  5%|▍         | 252/5198 [7:37:56<128:24:10, 93.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.95s/it][A100%|██████████| 1/1 [01:37<00:00, 97.95s/it]
  5%|▍         | 252/5198 [7:37:56<128:23:48, 93.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.97s/it][A100%|██████████| 1/1 [01:37<00:00, 97.97s/it]
  5%|▍         | 252/5198 [7:37:58<128:23:55, 93.46s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_237
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.84s/it][A100%|██████████| 1/1 [01:25<00:00, 85.84s/it]
  5%|▍         | 253/5198 [7:39:20<125:18:04, 91.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 03:04:26,393] [INFO] [logging.py:96:log_dist] [Rank 0] step=249, skipped=0, lr=[1.999037767846735e-05], mom=[(0.9, 0.999)]
steps: 249 loss: 0.6591 iter time (s): 84.871 samples/sec: 1.508

100%|██████████| 1/1 [01:25<00:00, 85.58s/it][A100%|██████████| 1/1 [01:25<00:00, 85.58s/it]
  5%|▍         | 253/5198 [7:39:20<125:11:04, 91.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.63s/it][A100%|██████████| 1/1 [01:25<00:00, 85.63s/it]
  5%|▍         | 253/5198 [7:39:21<125:10:36, 91.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.58s/it][A100%|██████████| 1/1 [01:25<00:00, 85.58s/it]
  5%|▍         | 253/5198 [7:39:21<125:11:31, 91.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.61s/it][A100%|██████████| 1/1 [01:25<00:00, 85.61s/it]
  5%|▍         | 253/5198 [7:39:21<125:11:23, 91.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.66s/it][A100%|██████████| 1/1 [01:25<00:00, 85.66s/it]
  5%|▍         | 253/5198 [7:39:21<125:12:17, 91.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.68s/it][A100%|██████████| 1/1 [01:25<00:00, 85.68s/it]

  5%|▍         | 253/5198 [7:39:21<125:12:28, 91.15s/it]100%|██████████| 1/1 [01:25<00:00, 85.66s/it][A100%|██████████| 1/1 [01:25<00:00, 85.66s/it]
  5%|▍         | 253/5198 [7:39:23<125:12:11, 91.15s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_238
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:17<00:00, 137.91s/it][A100%|██████████| 1/1 [02:17<00:00, 137.91s/it]
  5%|▍         | 254/5198 [7:41:38<144:24:12, 105.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 03:06:45,889] [INFO] [logging.py:96:log_dist] [Rank 0] step=250, skipped=0, lr=[1.9990127669710612e-05], mom=[(0.9, 0.999)]
steps: 250 loss: 0.6057 iter time (s): 138.696 samples/sec: 0.923

100%|██████████| 1/1 [02:19<00:00, 139.49s/it][A100%|██████████| 1/1 [02:19<00:00, 139.49s/it]
  5%|▍         | 254/5198 [7:41:40<144:55:14, 105.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:19<00:00, 139.54s/it][A100%|██████████| 1/1 [02:19<00:00, 139.54s/it]
  5%|▍         | 254/5198 [7:41:40<144:55:57, 105.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:19<00:00, 139.49s/it][A100%|██████████| 1/1 [02:19<00:00, 139.49s/it]
  5%|▍         | 254/5198 [7:41:41<144:55:20, 105.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:19<00:00, 139.46s/it][A100%|██████████| 1/1 [02:19<00:00, 139.46s/it]
  5%|▍         | 254/5198 [7:41:41<144:54:27, 105.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:19<00:00, 139.43s/it][A100%|██████████| 1/1 [02:19<00:00, 139.43s/it]
  5%|▍         | 254/5198 [7:41:41<144:54:28, 105.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:19<00:00, 139.41s/it][A100%|██████████| 1/1 [02:19<00:00, 139.41s/it]
  5%|▍         | 254/5198 [7:41:41<144:54:01, 105.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:19<00:00, 139.44s/it][A100%|██████████| 1/1 [02:19<00:00, 139.44s/it]
  5%|▍         | 254/5198 [7:41:43<144:54:29, 105.52s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_239
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.98s/it][A100%|██████████| 1/1 [01:44<00:00, 104.98s/it]
  5%|▍         | 255/5198 [7:43:23<144:22:13, 105.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 03:08:29,810] [INFO] [logging.py:96:log_dist] [Rank 0] step=251, skipped=0, lr=[1.998987445619376e-05], mom=[(0.9, 0.999)]
steps: 251 loss: 0.6524 iter time (s): 103.194 samples/sec: 1.240

100%|██████████| 1/1 [01:44<00:00, 104.25s/it][A100%|██████████| 1/1 [01:44<00:00, 104.25s/it]
  5%|▍         | 255/5198 [7:43:24<144:22:19, 105.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.16s/it][A100%|██████████| 1/1 [01:44<00:00, 104.16s/it]
  5%|▍         | 255/5198 [7:43:24<144:21:02, 105.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.18s/it][A100%|██████████| 1/1 [01:44<00:00, 104.18s/it]
  5%|▍         | 255/5198 [7:43:25<144:20:37, 105.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.22s/it][A100%|██████████| 1/1 [01:44<00:00, 104.22s/it]
  5%|▍         | 255/5198 [7:43:25<144:20:57, 105.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.19s/it][A100%|██████████| 1/1 [01:44<00:00, 104.19s/it]
  5%|▍         | 255/5198 [7:43:25<144:20:19, 105.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.19s/it][A100%|██████████| 1/1 [01:44<00:00, 104.19s/it]
  5%|▍         | 255/5198 [7:43:27<144:20:19, 105.12s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_15

100%|██████████| 1/1 [01:44<00:00, 104.22s/it][A100%|██████████| 1/1 [01:44<00:00, 104.22s/it]
  5%|▍         | 255/5198 [7:43:25<144:20:42, 105.13s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.95s/it][A100%|██████████| 1/1 [01:59<00:00, 119.95s/it]
  5%|▍         | 256/5198 [7:45:24<150:30:45, 109.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 03:10:30,463] [INFO] [logging.py:96:log_dist] [Rank 0] step=252, skipped=0, lr=[1.9989618037998025e-05], mom=[(0.9, 0.999)]
steps: 252 loss: 0.8212 iter time (s): 119.916 samples/sec: 1.067

100%|██████████| 1/1 [02:00<00:00, 120.69s/it][A100%|██████████| 1/1 [02:00<00:00, 120.69s/it]
  5%|▍         | 256/5198 [7:45:25<150:43:19, 109.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.66s/it][A100%|██████████| 1/1 [02:00<00:00, 120.66s/it]
  5%|▍         | 256/5198 [7:45:25<150:41:40, 109.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.67s/it][A100%|██████████| 1/1 [02:00<00:00, 120.67s/it]
  5%|▍         | 256/5198 [7:45:25<150:41:38, 109.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.70s/it][A100%|██████████| 1/1 [02:00<00:00, 120.70s/it]
  5%|▍         | 256/5198 [7:45:25<150:42:30, 109.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.75s/it][A100%|██████████| 1/1 [02:00<00:00, 120.75s/it]
  5%|▍         | 256/5198 [7:45:26<150:43:14, 109.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.71s/it][A100%|██████████| 1/1 [02:00<00:00, 120.71s/it]
  5%|▍         | 256/5198 [7:45:26<150:42:34, 109.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.73s/it][A100%|██████████| 1/1 [02:00<00:00, 120.73s/it]
  5%|▍         | 256/5198 [7:45:28<150:42:42, 109.79s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_240
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:04<00:00, 124.29s/it][A100%|██████████| 1/1 [02:04<00:00, 124.29s/it]
  5%|▍         | 257/5198 [7:47:28<156:34:19, 114.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 03:12:34,531] [INFO] [logging.py:96:log_dist] [Rank 0] step=253, skipped=0, lr=[1.998935841520568e-05], mom=[(0.9, 0.999)]
steps: 253 loss: 0.5946 iter time (s): 122.988 samples/sec: 1.041

100%|██████████| 1/1 [02:03<00:00, 123.76s/it][A100%|██████████| 1/1 [02:03<00:00, 123.76s/it]
  5%|▍         | 257/5198 [7:47:29<156:26:02, 113.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.80s/it][A100%|██████████| 1/1 [02:03<00:00, 123.80s/it]
  5%|▍         | 257/5198 [7:47:29<156:25:39, 113.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.78s/it][A100%|██████████| 1/1 [02:03<00:00, 123.79s/it]
  5%|▍         | 257/5198 [7:47:29<156:25:13, 113.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.81s/it][A100%|██████████| 1/1 [02:03<00:00, 123.81s/it]
  5%|▍         | 257/5198 [7:47:29<156:26:31, 113.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.78s/it][A100%|██████████| 1/1 [02:03<00:00, 123.78s/it]
  5%|▍         | 257/5198 [7:47:29<156:26:07, 113.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.79s/it][A100%|██████████| 1/1 [02:03<00:00, 123.79s/it]
  5%|▍         | 257/5198 [7:47:29<156:25:54, 113.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.79s/it][A100%|██████████| 1/1 [02:03<00:00, 123.79s/it]
  5%|▍         | 257/5198 [7:47:32<156:26:09, 113.98s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_241
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.31s/it][A100%|██████████| 1/1 [01:21<00:00, 81.32s/it]
  5%|▍         | 258/5198 [7:48:50<143:09:41, 104.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 03:13:55,611] [INFO] [logging.py:96:log_dist] [Rank 0] step=254, skipped=0, lr=[1.9989095587900017e-05], mom=[(0.9, 0.999)]
steps: 254 loss: 0.5811 iter time (s): 80.240 samples/sec: 1.595

100%|██████████| 1/1 [01:21<00:00, 81.01s/it][A100%|██████████| 1/1 [01:21<00:00, 81.01s/it]
  5%|▍         | 258/5198 [7:48:50<142:51:50, 104.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.04s/it][A100%|██████████| 1/1 [01:21<00:00, 81.04s/it]
  5%|▍         | 258/5198 [7:48:50<142:52:15, 104.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.98s/it][A100%|██████████| 1/1 [01:20<00:00, 80.98s/it]
  5%|▍         | 258/5198 [7:48:50<142:51:12, 104.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.11s/it][A100%|██████████| 1/1 [01:21<00:00, 81.11s/it]
  5%|▍         | 258/5198 [7:48:50<142:53:39, 104.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.04s/it][A100%|██████████| 1/1 [01:21<00:00, 81.04s/it]
  5%|▍         | 258/5198 [7:48:50<142:52:25, 104.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.07s/it][A100%|██████████| 1/1 [01:21<00:00, 81.07s/it]
  5%|▍         | 258/5198 [7:48:51<142:53:03, 104.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.06s/it][A100%|██████████| 1/1 [01:21<00:00, 81.06s/it]
  5%|▍         | 258/5198 [7:48:53<142:52:53, 104.12s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_242
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.24s/it][A100%|██████████| 1/1 [01:28<00:00, 88.24s/it]
  5%|▍         | 259/5198 [7:50:18<136:36:02, 99.57s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 03:15:24,247] [INFO] [logging.py:96:log_dist] [Rank 0] step=255, skipped=0, lr=[1.9988829556165354e-05], mom=[(0.9, 0.999)]
steps: 255 loss: 0.6318 iter time (s): 87.817 samples/sec: 1.458

100%|██████████| 1/1 [01:28<00:00, 88.60s/it][A100%|██████████| 1/1 [01:28<00:00, 88.60s/it]
  5%|▍         | 259/5198 [7:50:18<136:27:51, 99.47s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.67s/it][A100%|██████████| 1/1 [01:28<00:00, 88.67s/it]
  5%|▍         | 259/5198 [7:50:19<136:29:47, 99.49s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.55s/it][A100%|██████████| 1/1 [01:28<00:00, 88.55s/it]
  5%|▍         | 259/5198 [7:50:19<136:27:46, 99.47s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.63s/it][A100%|██████████| 1/1 [01:28<00:00, 88.63s/it]
  5%|▍         | 259/5198 [7:50:19<136:28:14, 99.47s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.65s/it][A100%|██████████| 1/1 [01:28<00:00, 88.66s/it]
  5%|▍         | 259/5198 [7:50:19<136:29:39, 99.49s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.61s/it][A100%|██████████| 1/1 [01:28<00:00, 88.61s/it]
  5%|▍         | 259/5198 [7:50:19<136:28:48, 99.48s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.62s/it][A100%|██████████| 1/1 [01:28<00:00, 88.62s/it]
  5%|▍         | 259/5198 [7:50:21<136:29:02, 99.48s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_243
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.96s/it][A100%|██████████| 1/1 [01:41<00:00, 101.96s/it]
  5%|▌         | 260/5198 [7:52:00<137:37:17, 100.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 03:17:06,774] [INFO] [logging.py:96:log_dist] [Rank 0] step=256, skipped=0, lr=[1.9988560320087043e-05], mom=[(0.9, 0.999)]
steps: 256 loss: 0.6467 iter time (s): 101.713 samples/sec: 1.258

100%|██████████| 1/1 [01:42<00:00, 102.57s/it][A100%|██████████| 1/1 [01:42<00:00, 102.57s/it]
  5%|▌         | 260/5198 [7:52:01<137:43:14, 100.40s/it]
100%|██████████| 1/1 [01:42<00:00, 102.43s/it][A100%|██████████| 1/1 [01:42<00:00, 102.43s/it]
  5%|▌         | 260/5198 [7:52:01<137:40:55, 100.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.55s/it][A100%|██████████| 1/1 [01:42<00:00, 102.56s/it]
  5%|▌         | 260/5198 [7:52:01<137:42:28, 100.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.65s/it][A100%|██████████| 1/1 [01:42<00:00, 102.65s/it]
  5%|▌         | 260/5198 [7:52:02<137:45:05, 100.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.55s/it][A100%|██████████| 1/1 [01:42<00:00, 102.55s/it]
  5%|▌         | 260/5198 [7:52:02<137:43:34, 100.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.52s/it][A100%|██████████| 1/1 [01:42<00:00, 102.52s/it]
  5%|▌         | 260/5198 [7:52:04<137:42:34, 100.40s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_244

100%|██████████| 1/1 [01:42<00:00, 102.55s/it][A100%|██████████| 1/1 [01:42<00:00, 102.55s/it]
  5%|▌         | 260/5198 [7:52:02<137:43:01, 100.40s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.26s/it][A100%|██████████| 1/1 [01:51<00:00, 111.26s/it]
  5%|▌         | 261/5198 [7:53:52<142:08:10, 103.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 03:18:58,258] [INFO] [logging.py:96:log_dist] [Rank 0] step=257, skipped=0, lr=[1.9988287879751463e-05], mom=[(0.9, 0.999)]
steps: 257 loss: 0.5767 iter time (s): 110.718 samples/sec: 1.156

100%|██████████| 1/1 [01:51<00:00, 111.45s/it][A100%|██████████| 1/1 [01:51<00:00, 111.45s/it]
  5%|▌         | 261/5198 [7:53:52<142:14:21, 103.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.58s/it][A100%|██████████| 1/1 [01:51<00:00, 111.58s/it]
  5%|▌         | 261/5198 [7:53:53<142:15:48, 103.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.51s/it][A100%|██████████| 1/1 [01:51<00:00, 111.51s/it]
  5%|▌         | 261/5198 [7:53:53<142:15:15, 103.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.39s/it][A100%|██████████| 1/1 [01:51<00:00, 111.39s/it]
  5%|▌         | 261/5198 [7:53:53<142:14:03, 103.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.38s/it][A100%|██████████| 1/1 [01:51<00:00, 111.38s/it]
  5%|▌         | 261/5198 [7:53:53<142:12:51, 103.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.46s/it][A100%|██████████| 1/1 [01:51<00:00, 111.46s/it]
  5%|▌         | 261/5198 [7:53:53<142:14:20, 103.72s/it]
100%|██████████| 1/1 [01:51<00:00, 111.46s/it][A100%|██████████| 1/1 [01:51<00:00, 111.46s/it]
  5%|▌         | 261/5198 [7:53:55<142:14:07, 103.72s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_245
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.41s/it][A100%|██████████| 1/1 [01:58<00:00, 118.41s/it]
  5%|▌         | 262/5198 [7:55:50<148:14:53, 108.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 03:20:56,060] [INFO] [logging.py:96:log_dist] [Rank 0] step=258, skipped=0, lr=[1.9988012235246012e-05], mom=[(0.9, 0.999)]
steps: 258 loss: 0.5800 iter time (s): 117.042 samples/sec: 1.094

100%|██████████| 1/1 [01:57<00:00, 117.74s/it][A100%|██████████| 1/1 [01:57<00:00, 117.74s/it]
  5%|▌         | 262/5198 [7:55:50<147:58:41, 107.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:57<00:00, 117.73s/it][A100%|██████████| 1/1 [01:57<00:00, 117.73s/it]
  5%|▌         | 262/5198 [7:55:50<147:59:31, 107.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:57<00:00, 117.73s/it][A100%|██████████| 1/1 [01:57<00:00, 117.73s/it]
  5%|▌         | 262/5198 [7:55:51<147:59:28, 107.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:57<00:00, 117.75s/it][A100%|██████████| 1/1 [01:57<00:00, 117.75s/it]
  5%|▌         | 262/5198 [7:55:51<147:58:48, 107.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:57<00:00, 117.83s/it][A100%|██████████| 1/1 [01:57<00:00, 117.83s/it]
  5%|▌         | 262/5198 [7:55:51<148:00:03, 107.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:57<00:00, 117.79s/it][A100%|██████████| 1/1 [01:57<00:00, 117.79s/it]
  5%|▌         | 262/5198 [7:55:51<147:59:59, 107.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:57<00:00, 117.81s/it][A100%|██████████| 1/1 [01:57<00:00, 117.81s/it]
  5%|▌         | 262/5198 [7:55:53<148:00:11, 107.94s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_246
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.87s/it][A100%|██████████| 1/1 [01:55<00:00, 115.87s/it]
  5%|▌         | 263/5198 [7:57:46<151:29:44, 110.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 03:22:53,000] [INFO] [logging.py:96:log_dist] [Rank 0] step=259, skipped=0, lr=[1.9987733386659135e-05], mom=[(0.9, 0.999)]
steps: 259 loss: 0.5854 iter time (s): 116.143 samples/sec: 1.102

100%|██████████| 1/1 [01:56<00:00, 116.97s/it][A100%|██████████| 1/1 [01:56<00:00, 116.97s/it]
  5%|▌         | 263/5198 [7:57:47<151:40:34, 110.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.93s/it][A100%|██████████| 1/1 [01:56<00:00, 116.93s/it]
  5%|▌         | 263/5198 [7:57:47<151:39:42, 110.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.90s/it][A100%|██████████| 1/1 [01:56<00:00, 116.90s/it]
  5%|▌         | 263/5198 [7:57:48<151:39:21, 110.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.99s/it][A100%|██████████| 1/1 [01:56<00:00, 116.99s/it]
  5%|▌         | 263/5198 [7:57:48<151:40:41, 110.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.95s/it][A100%|██████████| 1/1 [01:56<00:00, 116.95s/it]
  5%|▌         | 263/5198 [7:57:48<151:40:37, 110.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.95s/it][A100%|██████████| 1/1 [01:56<00:00, 116.95s/it]
  5%|▌         | 263/5198 [7:57:50<151:40:37, 110.65s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_247

100%|██████████| 1/1 [01:56<00:00, 116.96s/it][A100%|██████████| 1/1 [01:56<00:00, 116.96s/it]
  5%|▌         | 263/5198 [7:57:48<151:40:56, 110.65s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.02s/it][A100%|██████████| 1/1 [01:25<00:00, 85.02s/it]
  5%|▌         | 264/5198 [7:59:11<141:04:27, 102.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 03:24:17,599] [INFO] [logging.py:96:log_dist] [Rank 0] step=260, skipped=0, lr=[1.9987451334080285e-05], mom=[(0.9, 0.999)]
steps: 260 loss: 0.5732 iter time (s): 83.767 samples/sec: 1.528

100%|██████████| 1/1 [01:24<00:00, 84.52s/it][A100%|██████████| 1/1 [01:24<00:00, 84.52s/it]
  5%|▌         | 264/5198 [7:59:12<140:54:49, 102.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.57s/it][A100%|██████████| 1/1 [01:24<00:00, 84.57s/it]
  5%|▌         | 264/5198 [7:59:12<140:55:07, 102.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.60s/it][A100%|██████████| 1/1 [01:24<00:00, 84.60s/it]
  5%|▌         | 264/5198 [7:59:12<140:55:38, 102.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.55s/it][A100%|██████████| 1/1 [01:24<00:00, 84.55s/it]
  5%|▌         | 264/5198 [7:59:12<140:55:24, 102.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.53s/it][A100%|██████████| 1/1 [01:24<00:00, 84.53s/it]
  5%|▌         | 264/5198 [7:59:12<140:54:53, 102.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.50s/it][A100%|██████████| 1/1 [01:24<00:00, 84.50s/it]
  5%|▌         | 264/5198 [7:59:12<140:54:23, 102.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.52s/it][A100%|██████████| 1/1 [01:24<00:00, 84.52s/it]
  5%|▌         | 264/5198 [7:59:15<140:54:36, 102.81s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_248
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.08s/it][A100%|██████████| 1/1 [01:27<00:00, 87.08s/it]
  5%|▌         | 265/5198 [8:00:39<134:36:28, 98.23s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 03:25:44,898] [INFO] [logging.py:96:log_dist] [Rank 0] step=261, skipped=0, lr=[1.9987166077599955e-05], mom=[(0.9, 0.999)]
steps: 261 loss: 0.6290 iter time (s): 86.540 samples/sec: 1.479

100%|██████████| 1/1 [01:27<00:00, 87.33s/it][A100%|██████████| 1/1 [01:27<00:00, 87.33s/it]
  5%|▌         | 265/5198 [8:00:39<134:31:22, 98.17s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.32s/it][A100%|██████████| 1/1 [01:27<00:00, 87.33s/it]
  5%|▌         | 265/5198 [8:00:39<134:31:31, 98.17s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.28s/it][A100%|██████████| 1/1 [01:27<00:00, 87.28s/it]
  5%|▌         | 265/5198 [8:00:40<134:30:47, 98.16s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.34s/it][A100%|██████████| 1/1 [01:27<00:00, 87.34s/it]
  5%|▌         | 265/5198 [8:00:40<134:32:04, 98.18s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.33s/it][A100%|██████████| 1/1 [01:27<00:00, 87.33s/it]
  5%|▌         | 265/5198 [8:00:40<134:31:25, 98.17s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.34s/it][A100%|██████████| 1/1 [01:27<00:00, 87.34s/it]
  5%|▌         | 265/5198 [8:00:42<134:31:27, 98.17s/it] 
Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_249
100%|██████████| 1/1 [01:27<00:00, 87.35s/it][A100%|██████████| 1/1 [01:27<00:00, 87.35s/it]
  5%|▌         | 265/5198 [8:00:40<134:31:40, 98.18s/it] Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.21s/it][A100%|██████████| 1/1 [01:28<00:00, 88.21s/it]
  5%|▌         | 266/5198 [8:02:07<130:31:54, 95.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 03:27:13,327] [INFO] [logging.py:96:log_dist] [Rank 0] step=262, skipped=0, lr=[1.9986877617309664e-05], mom=[(0.9, 0.999)]
steps: 262 loss: 0.5838 iter time (s): 87.619 samples/sec: 1.461

100%|██████████| 1/1 [01:28<00:00, 88.41s/it][A100%|██████████| 1/1 [01:28<00:00, 88.41s/it]
  5%|▌         | 266/5198 [8:02:07<130:29:10, 95.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.47s/it][A100%|██████████| 1/1 [01:28<00:00, 88.47s/it]
  5%|▌         | 266/5198 [8:02:08<130:30:52, 95.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.54s/it][A100%|██████████| 1/1 [01:28<00:00, 88.54s/it]
  5%|▌         | 266/5198 [8:02:08<130:31:58, 95.28s/it]
100%|██████████| 1/1 [01:28<00:00, 88.42s/it][A100%|██████████| 1/1 [01:28<00:00, 88.42s/it]
  5%|▌         | 266/5198 [8:02:08<130:30:03, 95.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.44s/it][A100%|██████████| 1/1 [01:28<00:00, 88.44s/it]
  5%|▌         | 266/5198 [8:02:08<130:29:55, 95.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.43s/it][A100%|██████████| 1/1 [01:28<00:00, 88.43s/it]
  5%|▌         | 266/5198 [8:02:08<130:29:58, 95.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.44s/it][A100%|██████████| 1/1 [01:28<00:00, 88.44s/it]
  5%|▌         | 266/5198 [8:02:10<130:30:07, 95.26s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_250
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.89s/it][A100%|██████████| 1/1 [01:41<00:00, 101.89s/it]
  5%|▌         | 267/5198 [8:03:49<133:17:22, 97.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 03:28:55,772] [INFO] [logging.py:96:log_dist] [Rank 0] step=263, skipped=0, lr=[1.998658595330195e-05], mom=[(0.9, 0.999)]
steps: 263 loss: 0.6133 iter time (s): 101.617 samples/sec: 1.260

100%|██████████| 1/1 [01:42<00:00, 102.50s/it][A100%|██████████| 1/1 [01:42<00:00, 102.50s/it]
  5%|▌         | 267/5198 [8:03:50<133:26:42, 97.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.45s/it][A100%|██████████| 1/1 [01:42<00:00, 102.45s/it]
  5%|▌         | 267/5198 [8:03:50<133:26:41, 97.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.38s/it][A100%|██████████| 1/1 [01:42<00:00, 102.38s/it]
  5%|▌         | 267/5198 [8:03:50<133:25:46, 97.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.46s/it][A100%|██████████| 1/1 [01:42<00:00, 102.46s/it]
  5%|▌         | 267/5198 [8:03:51<133:26:13, 97.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.46s/it][A100%|██████████| 1/1 [01:42<00:00, 102.46s/it]
  5%|▌         | 267/5198 [8:03:51<133:26:05, 97.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.44s/it][A100%|██████████| 1/1 [01:42<00:00, 102.44s/it]
  5%|▌         | 267/5198 [8:03:51<133:25:40, 97.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.44s/it][A100%|██████████| 1/1 [01:42<00:00, 102.44s/it]
  5%|▌         | 267/5198 [8:03:53<133:25:49, 97.41s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_251
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.36s/it][A100%|██████████| 1/1 [01:38<00:00, 98.36s/it]
  5%|▌         | 268/5198 [8:05:28<133:44:48, 97.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 03:30:34,166] [INFO] [logging.py:96:log_dist] [Rank 0] step=264, skipped=0, lr=[1.9986291085670394e-05], mom=[(0.9, 0.999)]
steps: 264 loss: 0.6258 iter time (s): 97.563 samples/sec: 1.312

100%|██████████| 1/1 [01:38<00:00, 98.37s/it][A100%|██████████| 1/1 [01:38<00:00, 98.37s/it]
  5%|▌         | 268/5198 [8:05:28<133:48:29, 97.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.27s/it][A100%|██████████| 1/1 [01:38<00:00, 98.28s/it]
  5%|▌         | 268/5198 [8:05:28<133:46:21, 97.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.35s/it][A100%|██████████| 1/1 [01:38<00:00, 98.35s/it]
  5%|▌         | 268/5198 [8:05:29<133:47:23, 97.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.35s/it][A100%|██████████| 1/1 [01:38<00:00, 98.35s/it]
  5%|▌         | 268/5198 [8:05:29<133:47:51, 97.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.32s/it][A100%|██████████| 1/1 [01:38<00:00, 98.32s/it]
  5%|▌         | 268/5198 [8:05:29<133:46:58, 97.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.34s/it][A100%|██████████| 1/1 [01:38<00:00, 98.34s/it]
  5%|▌         | 268/5198 [8:05:29<133:47:09, 97.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.34s/it][A100%|██████████| 1/1 [01:38<00:00, 98.34s/it]
  5%|▌         | 268/5198 [8:05:31<133:47:16, 97.70s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_252
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.53s/it][A100%|██████████| 1/1 [01:36<00:00, 96.53s/it]
  5%|▌         | 269/5198 [8:07:04<133:18:39, 97.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 03:32:10,787] [INFO] [logging.py:96:log_dist] [Rank 0] step=265, skipped=0, lr=[1.9985993014509595e-05], mom=[(0.9, 0.999)]
steps: 265 loss: 0.6208 iter time (s): 95.832 samples/sec: 1.336

100%|██████████| 1/1 [01:36<00:00, 96.56s/it][A100%|██████████| 1/1 [01:36<00:00, 96.56s/it]
  5%|▌         | 269/5198 [8:07:05<133:18:38, 97.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.59s/it][A100%|██████████| 1/1 [01:36<00:00, 96.59s/it]
  5%|▌         | 269/5198 [8:07:05<133:17:53, 97.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.59s/it][A100%|██████████| 1/1 [01:36<00:00, 96.59s/it]
  5%|▌         | 269/5198 [8:07:05<133:18:34, 97.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.56s/it][A100%|██████████| 1/1 [01:36<00:00, 96.56s/it]
  5%|▌         | 269/5198 [8:07:05<133:18:14, 97.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.60s/it][A100%|██████████| 1/1 [01:36<00:00, 96.60s/it]
  5%|▌         | 269/5198 [8:07:06<133:18:45, 97.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.59s/it][A100%|██████████| 1/1 [01:36<00:00, 96.59s/it]
  5%|▌         | 269/5198 [8:07:08<133:18:33, 97.37s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_253

100%|██████████| 1/1 [01:36<00:00, 96.61s/it][A100%|██████████| 1/1 [01:36<00:00, 96.61s/it]
Training on 128 of 128 sentences.
  5%|▌         | 269/5198 [8:07:06<133:18:57, 97.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.91s/it][A100%|██████████| 1/1 [01:24<00:00, 84.91s/it]
  5%|▌         | 270/5198 [8:08:29<128:13:39, 93.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 03:33:35,497] [INFO] [logging.py:96:log_dist] [Rank 0] step=266, skipped=0, lr=[1.9985691739915178e-05], mom=[(0.9, 0.999)]
steps: 266 loss: 0.6045 iter time (s): 83.948 samples/sec: 1.525

100%|██████████| 1/1 [01:24<00:00, 84.73s/it][A100%|██████████| 1/1 [01:24<00:00, 84.73s/it]
  5%|▌         | 270/5198 [8:08:30<128:06:07, 93.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.79s/it][A100%|██████████| 1/1 [01:24<00:00, 84.79s/it]
  5%|▌         | 270/5198 [8:08:30<128:06:48, 93.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.75s/it][A100%|██████████| 1/1 [01:24<00:00, 84.75s/it]
  5%|▌         | 270/5198 [8:08:30<128:06:15, 93.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.79s/it][A100%|██████████| 1/1 [01:24<00:00, 84.79s/it]
  5%|▌         | 270/5198 [8:08:30<128:07:03, 93.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.76s/it][A100%|██████████| 1/1 [01:24<00:00, 84.76s/it]
  5%|▌         | 270/5198 [8:08:30<128:06:35, 93.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.74s/it][A100%|██████████| 1/1 [01:24<00:00, 84.74s/it]
  5%|▌         | 270/5198 [8:08:30<128:06:16, 93.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.76s/it][A100%|██████████| 1/1 [01:24<00:00, 84.76s/it]
  5%|▌         | 270/5198 [8:08:33<128:06:35, 93.59s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_254
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.48s/it][A100%|██████████| 1/1 [01:20<00:00, 80.48s/it]
  5%|▌         | 271/5198 [8:09:50<122:51:34, 89.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 03:34:56,048] [INFO] [logging.py:96:log_dist] [Rank 0] step=267, skipped=0, lr=[1.9985387261983802e-05], mom=[(0.9, 0.999)]
steps: 267 loss: 0.5812 iter time (s): 79.728 samples/sec: 1.605

100%|██████████| 1/1 [01:20<00:00, 80.59s/it][A100%|██████████| 1/1 [01:20<00:00, 80.60s/it]
  5%|▌         | 271/5198 [8:09:50<122:44:53, 89.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.53s/it][A100%|██████████| 1/1 [01:20<00:00, 80.53s/it]
  5%|▌         | 271/5198 [8:09:50<122:43:40, 89.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.52s/it][A100%|██████████| 1/1 [01:20<00:00, 80.52s/it]
  5%|▌         | 271/5198 [8:09:51<122:43:08, 89.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.47s/it][A100%|██████████| 1/1 [01:20<00:00, 80.47s/it]
  5%|▌         | 271/5198 [8:09:51<122:42:22, 89.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.49s/it][A100%|██████████| 1/1 [01:20<00:00, 80.49s/it]
  5%|▌         | 271/5198 [8:09:51<122:42:31, 89.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.54s/it][A100%|██████████| 1/1 [01:20<00:00, 80.54s/it]
  5%|▌         | 271/5198 [8:09:51<122:43:29, 89.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.53s/it][A100%|██████████| 1/1 [01:20<00:00, 80.53s/it]
  5%|▌         | 271/5198 [8:09:53<122:43:34, 89.67s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_16
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:57<00:00, 117.73s/it][A100%|██████████| 1/1 [01:57<00:00, 117.73s/it]
  5%|▌         | 272/5198 [8:11:48<134:21:04, 98.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 03:36:54,668] [INFO] [logging.py:96:log_dist] [Rank 0] step=268, skipped=0, lr=[1.998507958081315e-05], mom=[(0.9, 0.999)]
steps: 268 loss: 0.8055 iter time (s): 118.036 samples/sec: 1.084

100%|██████████| 1/1 [01:58<00:00, 118.76s/it][A100%|██████████| 1/1 [01:58<00:00, 118.76s/it]
  5%|▌         | 272/5198 [8:11:49<134:39:45, 98.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.80s/it][A100%|██████████| 1/1 [01:58<00:00, 118.80s/it]
  5%|▌         | 272/5198 [8:11:49<134:39:57, 98.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.79s/it][A100%|██████████| 1/1 [01:58<00:00, 118.79s/it]
  5%|▌         | 272/5198 [8:11:49<134:39:11, 98.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.84s/it][A100%|██████████| 1/1 [01:58<00:00, 118.84s/it]
  5%|▌         | 272/5198 [8:11:50<134:39:45, 98.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.85s/it][A100%|██████████| 1/1 [01:58<00:00, 118.85s/it]
  5%|▌         | 272/5198 [8:11:50<134:40:13, 98.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.79s/it][A100%|██████████| 1/1 [01:58<00:00, 118.79s/it]
  5%|▌         | 272/5198 [8:11:52<134:39:27, 98.41s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_255

100%|██████████| 1/1 [01:58<00:00, 118.80s/it][A100%|██████████| 1/1 [01:58<00:00, 118.81s/it]
  5%|▌         | 272/5198 [8:11:50<134:39:44, 98.41s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.96s/it][A100%|██████████| 1/1 [01:22<00:00, 82.96s/it]
  5%|▌         | 273/5198 [8:13:11<128:09:05, 93.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 03:38:17,044] [INFO] [logging.py:96:log_dist] [Rank 0] step=269, skipped=0, lr=[1.998476869650194e-05], mom=[(0.9, 0.999)]
steps: 269 loss: 0.5665 iter time (s): 81.393 samples/sec: 1.573

100%|██████████| 1/1 [01:22<00:00, 82.16s/it][A100%|██████████| 1/1 [01:22<00:00, 82.16s/it]
  5%|▌         | 273/5198 [8:13:11<127:58:15, 93.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.17s/it][A100%|██████████| 1/1 [01:22<00:00, 82.17s/it]
  5%|▌         | 273/5198 [8:13:11<127:58:21, 93.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.13s/it][A100%|██████████| 1/1 [01:22<00:00, 82.13s/it]
  5%|▌         | 273/5198 [8:13:12<127:57:03, 93.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.13s/it][A100%|██████████| 1/1 [01:22<00:00, 82.13s/it]
  5%|▌         | 273/5198 [8:13:12<127:57:48, 93.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.22s/it][A100%|██████████| 1/1 [01:22<00:00, 82.22s/it]
  5%|▌         | 273/5198 [8:13:12<127:59:31, 93.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.16s/it][A100%|██████████| 1/1 [01:22<00:00, 82.16s/it]
  5%|▌         | 273/5198 [8:13:12<127:57:58, 93.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.19s/it][A100%|██████████| 1/1 [01:22<00:00, 82.19s/it]
  5%|▌         | 273/5198 [8:13:14<127:58:28, 93.54s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_256
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.58s/it][A100%|██████████| 1/1 [01:40<00:00, 100.58s/it]
  5%|▌         | 274/5198 [8:14:52<131:00:38, 95.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 03:39:58,292] [INFO] [logging.py:96:log_dist] [Rank 0] step=270, skipped=0, lr=[1.9984454609149903e-05], mom=[(0.9, 0.999)]
steps: 270 loss: 0.6205 iter time (s): 100.443 samples/sec: 1.274

100%|██████████| 1/1 [01:41<00:00, 101.26s/it][A100%|██████████| 1/1 [01:41<00:00, 101.26s/it]
  5%|▌         | 274/5198 [8:14:52<131:06:59, 95.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.29s/it][A100%|██████████| 1/1 [01:41<00:00, 101.29s/it]
  5%|▌         | 274/5198 [8:14:53<131:07:57, 95.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.44s/it][A100%|██████████| 1/1 [01:41<00:00, 101.44s/it]
  5%|▌         | 274/5198 [8:14:53<131:10:30, 95.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.31s/it][A100%|██████████| 1/1 [01:41<00:00, 101.31s/it]
  5%|▌         | 274/5198 [8:14:53<131:07:47, 95.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.32s/it][A100%|██████████| 1/1 [01:41<00:00, 101.32s/it]
  5%|▌         | 274/5198 [8:14:53<131:09:12, 95.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.31s/it][A100%|██████████| 1/1 [01:41<00:00, 101.32s/it]
  5%|▌         | 274/5198 [8:14:55<131:08:21, 95.88s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_257

100%|██████████| 1/1 [01:41<00:00, 101.35s/it][A100%|██████████| 1/1 [01:41<00:00, 101.35s/it]
  5%|▌         | 274/5198 [8:14:53<131:08:47, 95.88s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.99s/it][A100%|██████████| 1/1 [01:26<00:00, 86.99s/it]
  5%|▌         | 275/5198 [8:16:19<127:26:00, 93.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 03:41:25,045] [INFO] [logging.py:96:log_dist] [Rank 0] step=271, skipped=0, lr=[1.9984137318857806e-05], mom=[(0.9, 0.999)]
steps: 271 loss: 0.6330 iter time (s): 85.875 samples/sec: 1.491

100%|██████████| 1/1 [01:26<00:00, 86.68s/it][A100%|██████████| 1/1 [01:26<00:00, 86.68s/it]
  5%|▌         | 275/5198 [8:16:19<127:19:42, 93.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.66s/it][A100%|██████████| 1/1 [01:26<00:00, 86.66s/it]
  5%|▌         | 275/5198 [8:16:19<127:19:42, 93.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.63s/it][A100%|██████████| 1/1 [01:26<00:00, 86.63s/it]
  5%|▌         | 275/5198 [8:16:20<127:20:53, 93.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.60s/it][A100%|██████████| 1/1 [01:26<00:00, 86.60s/it]
  5%|▌         | 275/5198 [8:16:20<127:19:06, 93.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.66s/it][A100%|██████████| 1/1 [01:26<00:00, 86.66s/it]
  5%|▌         | 275/5198 [8:16:20<127:19:47, 93.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.63s/it][A100%|██████████| 1/1 [01:26<00:00, 86.63s/it]
  5%|▌         | 275/5198 [8:16:20<127:19:35, 93.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.65s/it][A100%|██████████| 1/1 [01:26<00:00, 86.65s/it]
  5%|▌         | 275/5198 [8:16:22<127:19:41, 93.11s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_258
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.43s/it][A100%|██████████| 1/1 [01:37<00:00, 97.43s/it]
  5%|▌         | 276/5198 [8:17:56<129:12:47, 94.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 03:43:02,941] [INFO] [logging.py:96:log_dist] [Rank 0] step=272, skipped=0, lr=[1.998381682572745e-05], mom=[(0.9, 0.999)]
steps: 272 loss: 0.6147 iter time (s): 97.120 samples/sec: 1.318

100%|██████████| 1/1 [01:37<00:00, 97.88s/it][A100%|██████████| 1/1 [01:37<00:00, 97.88s/it]
  5%|▌         | 276/5198 [8:17:57<129:15:51, 94.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.96s/it][A100%|██████████| 1/1 [01:37<00:00, 97.96s/it]
  5%|▌         | 276/5198 [8:17:57<129:17:50, 94.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.84s/it][A100%|██████████| 1/1 [01:37<00:00, 97.84s/it]
  5%|▌         | 276/5198 [8:17:58<129:14:15, 94.53s/it]
100%|██████████| 1/1 [01:37<00:00, 97.85s/it][A100%|██████████| 1/1 [01:37<00:00, 97.85s/it]
  5%|▌         | 276/5198 [8:17:58<129:16:02, 94.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.88s/it][A100%|██████████| 1/1 [01:37<00:00, 97.88s/it]
  5%|▌         | 276/5198 [8:17:58<129:15:51, 94.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.86s/it][A100%|██████████| 1/1 [01:37<00:00, 97.86s/it]
  5%|▌         | 276/5198 [8:17:58<129:15:13, 94.54s/it]
100%|██████████| 1/1 [01:37<00:00, 97.86s/it][A100%|██████████| 1/1 [01:37<00:00, 97.86s/it]
  5%|▌         | 276/5198 [8:18:00<129:15:02, 94.54s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_259
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.33s/it][A100%|██████████| 1/1 [01:39<00:00, 99.33s/it]
  5%|▌         | 277/5198 [8:19:36<131:13:39, 96.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 03:44:42,404] [INFO] [logging.py:96:log_dist] [Rank 0] step=273, skipped=0, lr=[1.9983493129861654e-05], mom=[(0.9, 0.999)]
steps: 273 loss: 0.6561 iter time (s): 98.722 samples/sec: 1.297

100%|██████████| 1/1 [01:39<00:00, 99.42s/it][A100%|██████████| 1/1 [01:39<00:00, 99.42s/it]
  5%|▌         | 277/5198 [8:19:36<131:14:32, 96.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.44s/it][A100%|██████████| 1/1 [01:39<00:00, 99.44s/it]
  5%|▌         | 277/5198 [8:19:37<131:16:16, 96.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.48s/it][A100%|██████████| 1/1 [01:39<00:00, 99.49s/it]
  5%|▌         | 277/5198 [8:19:37<131:14:55, 96.02s/it]
100%|██████████| 1/1 [01:39<00:00, 99.48s/it][A100%|██████████| 1/1 [01:39<00:00, 99.48s/it]
  5%|▌         | 277/5198 [8:19:37<131:16:11, 96.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.43s/it][A100%|██████████| 1/1 [01:39<00:00, 99.43s/it]
  5%|▌         | 277/5198 [8:19:37<131:14:43, 96.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.43s/it][A100%|██████████| 1/1 [01:39<00:00, 99.43s/it]
  5%|▌         | 277/5198 [8:19:37<131:14:11, 96.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.45s/it][A100%|██████████| 1/1 [01:39<00:00, 99.45s/it]
  5%|▌         | 277/5198 [8:19:39<131:14:34, 96.01s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_260
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.26s/it][A100%|██████████| 1/1 [01:22<00:00, 82.27s/it]
  5%|▌         | 278/5198 [8:20:58<125:37:41, 91.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 03:46:04,383] [INFO] [logging.py:96:log_dist] [Rank 0] step=274, skipped=0, lr=[1.9983166231364267e-05], mom=[(0.9, 0.999)]
steps: 274 loss: 0.5807 iter time (s): 81.242 samples/sec: 1.576

100%|██████████| 1/1 [01:21<00:00, 81.96s/it][A100%|██████████| 1/1 [01:21<00:00, 81.96s/it]
  5%|▌         | 278/5198 [8:20:58<125:27:27, 91.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.01s/it][A100%|██████████| 1/1 [01:22<00:00, 82.01s/it]
  5%|▌         | 278/5198 [8:20:59<125:30:00, 91.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.88s/it][A100%|██████████| 1/1 [01:21<00:00, 81.89s/it]
  5%|▌         | 278/5198 [8:20:59<125:26:50, 91.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 82.00s/it][A100%|██████████| 1/1 [01:21<00:00, 82.00s/it]
  5%|▌         | 278/5198 [8:20:59<125:28:39, 91.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.01s/it][A100%|██████████| 1/1 [01:22<00:00, 82.01s/it]

  5%|▌         | 278/5198 [8:20:59<125:28:26, 91.81s/it]100%|██████████| 1/1 [01:22<00:00, 82.04s/it][A100%|██████████| 1/1 [01:22<00:00, 82.04s/it]
  5%|▌         | 278/5198 [8:20:59<125:29:38, 91.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.03s/it][A100%|██████████| 1/1 [01:22<00:00, 82.03s/it]
  5%|▌         | 278/5198 [8:21:01<125:29:14, 91.82s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_261
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.51s/it][A100%|██████████| 1/1 [01:42<00:00, 102.52s/it]
  5%|▌         | 279/5198 [8:22:41<129:59:42, 95.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 03:47:47,472] [INFO] [logging.py:96:log_dist] [Rank 0] step=275, skipped=0, lr=[1.9982836130340166e-05], mom=[(0.9, 0.999)]
steps: 275 loss: 0.6255 iter time (s): 102.400 samples/sec: 1.250

100%|██████████| 1/1 [01:43<00:00, 103.20s/it][A100%|██████████| 1/1 [01:43<00:00, 103.20s/it]
  5%|▌         | 279/5198 [8:22:42<130:06:37, 95.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.05s/it][A100%|██████████| 1/1 [01:43<00:00, 103.05s/it]
  5%|▌         | 279/5198 [8:22:42<130:04:46, 95.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.19s/it][A100%|██████████| 1/1 [01:43<00:00, 103.19s/it]
  5%|▌         | 279/5198 [8:22:42<130:05:53, 95.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.11s/it][A100%|██████████| 1/1 [01:43<00:00, 103.11s/it]
  5%|▌         | 279/5198 [8:22:42<130:05:46, 95.21s/it]
100%|██████████| 1/1 [01:43<00:00, 103.19s/it][A100%|██████████| 1/1 [01:43<00:00, 103.19s/it]
  5%|▌         | 279/5198 [8:22:42<130:07:08, 95.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.18s/it][A100%|██████████| 1/1 [01:43<00:00, 103.18s/it]
  5%|▌         | 279/5198 [8:22:42<130:06:47, 95.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.15s/it][A100%|██████████| 1/1 [01:43<00:00, 103.15s/it]
  5%|▌         | 279/5198 [8:22:45<130:06:39, 95.22s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_262
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:16<00:00, 136.41s/it][A100%|██████████| 1/1 [02:16<00:00, 136.41s/it]
  5%|▌         | 280/5198 [8:24:58<146:57:39, 107.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 03:50:04,424] [INFO] [logging.py:96:log_dist] [Rank 0] step=276, skipped=0, lr=[1.9982502826895257e-05], mom=[(0.9, 0.999)]
steps: 276 loss: 0.5823 iter time (s): 136.263 samples/sec: 0.939

100%|██████████| 1/1 [02:17<00:00, 137.02s/it][A100%|██████████| 1/1 [02:17<00:00, 137.02s/it]
  5%|▌         | 280/5198 [8:24:59<147:13:03, 107.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:16<00:00, 136.99s/it][A100%|██████████| 1/1 [02:16<00:00, 136.99s/it]
  5%|▌         | 280/5198 [8:24:59<147:10:55, 107.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:17<00:00, 137.04s/it][A100%|██████████| 1/1 [02:17<00:00, 137.04s/it]
  5%|▌         | 280/5198 [8:24:59<147:12:58, 107.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:17<00:00, 137.02s/it][A100%|██████████| 1/1 [02:17<00:00, 137.02s/it]
  5%|▌         | 280/5198 [8:24:59<147:13:20, 107.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:17<00:00, 137.04s/it][A100%|██████████| 1/1 [02:17<00:00, 137.04s/it]
  5%|▌         | 280/5198 [8:24:59<147:12:58, 107.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:17<00:00, 137.00s/it][A100%|██████████| 1/1 [02:17<00:00, 137.00s/it]
  5%|▌         | 280/5198 [8:24:59<147:12:44, 107.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:17<00:00, 137.04s/it][A100%|██████████| 1/1 [02:17<00:00, 137.04s/it]
  5%|▌         | 280/5198 [8:25:02<147:13:29, 107.77s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_263
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:24<00:00, 144.39s/it][A100%|██████████| 1/1 [02:24<00:00, 144.39s/it]
  5%|▌         | 281/5198 [8:27:22<162:13:29, 118.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 03:52:30,073] [INFO] [logging.py:96:log_dist] [Rank 0] step=277, skipped=0, lr=[1.9982166321136472e-05], mom=[(0.9, 0.999)]
steps: 277 loss: 0.6163 iter time (s): 144.700 samples/sec: 0.885

100%|██████████| 1/1 [02:25<00:00, 145.50s/it][A100%|██████████| 1/1 [02:25<00:00, 145.50s/it]
  5%|▌         | 281/5198 [8:27:24<162:39:17, 119.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:25<00:00, 145.61s/it][A100%|██████████| 1/1 [02:25<00:00, 145.61s/it]
  5%|▌         | 281/5198 [8:27:24<162:40:25, 119.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:25<00:00, 145.49s/it][A100%|██████████| 1/1 [02:25<00:00, 145.49s/it]
  5%|▌         | 281/5198 [8:27:25<162:38:56, 119.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:25<00:00, 145.48s/it][A100%|██████████| 1/1 [02:25<00:00, 145.48s/it]
  5%|▌         | 281/5198 [8:27:25<162:38:52, 119.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:25<00:00, 145.52s/it][A100%|██████████| 1/1 [02:25<00:00, 145.52s/it]
  5%|▌         | 281/5198 [8:27:25<162:39:46, 119.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:25<00:00, 145.52s/it][A100%|██████████| 1/1 [02:25<00:00, 145.52s/it]
  5%|▌         | 281/5198 [8:27:25<162:39:35, 119.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:25<00:00, 145.49s/it][A100%|██████████| 1/1 [02:25<00:00, 145.49s/it]
  5%|▌         | 281/5198 [8:27:27<162:39:13, 119.09s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_264
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.23s/it][A100%|██████████| 1/1 [01:43<00:00, 103.23s/it]
  5%|▌         | 282/5198 [8:29:06<155:54:44, 114.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 03:54:12,000] [INFO] [logging.py:96:log_dist] [Rank 0] step=278, skipped=0, lr=[1.9981826613171765e-05], mom=[(0.9, 0.999)]
steps: 278 loss: 0.6120 iter time (s): 101.116 samples/sec: 1.266

100%|██████████| 1/1 [01:41<00:00, 101.97s/it][A100%|██████████| 1/1 [01:41<00:00, 101.97s/it]
  5%|▌         | 282/5198 [8:29:06<155:36:44, 113.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.91s/it][A100%|██████████| 1/1 [01:41<00:00, 101.92s/it]
  5%|▌         | 282/5198 [8:29:06<155:36:12, 113.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.92s/it][A100%|██████████| 1/1 [01:41<00:00, 101.92s/it]
  5%|▌         | 282/5198 [8:29:07<155:35:26, 113.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 102.00s/it][A100%|██████████| 1/1 [01:41<00:00, 102.00s/it]
  5%|▌         | 282/5198 [8:29:07<155:37:10, 113.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.95s/it][A100%|██████████| 1/1 [01:41<00:00, 101.95s/it]
  5%|▌         | 282/5198 [8:29:07<155:36:35, 113.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.97s/it][A100%|██████████| 1/1 [01:41<00:00, 101.97s/it]
  5%|▌         | 282/5198 [8:29:07<155:36:52, 113.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.98s/it][A100%|██████████| 1/1 [01:41<00:00, 101.98s/it]
  5%|▌         | 282/5198 [8:29:09<155:36:49, 113.96s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_265
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.51s/it][A100%|██████████| 1/1 [01:30<00:00, 90.51s/it]
  5%|▌         | 283/5198 [8:30:37<146:14:56, 107.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 03:55:42,859] [INFO] [logging.py:96:log_dist] [Rank 0] step=279, skipped=0, lr=[1.9981483703110132e-05], mom=[(0.9, 0.999)]
steps: 279 loss: 0.6267 iter time (s): 89.995 samples/sec: 1.422

100%|██████████| 1/1 [01:30<00:00, 90.79s/it][A100%|██████████| 1/1 [01:30<00:00, 90.79s/it]
  5%|▌         | 283/5198 [8:30:37<146:05:49, 107.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.75s/it][A100%|██████████| 1/1 [01:30<00:00, 90.75s/it]
  5%|▌         | 283/5198 [8:30:37<146:04:36, 106.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.84s/it][A100%|██████████| 1/1 [01:30<00:00, 90.84s/it]
  5%|▌         | 283/5198 [8:30:37<146:06:02, 107.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.71s/it][A100%|██████████| 1/1 [01:30<00:00, 90.71s/it]
  5%|▌         | 283/5198 [8:30:38<146:04:01, 106.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.73s/it][A100%|██████████| 1/1 [01:30<00:00, 90.73s/it]
  5%|▌         | 283/5198 [8:30:38<146:04:10, 106.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.77s/it][A100%|██████████| 1/1 [01:30<00:00, 90.78s/it]
  5%|▌         | 283/5198 [8:30:38<146:05:28, 107.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.77s/it][A100%|██████████| 1/1 [01:30<00:00, 90.77s/it]
  5%|▌         | 283/5198 [8:30:40<146:05:11, 107.00s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_266
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.16s/it][A100%|██████████| 1/1 [01:26<00:00, 86.16s/it]
  5%|▌         | 284/5198 [8:32:03<137:42:33, 100.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 03:57:09,072] [INFO] [logging.py:96:log_dist] [Rank 0] step=280, skipped=0, lr=[1.9981137591061585e-05], mom=[(0.9, 0.999)]
steps: 280 loss: 0.5889 iter time (s): 85.433 samples/sec: 1.498

100%|██████████| 1/1 [01:26<00:00, 86.40s/it][A100%|██████████| 1/1 [01:26<00:00, 86.40s/it]
  5%|▌         | 284/5198 [8:32:03<137:38:02, 100.83s/it]
100%|██████████| 1/1 [01:26<00:00, 86.36s/it][A100%|██████████| 1/1 [01:26<00:00, 86.36s/it]
  5%|▌         | 284/5198 [8:32:03<137:36:03, 100.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.26s/it][A100%|██████████| 1/1 [01:26<00:00, 86.26s/it]
  5%|▌         | 284/5198 [8:32:04<137:34:41, 100.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.48s/it][A100%|██████████| 1/1 [01:26<00:00, 86.48s/it]

  5%|▌         | 284/5198 [8:32:04<137:38:47, 100.84s/it]100%|██████████| 1/1 [01:26<00:00, 86.53s/it][A100%|██████████| 1/1 [01:26<00:00, 86.53s/it]
  5%|▌         | 284/5198 [8:32:04<137:39:41, 100.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.62s/it][A100%|██████████| 1/1 [01:26<00:00, 86.62s/it]
  5%|▌         | 284/5198 [8:32:07<137:42:50, 100.89s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_267
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.74s/it][A100%|██████████| 1/1 [01:26<00:00, 86.74s/it]
  5%|▌         | 284/5198 [8:32:04<137:45:57, 100.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.20s/it][A100%|██████████| 1/1 [01:31<00:00, 91.20s/it]
  5%|▌         | 285/5198 [8:33:34<133:47:06, 98.03s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 03:58:40,539] [INFO] [logging.py:96:log_dist] [Rank 0] step=281, skipped=0, lr=[1.9980788277137157e-05], mom=[(0.9, 0.999)]
steps: 281 loss: 0.5812 iter time (s): 90.267 samples/sec: 1.418

100%|██████████| 1/1 [01:31<00:00, 91.23s/it][A100%|██████████| 1/1 [01:31<00:00, 91.23s/it]
  5%|▌         | 285/5198 [8:33:35<133:41:15, 97.96s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.26s/it][A100%|██████████| 1/1 [01:31<00:00, 91.26s/it]
  5%|▌         | 285/5198 [8:33:35<133:40:32, 97.95s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.30s/it][A100%|██████████| 1/1 [01:31<00:00, 91.30s/it]
  5%|▌         | 285/5198 [8:33:35<133:40:36, 97.95s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.20s/it][A100%|██████████| 1/1 [01:31<00:00, 91.20s/it]
  5%|▌         | 285/5198 [8:33:35<133:41:09, 97.96s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.93s/it][A100%|██████████| 1/1 [01:30<00:00, 90.93s/it]
  5%|▌         | 285/5198 [8:33:35<133:39:00, 97.93s/it] 
100%|██████████| 1/1 [01:31<00:00, 91.29s/it][A100%|██████████| 1/1 [01:31<00:00, 91.29s/it]
  5%|▌         | 285/5198 [8:33:35<133:42:44, 97.98s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.06s/it][A100%|██████████| 1/1 [01:31<00:00, 91.06s/it]
  5%|▌         | 285/5198 [8:33:38<133:39:52, 97.94s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_268
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.25s/it][A100%|██████████| 1/1 [01:29<00:00, 89.25s/it]
  6%|▌         | 286/5198 [8:35:04<130:13:33, 95.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 04:00:09,954] [INFO] [logging.py:96:log_dist] [Rank 0] step=282, skipped=0, lr=[1.9980435761448926e-05], mom=[(0.9, 0.999)]
steps: 282 loss: 0.5721 iter time (s): 88.602 samples/sec: 1.445

100%|██████████| 1/1 [01:29<00:00, 89.49s/it][A100%|██████████| 1/1 [01:29<00:00, 89.49s/it]
  6%|▌         | 286/5198 [8:35:04<130:11:52, 95.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.65s/it][A100%|██████████| 1/1 [01:29<00:00, 89.65s/it]
  6%|▌         | 286/5198 [8:35:04<130:15:13, 95.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.57s/it][A100%|██████████| 1/1 [01:29<00:00, 89.57s/it]
  6%|▌         | 286/5198 [8:35:05<130:13:17, 95.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.44s/it][A100%|██████████| 1/1 [01:29<00:00, 89.44s/it]
  6%|▌         | 286/5198 [8:35:05<130:11:34, 95.42s/it]
100%|██████████| 1/1 [01:29<00:00, 89.54s/it][A100%|██████████| 1/1 [01:29<00:00, 89.54s/it]
  6%|▌         | 286/5198 [8:35:05<130:12:52, 95.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.84s/it][A100%|██████████| 1/1 [01:29<00:00, 89.84s/it]
  6%|▌         | 286/5198 [8:35:05<130:18:45, 95.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.82s/it][A100%|██████████| 1/1 [01:29<00:00, 89.82s/it]
  6%|▌         | 286/5198 [8:35:07<130:19:13, 95.51s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_269
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.34s/it][A100%|██████████| 1/1 [01:28<00:00, 88.34s/it]
  6%|▌         | 287/5198 [8:36:32<127:21:25, 93.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 04:01:38,343] [INFO] [logging.py:96:log_dist] [Rank 0] step=283, skipped=0, lr=[1.9980080044109983e-05], mom=[(0.9, 0.999)]
steps: 283 loss: 0.6314 iter time (s): 87.163 samples/sec: 1.469

100%|██████████| 1/1 [01:28<00:00, 88.29s/it][A100%|██████████| 1/1 [01:28<00:00, 88.29s/it]
  6%|▌         | 287/5198 [8:36:32<127:16:08, 93.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.22s/it][A100%|██████████| 1/1 [01:28<00:00, 88.22s/it]
  6%|▌         | 287/5198 [8:36:33<127:15:58, 93.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.30s/it][A100%|██████████| 1/1 [01:28<00:00, 88.30s/it]
  6%|▌         | 287/5198 [8:36:33<127:16:26, 93.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.43s/it][A100%|██████████| 1/1 [01:28<00:00, 88.43s/it]
  6%|▌         | 287/5198 [8:36:33<127:19:52, 93.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.38s/it][A100%|██████████| 1/1 [01:28<00:00, 88.38s/it]
  6%|▌         | 287/5198 [8:36:33<127:17:26, 93.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.03s/it][A100%|██████████| 1/1 [01:28<00:00, 88.03s/it]
  6%|▌         | 287/5198 [8:36:33<127:13:40, 93.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.04s/it][A100%|██████████| 1/1 [01:28<00:00, 88.04s/it]
  6%|▌         | 287/5198 [8:36:36<127:14:22, 93.27s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_17
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.13s/it][A100%|██████████| 1/1 [01:59<00:00, 119.13s/it]
  6%|▌         | 288/5198 [8:38:31<137:55:59, 101.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 04:03:38,261] [INFO] [logging.py:96:log_dist] [Rank 0] step=284, skipped=0, lr=[1.997972112523445e-05], mom=[(0.9, 0.999)]
steps: 284 loss: 0.8206 iter time (s): 119.266 samples/sec: 1.073

100%|██████████| 1/1 [02:00<00:00, 120.35s/it][A100%|██████████| 1/1 [02:00<00:00, 120.35s/it]
  6%|▌         | 288/5198 [8:38:33<138:19:02, 101.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.35s/it][A100%|██████████| 1/1 [02:00<00:00, 120.35s/it]
  6%|▌         | 288/5198 [8:38:33<138:18:59, 101.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.34s/it][A100%|██████████| 1/1 [02:00<00:00, 120.34s/it]
  6%|▌         | 288/5198 [8:38:33<138:21:28, 101.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.48s/it][A100%|██████████| 1/1 [02:00<00:00, 120.48s/it]
  6%|▌         | 288/5198 [8:38:34<138:22:20, 101.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.40s/it][A100%|██████████| 1/1 [02:00<00:00, 120.41s/it]
  6%|▌         | 288/5198 [8:38:36<138:19:05, 101.41s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_270

100%|██████████| 1/1 [02:00<00:00, 120.47s/it][A100%|██████████| 1/1 [02:00<00:00, 120.47s/it]
  6%|▌         | 288/5198 [8:38:34<138:22:57, 101.46s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.45s/it][A100%|██████████| 1/1 [02:00<00:00, 120.45s/it]
  6%|▌         | 288/5198 [8:38:34<138:19:42, 101.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.94s/it][A100%|██████████| 1/1 [01:51<00:00, 111.94s/it]
  6%|▌         | 289/5198 [8:40:24<142:22:50, 104.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 04:05:30,365] [INFO] [logging.py:96:log_dist] [Rank 0] step=285, skipped=0, lr=[1.9979359004937486e-05], mom=[(0.9, 0.999)]
steps: 285 loss: 0.5794 iter time (s): 110.729 samples/sec: 1.156

100%|██████████| 1/1 [01:51<00:00, 111.60s/it][A100%|██████████| 1/1 [01:51<00:00, 111.60s/it]
  6%|▌         | 289/5198 [8:40:24<142:27:38, 104.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.61s/it][A100%|██████████| 1/1 [01:51<00:00, 111.61s/it]
  6%|▌         | 289/5198 [8:40:25<142:27:46, 104.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.46s/it][A100%|██████████| 1/1 [01:51<00:00, 111.46s/it]
  6%|▌         | 289/5198 [8:40:25<142:25:48, 104.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.48s/it][A100%|██████████| 1/1 [01:51<00:00, 111.48s/it]
  6%|▌         | 289/5198 [8:40:25<142:26:56, 104.46s/it]
100%|██████████| 1/1 [01:51<00:00, 111.42s/it][A100%|██████████| 1/1 [01:51<00:00, 111.42s/it]
  6%|▌         | 289/5198 [8:40:25<142:25:49, 104.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.48s/it][A100%|██████████| 1/1 [01:51<00:00, 111.48s/it]
  6%|▌         | 289/5198 [8:40:27<142:24:36, 104.44s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_271

100%|██████████| 1/1 [01:51<00:00, 111.46s/it][A100%|██████████| 1/1 [01:51<00:00, 111.46s/it]
  6%|▌         | 289/5198 [8:40:25<142:24:42, 104.44s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.36s/it][A100%|██████████| 1/1 [01:25<00:00, 85.36s/it]
  6%|▌         | 290/5198 [8:41:49<134:43:14, 98.82s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 04:06:55,395] [INFO] [logging.py:96:log_dist] [Rank 0] step=286, skipped=0, lr=[1.9978993683335252e-05], mom=[(0.9, 0.999)]
steps: 286 loss: 0.5898 iter time (s): 84.272 samples/sec: 1.519

100%|██████████| 1/1 [01:25<00:00, 85.05s/it][A100%|██████████| 1/1 [01:25<00:00, 85.05s/it]
  6%|▌         | 290/5198 [8:41:50<134:29:32, 98.65s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.03s/it][A100%|██████████| 1/1 [01:25<00:00, 85.03s/it]
  6%|▌         | 290/5198 [8:41:50<134:29:17, 98.65s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.02s/it][A100%|██████████| 1/1 [01:25<00:00, 85.02s/it]
  6%|▌         | 290/5198 [8:41:50<134:27:39, 98.63s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.98s/it][A100%|██████████| 1/1 [01:24<00:00, 84.98s/it]
  6%|▌         | 290/5198 [8:41:50<134:27:11, 98.62s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.98s/it][A100%|██████████| 1/1 [01:24<00:00, 84.98s/it]
  6%|▌         | 290/5198 [8:41:50<134:26:34, 98.61s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.01s/it][A100%|██████████| 1/1 [01:25<00:00, 85.01s/it]
  6%|▌         | 290/5198 [8:41:50<134:26:19, 98.61s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.03s/it][A100%|██████████| 1/1 [01:25<00:00, 85.03s/it]
  6%|▌         | 290/5198 [8:41:52<134:26:41, 98.61s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_272
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.26s/it][A100%|██████████| 1/1 [01:30<00:00, 90.26s/it]
  6%|▌         | 291/5198 [8:43:20<131:15:00, 96.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 04:08:25,985] [INFO] [logging.py:96:log_dist] [Rank 0] step=287, skipped=0, lr=[1.9978625160544965e-05], mom=[(0.9, 0.999)]
steps: 287 loss: 0.6285 iter time (s): 89.829 samples/sec: 1.425

100%|██████████| 1/1 [01:30<00:00, 90.59s/it][A100%|██████████| 1/1 [01:30<00:00, 90.59s/it]
  6%|▌         | 291/5198 [8:43:20<131:10:16, 96.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.72s/it][A100%|██████████| 1/1 [01:30<00:00, 90.72s/it]
  6%|▌         | 291/5198 [8:43:20<131:13:24, 96.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.70s/it][A100%|██████████| 1/1 [01:30<00:00, 90.70s/it]
  6%|▌         | 291/5198 [8:43:21<131:11:54, 96.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.68s/it][A100%|██████████| 1/1 [01:30<00:00, 90.68s/it]
  6%|▌         | 291/5198 [8:43:21<131:10:49, 96.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.71s/it][A100%|██████████| 1/1 [01:30<00:00, 90.71s/it]
  6%|▌         | 291/5198 [8:43:21<131:11:16, 96.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.67s/it][A100%|██████████| 1/1 [01:30<00:00, 90.67s/it]
  6%|▌         | 291/5198 [8:43:21<131:09:55, 96.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.67s/it][A100%|██████████| 1/1 [01:30<00:00, 90.67s/it]
  6%|▌         | 291/5198 [8:43:23<131:10:22, 96.23s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_273
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.92s/it][A100%|██████████| 1/1 [01:31<00:00, 91.92s/it]
  6%|▌         | 292/5198 [8:44:52<129:31:19, 95.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 04:09:58,136] [INFO] [logging.py:96:log_dist] [Rank 0] step=288, skipped=0, lr=[1.9978253436684857e-05], mom=[(0.9, 0.999)]
steps: 288 loss: 0.6164 iter time (s): 91.303 samples/sec: 1.402

100%|██████████| 1/1 [01:32<00:00, 92.11s/it][A100%|██████████| 1/1 [01:32<00:00, 92.11s/it]
  6%|▌         | 292/5198 [8:44:52<129:27:36, 95.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.06s/it][A100%|██████████| 1/1 [01:32<00:00, 92.06s/it]
  6%|▌         | 292/5198 [8:44:52<129:28:48, 95.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.18s/it][A100%|██████████| 1/1 [01:32<00:00, 92.18s/it]
  6%|▌         | 292/5198 [8:44:53<129:30:32, 95.03s/it]
100%|██████████| 1/1 [01:32<00:00, 92.12s/it][A100%|██████████| 1/1 [01:32<00:00, 92.12s/it]
  6%|▌         | 292/5198 [8:44:53<129:28:23, 95.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.09s/it][A100%|██████████| 1/1 [01:32<00:00, 92.09s/it]
  6%|▌         | 292/5198 [8:44:53<129:28:01, 95.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.13s/it][A100%|██████████| 1/1 [01:32<00:00, 92.13s/it]
  6%|▌         | 292/5198 [8:44:53<129:27:58, 95.00s/it]
100%|██████████| 1/1 [01:32<00:00, 92.12s/it][A100%|██████████| 1/1 [01:32<00:00, 92.12s/it]
  6%|▌         | 292/5198 [8:44:55<129:27:56, 95.00s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_274

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.71s/it][A100%|██████████| 1/1 [01:26<00:00, 86.71s/it]
  6%|▌         | 293/5198 [8:46:19<126:10:41, 92.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 04:11:24,890] [INFO] [logging.py:96:log_dist] [Rank 0] step=289, skipped=0, lr=[1.997787851187418e-05], mom=[(0.9, 0.999)]
steps: 289 loss: 0.6361 iter time (s): 85.933 samples/sec: 1.490

100%|██████████| 1/1 [01:26<00:00, 86.72s/it][A100%|██████████| 1/1 [01:26<00:00, 86.72s/it]
  6%|▌         | 293/5198 [8:46:19<126:03:11, 92.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.72s/it][A100%|██████████| 1/1 [01:26<00:00, 86.72s/it]
  6%|▌         | 293/5198 [8:46:19<126:04:02, 92.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.55s/it][A100%|██████████| 1/1 [01:26<00:00, 86.55s/it]
  6%|▌         | 293/5198 [8:46:19<126:01:10, 92.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.65s/it][A100%|██████████| 1/1 [01:26<00:00, 86.65s/it]
  6%|▌         | 293/5198 [8:46:20<126:01:55, 92.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.67s/it][A100%|██████████| 1/1 [01:26<00:00, 86.67s/it]
  6%|▌         | 293/5198 [8:46:20<126:02:16, 92.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.65s/it][A100%|██████████| 1/1 [01:26<00:00, 86.65s/it]
  6%|▌         | 293/5198 [8:46:20<126:01:37, 92.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.67s/it][A100%|██████████| 1/1 [01:26<00:00, 86.67s/it]
  6%|▌         | 293/5198 [8:46:22<126:02:06, 92.50s/it]Shard 293 in [76, 158, 182, 242, 293, 363, 418, 421, 752, 814, 842, 991, 1266, 1366, 1425, 1464, 1574, 1728, 2166, 2441, 2563, 2739, 2854, 2894, 3089, 3181, 3395, 3576, 3831, 4300, 4589, 4947, 4950]: file /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_275 skipped to avoid exceeding cuda memory
Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_276
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.04s/it][A100%|██████████| 1/1 [01:27<00:00, 87.04s/it]
  6%|▌         | 295/5198 [8:47:46<95:18:27, 69.98s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 04:12:52,074] [INFO] [logging.py:96:log_dist] [Rank 0] step=290, skipped=0, lr=[1.997750038623322e-05], mom=[(0.9, 0.999)]
steps: 290 loss: 0.6665 iter time (s): 86.441 samples/sec: 1.481

100%|██████████| 1/1 [01:27<00:00, 87.23s/it][A100%|██████████| 1/1 [01:27<00:00, 87.23s/it]
  6%|▌         | 295/5198 [8:47:46<95:15:55, 69.95s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.17s/it][A100%|██████████| 1/1 [01:27<00:00, 87.17s/it]
  6%|▌         | 295/5198 [8:47:46<95:15:12, 69.94s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.20s/it][A100%|██████████| 1/1 [01:27<00:00, 87.20s/it]
  6%|▌         | 295/5198 [8:47:47<95:14:18, 69.93s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.23s/it][A100%|██████████| 1/1 [01:27<00:00, 87.23s/it]
  6%|▌         | 295/5198 [8:47:47<95:15:20, 69.94s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.20s/it][A100%|██████████| 1/1 [01:27<00:00, 87.20s/it]
  6%|▌         | 295/5198 [8:47:47<95:14:58, 69.94s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.23s/it][A100%|██████████| 1/1 [01:27<00:00, 87.23s/it]
  6%|▌         | 295/5198 [8:47:47<95:15:07, 69.94s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.22s/it][A100%|██████████| 1/1 [01:27<00:00, 87.22s/it]
  6%|▌         | 295/5198 [8:47:49<95:15:06, 69.94s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_277
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.54s/it][A100%|██████████| 1/1 [01:34<00:00, 94.54s/it]
  6%|▌         | 296/5198 [8:49:21<103:38:17, 76.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 04:14:27,021] [INFO] [logging.py:96:log_dist] [Rank 0] step=291, skipped=0, lr=[1.9977119059883292e-05], mom=[(0.9, 0.999)]
steps: 291 loss: 0.6231 iter time (s): 94.163 samples/sec: 1.359

100%|██████████| 1/1 [01:34<00:00, 94.95s/it][A100%|██████████| 1/1 [01:34<00:00, 94.95s/it]
  6%|▌         | 296/5198 [8:49:21<103:41:27, 76.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.97s/it][A100%|██████████| 1/1 [01:34<00:00, 94.97s/it]
  6%|▌         | 296/5198 [8:49:21<103:41:16, 76.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.94s/it][A100%|██████████| 1/1 [01:34<00:00, 94.94s/it]
  6%|▌         | 296/5198 [8:49:22<103:40:03, 76.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.90s/it][A100%|██████████| 1/1 [01:34<00:00, 94.90s/it]
  6%|▌         | 296/5198 [8:49:22<103:39:58, 76.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.97s/it][A100%|██████████| 1/1 [01:34<00:00, 94.97s/it]
  6%|▌         | 296/5198 [8:49:22<103:41:03, 76.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.93s/it][A100%|██████████| 1/1 [01:34<00:00, 94.94s/it]
  6%|▌         | 296/5198 [8:49:22<103:40:28, 76.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.95s/it][A100%|██████████| 1/1 [01:34<00:00, 94.95s/it]
  6%|▌         | 296/5198 [8:49:24<103:40:42, 76.14s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_278
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.79s/it][A100%|██████████| 1/1 [01:36<00:00, 96.79s/it]
  6%|▌         | 297/5198 [8:50:58<111:01:22, 81.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 04:16:03,964] [INFO] [logging.py:96:log_dist] [Rank 0] step=292, skipped=0, lr=[1.997673453294673e-05], mom=[(0.9, 0.999)]
steps: 292 loss: 0.6373 iter time (s): 96.152 samples/sec: 1.331

100%|██████████| 1/1 [01:36<00:00, 96.93s/it][A100%|██████████| 1/1 [01:36<00:00, 96.93s/it]
  6%|▌         | 297/5198 [8:50:58<111:04:23, 81.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.81s/it][A100%|██████████| 1/1 [01:36<00:00, 96.81s/it]
  6%|▌         | 297/5198 [8:50:58<111:01:36, 81.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.95s/it][A100%|██████████| 1/1 [01:36<00:00, 96.95s/it]
  6%|▌         | 297/5198 [8:50:59<111:03:38, 81.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.93s/it][A100%|██████████| 1/1 [01:36<00:00, 96.93s/it]
  6%|▌         | 297/5198 [8:50:59<111:03:24, 81.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.90s/it][A100%|██████████| 1/1 [01:36<00:00, 96.90s/it]
  6%|▌         | 297/5198 [8:50:59<111:03:22, 81.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.89s/it][A100%|██████████| 1/1 [01:36<00:00, 96.89s/it]
  6%|▌         | 297/5198 [8:50:59<111:02:48, 81.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.89s/it][A100%|██████████| 1/1 [01:36<00:00, 96.89s/it]
  6%|▌         | 297/5198 [8:51:01<111:02:57, 81.57s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_279
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:02<00:00, 122.57s/it][A100%|██████████| 1/1 [02:02<00:00, 122.57s/it]
  6%|▌         | 298/5198 [8:53:00<126:14:20, 92.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 04:18:07,377] [INFO] [logging.py:96:log_dist] [Rank 0] step=293, skipped=0, lr=[1.9976346805546906e-05], mom=[(0.9, 0.999)]
steps: 293 loss: 0.6353 iter time (s): 122.663 samples/sec: 1.044

100%|██████████| 1/1 [02:03<00:00, 123.36s/it][A100%|██████████| 1/1 [02:03<00:00, 123.36s/it]
  6%|▌         | 298/5198 [8:53:01<126:31:14, 92.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.53s/it][A100%|██████████| 1/1 [02:03<00:00, 123.53s/it]
  6%|▌         | 298/5198 [8:53:02<126:32:57, 92.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.53s/it][A100%|██████████| 1/1 [02:03<00:00, 123.53s/it]
  6%|▌         | 298/5198 [8:53:02<126:34:22, 92.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.53s/it][A100%|██████████| 1/1 [02:03<00:00, 123.53s/it]
  6%|▌         | 298/5198 [8:53:02<126:34:16, 92.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.53s/it][A100%|██████████| 1/1 [02:03<00:00, 123.53s/it]
  6%|▌         | 298/5198 [8:53:02<126:34:08, 92.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.53s/it][A100%|██████████| 1/1 [02:03<00:00, 123.53s/it]
  6%|▌         | 298/5198 [8:53:02<126:33:40, 92.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.51s/it][A100%|██████████| 1/1 [02:03<00:00, 123.51s/it]
  6%|▌         | 298/5198 [8:53:05<126:33:30, 92.98s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_280
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.27s/it][A100%|██████████| 1/1 [01:32<00:00, 92.27s/it]
  6%|▌         | 299/5198 [8:54:33<126:05:57, 92.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 04:19:38,953] [INFO] [logging.py:96:log_dist] [Rank 0] step=294, skipped=0, lr=[1.9975955877808212e-05], mom=[(0.9, 0.999)]
steps: 294 loss: 0.5844 iter time (s): 90.717 samples/sec: 1.411

100%|██████████| 1/1 [01:31<00:00, 91.62s/it][A100%|██████████| 1/1 [01:31<00:00, 91.62s/it]
  6%|▌         | 299/5198 [8:54:33<125:59:22, 92.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.56s/it][A100%|██████████| 1/1 [01:31<00:00, 91.56s/it]
  6%|▌         | 299/5198 [8:54:33<125:59:16, 92.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.46s/it][A100%|██████████| 1/1 [01:31<00:00, 91.46s/it]
  6%|▌         | 299/5198 [8:54:34<125:57:56, 92.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.43s/it][A100%|██████████| 1/1 [01:31<00:00, 91.43s/it]
  6%|▌         | 299/5198 [8:54:34<125:57:28, 92.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.46s/it][A100%|██████████| 1/1 [01:31<00:00, 91.46s/it]
  6%|▌         | 299/5198 [8:54:34<125:57:51, 92.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.49s/it][A100%|██████████| 1/1 [01:31<00:00, 91.49s/it]
  6%|▌         | 299/5198 [8:54:34<125:58:04, 92.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.49s/it][A100%|██████████| 1/1 [01:31<00:00, 91.50s/it]
  6%|▌         | 299/5198 [8:54:36<125:58:11, 92.57s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_281
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.58s/it][A100%|██████████| 1/1 [01:59<00:00, 119.58s/it]
[2024-06-30 04:21:39,532] [INFO] [logging.py:96:log_dist] [Rank 0] step=295, skipped=0, lr=[1.9975561749856065e-05], mom=[(0.9, 0.999)]
steps: 295 loss: 0.5857 iter time (s): 119.793 samples/sec: 1.069

100%|██████████| 1/1 [02:00<00:00, 120.54s/it][A100%|██████████| 1/1 [02:00<00:00, 120.54s/it]

100%|██████████| 1/1 [02:00<00:00, 120.53s/it][A100%|██████████| 1/1 [02:00<00:00, 120.53s/it]

100%|██████████| 1/1 [02:00<00:00, 120.62s/it][A100%|██████████| 1/1 [02:00<00:00, 120.62s/it]

100%|██████████| 1/1 [02:00<00:00, 120.65s/it][A100%|██████████| 1/1 [02:00<00:00, 120.65s/it]

100%|██████████| 1/1 [02:00<00:00, 120.65s/it][A100%|██████████| 1/1 [02:00<00:00, 120.65s/it]
Checkpointing at shard 299

100%|██████████| 1/1 [02:00<00:00, 120.73s/it][A100%|██████████| 1/1 [02:00<00:00, 120.73s/it]

100%|██████████| 1/1 [02:00<00:00, 120.68s/it][A100%|██████████| 1/1 [02:00<00:00, 120.68s/it]
[2024-06-30 04:21:40,391] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step295 is about to be saved!
[2024-06-30 04:21:41,551] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step295/layer_00-model_states.pt...
[2024-06-30 04:21:44,408] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step295/layer_02-model_states.pt...
[2024-06-30 04:21:45,860] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step295/layer_07-model_states.pt...
[2024-06-30 04:21:46,088] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step295/layer_06-model_states.pt...
[2024-06-30 04:21:46,295] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step295/layer_05-model_states.pt...
[2024-06-30 04:21:46,802] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step295/layer_08-model_states.pt...
[2024-06-30 04:21:49,872] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step295/layer_00-model_states.pt.
[2024-06-30 04:21:53,044] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step295/layer_01-model_states.pt...
[2024-06-30 04:21:57,312] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step295/layer_04-model_states.pt...
[2024-06-30 04:21:57,616] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step295/layer_03-model_states.pt...
[2024-06-30 04:26:31,552] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step295/layer_07-model_states.pt.
[2024-06-30 04:26:31,608] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step295/mp_rank_06_model_states.pt...
[2024-06-30 04:26:31,927] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step295/mp_rank_06_model_states.pt.
[2024-06-30 04:26:31,927] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step295 is ready now!
[2024-06-30 04:26:39,649] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step295/layer_04-model_states.pt.
[2024-06-30 04:26:39,808] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step295/mp_rank_03_model_states.pt...
[2024-06-30 04:26:39,899] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step295/mp_rank_03_model_states.pt.
[2024-06-30 04:26:39,899] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step295 is ready now!
[2024-06-30 04:26:44,363] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step295/layer_02-model_states.pt.
[2024-06-30 04:26:44,390] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step295/layer_06-model_states.pt.
[2024-06-30 04:26:44,398] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step295/layer_05-model_states.pt.
[2024-06-30 04:26:44,398] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step295/layer_03-model_states.pt.
[2024-06-30 04:26:44,407] [INFO] [logging.py:96:log_dist] [Rank 1] Saving model checkpoint: /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step295/mp_rank_01_model_states.pt
[2024-06-30 04:26:44,407] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step295/mp_rank_01_model_states.pt...
[2024-06-30 04:26:44,426] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step295/layer_08-model_states.pt.
[2024-06-30 04:26:44,434] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step295/mp_rank_05_model_states.pt...
[2024-06-30 04:26:44,458] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step295/mp_rank_01_model_states.pt.
[2024-06-30 04:26:44,458] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step295 is ready now!
[2024-06-30 04:26:44,462] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step295/mp_rank_04_model_states.pt...
[2024-06-30 04:26:44,517] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step295/mp_rank_05_model_states.pt.
[2024-06-30 04:26:44,517] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step295 is ready now!
[2024-06-30 04:26:44,521] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step295/mp_rank_04_model_states.pt.
[2024-06-30 04:26:44,521] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step295 is ready now!
[2024-06-30 04:26:44,538] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step295/layer_09-model_states.pt...
[2024-06-30 04:26:44,568] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step295/mp_rank_02_model_states.pt...
[2024-06-30 04:26:44,642] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step295/mp_rank_02_model_states.pt.
[2024-06-30 04:26:44,642] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step295 is ready now!
[2024-06-30 04:26:44,733] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step295/layer_01-model_states.pt.
[2024-06-30 04:26:44,775] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step295/mp_rank_00_model_states.pt
[2024-06-30 04:26:44,775] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step295/mp_rank_00_model_states.pt...
[2024-06-30 04:26:45,186] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step295/mp_rank_00_model_states.pt.
[2024-06-30 04:26:45,186] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step295 is ready now!
[2024-06-30 04:26:45,206] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step295/layer_09-model_states.pt.
[2024-06-30 04:26:45,208] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step295/mp_rank_07_model_states.pt...
[2024-06-30 04:26:45,256] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step295/mp_rank_07_model_states.pt.
[2024-06-30 04:26:45,256] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step295 is ready now!
Checkpoint saved using --- 304.87042808532715 seconds ---
  6%|▌         | 300/5198 [9:01:39<255:19:53, 187.67s/it]  6%|▌         | 300/5198 [9:01:39<255:26:32, 187.75s/it]  6%|▌         | 300/5198 [9:01:39<255:23:57, 187.72s/it]  6%|▌         | 300/5198 [9:01:42<255:19:29, 187.66s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_282
  6%|▌         | 300/5198 [9:01:39<255:20:58, 187.68s/it]  6%|▌         | 300/5198 [9:01:41<256:32:10, 188.55s/it]  6%|▌         | 300/5198 [9:01:39<255:22:02, 187.69s/it]  6%|▌         | 300/5198 [9:01:39<255:29:47, 187.79s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A

  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:00<?, ?it/s][A[A

  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.36s/it][A100%|██████████| 1/1 [01:27<00:00, 87.36s/it]
  6%|▌         | 301/5198 [9:03:09<216:40:36, 159.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 04:28:14,617] [INFO] [logging.py:96:log_dist] [Rank 0] step=296, skipped=0, lr=[1.9975164421816905e-05], mom=[(0.9, 0.999)]
steps: 296 loss: 0.5734 iter time (s): 89.169 samples/sec: 1.435

100%|██████████| 1/1 [01:29<00:00, 89.44s/it][A100%|██████████| 1/1 [01:29<00:00, 89.44s/it]
  6%|▌         | 301/5198 [9:03:09<216:45:38, 159.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.55s/it][A100%|██████████| 1/1 [01:29<00:00, 89.55s/it]
  6%|▌         | 301/5198 [9:03:09<216:45:53, 159.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.69s/it][A100%|██████████| 1/1 [01:29<00:00, 89.69s/it]
  6%|▌         | 301/5198 [9:03:09<216:47:28, 159.37s/it]
100%|██████████| 1/1 [01:29<00:00, 89.71s/it][A100%|██████████| 1/1 [01:29<00:00, 89.71s/it]
  6%|▌         | 301/5198 [9:03:09<216:46:23, 159.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.75s/it][A100%|██████████| 1/1 [01:29<00:00, 89.75s/it]
  6%|▌         | 301/5198 [9:03:09<216:46:41, 159.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.85s/it][A100%|██████████| 1/1 [01:29<00:00, 89.85s/it]
  6%|▌         | 301/5198 [9:03:09<216:48:20, 159.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.91s/it][A100%|██████████| 1/1 [01:29<00:00, 89.91s/it]
  6%|▌         | 301/5198 [9:03:12<216:49:27, 159.40s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_283
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:09<00:00, 129.70s/it][A100%|██████████| 1/1 [02:09<00:00, 129.71s/it]
  6%|▌         | 302/5198 [9:05:19<205:08:32, 150.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 04:30:26,052] [INFO] [logging.py:96:log_dist] [Rank 0] step=297, skipped=0, lr=[1.9974763893818215e-05], mom=[(0.9, 0.999)]
steps: 297 loss: 0.6036 iter time (s): 130.659 samples/sec: 0.980

100%|██████████| 1/1 [02:11<00:00, 131.50s/it][A100%|██████████| 1/1 [02:11<00:00, 131.50s/it]
  6%|▌         | 302/5198 [9:05:20<205:37:57, 151.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:11<00:00, 131.49s/it][A100%|██████████| 1/1 [02:11<00:00, 131.49s/it]
  6%|▌         | 302/5198 [9:05:20<205:38:00, 151.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:11<00:00, 131.44s/it][A100%|██████████| 1/1 [02:11<00:00, 131.44s/it]
  6%|▌         | 302/5198 [9:05:21<205:37:58, 151.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:11<00:00, 131.50s/it][A100%|██████████| 1/1 [02:11<00:00, 131.50s/it]
  6%|▌         | 302/5198 [9:05:21<205:38:22, 151.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:11<00:00, 131.55s/it][A100%|██████████| 1/1 [02:11<00:00, 131.55s/it]
  6%|▌         | 302/5198 [9:05:21<205:39:41, 151.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:11<00:00, 131.49s/it][A100%|██████████| 1/1 [02:11<00:00, 131.49s/it]
  6%|▌         | 302/5198 [9:05:21<205:39:25, 151.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:11<00:00, 131.44s/it][A100%|██████████| 1/1 [02:11<00:00, 131.44s/it]
  6%|▌         | 302/5198 [9:05:23<205:39:05, 151.21s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_284
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:04<00:00, 124.31s/it][A100%|██████████| 1/1 [02:04<00:00, 124.31s/it]
  6%|▌         | 303/5198 [9:07:25<194:59:46, 143.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 04:32:31,605] [INFO] [logging.py:96:log_dist] [Rank 0] step=298, skipped=0, lr=[1.997436016598849e-05], mom=[(0.9, 0.999)]
steps: 298 loss: 0.5790 iter time (s): 124.762 samples/sec: 1.026

100%|██████████| 1/1 [02:05<00:00, 125.59s/it][A100%|██████████| 1/1 [02:05<00:00, 125.59s/it]
  6%|▌         | 303/5198 [9:07:26<195:19:35, 143.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:05<00:00, 125.59s/it][A100%|██████████| 1/1 [02:05<00:00, 125.59s/it]
  6%|▌         | 303/5198 [9:07:26<195:19:26, 143.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:05<00:00, 125.69s/it][A100%|██████████| 1/1 [02:05<00:00, 125.69s/it]
  6%|▌         | 303/5198 [9:07:26<195:21:54, 143.68s/it]

100%|██████████| 1/1 [02:05<00:00, 125.64s/it][A  0%|          | 0/1 [00:00<?, ?it/s][A100%|██████████| 1/1 [02:05<00:00, 125.64s/it]
  6%|▌         | 303/5198 [9:07:26<195:21:01, 143.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:05<00:00, 125.62s/it][A100%|██████████| 1/1 [02:05<00:00, 125.62s/it]
  6%|▌         | 303/5198 [9:07:26<195:21:20, 143.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:05<00:00, 125.63s/it][A100%|██████████| 1/1 [02:05<00:00, 125.63s/it]
  6%|▌         | 303/5198 [9:07:27<195:21:23, 143.67s/it]
100%|██████████| 1/1 [02:05<00:00, 125.62s/it][A100%|██████████| 1/1 [02:05<00:00, 125.62s/it]
  6%|▌         | 303/5198 [9:07:29<195:20:55, 143.67s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_18

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.59s/it][A100%|██████████| 1/1 [02:03<00:00, 123.59s/it]
  6%|▌         | 304/5198 [9:09:28<187:00:27, 137.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 04:34:35,314] [INFO] [logging.py:96:log_dist] [Rank 0] step=299, skipped=0, lr=[1.9973953238457254e-05], mom=[(0.9, 0.999)]
steps: 299 loss: 0.8025 iter time (s): 123.080 samples/sec: 1.040

100%|██████████| 1/1 [02:03<00:00, 123.98s/it][A100%|██████████| 1/1 [02:03<00:00, 123.98s/it]
  6%|▌         | 304/5198 [9:09:30<187:21:52, 137.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:04<00:00, 124.15s/it][A100%|██████████| 1/1 [02:04<00:00, 124.15s/it]
  6%|▌         | 304/5198 [9:09:30<187:25:58, 137.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.98s/it][A100%|██████████| 1/1 [02:03<00:00, 123.98s/it]
  6%|▌         | 304/5198 [9:09:30<187:23:29, 137.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.99s/it][A100%|██████████| 1/1 [02:03<00:00, 123.99s/it]
  6%|▌         | 304/5198 [9:09:30<187:22:56, 137.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.97s/it][A100%|██████████| 1/1 [02:03<00:00, 123.97s/it]
  6%|▌         | 304/5198 [9:09:30<187:22:48, 137.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.99s/it][A100%|██████████| 1/1 [02:03<00:00, 123.99s/it]
  6%|▌         | 304/5198 [9:09:33<187:22:57, 137.84s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_285

100%|██████████| 1/1 [02:04<00:00, 124.00s/it][A100%|██████████| 1/1 [02:04<00:00, 124.00s/it]
Training on 128 of 128 sentences.  6%|▌         | 304/5198 [9:09:31<187:23:29, 137.84s/it]

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.64s/it][A100%|██████████| 1/1 [01:27<00:00, 87.64s/it]
  6%|▌         | 305/5198 [9:10:56<166:50:28, 122.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 04:36:02,374] [INFO] [logging.py:96:log_dist] [Rank 0] step=300, skipped=0, lr=[1.9973543111355067e-05], mom=[(0.9, 0.999)]
steps: 300 loss: 0.6167 iter time (s): 85.922 samples/sec: 1.490

100%|██████████| 1/1 [01:26<00:00, 86.65s/it][A100%|██████████| 1/1 [01:26<00:00, 86.65s/it]
  6%|▌         | 305/5198 [9:10:56<166:38:20, 122.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.49s/it][A100%|██████████| 1/1 [01:26<00:00, 86.49s/it]
  6%|▌         | 305/5198 [9:10:57<166:37:29, 122.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.61s/it][A100%|██████████| 1/1 [01:26<00:00, 86.61s/it]
  6%|▌         | 305/5198 [9:10:57<166:38:25, 122.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.66s/it][A100%|██████████| 1/1 [01:26<00:00, 86.66s/it]
  6%|▌         | 305/5198 [9:10:57<166:39:24, 122.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.68s/it][A100%|██████████| 1/1 [01:26<00:00, 86.68s/it]
  6%|▌         | 305/5198 [9:10:57<166:39:46, 122.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.66s/it][A100%|██████████| 1/1 [01:26<00:00, 86.66s/it]
  6%|▌         | 305/5198 [9:10:57<166:39:36, 122.62s/it]
100%|██████████| 1/1 [01:26<00:00, 86.66s/it][A100%|██████████| 1/1 [01:26<00:00, 86.66s/it]
  6%|▌         | 305/5198 [9:10:59<166:39:23, 122.62s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_286
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.74s/it][A100%|██████████| 1/1 [01:25<00:00, 85.74s/it]
  6%|▌         | 306/5198 [9:12:22<151:51:29, 111.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 04:37:28,185] [INFO] [logging.py:96:log_dist] [Rank 0] step=301, skipped=0, lr=[1.9973129784813498e-05], mom=[(0.9, 0.999)]
steps: 301 loss: 0.6151 iter time (s): 85.045 samples/sec: 1.505

100%|██████████| 1/1 [01:25<00:00, 85.80s/it][A100%|██████████| 1/1 [01:25<00:00, 85.80s/it]
  6%|▌         | 306/5198 [9:12:22<151:41:49, 111.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.90s/it][A100%|██████████| 1/1 [01:25<00:00, 85.90s/it]
  6%|▌         | 306/5198 [9:12:22<151:43:39, 111.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.88s/it][A100%|██████████| 1/1 [01:25<00:00, 85.88s/it]
  6%|▌         | 306/5198 [9:12:23<151:43:36, 111.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.85s/it][A100%|██████████| 1/1 [01:25<00:00, 85.86s/it]
  6%|▌         | 306/5198 [9:12:23<151:43:41, 111.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.87s/it][A100%|██████████| 1/1 [01:25<00:00, 85.87s/it]
  6%|▌         | 306/5198 [9:12:23<151:44:14, 111.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.85s/it][A100%|██████████| 1/1 [01:25<00:00, 85.85s/it]
  6%|▌         | 306/5198 [9:12:25<151:43:34, 111.65s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_287

100%|██████████| 1/1 [01:25<00:00, 85.85s/it][A100%|██████████| 1/1 [01:25<00:00, 85.85s/it]
Training on 128 of 128 sentences.
  6%|▌         | 306/5198 [9:12:23<151:43:51, 111.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.30s/it][A100%|██████████| 1/1 [01:31<00:00, 91.30s/it]
  6%|▌         | 307/5198 [9:13:53<143:35:01, 105.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 04:38:59,802] [INFO] [logging.py:96:log_dist] [Rank 0] step=302, skipped=0, lr=[1.9972713258965157e-05], mom=[(0.9, 0.999)]
steps: 302 loss: 0.5770 iter time (s): 90.811 samples/sec: 1.410

100%|██████████| 1/1 [01:31<00:00, 91.59s/it][A100%|██████████| 1/1 [01:31<00:00, 91.59s/it]
  6%|▌         | 307/5198 [9:13:54<143:31:59, 105.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.58s/it][A100%|██████████| 1/1 [01:31<00:00, 91.58s/it]
  6%|▌         | 307/5198 [9:13:54<143:32:58, 105.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.60s/it][A100%|██████████| 1/1 [01:31<00:00, 91.60s/it]
  6%|▌         | 307/5198 [9:13:54<143:33:36, 105.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.61s/it][A100%|██████████| 1/1 [01:31<00:00, 91.62s/it]
  6%|▌         | 307/5198 [9:13:55<143:33:57, 105.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.57s/it][A100%|██████████| 1/1 [01:31<00:00, 91.57s/it]
  6%|▌         | 307/5198 [9:13:55<143:33:12, 105.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.57s/it][A100%|██████████| 1/1 [01:31<00:00, 91.57s/it]
  6%|▌         | 307/5198 [9:13:55<143:32:57, 105.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.61s/it][A100%|██████████| 1/1 [01:31<00:00, 91.61s/it]
  6%|▌         | 307/5198 [9:13:57<143:33:40, 105.67s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_288
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.82s/it][A100%|██████████| 1/1 [01:34<00:00, 94.82s/it]
  6%|▌         | 308/5198 [9:15:28<139:12:18, 102.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 04:40:34,865] [INFO] [logging.py:96:log_dist] [Rank 0] step=303, skipped=0, lr=[1.9972293533943674e-05], mom=[(0.9, 0.999)]
steps: 303 loss: 0.6002 iter time (s): 94.255 samples/sec: 1.358

100%|██████████| 1/1 [01:35<00:00, 95.11s/it][A100%|██████████| 1/1 [01:35<00:00, 95.11s/it]
  6%|▌         | 308/5198 [9:15:29<139:13:33, 102.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.03s/it][A100%|██████████| 1/1 [01:35<00:00, 95.03s/it]
  6%|▌         | 308/5198 [9:15:29<139:12:16, 102.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.05s/it][A100%|██████████| 1/1 [01:35<00:00, 95.05s/it]
  6%|▌         | 308/5198 [9:15:30<139:13:16, 102.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.04s/it][A100%|██████████| 1/1 [01:35<00:00, 95.04s/it]
  6%|▌         | 308/5198 [9:15:30<139:12:44, 102.49s/it]
100%|██████████| 1/1 [01:35<00:00, 95.08s/it][A100%|██████████| 1/1 [01:35<00:00, 95.08s/it]
  6%|▌         | 308/5198 [9:15:30<139:14:14, 102.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.08s/it][A100%|██████████| 1/1 [01:35<00:00, 95.08s/it]
  6%|▌         | 308/5198 [9:15:30<139:13:22, 102.50s/it]
100%|██████████| 1/1 [01:35<00:00, 95.05s/it][A100%|██████████| 1/1 [01:35<00:00, 95.05s/it]
  6%|▌         | 308/5198 [9:15:32<139:13:09, 102.49s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_289

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:02<00:00, 122.38s/it][A100%|██████████| 1/1 [02:02<00:00, 122.38s/it]
  6%|▌         | 309/5198 [9:17:31<147:18:34, 108.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 04:42:38,094] [INFO] [logging.py:96:log_dist] [Rank 0] step=304, skipped=0, lr=[1.9971870609883714e-05], mom=[(0.9, 0.999)]
steps: 304 loss: 0.5966 iter time (s): 122.429 samples/sec: 1.046

100%|██████████| 1/1 [02:03<00:00, 123.21s/it][A100%|██████████| 1/1 [02:03<00:00, 123.21s/it]
  6%|▌         | 309/5198 [9:17:32<147:37:32, 108.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.26s/it][A100%|██████████| 1/1 [02:03<00:00, 123.27s/it]
  6%|▌         | 309/5198 [9:17:32<147:37:47, 108.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.16s/it][A100%|██████████| 1/1 [02:03<00:00, 123.16s/it]
  6%|▌         | 309/5198 [9:17:33<147:35:56, 108.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.15s/it][A100%|██████████| 1/1 [02:03<00:00, 123.15s/it]
  6%|▌         | 309/5198 [9:17:33<147:36:24, 108.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.21s/it][A100%|██████████| 1/1 [02:03<00:00, 123.21s/it]
  6%|▌         | 309/5198 [9:17:33<147:36:39, 108.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.20s/it][A100%|██████████| 1/1 [02:03<00:00, 123.20s/it]
  6%|▌         | 309/5198 [9:17:33<147:36:53, 108.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.21s/it][A100%|██████████| 1/1 [02:03<00:00, 123.21s/it]
  6%|▌         | 309/5198 [9:17:35<147:36:54, 108.70s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_290
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.07s/it][A100%|██████████| 1/1 [02:00<00:00, 120.07s/it]
  6%|▌         | 310/5198 [9:19:31<152:03:24, 111.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 04:44:38,251] [INFO] [logging.py:96:log_dist] [Rank 0] step=305, skipped=0, lr=[1.9971444486920952e-05], mom=[(0.9, 0.999)]
steps: 305 loss: 0.6062 iter time (s): 119.374 samples/sec: 1.072

100%|██████████| 1/1 [02:00<00:00, 120.11s/it][A100%|██████████| 1/1 [02:00<00:00, 120.11s/it]
  6%|▌         | 310/5198 [9:19:32<152:14:38, 112.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.05s/it][A100%|██████████| 1/1 [02:00<00:00, 120.05s/it]
  6%|▌         | 310/5198 [9:19:32<152:13:06, 112.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.12s/it][A100%|██████████| 1/1 [02:00<00:00, 120.12s/it]
  6%|▌         | 310/5198 [9:19:33<152:13:26, 112.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.17s/it][A100%|██████████| 1/1 [02:00<00:00, 120.17s/it]
  6%|▌         | 310/5198 [9:19:33<152:15:01, 112.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.24s/it][A100%|██████████| 1/1 [02:00<00:00, 120.24s/it]
  6%|▌         | 310/5198 [9:19:33<152:16:53, 112.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.15s/it][A100%|██████████| 1/1 [02:00<00:00, 120.15s/it]
  6%|▌         | 310/5198 [9:19:33<152:14:44, 112.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.16s/it][A100%|██████████| 1/1 [02:00<00:00, 120.16s/it]
  6%|▌         | 310/5198 [9:19:35<152:15:04, 112.13s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_291
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.50s/it][A100%|██████████| 1/1 [01:22<00:00, 82.50s/it]
  6%|▌         | 311/5198 [9:20:54<140:04:56, 103.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 04:45:59,839] [INFO] [logging.py:96:log_dist] [Rank 0] step=306, skipped=0, lr=[1.9971015165192106e-05], mom=[(0.9, 0.999)]
steps: 306 loss: 0.5868 iter time (s): 80.795 samples/sec: 1.584

100%|██████████| 1/1 [01:21<00:00, 81.68s/it][A100%|██████████| 1/1 [01:21<00:00, 81.68s/it]
  6%|▌         | 311/5198 [9:20:54<139:49:47, 103.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.64s/it][A100%|██████████| 1/1 [01:21<00:00, 81.65s/it]
  6%|▌         | 311/5198 [9:20:54<139:47:49, 102.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.66s/it][A100%|██████████| 1/1 [01:21<00:00, 81.66s/it]
  6%|▌         | 311/5198 [9:20:54<139:48:26, 102.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.56s/it][A100%|██████████| 1/1 [01:21<00:00, 81.56s/it]
  6%|▌         | 311/5198 [9:20:55<139:48:16, 102.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.64s/it][A100%|██████████| 1/1 [01:21<00:00, 81.64s/it]
  6%|▌         | 311/5198 [9:20:55<139:49:04, 103.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.63s/it][A100%|██████████| 1/1 [01:21<00:00, 81.63s/it]
  6%|▌         | 311/5198 [9:20:55<139:48:33, 102.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.63s/it][A100%|██████████| 1/1 [01:21<00:00, 81.63s/it]
  6%|▌         | 311/5198 [9:20:57<139:48:47, 102.99s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_292
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.96s/it][A100%|██████████| 1/1 [01:25<00:00, 85.96s/it]
  6%|▌         | 312/5198 [9:22:20<133:05:41, 98.06s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 04:47:26,081] [INFO] [logging.py:96:log_dist] [Rank 0] step=307, skipped=0, lr=[1.997058264483491e-05], mom=[(0.9, 0.999)]
steps: 307 loss: 0.6245 iter time (s): 85.404 samples/sec: 1.499

100%|██████████| 1/1 [01:26<00:00, 86.13s/it][A100%|██████████| 1/1 [01:26<00:00, 86.13s/it]
  6%|▌         | 312/5198 [9:22:20<132:56:30, 97.95s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.22s/it][A100%|██████████| 1/1 [01:26<00:00, 86.22s/it]
  6%|▌         | 312/5198 [9:22:20<132:57:20, 97.96s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.24s/it][A100%|██████████| 1/1 [01:26<00:00, 86.24s/it]
  6%|▌         | 312/5198 [9:22:21<132:58:07, 97.97s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.20s/it][A100%|██████████| 1/1 [01:26<00:00, 86.20s/it]
  6%|▌         | 312/5198 [9:22:21<132:56:53, 97.96s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.24s/it][A100%|██████████| 1/1 [01:26<00:00, 86.24s/it]
  6%|▌         | 312/5198 [9:22:21<132:58:26, 97.98s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.23s/it][A100%|██████████| 1/1 [01:26<00:00, 86.23s/it]
  6%|▌         | 312/5198 [9:22:21<132:57:57, 97.97s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.22s/it][A100%|██████████| 1/1 [01:26<00:00, 86.22s/it]
  6%|▌         | 312/5198 [9:22:23<132:57:49, 97.97s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_293
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.64s/it][A100%|██████████| 1/1 [01:58<00:00, 118.64s/it]
  6%|▌         | 313/5198 [9:24:19<141:29:59, 104.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 04:49:25,734] [INFO] [logging.py:96:log_dist] [Rank 0] step=308, skipped=0, lr=[1.9970146925988127e-05], mom=[(0.9, 0.999)]
steps: 308 loss: 0.6238 iter time (s): 118.826 samples/sec: 1.077

100%|██████████| 1/1 [01:59<00:00, 119.69s/it][A100%|██████████| 1/1 [01:59<00:00, 119.69s/it]
  6%|▌         | 313/5198 [9:24:20<141:45:52, 104.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.68s/it][A100%|██████████| 1/1 [01:59<00:00, 119.68s/it]
  6%|▌         | 313/5198 [9:24:20<141:46:16, 104.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.60s/it][A100%|██████████| 1/1 [01:59<00:00, 119.60s/it]
  6%|▌         | 313/5198 [9:24:20<141:44:45, 104.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.62s/it][A100%|██████████| 1/1 [01:59<00:00, 119.62s/it]
  6%|▌         | 313/5198 [9:24:20<141:44:18, 104.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.58s/it][A100%|██████████| 1/1 [01:59<00:00, 119.58s/it]
  6%|▌         | 313/5198 [9:24:21<141:44:23, 104.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.59s/it][A100%|██████████| 1/1 [01:59<00:00, 119.59s/it]
  6%|▌         | 313/5198 [9:24:21<141:44:16, 104.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.60s/it][A100%|██████████| 1/1 [01:59<00:00, 119.60s/it]
  6%|▌         | 313/5198 [9:24:23<141:44:23, 104.46s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_294
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.66s/it][A100%|██████████| 1/1 [01:53<00:00, 113.66s/it]
  6%|▌         | 314/5198 [9:26:12<145:20:39, 107.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 04:51:19,393] [INFO] [logging.py:96:log_dist] [Rank 0] step=309, skipped=0, lr=[1.9969708008791543e-05], mom=[(0.9, 0.999)]
steps: 309 loss: 0.6058 iter time (s): 112.881 samples/sec: 1.134

100%|██████████| 1/1 [01:53<00:00, 113.56s/it][A100%|██████████| 1/1 [01:53<00:00, 113.57s/it]
  6%|▌         | 314/5198 [9:26:13<145:26:15, 107.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.54s/it][A100%|██████████| 1/1 [01:53<00:00, 113.54s/it]
  6%|▌         | 314/5198 [9:26:14<145:26:05, 107.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.67s/it][A100%|██████████| 1/1 [01:53<00:00, 113.67s/it]
  6%|▌         | 314/5198 [9:26:14<145:28:00, 107.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.62s/it][A100%|██████████| 1/1 [01:53<00:00, 113.62s/it]
  6%|▌         | 314/5198 [9:26:14<145:26:45, 107.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.69s/it][A100%|██████████| 1/1 [01:53<00:00, 113.69s/it]
  6%|▌         | 314/5198 [9:26:14<145:28:19, 107.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.64s/it][A100%|██████████| 1/1 [01:53<00:00, 113.64s/it]
  6%|▌         | 314/5198 [9:26:14<145:27:02, 107.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.63s/it][A100%|██████████| 1/1 [01:53<00:00, 113.63s/it]
  6%|▌         | 314/5198 [9:26:16<145:26:52, 107.21s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_295
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.65s/it][A100%|██████████| 1/1 [01:22<00:00, 82.65s/it]
  6%|▌         | 315/5198 [9:27:35<135:24:40, 99.83s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 04:52:41,345] [INFO] [logging.py:96:log_dist] [Rank 0] step=310, skipped=0, lr=[1.996926589338598e-05], mom=[(0.9, 0.999)]
steps: 310 loss: 0.6558 iter time (s): 81.191 samples/sec: 1.577

100%|██████████| 1/1 [01:21<00:00, 81.97s/it][A100%|██████████| 1/1 [01:21<00:00, 81.97s/it]
  6%|▌         | 315/5198 [9:27:35<135:08:44, 99.64s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.95s/it][A100%|██████████| 1/1 [01:21<00:00, 81.95s/it]
  6%|▌         | 315/5198 [9:27:36<135:08:16, 99.63s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.91s/it][A100%|██████████| 1/1 [01:21<00:00, 81.91s/it]
  6%|▌         | 315/5198 [9:27:36<135:08:37, 99.63s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.91s/it][A100%|██████████| 1/1 [01:21<00:00, 81.91s/it]
  6%|▌         | 315/5198 [9:27:36<135:08:43, 99.64s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.96s/it][A100%|██████████| 1/1 [01:21<00:00, 81.96s/it]
  6%|▌         | 315/5198 [9:27:36<135:08:50, 99.64s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.96s/it][A100%|██████████| 1/1 [01:21<00:00, 81.96s/it]
  6%|▌         | 315/5198 [9:27:36<135:09:07, 99.64s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.97s/it][A100%|██████████| 1/1 [01:21<00:00, 81.97s/it]
  6%|▌         | 315/5198 [9:27:38<135:09:04, 99.64s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_296
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.87s/it][A100%|██████████| 1/1 [01:20<00:00, 80.87s/it]
  6%|▌         | 316/5198 [9:28:56<127:44:28, 94.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 04:54:02,318] [INFO] [logging.py:96:log_dist] [Rank 0] step=311, skipped=0, lr=[1.9968820579913283e-05], mom=[(0.9, 0.999)]
steps: 311 loss: 0.5631 iter time (s): 80.193 samples/sec: 1.596

100%|██████████| 1/1 [01:20<00:00, 80.96s/it][A100%|██████████| 1/1 [01:20<00:00, 80.96s/it]
  6%|▌         | 316/5198 [9:28:56<127:31:36, 94.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.12s/it][A100%|██████████| 1/1 [01:21<00:00, 81.12s/it]
  6%|▌         | 316/5198 [9:28:57<127:34:59, 94.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.04s/it][A100%|██████████| 1/1 [01:21<00:00, 81.05s/it]
  6%|▌         | 316/5198 [9:28:57<127:33:31, 94.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.97s/it][A100%|██████████| 1/1 [01:20<00:00, 80.97s/it]
  6%|▌         | 316/5198 [9:28:57<127:31:44, 94.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.01s/it][A100%|██████████| 1/1 [01:21<00:00, 81.01s/it]
  6%|▌         | 316/5198 [9:28:57<127:32:45, 94.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.99s/it][A100%|██████████| 1/1 [01:20<00:00, 81.00s/it]
  6%|▌         | 316/5198 [9:28:57<127:32:34, 94.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.99s/it][A100%|██████████| 1/1 [01:20<00:00, 80.99s/it]
  6%|▌         | 316/5198 [9:28:59<127:32:26, 94.05s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_297
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.70s/it][A100%|██████████| 1/1 [01:52<00:00, 112.70s/it]
  6%|▌         | 317/5198 [9:30:49<135:17:40, 99.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 04:55:56,056] [INFO] [logging.py:96:log_dist] [Rank 0] step=312, skipped=0, lr=[1.9968372068516306e-05], mom=[(0.9, 0.999)]
steps: 312 loss: 0.6015 iter time (s): 112.933 samples/sec: 1.133

100%|██████████| 1/1 [01:53<00:00, 113.76s/it][A100%|██████████| 1/1 [01:53<00:00, 113.76s/it]
  6%|▌         | 317/5198 [9:30:50<135:31:34, 99.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.68s/it][A100%|██████████| 1/1 [01:53<00:00, 113.68s/it]
  6%|▌         | 317/5198 [9:30:50<135:31:56, 99.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.72s/it][A100%|██████████| 1/1 [01:53<00:00, 113.72s/it]
  6%|▌         | 317/5198 [9:30:51<135:31:52, 99.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.69s/it][A100%|██████████| 1/1 [01:53<00:00, 113.69s/it]
  6%|▌         | 317/5198 [9:30:51<135:30:37, 99.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.75s/it][A100%|██████████| 1/1 [01:53<00:00, 113.75s/it]
  6%|▌         | 317/5198 [9:30:51<135:31:19, 99.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.71s/it][A100%|██████████| 1/1 [01:53<00:00, 113.71s/it]
  6%|▌         | 317/5198 [9:30:51<135:31:01, 99.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.73s/it][A100%|██████████| 1/1 [01:53<00:00, 113.73s/it]
  6%|▌         | 317/5198 [9:30:53<135:31:18, 99.95s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_298
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.08s/it][A100%|██████████| 1/1 [01:35<00:00, 95.08s/it]
  6%|▌         | 318/5198 [9:32:24<133:24:27, 98.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 04:57:30,749] [INFO] [logging.py:96:log_dist] [Rank 0] step=313, skipped=0, lr=[1.9967920359338956e-05], mom=[(0.9, 0.999)]
steps: 313 loss: 0.6558 iter time (s): 93.884 samples/sec: 1.363

100%|██████████| 1/1 [01:34<00:00, 94.71s/it][A100%|██████████| 1/1 [01:34<00:00, 94.71s/it]
  6%|▌         | 318/5198 [9:32:25<133:22:08, 98.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.67s/it][A100%|██████████| 1/1 [01:34<00:00, 94.67s/it]
  6%|▌         | 318/5198 [9:32:25<133:21:25, 98.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.72s/it][A100%|██████████| 1/1 [01:34<00:00, 94.72s/it]
  6%|▌         | 318/5198 [9:32:25<133:22:25, 98.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.73s/it][A100%|██████████| 1/1 [01:34<00:00, 94.73s/it]
  6%|▌         | 318/5198 [9:32:25<133:21:54, 98.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.71s/it][A100%|██████████| 1/1 [01:34<00:00, 94.71s/it]
  6%|▌         | 318/5198 [9:32:26<133:21:54, 98.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.71s/it][A100%|██████████| 1/1 [01:34<00:00, 94.71s/it]
  6%|▌         | 318/5198 [9:32:26<133:21:39, 98.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.69s/it][A100%|██████████| 1/1 [01:34<00:00, 94.69s/it]
  6%|▌         | 318/5198 [9:32:28<133:21:29, 98.38s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_299
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:17<00:00, 77.07s/it][A100%|██████████| 1/1 [01:17<00:00, 77.07s/it]
  6%|▌         | 319/5198 [9:33:42<124:45:39, 92.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 04:58:47,493] [INFO] [logging.py:96:log_dist] [Rank 0] step=314, skipped=0, lr=[1.996746545252614e-05], mom=[(0.9, 0.999)]
steps: 314 loss: 0.6189 iter time (s): 75.932 samples/sec: 1.686

100%|██████████| 1/1 [01:16<00:00, 76.70s/it][A100%|██████████| 1/1 [01:16<00:00, 76.70s/it]
  6%|▌         | 319/5198 [9:33:42<124:31:47, 91.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:16<00:00, 76.64s/it][A100%|██████████| 1/1 [01:16<00:00, 76.64s/it]
  6%|▌         | 319/5198 [9:33:42<124:29:50, 91.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:16<00:00, 76.51s/it][A100%|██████████| 1/1 [01:16<00:00, 76.51s/it]
  6%|▌         | 319/5198 [9:33:42<124:27:21, 91.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:16<00:00, 76.58s/it][A100%|██████████| 1/1 [01:16<00:00, 76.58s/it]
  6%|▌         | 319/5198 [9:33:42<124:28:32, 91.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:16<00:00, 76.63s/it][A100%|██████████| 1/1 [01:16<00:00, 76.63s/it]
  6%|▌         | 319/5198 [9:33:42<124:29:45, 91.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:16<00:00, 76.64s/it][A100%|██████████| 1/1 [01:16<00:00, 76.64s/it]
  6%|▌         | 319/5198 [9:33:42<124:29:50, 91.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:16<00:00, 76.65s/it][A100%|██████████| 1/1 [01:16<00:00, 76.65s/it]
  6%|▌         | 319/5198 [9:33:45<124:29:52, 91.86s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_19
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.60s/it][A100%|██████████| 1/1 [02:03<00:00, 123.60s/it]
  6%|▌         | 320/5198 [9:35:45<137:36:28, 101.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 05:00:52,260] [INFO] [logging.py:96:log_dist] [Rank 0] step=315, skipped=0, lr=[1.9967007348223816e-05], mom=[(0.9, 0.999)]
steps: 315 loss: 0.7989 iter time (s): 124.285 samples/sec: 1.030

100%|██████████| 1/1 [02:05<00:00, 125.15s/it][A100%|██████████| 1/1 [02:05<00:00, 125.15s/it]
  6%|▌         | 320/5198 [9:35:47<138:01:57, 101.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:05<00:00, 125.25s/it][A100%|██████████| 1/1 [02:05<00:00, 125.25s/it]
  6%|▌         | 320/5198 [9:35:47<138:02:45, 101.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:05<00:00, 125.41s/it][A100%|██████████| 1/1 [02:05<00:00, 125.41s/it]
  6%|▌         | 320/5198 [9:35:47<138:04:57, 101.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:05<00:00, 125.22s/it][A100%|██████████| 1/1 [02:05<00:00, 125.22s/it]
  6%|▌         | 320/5198 [9:35:48<138:02:05, 101.87s/it]
100%|██████████| 1/1 [02:05<00:00, 125.36s/it][A100%|██████████| 1/1 [02:05<00:00, 125.36s/it]
  6%|▌         | 320/5198 [9:35:47<138:04:29, 101.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:05<00:00, 125.29s/it][A100%|██████████| 1/1 [02:05<00:00, 125.29s/it]
  6%|▌         | 320/5198 [9:35:48<138:03:39, 101.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:05<00:00, 125.24s/it][A100%|██████████| 1/1 [02:05<00:00, 125.24s/it]
  6%|▌         | 320/5198 [9:35:50<138:02:32, 101.88s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_300
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.49s/it][A100%|██████████| 1/1 [01:32<00:00, 92.49s/it]
  6%|▌         | 321/5198 [9:37:18<133:57:30, 98.88s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 05:02:24,270] [INFO] [logging.py:96:log_dist] [Rank 0] step=316, skipped=0, lr=[1.996654604657895e-05], mom=[(0.9, 0.999)]
steps: 316 loss: 0.5908 iter time (s): 90.818 samples/sec: 1.409

100%|██████████| 1/1 [01:31<00:00, 91.55s/it][A100%|██████████| 1/1 [01:31<00:00, 91.55s/it]
  6%|▌         | 321/5198 [9:37:18<133:48:54, 98.78s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.56s/it][A100%|██████████| 1/1 [01:31<00:00, 91.56s/it]
  6%|▌         | 321/5198 [9:37:19<133:49:35, 98.79s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.47s/it][A100%|██████████| 1/1 [01:31<00:00, 91.47s/it]
  6%|▌         | 321/5198 [9:37:19<133:48:44, 98.77s/it] 
100%|██████████| 1/1 [01:31<00:00, 91.53s/it][A100%|██████████| 1/1 [01:31<00:00, 91.53s/it]
  6%|▌         | 321/5198 [9:37:19<133:50:34, 98.80s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.53s/it][A100%|██████████| 1/1 [01:31<00:00, 91.53s/it]
  6%|▌         | 321/5198 [9:37:19<133:49:34, 98.79s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.60s/it][A100%|██████████| 1/1 [01:31<00:00, 91.60s/it]
  6%|▌         | 321/5198 [9:37:19<133:50:09, 98.79s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.59s/it][A100%|██████████| 1/1 [01:31<00:00, 91.59s/it]
  6%|▌         | 321/5198 [9:37:21<133:50:15, 98.79s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_301
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.26s/it][A100%|██████████| 1/1 [01:46<00:00, 106.26s/it]
  6%|▌         | 322/5198 [9:39:04<136:59:51, 101.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 05:04:11,044] [INFO] [logging.py:96:log_dist] [Rank 0] step=317, skipped=0, lr=[1.9966081547739534e-05], mom=[(0.9, 0.999)]
steps: 317 loss: 0.6091 iter time (s): 105.995 samples/sec: 1.208

100%|██████████| 1/1 [01:46<00:00, 106.84s/it][A100%|██████████| 1/1 [01:46<00:00, 106.84s/it]
  6%|▌         | 322/5198 [9:39:05<137:04:11, 101.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.85s/it][A100%|██████████| 1/1 [01:46<00:00, 106.85s/it]
  6%|▌         | 322/5198 [9:39:05<137:04:45, 101.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.76s/it][A100%|██████████| 1/1 [01:46<00:00, 106.76s/it]
  6%|▌         | 322/5198 [9:39:06<137:03:21, 101.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.82s/it][A100%|██████████| 1/1 [01:46<00:00, 106.82s/it]
  6%|▌         | 322/5198 [9:39:06<137:03:58, 101.20s/it]
100%|██████████| 1/1 [01:46<00:00, 106.89s/it][A100%|██████████| 1/1 [01:46<00:00, 106.89s/it]
  6%|▌         | 322/5198 [9:39:06<137:05:11, 101.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.82s/it][A100%|██████████| 1/1 [01:46<00:00, 106.82s/it]
  6%|▌         | 322/5198 [9:39:06<137:04:27, 101.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.83s/it][A100%|██████████| 1/1 [01:46<00:00, 106.83s/it]
  6%|▌         | 322/5198 [9:39:08<137:04:43, 101.21s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_302
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:04<00:00, 124.99s/it][A100%|██████████| 1/1 [02:04<00:00, 124.99s/it]
  6%|▌         | 323/5198 [9:41:10<146:48:55, 108.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 05:06:16,091] [INFO] [logging.py:96:log_dist] [Rank 0] step=318, skipped=0, lr=[1.99656138518546e-05], mom=[(0.9, 0.999)]
steps: 318 loss: 0.6002 iter time (s): 124.196 samples/sec: 1.031

100%|██████████| 1/1 [02:04<00:00, 124.95s/it][A100%|██████████| 1/1 [02:04<00:00, 124.95s/it]
  6%|▌         | 323/5198 [9:41:10<146:41:43, 108.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:04<00:00, 124.89s/it][A100%|██████████| 1/1 [02:04<00:00, 124.89s/it]
  6%|▌         | 323/5198 [9:41:10<146:40:44, 108.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:05<00:00, 125.02s/it][A100%|██████████| 1/1 [02:05<00:00, 125.02s/it]
  6%|▌         | 323/5198 [9:41:11<146:42:58, 108.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:04<00:00, 124.94s/it][A100%|██████████| 1/1 [02:04<00:00, 124.95s/it]
  6%|▌         | 323/5198 [9:41:11<146:42:10, 108.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:04<00:00, 125.00s/it][A100%|██████████| 1/1 [02:04<00:00, 125.00s/it]
  6%|▌         | 323/5198 [9:41:11<146:42:40, 108.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:04<00:00, 124.99s/it][A100%|██████████| 1/1 [02:04<00:00, 124.99s/it]
  6%|▌         | 323/5198 [9:41:11<146:42:44, 108.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:04<00:00, 124.98s/it][A100%|██████████| 1/1 [02:04<00:00, 124.98s/it]
  6%|▌         | 323/5198 [9:41:13<146:42:39, 108.34s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_303
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.84s/it][A100%|██████████| 1/1 [01:47<00:00, 107.84s/it]
  6%|▌         | 324/5198 [9:42:58<146:36:39, 108.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 05:08:04,503] [INFO] [logging.py:96:log_dist] [Rank 0] step=319, skipped=0, lr=[1.9965142959074188e-05], mom=[(0.9, 0.999)]
steps: 319 loss: 0.5646 iter time (s): 107.619 samples/sec: 1.189

100%|██████████| 1/1 [01:48<00:00, 108.48s/it][A100%|██████████| 1/1 [01:48<00:00, 108.48s/it]
  6%|▌         | 324/5198 [9:42:59<146:43:54, 108.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.51s/it][A100%|██████████| 1/1 [01:48<00:00, 108.51s/it]
  6%|▌         | 324/5198 [9:42:59<146:43:49, 108.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.45s/it][A100%|██████████| 1/1 [01:48<00:00, 108.45s/it]
  6%|▌         | 324/5198 [9:42:59<146:44:04, 108.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.45s/it][A100%|██████████| 1/1 [01:48<00:00, 108.45s/it]
  6%|▌         | 324/5198 [9:42:59<146:43:23, 108.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.47s/it][A100%|██████████| 1/1 [01:48<00:00, 108.47s/it]
  6%|▌         | 324/5198 [9:42:59<146:44:09, 108.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.44s/it][A100%|██████████| 1/1 [01:48<00:00, 108.45s/it]
  6%|▌         | 324/5198 [9:42:59<146:43:39, 108.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.44s/it][A100%|██████████| 1/1 [01:48<00:00, 108.44s/it]
  6%|▌         | 324/5198 [9:43:02<146:43:25, 108.37s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_304
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.89s/it][A100%|██████████| 1/1 [01:36<00:00, 96.89s/it]
  6%|▋         | 325/5198 [9:44:35<142:00:34, 104.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 05:09:41,214] [INFO] [logging.py:96:log_dist] [Rank 0] step=320, skipped=0, lr=[1.9964668869549378e-05], mom=[(0.9, 0.999)]
steps: 320 loss: 0.5739 iter time (s): 95.882 samples/sec: 1.335

100%|██████████| 1/1 [01:36<00:00, 96.64s/it][A100%|██████████| 1/1 [01:36<00:00, 96.64s/it]
  6%|▋         | 325/5198 [9:44:35<141:56:28, 104.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.60s/it][A100%|██████████| 1/1 [01:36<00:00, 96.60s/it]
  6%|▋         | 325/5198 [9:44:35<141:55:20, 104.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.55s/it][A100%|██████████| 1/1 [01:36<00:00, 96.55s/it]
  6%|▋         | 325/5198 [9:44:36<141:54:14, 104.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.55s/it][A100%|██████████| 1/1 [01:36<00:00, 96.55s/it]
  6%|▋         | 325/5198 [9:44:36<141:53:44, 104.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.60s/it][A100%|██████████| 1/1 [01:36<00:00, 96.60s/it]
  6%|▋         | 325/5198 [9:44:36<141:55:25, 104.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.59s/it][A100%|██████████| 1/1 [01:36<00:00, 96.59s/it]
  6%|▋         | 325/5198 [9:44:38<141:54:45, 104.84s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_305

Training on 128 of 128 sentences.
100%|██████████| 1/1 [01:36<00:00, 96.61s/it][A100%|██████████| 1/1 [01:36<00:00, 96.61s/it]
  6%|▋         | 325/5198 [9:44:36<141:55:23, 104.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.19s/it][A100%|██████████| 1/1 [01:28<00:00, 88.19s/it]
  6%|▋         | 326/5198 [9:46:03<135:14:08, 99.93s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 05:11:09,270] [INFO] [logging.py:96:log_dist] [Rank 0] step=321, skipped=0, lr=[1.9964191583432265e-05], mom=[(0.9, 0.999)]
steps: 321 loss: 0.5814 iter time (s): 87.342 samples/sec: 1.466

100%|██████████| 1/1 [01:28<00:00, 88.12s/it][A100%|██████████| 1/1 [01:28<00:00, 88.12s/it]
  6%|▋         | 326/5198 [9:46:03<135:07:01, 99.84s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.14s/it][A100%|██████████| 1/1 [01:28<00:00, 88.14s/it]
  6%|▋         | 326/5198 [9:46:04<135:06:58, 99.84s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.20s/it][A100%|██████████| 1/1 [01:28<00:00, 88.20s/it]
  6%|▋         | 326/5198 [9:46:04<135:07:38, 99.85s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.32s/it][A100%|██████████| 1/1 [01:28<00:00, 88.32s/it]
  6%|▋         | 326/5198 [9:46:04<135:10:06, 99.88s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.24s/it][A100%|██████████| 1/1 [01:28<00:00, 88.24s/it]
  6%|▋         | 326/5198 [9:46:04<135:09:24, 99.87s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.38s/it][A100%|██████████| 1/1 [01:28<00:00, 88.38s/it]
  6%|▋         | 326/5198 [9:46:07<135:12:07, 99.90s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_306
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.69s/it][A100%|██████████| 1/1 [01:28<00:00, 88.69s/it]
  6%|▋         | 326/5198 [9:46:05<135:20:12, 100.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.62s/it][A100%|██████████| 1/1 [01:49<00:00, 109.62s/it]
  6%|▋         | 327/5198 [9:47:53<139:12:30, 102.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 05:12:59,672] [INFO] [logging.py:96:log_dist] [Rank 0] step=322, skipped=0, lr=[1.9963711100875983e-05], mom=[(0.9, 0.999)]
steps: 322 loss: 0.5841 iter time (s): 109.361 samples/sec: 1.170

100%|██████████| 1/1 [01:50<00:00, 110.33s/it][A100%|██████████| 1/1 [01:50<00:00, 110.33s/it]
  6%|▋         | 327/5198 [9:47:54<139:21:06, 102.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.38s/it][A100%|██████████| 1/1 [01:50<00:00, 110.38s/it]
  6%|▋         | 327/5198 [9:47:54<139:22:44, 103.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.27s/it][A100%|██████████| 1/1 [01:50<00:00, 110.27s/it]
  6%|▋         | 327/5198 [9:47:54<139:20:28, 102.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.21s/it][A100%|██████████| 1/1 [01:50<00:00, 110.21s/it]
  6%|▋         | 327/5198 [9:47:54<139:20:15, 102.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.26s/it][A100%|██████████| 1/1 [01:50<00:00, 110.26s/it]
  6%|▋         | 327/5198 [9:47:54<139:21:08, 102.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.81s/it][A100%|██████████| 1/1 [01:49<00:00, 109.81s/it]
  6%|▋         | 327/5198 [9:47:55<139:17:53, 102.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.16s/it][A100%|██████████| 1/1 [01:50<00:00, 110.16s/it]
  6%|▋         | 327/5198 [9:47:57<139:20:25, 102.98s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_307
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.59s/it][A100%|██████████| 1/1 [01:56<00:00, 116.59s/it]
  6%|▋         | 328/5198 [9:49:50<144:48:34, 107.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 05:14:56,603] [INFO] [logging.py:96:log_dist] [Rank 0] step=323, skipped=0, lr=[1.996322742203467e-05], mom=[(0.9, 0.999)]
steps: 323 loss: 0.6140 iter time (s): 116.125 samples/sec: 1.102

100%|██████████| 1/1 [01:56<00:00, 116.91s/it][A100%|██████████| 1/1 [01:56<00:00, 116.91s/it]
  6%|▋         | 328/5198 [9:49:51<144:58:42, 107.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.84s/it][A100%|██████████| 1/1 [01:56<00:00, 116.84s/it]
  6%|▋         | 328/5198 [9:49:51<144:57:52, 107.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.94s/it][A100%|██████████| 1/1 [01:56<00:00, 116.94s/it]
  6%|▋         | 328/5198 [9:49:51<144:59:04, 107.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.97s/it][A100%|██████████| 1/1 [01:56<00:00, 116.97s/it]
  6%|▋         | 328/5198 [9:49:51<144:59:19, 107.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.89s/it][A100%|██████████| 1/1 [01:56<00:00, 116.89s/it]
  6%|▋         | 328/5198 [9:49:51<144:58:12, 107.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.89s/it][A100%|██████████| 1/1 [01:56<00:00, 116.89s/it]
  6%|▋         | 328/5198 [9:49:54<144:57:30, 107.16s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_308
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.92s/it][A100%|██████████| 1/1 [01:56<00:00, 116.92s/it]
  6%|▋         | 328/5198 [9:49:51<144:56:35, 107.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.32s/it][A100%|██████████| 1/1 [01:22<00:00, 82.32s/it]
  6%|▋         | 329/5198 [9:51:12<134:47:50, 99.67s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 05:16:18,093] [INFO] [logging.py:96:log_dist] [Rank 0] step=324, skipped=0, lr=[1.996274054706351e-05], mom=[(0.9, 0.999)]
steps: 324 loss: 0.5987 iter time (s): 80.719 samples/sec: 1.586

100%|██████████| 1/1 [01:21<00:00, 81.51s/it][A100%|██████████| 1/1 [01:21<00:00, 81.51s/it]
  6%|▋         | 329/5198 [9:51:12<134:32:21, 99.47s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.50s/it][A100%|██████████| 1/1 [01:21<00:00, 81.50s/it]
  6%|▋         | 329/5198 [9:51:12<134:31:39, 99.47s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.51s/it][A100%|██████████| 1/1 [01:21<00:00, 81.51s/it]
  6%|▋         | 329/5198 [9:51:13<134:32:36, 99.48s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.46s/it][A100%|██████████| 1/1 [01:21<00:00, 81.46s/it]
  6%|▋         | 329/5198 [9:51:13<134:31:33, 99.46s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.46s/it][A100%|██████████| 1/1 [01:21<00:00, 81.46s/it]
  6%|▋         | 329/5198 [9:51:13<134:30:54, 99.46s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.45s/it][A100%|██████████| 1/1 [01:21<00:00, 81.45s/it]
  6%|▋         | 329/5198 [9:51:13<134:29:23, 99.44s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.49s/it][A100%|██████████| 1/1 [01:21<00:00, 81.49s/it]
  6%|▋         | 329/5198 [9:51:15<134:31:04, 99.46s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_309
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.90s/it][A100%|██████████| 1/1 [01:24<00:00, 84.90s/it]
  6%|▋         | 330/5198 [9:52:37<128:50:34, 95.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 05:17:43,252] [INFO] [logging.py:96:log_dist] [Rank 0] step=325, skipped=0, lr=[1.9962250476118704e-05], mom=[(0.9, 0.999)]
steps: 325 loss: 0.6409 iter time (s): 84.373 samples/sec: 1.517

100%|██████████| 1/1 [01:25<00:00, 85.09s/it][A100%|██████████| 1/1 [01:25<00:00, 85.09s/it]
  6%|▋         | 330/5198 [9:52:37<128:40:25, 95.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.24s/it][A100%|██████████| 1/1 [01:25<00:00, 85.24s/it]
  6%|▋         | 330/5198 [9:52:37<128:44:24, 95.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.10s/it][A100%|██████████| 1/1 [01:25<00:00, 85.10s/it]
  6%|▋         | 330/5198 [9:52:38<128:41:13, 95.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.20s/it][A100%|██████████| 1/1 [01:25<00:00, 85.20s/it]
  6%|▋         | 330/5198 [9:52:38<128:42:51, 95.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.20s/it][A100%|██████████| 1/1 [01:25<00:00, 85.20s/it]
  6%|▋         | 330/5198 [9:52:38<128:42:34, 95.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.21s/it][A100%|██████████| 1/1 [01:25<00:00, 85.21s/it]
  6%|▋         | 330/5198 [9:52:38<128:41:32, 95.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.19s/it][A100%|██████████| 1/1 [01:25<00:00, 85.19s/it]
  6%|▋         | 330/5198 [9:52:40<128:42:18, 95.18s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_310
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.01s/it][A100%|██████████| 1/1 [01:37<00:00, 97.01s/it]
  6%|▋         | 331/5198 [9:54:14<129:34:27, 95.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 05:19:20,743] [INFO] [logging.py:96:log_dist] [Rank 0] step=326, skipped=0, lr=[1.9961757209357476e-05], mom=[(0.9, 0.999)]
steps: 326 loss: 0.5708 iter time (s): 96.673 samples/sec: 1.324

100%|██████████| 1/1 [01:37<00:00, 97.47s/it][A100%|██████████| 1/1 [01:37<00:00, 97.47s/it]
  6%|▋         | 331/5198 [9:54:15<129:38:08, 95.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.60s/it][A100%|██████████| 1/1 [01:37<00:00, 97.60s/it]
  6%|▋         | 331/5198 [9:54:15<129:38:36, 95.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.58s/it][A100%|██████████| 1/1 [01:37<00:00, 97.58s/it]
  6%|▋         | 331/5198 [9:54:15<129:38:38, 95.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.51s/it][A100%|██████████| 1/1 [01:37<00:00, 97.51s/it]
  6%|▋         | 331/5198 [9:54:16<129:38:04, 95.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.59s/it][A100%|██████████| 1/1 [01:37<00:00, 97.59s/it]
  6%|▋         | 331/5198 [9:54:16<129:39:39, 95.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.55s/it][A100%|██████████| 1/1 [01:37<00:00, 97.55s/it]
  6%|▋         | 331/5198 [9:54:16<129:38:03, 95.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.57s/it][A100%|██████████| 1/1 [01:37<00:00, 97.57s/it]
  6%|▋         | 331/5198 [9:54:18<129:39:03, 95.90s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_311
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.60s/it][A100%|██████████| 1/1 [01:26<00:00, 86.60s/it]
  6%|▋         | 332/5198 [9:55:41<125:51:21, 93.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 05:20:47,152] [INFO] [logging.py:96:log_dist] [Rank 0] step=327, skipped=0, lr=[1.9961260746938083e-05], mom=[(0.9, 0.999)]
steps: 327 loss: 0.5668 iter time (s): 85.504 samples/sec: 1.497

100%|██████████| 1/1 [01:26<00:00, 86.34s/it][A100%|██████████| 1/1 [01:26<00:00, 86.34s/it]
  6%|▋         | 332/5198 [9:55:41<125:44:31, 93.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.29s/it][A100%|██████████| 1/1 [01:26<00:00, 86.29s/it]
  6%|▋         | 332/5198 [9:55:41<125:43:28, 93.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.27s/it][A100%|██████████| 1/1 [01:26<00:00, 86.27s/it]
  6%|▋         | 332/5198 [9:55:42<125:43:16, 93.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.30s/it][A100%|██████████| 1/1 [01:26<00:00, 86.30s/it]
  6%|▋         | 332/5198 [9:55:42<125:43:26, 93.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.26s/it][A100%|██████████| 1/1 [01:26<00:00, 86.26s/it]
  6%|▋         | 332/5198 [9:55:42<125:43:47, 93.02s/it]
100%|██████████| 1/1 [01:26<00:00, 86.25s/it][A100%|██████████| 1/1 [01:26<00:00, 86.26s/it]
  6%|▋         | 332/5198 [9:55:42<125:42:19, 93.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.26s/it][A100%|██████████| 1/1 [01:26<00:00, 86.26s/it]
  6%|▋         | 332/5198 [9:55:44<125:43:01, 93.01s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_312
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.77s/it][A100%|██████████| 1/1 [01:18<00:00, 78.77s/it]
  6%|▋         | 333/5198 [9:57:00<120:05:00, 88.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 05:22:05,897] [INFO] [logging.py:96:log_dist] [Rank 0] step=328, skipped=0, lr=[1.9960761089019802e-05], mom=[(0.9, 0.999)]
steps: 328 loss: 0.6379 iter time (s): 77.986 samples/sec: 1.641

100%|██████████| 1/1 [01:18<00:00, 78.57s/it][A100%|██████████| 1/1 [01:18<00:00, 78.57s/it]
  6%|▋         | 333/5198 [9:57:00<119:51:26, 88.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.75s/it][A100%|██████████| 1/1 [01:18<00:00, 78.75s/it]
  6%|▋         | 333/5198 [9:57:00<119:55:13, 88.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.71s/it][A100%|██████████| 1/1 [01:18<00:00, 78.71s/it]
  6%|▋         | 333/5198 [9:57:00<119:54:10, 88.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.77s/it][A100%|██████████| 1/1 [01:18<00:00, 78.77s/it]
  6%|▋         | 333/5198 [9:57:01<119:55:39, 88.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.75s/it][A100%|██████████| 1/1 [01:18<00:00, 78.75s/it]
  6%|▋         | 333/5198 [9:57:01<119:54:20, 88.73s/it]
100%|██████████| 1/1 [01:18<00:00, 78.76s/it][A100%|██████████| 1/1 [01:18<00:00, 78.76s/it]
  6%|▋         | 333/5198 [9:57:01<119:55:30, 88.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.75s/it][A100%|██████████| 1/1 [01:18<00:00, 78.75s/it]
  6%|▋         | 333/5198 [9:57:03<119:54:53, 88.73s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_313
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.95s/it][A100%|██████████| 1/1 [01:48<00:00, 108.95s/it]
  6%|▋         | 334/5198 [9:58:49<128:17:20, 94.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 05:23:55,914] [INFO] [logging.py:96:log_dist] [Rank 0] step=329, skipped=0, lr=[1.996025823576293e-05], mom=[(0.9, 0.999)]
steps: 329 loss: 0.5633 iter time (s): 109.245 samples/sec: 1.172

100%|██████████| 1/1 [01:50<00:00, 110.16s/it][A100%|██████████| 1/1 [01:50<00:00, 110.16s/it]
  6%|▋         | 334/5198 [9:58:50<128:32:25, 95.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.03s/it][A100%|██████████| 1/1 [01:50<00:00, 110.03s/it]
  6%|▋         | 334/5198 [9:58:50<128:31:53, 95.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.06s/it][A100%|██████████| 1/1 [01:50<00:00, 110.06s/it]
  6%|▋         | 334/5198 [9:58:51<128:31:50, 95.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.03s/it][A100%|██████████| 1/1 [01:50<00:00, 110.03s/it]
  6%|▋         | 334/5198 [9:58:51<128:32:04, 95.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.03s/it][A100%|██████████| 1/1 [01:50<00:00, 110.03s/it]
  6%|▋         | 334/5198 [9:58:51<128:32:03, 95.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.10s/it][A100%|██████████| 1/1 [01:50<00:00, 110.10s/it]
  6%|▋         | 334/5198 [9:58:51<128:32:43, 95.14s/it]
100%|██████████| 1/1 [01:50<00:00, 110.08s/it][A100%|██████████| 1/1 [01:50<00:00, 110.08s/it]
  6%|▋         | 334/5198 [9:58:53<128:32:33, 95.14s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_314

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.16s/it][A100%|██████████| 1/1 [01:31<00:00, 91.16s/it]
  6%|▋         | 335/5198 [10:00:20<126:47:54, 93.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 05:25:26,749] [INFO] [logging.py:96:log_dist] [Rank 0] step=330, skipped=0, lr=[1.99597521873288e-05], mom=[(0.9, 0.999)]
steps: 330 loss: 0.5805 iter time (s): 89.998 samples/sec: 1.422

100%|██████████| 1/1 [01:30<00:00, 90.77s/it][A100%|██████████| 1/1 [01:30<00:00, 90.77s/it]
  6%|▋         | 335/5198 [10:00:21<126:44:59, 93.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.82s/it][A100%|██████████| 1/1 [01:30<00:00, 90.82s/it]
  6%|▋         | 335/5198 [10:00:21<126:45:41, 93.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.78s/it][A100%|██████████| 1/1 [01:30<00:00, 90.78s/it]
  6%|▋         | 335/5198 [10:00:21<126:44:40, 93.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.80s/it][A100%|██████████| 1/1 [01:30<00:00, 90.80s/it]
  6%|▋         | 335/5198 [10:00:21<126:45:14, 93.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.75s/it][A100%|██████████| 1/1 [01:30<00:00, 90.75s/it]
  6%|▋         | 335/5198 [10:00:22<126:44:05, 93.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.75s/it][A100%|██████████| 1/1 [01:30<00:00, 90.75s/it]
  6%|▋         | 335/5198 [10:00:22<126:44:34, 93.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.77s/it][A100%|██████████| 1/1 [01:30<00:00, 90.77s/it]
  6%|▋         | 335/5198 [10:00:24<126:44:51, 93.83s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_20
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.74s/it][A100%|██████████| 1/1 [02:00<00:00, 120.74s/it]
  6%|▋         | 336/5198 [10:02:21<137:42:09, 101.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 05:27:28,144] [INFO] [logging.py:96:log_dist] [Rank 0] step=331, skipped=0, lr=[1.9959242943879762e-05], mom=[(0.9, 0.999)]
steps: 331 loss: 0.7844 iter time (s): 120.905 samples/sec: 1.059

100%|██████████| 1/1 [02:01<00:00, 121.80s/it][A100%|██████████| 1/1 [02:01<00:00, 121.80s/it]
  6%|▋         | 336/5198 [10:02:23<138:03:27, 102.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:01<00:00, 121.73s/it][A100%|██████████| 1/1 [02:01<00:00, 121.73s/it]
  6%|▋         | 336/5198 [10:02:23<138:02:23, 102.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:01<00:00, 121.94s/it][A100%|██████████| 1/1 [02:01<00:00, 121.94s/it]
  6%|▋         | 336/5198 [10:02:23<138:06:41, 102.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:01<00:00, 121.83s/it][A100%|██████████| 1/1 [02:01<00:00, 121.83s/it]
  6%|▋         | 336/5198 [10:02:23<138:04:29, 102.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:01<00:00, 121.94s/it][A100%|██████████| 1/1 [02:01<00:00, 121.94s/it]
  6%|▋         | 336/5198 [10:02:23<138:06:15, 102.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:01<00:00, 121.91s/it][A100%|██████████| 1/1 [02:01<00:00, 121.91s/it]
  6%|▋         | 336/5198 [10:02:24<138:05:54, 102.25s/it]
100%|██████████| 1/1 [02:01<00:00, 121.89s/it][A100%|██████████| 1/1 [02:01<00:00, 121.89s/it]
  6%|▋         | 336/5198 [10:02:26<138:05:41, 102.25s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_315

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.04s/it][A100%|██████████| 1/1 [01:35<00:00, 95.04s/it]
  6%|▋         | 337/5198 [10:03:56<134:55:08, 99.92s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 05:29:02,842] [INFO] [logging.py:96:log_dist] [Rank 0] step=332, skipped=0, lr=[1.9958730505579195e-05], mom=[(0.9, 0.999)]
steps: 332 loss: 0.6190 iter time (s): 93.416 samples/sec: 1.370

100%|██████████| 1/1 [01:34<00:00, 94.28s/it][A100%|██████████| 1/1 [01:34<00:00, 94.28s/it]
  6%|▋         | 337/5198 [10:03:57<134:49:04, 99.84s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.39s/it][A100%|██████████| 1/1 [01:34<00:00, 94.39s/it]
  6%|▋         | 337/5198 [10:03:57<134:50:55, 99.87s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.15s/it][A100%|██████████| 1/1 [01:34<00:00, 94.15s/it]
  6%|▋         | 337/5198 [10:03:57<134:48:05, 99.83s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.32s/it][A100%|██████████| 1/1 [01:34<00:00, 94.32s/it]
  6%|▋         | 337/5198 [10:03:58<134:50:31, 99.86s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.22s/it][A100%|██████████| 1/1 [01:34<00:00, 94.22s/it]
  6%|▋         | 337/5198 [10:03:58<134:49:30, 99.85s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.23s/it][A100%|██████████| 1/1 [01:34<00:00, 94.23s/it]
  6%|▋         | 337/5198 [10:03:58<134:49:30, 99.85s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.23s/it][A100%|██████████| 1/1 [01:34<00:00, 94.23s/it]
  6%|▋         | 337/5198 [10:04:00<134:49:24, 99.85s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_316
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.04s/it][A100%|██████████| 1/1 [01:39<00:00, 99.04s/it]
  7%|▋         | 338/5198 [10:05:36<134:35:32, 99.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 05:30:42,180] [INFO] [logging.py:96:log_dist] [Rank 0] step=333, skipped=0, lr=[1.9958214872591502e-05], mom=[(0.9, 0.999)]
steps: 333 loss: 0.5971 iter time (s): 98.544 samples/sec: 1.299

100%|██████████| 1/1 [01:39<00:00, 99.50s/it][A100%|██████████| 1/1 [01:39<00:00, 99.50s/it]
  7%|▋         | 338/5198 [10:05:36<134:39:17, 99.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.42s/it][A100%|██████████| 1/1 [01:39<00:00, 99.42s/it]
  7%|▋         | 338/5198 [10:05:37<134:38:29, 99.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.42s/it][A100%|██████████| 1/1 [01:39<00:00, 99.42s/it]
  7%|▋         | 338/5198 [10:05:37<134:36:39, 99.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.31s/it][A100%|██████████| 1/1 [01:39<00:00, 99.31s/it]
  7%|▋         | 338/5198 [10:05:37<134:35:30, 99.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.31s/it][A100%|██████████| 1/1 [01:39<00:00, 99.31s/it]
  7%|▋         | 338/5198 [10:05:37<134:34:57, 99.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.32s/it][A100%|██████████| 1/1 [01:39<00:00, 99.32s/it]
  7%|▋         | 338/5198 [10:05:39<134:34:58, 99.69s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_317
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.33s/it][A100%|██████████| 1/1 [01:39<00:00, 99.33s/it]
  7%|▋         | 338/5198 [10:05:37<134:35:27, 99.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.98s/it][A100%|██████████| 1/1 [01:37<00:00, 97.98s/it]
  7%|▋         | 339/5198 [10:07:14<133:56:31, 99.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 05:32:20,263] [INFO] [logging.py:96:log_dist] [Rank 0] step=334, skipped=0, lr=[1.995769604508211e-05], mom=[(0.9, 0.999)]
steps: 334 loss: 0.5786 iter time (s): 97.267 samples/sec: 1.316

100%|██████████| 1/1 [01:37<00:00, 97.92s/it][A100%|██████████| 1/1 [01:37<00:00, 97.92s/it]
  7%|▋         | 339/5198 [10:07:14<133:53:38, 99.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.96s/it][A100%|██████████| 1/1 [01:37<00:00, 97.96s/it]
  7%|▋         | 339/5198 [10:07:15<133:53:50, 99.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.03s/it][A100%|██████████| 1/1 [01:38<00:00, 98.03s/it]
  7%|▋         | 339/5198 [10:07:15<133:54:27, 99.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.04s/it][A100%|██████████| 1/1 [01:38<00:00, 98.04s/it]
  7%|▋         | 339/5198 [10:07:15<133:53:41, 99.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.07s/it][A100%|██████████| 1/1 [01:38<00:00, 98.07s/it]
  7%|▋         | 339/5198 [10:07:15<133:54:07, 99.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.04s/it][A100%|██████████| 1/1 [01:38<00:00, 98.04s/it]
  7%|▋         | 339/5198 [10:07:15<133:53:43, 99.20s/it]
100%|██████████| 1/1 [01:38<00:00, 98.05s/it][A100%|██████████| 1/1 [01:38<00:00, 98.05s/it]
  7%|▋         | 339/5198 [10:07:17<133:53:43, 99.20s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_318

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:13<00:00, 133.46s/it][A100%|██████████| 1/1 [02:13<00:00, 133.46s/it]
  7%|▋         | 340/5198 [10:09:27<147:49:25, 109.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 05:34:34,872] [INFO] [logging.py:96:log_dist] [Rank 0] step=335, skipped=0, lr=[1.9957174023217473e-05], mom=[(0.9, 0.999)]
steps: 335 loss: 0.5723 iter time (s): 133.817 samples/sec: 0.957

100%|██████████| 1/1 [02:14<00:00, 134.56s/it][A100%|██████████| 1/1 [02:14<00:00, 134.56s/it]
  7%|▋         | 340/5198 [10:09:29<148:11:14, 109.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:14<00:00, 134.59s/it][A100%|██████████| 1/1 [02:14<00:00, 134.59s/it]
  7%|▋         | 340/5198 [10:09:29<148:11:54, 109.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:14<00:00, 134.54s/it][A100%|██████████| 1/1 [02:14<00:00, 134.54s/it]
  7%|▋         | 340/5198 [10:09:29<148:11:24, 109.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:14<00:00, 134.54s/it][A100%|██████████| 1/1 [02:14<00:00, 134.54s/it]
  7%|▋         | 340/5198 [10:09:30<148:10:41, 109.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:14<00:00, 134.52s/it][A100%|██████████| 1/1 [02:14<00:00, 134.52s/it]
  7%|▋         | 340/5198 [10:09:30<148:10:24, 109.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:14<00:00, 134.55s/it][A100%|██████████| 1/1 [02:14<00:00, 134.55s/it]
  7%|▋         | 340/5198 [10:09:30<148:10:46, 109.81s/it]
100%|██████████| 1/1 [02:14<00:00, 134.55s/it][A100%|██████████| 1/1 [02:14<00:00, 134.55s/it]
  7%|▋         | 340/5198 [10:09:32<148:10:47, 109.81s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_319

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.55s/it][A100%|██████████| 1/1 [01:28<00:00, 88.55s/it]
  7%|▋         | 341/5198 [10:10:56<139:21:30, 103.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 05:36:02,276] [INFO] [logging.py:96:log_dist] [Rank 0] step=336, skipped=0, lr=[1.9956648807165074e-05], mom=[(0.9, 0.999)]
steps: 336 loss: 0.5718 iter time (s): 86.661 samples/sec: 1.477

100%|██████████| 1/1 [01:27<00:00, 87.44s/it][A100%|██████████| 1/1 [01:27<00:00, 87.44s/it]
  7%|▋         | 341/5198 [10:10:56<139:06:15, 103.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.37s/it][A100%|██████████| 1/1 [01:27<00:00, 87.37s/it]
  7%|▋         | 341/5198 [10:10:56<139:04:57, 103.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.38s/it][A100%|██████████| 1/1 [01:27<00:00, 87.38s/it]
  7%|▋         | 341/5198 [10:10:57<139:04:55, 103.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.39s/it][A100%|██████████| 1/1 [01:27<00:00, 87.39s/it]
  7%|▋         | 341/5198 [10:10:57<139:04:31, 103.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.45s/it][A100%|██████████| 1/1 [01:27<00:00, 87.45s/it]
  7%|▋         | 341/5198 [10:10:57<139:06:03, 103.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A

100%|██████████| 1/1 [01:27<00:00, 87.42s/it][A100%|██████████| 1/1 [01:27<00:00, 87.42s/it][A100%|██████████| 1/1 [01:27<00:00, 87.42s/it]
  7%|▋         | 341/5198 [10:10:59<139:05:23, 103.09s/it]100%|██████████| 1/1 [01:27<00:00, 87.42s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_320

  7%|▋         | 341/5198 [10:10:57<139:05:32, 103.09s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.21s/it][A100%|██████████| 1/1 [01:27<00:00, 87.21s/it]
  7%|▋         | 342/5198 [10:12:23<132:52:05, 98.50s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 05:37:29,607] [INFO] [logging.py:96:log_dist] [Rank 0] step=337, skipped=0, lr=[1.99561203970934e-05], mom=[(0.9, 0.999)]
steps: 337 loss: 0.6048 iter time (s): 86.568 samples/sec: 1.479

100%|██████████| 1/1 [01:27<00:00, 87.28s/it][A100%|██████████| 1/1 [01:27<00:00, 87.28s/it]
  7%|▋         | 342/5198 [10:12:24<132:40:32, 98.36s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.32s/it][A100%|██████████| 1/1 [01:27<00:00, 87.32s/it]
  7%|▋         | 342/5198 [10:12:24<132:40:32, 98.36s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.35s/it][A100%|██████████| 1/1 [01:27<00:00, 87.35s/it]
  7%|▋         | 342/5198 [10:12:24<132:41:26, 98.37s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.34s/it][A100%|██████████| 1/1 [01:27<00:00, 87.34s/it]
  7%|▋         | 342/5198 [10:12:24<132:40:50, 98.36s/it] 
100%|██████████| 1/1 [01:27<00:00, 87.34s/it][A100%|██████████| 1/1 [01:27<00:00, 87.34s/it]
  7%|▋         | 342/5198 [10:12:24<132:41:49, 98.38s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.36s/it][A100%|██████████| 1/1 [01:27<00:00, 87.36s/it]
  7%|▋         | 342/5198 [10:12:24<132:41:49, 98.38s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.37s/it][A100%|██████████| 1/1 [01:27<00:00, 87.37s/it]
  7%|▋         | 342/5198 [10:12:27<132:42:09, 98.38s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_321
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:05<00:00, 125.15s/it][A100%|██████████| 1/1 [02:05<00:00, 125.15s/it]
  7%|▋         | 343/5198 [10:14:29<143:41:35, 106.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 05:39:35,990] [INFO] [logging.py:96:log_dist] [Rank 0] step=338, skipped=0, lr=[1.9955588793171995e-05], mom=[(0.9, 0.999)]
steps: 338 loss: 0.5547 iter time (s): 125.581 samples/sec: 1.019

100%|██████████| 1/1 [02:06<00:00, 126.42s/it][A100%|██████████| 1/1 [02:06<00:00, 126.42s/it]
  7%|▋         | 343/5198 [10:14:30<144:00:29, 106.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:06<00:00, 126.36s/it][A100%|██████████| 1/1 [02:06<00:00, 126.36s/it]
  7%|▋         | 343/5198 [10:14:30<143:58:54, 106.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:06<00:00, 126.35s/it][A100%|██████████| 1/1 [02:06<00:00, 126.35s/it]
  7%|▋         | 343/5198 [10:14:31<143:59:15, 106.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:06<00:00, 126.29s/it][A100%|██████████| 1/1 [02:06<00:00, 126.29s/it]
  7%|▋         | 343/5198 [10:14:31<143:58:07, 106.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:06<00:00, 126.38s/it][A100%|██████████| 1/1 [02:06<00:00, 126.38s/it]
  7%|▋         | 343/5198 [10:14:31<143:59:36, 106.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:06<00:00, 126.30s/it][A100%|██████████| 1/1 [02:06<00:00, 126.30s/it]
  7%|▋         | 343/5198 [10:14:31<143:58:14, 106.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:06<00:00, 126.32s/it][A100%|██████████| 1/1 [02:06<00:00, 126.32s/it]
  7%|▋         | 343/5198 [10:14:33<143:58:56, 106.76s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_322
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.34s/it][A100%|██████████| 1/1 [01:47<00:00, 107.34s/it]
  7%|▋         | 344/5198 [10:16:16<144:03:25, 106.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 05:41:22,624] [INFO] [logging.py:96:log_dist] [Rank 0] step=339, skipped=0, lr=[1.9955053995571402e-05], mom=[(0.9, 0.999)]
steps: 339 loss: 0.6578 iter time (s): 105.880 samples/sec: 1.209

100%|██████████| 1/1 [01:46<00:00, 106.60s/it][A100%|██████████| 1/1 [01:46<00:00, 106.61s/it]
  7%|▋         | 344/5198 [10:16:17<143:54:45, 106.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.68s/it][A100%|██████████| 1/1 [01:46<00:00, 106.68s/it]
  7%|▋         | 344/5198 [10:16:17<143:55:33, 106.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.65s/it][A100%|██████████| 1/1 [01:46<00:00, 106.65s/it]
  7%|▋         | 344/5198 [10:16:17<143:54:49, 106.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.70s/it][A100%|██████████| 1/1 [01:46<00:00, 106.70s/it]
  7%|▋         | 344/5198 [10:16:17<143:55:24, 106.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.64s/it][A100%|██████████| 1/1 [01:46<00:00, 106.64s/it]
  7%|▋         | 344/5198 [10:16:17<143:54:48, 106.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.68s/it][A100%|██████████| 1/1 [01:46<00:00, 106.68s/it]
  7%|▋         | 344/5198 [10:16:17<143:54:55, 106.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.67s/it][A100%|██████████| 1/1 [01:46<00:00, 106.67s/it]
  7%|▋         | 344/5198 [10:16:20<143:54:57, 106.74s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_323
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.38s/it][A100%|██████████| 1/1 [01:26<00:00, 86.38s/it]
  7%|▋         | 345/5198 [10:17:43<135:49:45, 100.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 05:42:48,883] [INFO] [logging.py:96:log_dist] [Rank 0] step=340, skipped=0, lr=[1.9954516004463197e-05], mom=[(0.9, 0.999)]
steps: 340 loss: 0.5685 iter time (s): 85.467 samples/sec: 1.498

100%|██████████| 1/1 [01:26<00:00, 86.26s/it][A100%|██████████| 1/1 [01:26<00:00, 86.26s/it]
  7%|▋         | 345/5198 [10:17:43<135:36:40, 100.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.27s/it][A100%|██████████| 1/1 [01:26<00:00, 86.27s/it]
  7%|▋         | 345/5198 [10:17:43<135:37:14, 100.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.29s/it][A100%|██████████| 1/1 [01:26<00:00, 86.30s/it]
  7%|▋         | 345/5198 [10:17:44<135:37:17, 100.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.24s/it][A100%|██████████| 1/1 [01:26<00:00, 86.24s/it]
  7%|▋         | 345/5198 [10:17:44<135:36:23, 100.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.24s/it][A100%|██████████| 1/1 [01:26<00:00, 86.24s/it]
  7%|▋         | 345/5198 [10:17:44<135:35:51, 100.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.27s/it][A100%|██████████| 1/1 [01:26<00:00, 86.27s/it]
  7%|▋         | 345/5198 [10:17:44<135:36:38, 100.60s/it]

  0%|          | 0/1 [00:00<?, ?it/s][A100%|██████████| 1/1 [01:26<00:00, 86.26s/it][A100%|██████████| 1/1 [01:26<00:00, 86.26s/it]
  7%|▋         | 345/5198 [10:17:46<135:36:24, 100.59s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_324
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.24s/it][A100%|██████████| 1/1 [01:30<00:00, 90.24s/it]
  7%|▋         | 346/5198 [10:19:13<131:35:53, 97.64s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 05:44:19,462] [INFO] [logging.py:96:log_dist] [Rank 0] step=341, skipped=0, lr=[1.9953974820019984e-05], mom=[(0.9, 0.999)]
steps: 341 loss: 0.5969 iter time (s): 89.784 samples/sec: 1.426

100%|██████████| 1/1 [01:30<00:00, 90.68s/it][A100%|██████████| 1/1 [01:30<00:00, 90.68s/it]
  7%|▋         | 346/5198 [10:19:14<131:34:32, 97.62s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.58s/it][A100%|██████████| 1/1 [01:30<00:00, 90.59s/it]
  7%|▋         | 346/5198 [10:19:14<131:32:48, 97.60s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.60s/it][A100%|██████████| 1/1 [01:30<00:00, 90.60s/it]
  7%|▋         | 346/5198 [10:19:14<131:33:00, 97.61s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.64s/it][A100%|██████████| 1/1 [01:30<00:00, 90.65s/it]
  7%|▋         | 346/5198 [10:19:14<131:33:31, 97.61s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.66s/it][A100%|██████████| 1/1 [01:30<00:00, 90.66s/it]
  7%|▋         | 346/5198 [10:19:14<131:33:32, 97.61s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.63s/it][A100%|██████████| 1/1 [01:30<00:00, 90.63s/it]
  7%|▋         | 346/5198 [10:19:14<131:33:22, 97.61s/it] 
100%|██████████| 1/1 [01:30<00:00, 90.63s/it][A100%|██████████| 1/1 [01:30<00:00, 90.63s/it]
  7%|▋         | 346/5198 [10:19:17<131:33:09, 97.61s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_325

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.57s/it][A100%|██████████| 1/1 [01:55<00:00, 115.57s/it]
  7%|▋         | 347/5198 [10:21:09<138:52:20, 103.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 05:46:15,903] [INFO] [logging.py:96:log_dist] [Rank 0] step=342, skipped=0, lr=[1.9953430442415384e-05], mom=[(0.9, 0.999)]
steps: 342 loss: 0.5795 iter time (s): 115.589 samples/sec: 1.107

100%|██████████| 1/1 [01:56<00:00, 116.30s/it][A100%|██████████| 1/1 [01:56<00:00, 116.30s/it]
  7%|▋         | 347/5198 [10:21:10<139:06:06, 103.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.34s/it][A100%|██████████| 1/1 [01:56<00:00, 116.34s/it]
  7%|▋         | 347/5198 [10:21:10<139:05:58, 103.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.46s/it][A100%|██████████| 1/1 [01:56<00:00, 116.46s/it]
  7%|▋         | 347/5198 [10:21:11<139:08:54, 103.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.39s/it][A100%|██████████| 1/1 [01:56<00:00, 116.39s/it]
  7%|▋         | 347/5198 [10:21:11<139:07:32, 103.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.42s/it][A100%|██████████| 1/1 [01:56<00:00, 116.42s/it]
  7%|▋         | 347/5198 [10:21:11<139:08:15, 103.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.45s/it][A100%|██████████| 1/1 [01:56<00:00, 116.45s/it]
  7%|▋         | 347/5198 [10:21:11<139:08:47, 103.26s/it]
100%|██████████| 1/1 [01:56<00:00, 116.44s/it][A100%|██████████| 1/1 [01:56<00:00, 116.44s/it]
  7%|▋         | 347/5198 [10:21:13<139:08:32, 103.26s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_326
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.87s/it][A100%|██████████| 1/1 [01:53<00:00, 113.87s/it]
  7%|▋         | 348/5198 [10:23:03<143:16:34, 106.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 05:48:09,857] [INFO] [logging.py:96:log_dist] [Rank 0] step=343, skipped=0, lr=[1.9952882871824054e-05], mom=[(0.9, 0.999)]
steps: 343 loss: 0.6212 iter time (s): 113.095 samples/sec: 1.132

100%|██████████| 1/1 [01:54<00:00, 114.17s/it][A100%|██████████| 1/1 [01:54<00:00, 114.17s/it]
  7%|▋         | 348/5198 [10:23:04<143:29:49, 106.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.20s/it][A100%|██████████| 1/1 [01:54<00:00, 114.21s/it]
  7%|▋         | 348/5198 [10:23:04<143:30:51, 106.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.18s/it][A100%|██████████| 1/1 [01:54<00:00, 114.18s/it]
  7%|▋         | 348/5198 [10:23:05<143:32:05, 106.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.13s/it][A100%|██████████| 1/1 [01:54<00:00, 114.13s/it]
  7%|▋         | 348/5198 [10:23:05<143:30:29, 106.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.19s/it][A100%|██████████| 1/1 [01:54<00:00, 114.19s/it]
  7%|▋         | 348/5198 [10:23:05<143:31:34, 106.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.24s/it][A100%|██████████| 1/1 [01:54<00:00, 114.24s/it]
  7%|▋         | 348/5198 [10:23:07<143:33:17, 106.56s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_327
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.37s/it][A100%|██████████| 1/1 [01:54<00:00, 114.38s/it]
  7%|▋         | 348/5198 [10:23:05<143:36:43, 106.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.11s/it][A100%|██████████| 1/1 [01:27<00:00, 87.11s/it]
  7%|▋         | 349/5198 [10:24:30<135:31:38, 100.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 05:49:36,322] [INFO] [logging.py:96:log_dist] [Rank 0] step=344, skipped=0, lr=[1.995233210842166e-05], mom=[(0.9, 0.999)]
steps: 344 loss: 0.5815 iter time (s): 85.305 samples/sec: 1.501

100%|██████████| 1/1 [01:26<00:00, 86.35s/it][A100%|██████████| 1/1 [01:26<00:00, 86.35s/it]
  7%|▋         | 349/5198 [10:24:31<135:19:22, 100.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.30s/it][A100%|██████████| 1/1 [01:26<00:00, 86.30s/it]
  7%|▋         | 349/5198 [10:24:31<135:18:54, 100.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.19s/it][A100%|██████████| 1/1 [01:26<00:00, 86.19s/it]
  7%|▋         | 349/5198 [10:24:31<135:17:06, 100.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.22s/it][A100%|██████████| 1/1 [01:26<00:00, 86.23s/it]
  7%|▋         | 349/5198 [10:24:31<135:17:36, 100.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.26s/it][A100%|██████████| 1/1 [01:26<00:00, 86.26s/it]
  7%|▋         | 349/5198 [10:24:31<135:17:50, 100.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.12s/it][A100%|██████████| 1/1 [01:26<00:00, 86.12s/it]
  7%|▋         | 349/5198 [10:24:33<135:16:23, 100.43s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_328
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.99s/it][A100%|██████████| 1/1 [01:25<00:00, 85.99s/it]
  7%|▋         | 349/5198 [10:24:31<135:15:48, 100.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.92s/it][A100%|██████████| 1/1 [01:40<00:00, 100.92s/it]
  7%|▋         | 350/5198 [10:26:11<135:40:29, 100.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 05:51:17,808] [INFO] [logging.py:96:log_dist] [Rank 0] step=345, skipped=0, lr=[1.9951778152384908e-05], mom=[(0.9, 0.999)]
steps: 345 loss: 0.5817 iter time (s): 100.662 samples/sec: 1.272

100%|██████████| 1/1 [01:41<00:00, 101.37s/it][A100%|██████████| 1/1 [01:41<00:00, 101.37s/it]
  7%|▋         | 350/5198 [10:26:12<135:39:49, 100.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.37s/it][A100%|██████████| 1/1 [01:41<00:00, 101.37s/it]
  7%|▋         | 350/5198 [10:26:12<135:39:32, 100.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.38s/it][A100%|██████████| 1/1 [01:41<00:00, 101.38s/it]
  7%|▋         | 350/5198 [10:26:12<135:38:24, 100.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.40s/it][A100%|██████████| 1/1 [01:41<00:00, 101.40s/it]
  7%|▋         | 350/5198 [10:26:12<135:39:21, 100.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.44s/it][A100%|██████████| 1/1 [01:41<00:00, 101.44s/it]
  7%|▋         | 350/5198 [10:26:13<135:40:30, 100.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.39s/it][A100%|██████████| 1/1 [01:41<00:00, 101.39s/it]
  7%|▋         | 350/5198 [10:26:13<135:37:52, 100.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.42s/it][A100%|██████████| 1/1 [01:41<00:00, 101.42s/it]
  7%|▋         | 350/5198 [10:26:15<135:38:53, 100.73s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_329
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.83s/it][A100%|██████████| 1/1 [01:30<00:00, 90.83s/it]
  7%|▋         | 351/5198 [10:27:42<131:41:43, 97.81s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 05:52:48,451] [INFO] [logging.py:96:log_dist] [Rank 0] step=346, skipped=0, lr=[1.9951221003891517e-05], mom=[(0.9, 0.999)]
steps: 346 loss: 0.5885 iter time (s): 89.872 samples/sec: 1.424

100%|██████████| 1/1 [01:30<00:00, 90.55s/it][A100%|██████████| 1/1 [01:30<00:00, 90.55s/it]
  7%|▋         | 351/5198 [10:27:42<131:31:27, 97.69s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.61s/it][A100%|██████████| 1/1 [01:30<00:00, 90.61s/it]
  7%|▋         | 351/5198 [10:27:43<131:32:51, 97.70s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.72s/it][A100%|██████████| 1/1 [01:30<00:00, 90.72s/it]
  7%|▋         | 351/5198 [10:27:43<131:34:39, 97.73s/it] 
100%|██████████| 1/1 [01:30<00:00, 90.62s/it][A100%|██████████| 1/1 [01:30<00:00, 90.62s/it]
  7%|▋         | 351/5198 [10:27:43<131:32:45, 97.70s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.58s/it][A100%|██████████| 1/1 [01:30<00:00, 90.58s/it]
  7%|▋         | 351/5198 [10:27:43<131:32:29, 97.70s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.60s/it][A100%|██████████| 1/1 [01:30<00:00, 90.60s/it]
  7%|▋         | 351/5198 [10:27:43<131:31:07, 97.68s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.60s/it][A100%|██████████| 1/1 [01:30<00:00, 90.60s/it]
  7%|▋         | 351/5198 [10:27:45<131:32:05, 97.69s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_21
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:06<00:00, 126.27s/it][A100%|██████████| 1/1 [02:06<00:00, 126.27s/it]
  7%|▋         | 352/5198 [10:29:49<143:12:06, 106.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 05:54:55,542] [INFO] [logging.py:96:log_dist] [Rank 0] step=347, skipped=0, lr=[1.9950660663120237e-05], mom=[(0.9, 0.999)]
steps: 347 loss: 0.8003 iter time (s): 126.657 samples/sec: 1.011

100%|██████████| 1/1 [02:07<00:00, 127.65s/it][A100%|██████████| 1/1 [02:07<00:00, 127.65s/it]
  7%|▋         | 352/5198 [10:29:50<143:35:57, 106.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:07<00:00, 127.58s/it][A100%|██████████| 1/1 [02:07<00:00, 127.58s/it]
  7%|▋         | 352/5198 [10:29:50<143:35:18, 106.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:07<00:00, 127.46s/it][A100%|██████████| 1/1 [02:07<00:00, 127.46s/it]
  7%|▋         | 352/5198 [10:29:51<143:33:38, 106.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:07<00:00, 127.64s/it][A100%|██████████| 1/1 [02:07<00:00, 127.64s/it]
  7%|▋         | 352/5198 [10:29:51<143:36:43, 106.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:07<00:00, 127.58s/it][A100%|██████████| 1/1 [02:07<00:00, 127.59s/it]
  7%|▋         | 352/5198 [10:29:53<143:34:58, 106.66s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_330
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:07<00:00, 127.66s/it][A100%|██████████| 1/1 [02:07<00:00, 127.66s/it]
  7%|▋         | 352/5198 [10:29:51<143:37:04, 106.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:07<00:00, 127.64s/it][A100%|██████████| 1/1 [02:07<00:00, 127.64s/it]
  7%|▋         | 352/5198 [10:29:51<143:35:36, 106.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.66s/it][A100%|██████████| 1/1 [01:29<00:00, 89.66s/it]
  7%|▋         | 353/5198 [10:31:18<136:28:56, 101.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 05:56:24,516] [INFO] [logging.py:96:log_dist] [Rank 0] step=348, skipped=0, lr=[1.995009713025083e-05], mom=[(0.9, 0.999)]
steps: 348 loss: 0.5564 iter time (s): 87.734 samples/sec: 1.459

100%|██████████| 1/1 [01:28<00:00, 88.42s/it][A100%|██████████| 1/1 [01:28<00:00, 88.42s/it]
  7%|▋         | 353/5198 [10:31:19<136:12:17, 101.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.49s/it][A100%|██████████| 1/1 [01:28<00:00, 88.50s/it]
  7%|▋         | 353/5198 [10:31:19<136:13:29, 101.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.53s/it][A100%|██████████| 1/1 [01:28<00:00, 88.53s/it]
  7%|▋         | 353/5198 [10:31:19<136:13:07, 101.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.39s/it][A100%|██████████| 1/1 [01:28<00:00, 88.39s/it]
  7%|▋         | 353/5198 [10:31:19<136:12:03, 101.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.43s/it][A100%|██████████| 1/1 [01:28<00:00, 88.43s/it]
  7%|▋         | 353/5198 [10:31:19<136:13:04, 101.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.44s/it][A100%|██████████| 1/1 [01:28<00:00, 88.44s/it]
  7%|▋         | 353/5198 [10:31:19<136:12:22, 101.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.49s/it][A100%|██████████| 1/1 [01:28<00:00, 88.49s/it]
  7%|▋         | 353/5198 [10:31:22<136:13:17, 101.22s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_331
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:07<00:00, 127.09s/it][A100%|██████████| 1/1 [02:07<00:00, 127.09s/it]
  7%|▋         | 354/5198 [10:33:26<146:52:20, 109.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 05:58:32,877] [INFO] [logging.py:96:log_dist] [Rank 0] step=349, skipped=0, lr=[1.9949530405464102e-05], mom=[(0.9, 0.999)]
steps: 349 loss: 0.6449 iter time (s): 127.588 samples/sec: 1.003

100%|██████████| 1/1 [02:08<00:00, 128.38s/it][A100%|██████████| 1/1 [02:08<00:00, 128.38s/it]
  7%|▋         | 354/5198 [10:33:27<147:08:59, 109.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:08<00:00, 128.40s/it][A100%|██████████| 1/1 [02:08<00:00, 128.40s/it]
  7%|▋         | 354/5198 [10:33:27<147:10:24, 109.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:08<00:00, 128.33s/it][A100%|██████████| 1/1 [02:08<00:00, 128.33s/it]
  7%|▋         | 354/5198 [10:33:27<147:08:23, 109.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:08<00:00, 128.40s/it][A100%|██████████| 1/1 [02:08<00:00, 128.40s/it]
  7%|▋         | 354/5198 [10:33:28<147:09:24, 109.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:08<00:00, 128.38s/it][A100%|██████████| 1/1 [02:08<00:00, 128.38s/it]
  7%|▋         | 354/5198 [10:33:28<147:09:36, 109.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:08<00:00, 128.38s/it][A100%|██████████| 1/1 [02:08<00:00, 128.38s/it]
  7%|▋         | 354/5198 [10:33:28<147:08:57, 109.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:08<00:00, 128.36s/it][A100%|██████████| 1/1 [02:08<00:00, 128.36s/it]
  7%|▋         | 354/5198 [10:33:30<147:09:10, 109.36s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_332
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.95s/it][A100%|██████████| 1/1 [01:43<00:00, 103.95s/it]
  7%|▋         | 355/5198 [10:35:10<144:47:57, 107.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 06:00:16,321] [INFO] [logging.py:96:log_dist] [Rank 0] step=350, skipped=0, lr=[1.994896048894187e-05], mom=[(0.9, 0.999)]
steps: 350 loss: 0.5619 iter time (s): 102.665 samples/sec: 1.247

100%|██████████| 1/1 [01:43<00:00, 103.48s/it][A100%|██████████| 1/1 [01:43<00:00, 103.48s/it]
  7%|▋         | 355/5198 [10:35:10<144:45:03, 107.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.44s/it][A100%|██████████| 1/1 [01:43<00:00, 103.44s/it]
  7%|▋         | 355/5198 [10:35:11<144:45:04, 107.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.47s/it][A100%|██████████| 1/1 [01:43<00:00, 103.47s/it]
  7%|▋         | 355/5198 [10:35:11<144:44:27, 107.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.43s/it][A100%|██████████| 1/1 [01:43<00:00, 103.43s/it]
  7%|▋         | 355/5198 [10:35:11<144:44:09, 107.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.49s/it][A100%|██████████| 1/1 [01:43<00:00, 103.49s/it]
  7%|▋         | 355/5198 [10:35:11<144:45:43, 107.61s/it]
100%|██████████| 1/1 [01:43<00:00, 103.48s/it][A100%|██████████| 1/1 [01:43<00:00, 103.48s/it]
  7%|▋         | 355/5198 [10:35:11<144:44:50, 107.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.49s/it][A100%|██████████| 1/1 [01:43<00:00, 103.49s/it]
  7%|▋         | 355/5198 [10:35:13<144:45:19, 107.60s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_333
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.59s/it][A100%|██████████| 1/1 [01:41<00:00, 101.59s/it]
  7%|▋         | 356/5198 [10:36:51<142:23:07, 105.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 06:01:57,990] [INFO] [logging.py:96:log_dist] [Rank 0] step=351, skipped=0, lr=[1.9948387380866977e-05], mom=[(0.9, 0.999)]
steps: 351 loss: 0.5854 iter time (s): 100.837 samples/sec: 1.269

100%|██████████| 1/1 [01:41<00:00, 101.74s/it][A100%|██████████| 1/1 [01:41<00:00, 101.74s/it]
  7%|▋         | 356/5198 [10:36:52<142:21:41, 105.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.72s/it][A100%|██████████| 1/1 [01:41<00:00, 101.72s/it]
  7%|▋         | 356/5198 [10:36:52<142:21:08, 105.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.74s/it][A100%|██████████| 1/1 [01:41<00:00, 101.74s/it]
  7%|▋         | 356/5198 [10:36:53<142:21:09, 105.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.66s/it][A100%|██████████| 1/1 [01:41<00:00, 101.66s/it]
  7%|▋         | 356/5198 [10:36:53<142:19:14, 105.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.63s/it][A100%|██████████| 1/1 [01:41<00:00, 101.63s/it]
  7%|▋         | 356/5198 [10:36:53<142:19:22, 105.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.69s/it][A100%|██████████| 1/1 [01:41<00:00, 101.69s/it]
  7%|▋         | 356/5198 [10:36:53<142:20:16, 105.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.68s/it][A100%|██████████| 1/1 [01:41<00:00, 101.68s/it]
  7%|▋         | 356/5198 [10:36:55<142:20:18, 105.83s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_334
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.32s/it][A100%|██████████| 1/1 [01:24<00:00, 84.32s/it]
  7%|▋         | 357/5198 [10:38:16<133:43:33, 99.45s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 06:03:21,992] [INFO] [logging.py:96:log_dist] [Rank 0] step=352, skipped=0, lr=[1.9947811081423287e-05], mom=[(0.9, 0.999)]
steps: 352 loss: 0.5646 iter time (s): 83.150 samples/sec: 1.539

100%|██████████| 1/1 [01:23<00:00, 83.91s/it][A100%|██████████| 1/1 [01:23<00:00, 83.91s/it]
  7%|▋         | 357/5198 [10:38:16<133:29:10, 99.27s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.09s/it][A100%|██████████| 1/1 [01:24<00:00, 84.09s/it]
  7%|▋         | 357/5198 [10:38:16<133:33:15, 99.32s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 84.00s/it][A100%|██████████| 1/1 [01:23<00:00, 84.00s/it]
  7%|▋         | 357/5198 [10:38:17<133:30:55, 99.29s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.09s/it][A100%|██████████| 1/1 [01:24<00:00, 84.09s/it]
  7%|▋         | 357/5198 [10:38:17<133:31:50, 99.30s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.20s/it][A100%|██████████| 1/1 [01:24<00:00, 84.20s/it]
  7%|▋         | 357/5198 [10:38:17<133:34:30, 99.33s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.09s/it][A100%|██████████| 1/1 [01:24<00:00, 84.09s/it]
  7%|▋         | 357/5198 [10:38:17<133:32:35, 99.31s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.09s/it][A100%|██████████| 1/1 [01:24<00:00, 84.09s/it]
  7%|▋         | 357/5198 [10:38:19<133:32:36, 99.31s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_335
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.65s/it][A100%|██████████| 1/1 [01:33<00:00, 93.65s/it]
  7%|▋         | 358/5198 [10:39:50<131:25:38, 97.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 06:04:56,078] [INFO] [logging.py:96:log_dist] [Rank 0] step=353, skipped=0, lr=[1.994723159079569e-05], mom=[(0.9, 0.999)]
steps: 353 loss: 0.6404 iter time (s): 93.140 samples/sec: 1.374

100%|██████████| 1/1 [01:34<00:00, 94.02s/it][A100%|██████████| 1/1 [01:34<00:00, 94.02s/it]
  7%|▋         | 358/5198 [10:39:50<131:21:37, 97.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.83s/it][A100%|██████████| 1/1 [01:33<00:00, 93.83s/it]
  7%|▋         | 358/5198 [10:39:50<131:19:07, 97.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 94.00s/it][A100%|██████████| 1/1 [01:33<00:00, 94.00s/it]
  7%|▋         | 358/5198 [10:39:51<131:21:27, 97.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.86s/it][A100%|██████████| 1/1 [01:33<00:00, 93.86s/it]
  7%|▋         | 358/5198 [10:39:51<131:20:29, 97.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.90s/it][A100%|██████████| 1/1 [01:33<00:00, 93.90s/it]
  7%|▋         | 358/5198 [10:39:51<131:19:49, 97.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.91s/it][A100%|██████████| 1/1 [01:33<00:00, 93.91s/it]
  7%|▋         | 358/5198 [10:39:51<131:20:32, 97.69s/it]
100%|██████████| 1/1 [01:33<00:00, 93.91s/it][A100%|██████████| 1/1 [01:33<00:00, 93.91s/it]
  7%|▋         | 358/5198 [10:39:53<131:20:22, 97.69s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_336

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.51s/it][A100%|██████████| 1/1 [01:50<00:00, 110.51s/it]
  7%|▋         | 359/5198 [10:41:40<136:35:32, 101.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 06:06:47,172] [INFO] [logging.py:96:log_dist] [Rank 0] step=354, skipped=0, lr=[1.994664890917011e-05], mom=[(0.9, 0.999)]
steps: 354 loss: 0.6108 iter time (s): 110.319 samples/sec: 1.160

100%|██████████| 1/1 [01:51<00:00, 111.11s/it][A100%|██████████| 1/1 [01:51<00:00, 111.11s/it]
  7%|▋         | 359/5198 [10:41:41<136:44:31, 101.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.08s/it][A100%|██████████| 1/1 [01:51<00:00, 111.08s/it]
  7%|▋         | 359/5198 [10:41:41<136:42:12, 101.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.07s/it][A100%|██████████| 1/1 [01:51<00:00, 111.08s/it]
  7%|▋         | 359/5198 [10:41:42<136:43:34, 101.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.05s/it][A100%|██████████| 1/1 [01:51<00:00, 111.05s/it]
  7%|▋         | 359/5198 [10:41:42<136:42:16, 101.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.07s/it][A100%|██████████| 1/1 [01:51<00:00, 111.07s/it]
  7%|▋         | 359/5198 [10:41:42<136:42:22, 101.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.03s/it][A100%|██████████| 1/1 [01:51<00:00, 111.03s/it]
  7%|▋         | 359/5198 [10:41:42<136:41:41, 101.69s/it]
100%|██████████| 1/1 [01:51<00:00, 111.03s/it][A100%|██████████| 1/1 [01:51<00:00, 111.03s/it]
  7%|▋         | 359/5198 [10:41:44<136:41:37, 101.69s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_337

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.12s/it][A100%|██████████| 1/1 [01:36<00:00, 96.12s/it]
  7%|▋         | 360/5198 [10:43:17<134:24:25, 100.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 06:08:23,044] [INFO] [logging.py:96:log_dist] [Rank 0] step=355, skipped=0, lr=[1.9946063036733475e-05], mom=[(0.9, 0.999)]
steps: 355 loss: 0.6195 iter time (s): 95.154 samples/sec: 1.345

100%|██████████| 1/1 [01:35<00:00, 95.85s/it][A100%|██████████| 1/1 [01:35<00:00, 95.85s/it]
  7%|▋         | 360/5198 [10:43:17<134:20:52, 99.97s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.97s/it][A100%|██████████| 1/1 [01:35<00:00, 95.97s/it]
  7%|▋         | 360/5198 [10:43:17<134:22:10, 99.99s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.87s/it][A100%|██████████| 1/1 [01:35<00:00, 95.87s/it]
  7%|▋         | 360/5198 [10:43:18<134:20:38, 99.97s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.03s/it][A100%|██████████| 1/1 [01:36<00:00, 96.03s/it]
  7%|▋         | 360/5198 [10:43:18<134:23:28, 100.00s/it]
100%|██████████| 1/1 [01:35<00:00, 95.99s/it][A100%|██████████| 1/1 [01:35<00:00, 95.99s/it]
  7%|▋         | 360/5198 [10:43:18<134:22:43, 99.99s/it] 
100%|██████████| 1/1 [01:35<00:00, 95.97s/it][A100%|██████████| 1/1 [01:35<00:00, 95.97s/it]
  7%|▋         | 360/5198 [10:43:20<134:21:36, 99.98s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_338

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.01s/it][A100%|██████████| 1/1 [01:36<00:00, 96.01s/it]
  7%|▋         | 360/5198 [10:43:18<134:22:36, 99.99s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.18s/it][A100%|██████████| 1/1 [01:23<00:00, 83.18s/it]
  7%|▋         | 361/5198 [10:44:40<127:38:55, 95.00s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 06:09:45,970] [INFO] [logging.py:96:log_dist] [Rank 0] step=356, skipped=0, lr=[1.9945473973673758e-05], mom=[(0.9, 0.999)]
steps: 356 loss: 0.5995 iter time (s): 82.109 samples/sec: 1.559

100%|██████████| 1/1 [01:22<00:00, 82.92s/it][A100%|██████████| 1/1 [01:22<00:00, 82.92s/it]
  7%|▋         | 361/5198 [10:44:40<127:27:08, 94.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.82s/it][A100%|██████████| 1/1 [01:22<00:00, 82.82s/it]
  7%|▋         | 361/5198 [10:44:40<127:25:44, 94.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.92s/it][A100%|██████████| 1/1 [01:22<00:00, 82.92s/it]
  7%|▋         | 361/5198 [10:44:41<127:27:25, 94.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.79s/it][A100%|██████████| 1/1 [01:22<00:00, 82.79s/it]
  7%|▋         | 361/5198 [10:44:41<127:25:46, 94.84s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.83s/it][A100%|██████████| 1/1 [01:22<00:00, 82.83s/it]
  7%|▋         | 361/5198 [10:44:41<127:26:13, 94.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.87s/it][A100%|██████████| 1/1 [01:22<00:00, 82.87s/it]
  7%|▋         | 361/5198 [10:44:41<127:27:03, 94.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.92s/it][A100%|██████████| 1/1 [01:22<00:00, 82.92s/it]
  7%|▋         | 361/5198 [10:44:43<127:27:27, 94.86s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_339
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.82s/it][A100%|██████████| 1/1 [01:55<00:00, 115.82s/it]
  7%|▋         | 362/5198 [10:46:36<136:09:14, 101.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 06:11:42,379] [INFO] [logging.py:96:log_dist] [Rank 0] step=357, skipped=0, lr=[1.9944881720179935e-05], mom=[(0.9, 0.999)]
steps: 357 loss: 0.5648 iter time (s): 115.591 samples/sec: 1.107

100%|██████████| 1/1 [01:56<00:00, 116.33s/it][A100%|██████████| 1/1 [01:56<00:00, 116.33s/it]
  7%|▋         | 362/5198 [10:46:36<136:05:07, 101.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.41s/it][A100%|██████████| 1/1 [01:56<00:00, 116.41s/it]
  7%|▋         | 362/5198 [10:46:37<136:06:02, 101.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.38s/it][A100%|██████████| 1/1 [01:56<00:00, 116.38s/it]
  7%|▋         | 362/5198 [10:46:37<136:06:22, 101.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.39s/it][A100%|██████████| 1/1 [01:56<00:00, 116.39s/it]
  7%|▋         | 362/5198 [10:46:37<136:05:19, 101.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.38s/it][A100%|██████████| 1/1 [01:56<00:00, 116.38s/it]
  7%|▋         | 362/5198 [10:46:37<136:05:29, 101.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.35s/it][A100%|██████████| 1/1 [01:56<00:00, 116.35s/it]
  7%|▋         | 362/5198 [10:46:37<136:05:16, 101.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.35s/it][A100%|██████████| 1/1 [01:56<00:00, 116.35s/it]
  7%|▋         | 362/5198 [10:46:39<136:05:39, 101.31s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_340
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.46s/it][A100%|██████████| 1/1 [01:41<00:00, 101.46s/it]
  7%|▋         | 363/5198 [10:48:18<136:18:55, 101.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 06:13:24,503] [INFO] [logging.py:96:log_dist] [Rank 0] step=358, skipped=0, lr=[1.9944286276442023e-05], mom=[(0.9, 0.999)]
steps: 358 loss: 0.5827 iter time (s): 101.355 samples/sec: 1.263

100%|██████████| 1/1 [01:42<00:00, 102.15s/it][A100%|██████████| 1/1 [01:42<00:00, 102.16s/it]
  7%|▋         | 363/5198 [10:48:19<136:24:24, 101.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.27s/it][A100%|██████████| 1/1 [01:42<00:00, 102.27s/it]
  7%|▋         | 363/5198 [10:48:19<136:27:37, 101.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.19s/it][A100%|██████████| 1/1 [01:42<00:00, 102.19s/it]
  7%|▋         | 363/5198 [10:48:19<136:25:50, 101.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.20s/it][A100%|██████████| 1/1 [01:42<00:00, 102.20s/it]
  7%|▋         | 363/5198 [10:48:19<136:25:30, 101.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.26s/it][A100%|██████████| 1/1 [01:42<00:00, 102.26s/it]
  7%|▋         | 363/5198 [10:48:19<136:26:59, 101.60s/it]

  0%|          | 0/1 [00:00<?, ?it/s][A100%|██████████| 1/1 [01:42<00:00, 102.22s/it][A100%|██████████| 1/1 [01:42<00:00, 102.22s/it]
  7%|▋         | 363/5198 [10:48:19<136:25:53, 101.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.23s/it][A100%|██████████| 1/1 [01:42<00:00, 102.23s/it]
  7%|▋         | 363/5198 [10:48:22<136:26:25, 101.59s/it]Shard 363 in [76, 158, 182, 242, 293, 363, 418, 421, 752, 814, 842, 991, 1266, 1366, 1425, 1464, 1574, 1728, 2166, 2441, 2563, 2739, 2854, 2894, 3089, 3181, 3395, 3576, 3831, 4300, 4589, 4947, 4950]: file /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_341 skipped to avoid exceeding cuda memory
Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_342
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.17s/it][A100%|██████████| 1/1 [01:39<00:00, 99.17s/it]
  7%|▋         | 365/5198 [10:49:57<104:08:00, 77.57s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 06:15:03,622] [INFO] [logging.py:96:log_dist] [Rank 0] step=359, skipped=0, lr=[1.994368764265105e-05], mom=[(0.9, 0.999)]
steps: 359 loss: 0.6676 iter time (s): 98.529 samples/sec: 1.299

100%|██████████| 1/1 [01:39<00:00, 99.38s/it][A100%|██████████| 1/1 [01:39<00:00, 99.38s/it]
  7%|▋         | 365/5198 [10:49:58<104:12:54, 77.63s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.15s/it][A100%|██████████| 1/1 [01:39<00:00, 99.15s/it]
  7%|▋         | 365/5198 [10:49:58<104:10:09, 77.59s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.33s/it][A100%|██████████| 1/1 [01:39<00:00, 99.33s/it]
  7%|▋         | 365/5198 [10:49:59<104:12:27, 77.62s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.29s/it][A100%|██████████| 1/1 [01:39<00:00, 99.29s/it]
  7%|▋         | 365/5198 [10:49:59<104:11:33, 77.61s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.30s/it][A100%|██████████| 1/1 [01:39<00:00, 99.30s/it]
  7%|▋         | 365/5198 [10:49:59<104:12:36, 77.62s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.34s/it][A100%|██████████| 1/1 [01:39<00:00, 99.34s/it]
  7%|▋         | 365/5198 [10:49:59<104:12:40, 77.62s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.41s/it][A100%|██████████| 1/1 [01:39<00:00, 99.41s/it]
  7%|▋         | 365/5198 [10:50:01<104:14:20, 77.65s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_343
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.22s/it][A100%|██████████| 1/1 [01:51<00:00, 111.22s/it]
  7%|▋         | 366/5198 [10:51:49<115:30:42, 86.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 06:16:55,453] [INFO] [logging.py:96:log_dist] [Rank 0] step=360, skipped=0, lr=[1.994308581899908e-05], mom=[(0.9, 0.999)]
steps: 360 loss: 0.6089 iter time (s): 110.647 samples/sec: 1.157

100%|██████████| 1/1 [01:51<00:00, 111.56s/it][A100%|██████████| 1/1 [01:51<00:00, 111.56s/it]
  7%|▋         | 366/5198 [10:51:50<115:29:20, 86.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.69s/it][A100%|██████████| 1/1 [01:51<00:00, 111.69s/it]
  7%|▋         | 366/5198 [10:51:50<115:30:08, 86.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.50s/it][A100%|██████████| 1/1 [01:51<00:00, 111.50s/it]
  7%|▋         | 366/5198 [10:51:50<115:27:48, 86.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.57s/it][A100%|██████████| 1/1 [01:51<00:00, 111.57s/it]
  7%|▋         | 366/5198 [10:51:50<115:28:37, 86.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.52s/it][A100%|██████████| 1/1 [01:51<00:00, 111.52s/it]
  7%|▋         | 366/5198 [10:51:50<115:28:22, 86.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.44s/it][A100%|██████████| 1/1 [01:51<00:00, 111.44s/it]
  7%|▋         | 366/5198 [10:51:53<115:27:56, 86.03s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_344
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.55s/it][A100%|██████████| 1/1 [01:51<00:00, 111.55s/it]
  7%|▋         | 366/5198 [10:51:50<115:28:55, 86.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.97s/it][A100%|██████████| 1/1 [01:35<00:00, 95.97s/it]
  7%|▋         | 367/5198 [10:53:25<119:01:40, 88.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 06:18:31,602] [INFO] [logging.py:96:log_dist] [Rank 0] step=361, skipped=0, lr=[1.9942480805679182e-05], mom=[(0.9, 0.999)]
steps: 361 loss: 0.6078 iter time (s): 95.350 samples/sec: 1.342

100%|██████████| 1/1 [01:36<00:00, 96.09s/it][A100%|██████████| 1/1 [01:36<00:00, 96.09s/it]
  7%|▋         | 367/5198 [10:53:26<118:59:36, 88.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.18s/it][A100%|██████████| 1/1 [01:36<00:00, 96.18s/it]
  7%|▋         | 367/5198 [10:53:26<119:02:10, 88.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.17s/it][A100%|██████████| 1/1 [01:36<00:00, 96.17s/it]
  7%|▋         | 367/5198 [10:53:26<119:00:19, 88.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.14s/it][A100%|██████████| 1/1 [01:36<00:00, 96.14s/it]
  7%|▋         | 367/5198 [10:53:26<119:00:07, 88.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.10s/it][A100%|██████████| 1/1 [01:36<00:00, 96.10s/it]
  7%|▋         | 367/5198 [10:53:26<118:59:13, 88.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.09s/it][A100%|██████████| 1/1 [01:36<00:00, 96.09s/it]
  7%|▋         | 367/5198 [10:53:26<118:59:15, 88.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.11s/it][A100%|██████████| 1/1 [01:36<00:00, 96.11s/it]
  7%|▋         | 367/5198 [10:53:29<118:58:56, 88.66s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_22
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.23s/it][A100%|██████████| 1/1 [01:58<00:00, 118.23s/it]
  7%|▋         | 368/5198 [10:55:24<129:49:08, 96.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 06:20:30,319] [INFO] [logging.py:96:log_dist] [Rank 0] step=362, skipped=0, lr=[1.9941872602885468e-05], mom=[(0.9, 0.999)]
steps: 362 loss: 0.8180 iter time (s): 118.236 samples/sec: 1.083

100%|██████████| 1/1 [01:59<00:00, 119.13s/it][A100%|██████████| 1/1 [01:59<00:00, 119.13s/it]
  7%|▋         | 368/5198 [10:55:25<130:05:08, 96.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.93s/it][A100%|██████████| 1/1 [01:58<00:00, 118.93s/it]
  7%|▋         | 368/5198 [10:55:25<130:02:48, 96.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.08s/it][A100%|██████████| 1/1 [01:59<00:00, 119.09s/it]
  7%|▋         | 368/5198 [10:55:25<130:05:30, 96.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.11s/it][A100%|██████████| 1/1 [01:59<00:00, 119.11s/it]
  7%|▋         | 368/5198 [10:55:25<130:05:12, 96.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.16s/it][A100%|██████████| 1/1 [01:59<00:00, 119.16s/it]
  7%|▋         | 368/5198 [10:55:26<130:05:39, 96.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.17s/it][A100%|██████████| 1/1 [01:59<00:00, 119.17s/it]
  7%|▋         | 368/5198 [10:55:26<130:05:48, 96.97s/it]
100%|██████████| 1/1 [01:59<00:00, 119.16s/it][A100%|██████████| 1/1 [01:59<00:00, 119.16s/it]
  7%|▋         | 368/5198 [10:55:28<130:05:24, 96.96s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_345
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.43s/it][A100%|██████████| 1/1 [01:20<00:00, 80.43s/it]
  7%|▋         | 369/5198 [10:56:44<123:43:11, 92.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 06:21:50,029] [INFO] [logging.py:96:log_dist] [Rank 0] step=363, skipped=0, lr=[1.9941261210813058e-05], mom=[(0.9, 0.999)]
steps: 363 loss: 0.6303 iter time (s): 78.500 samples/sec: 1.631

100%|██████████| 1/1 [01:19<00:00, 79.30s/it][A100%|██████████| 1/1 [01:19<00:00, 79.30s/it]
  7%|▋         | 369/5198 [10:56:44<123:25:59, 92.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.27s/it][A100%|██████████| 1/1 [01:19<00:00, 79.27s/it]
  7%|▋         | 369/5198 [10:56:44<123:23:48, 91.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.28s/it][A100%|██████████| 1/1 [01:19<00:00, 79.28s/it]
  7%|▋         | 369/5198 [10:56:45<123:25:51, 92.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.27s/it][A100%|██████████| 1/1 [01:19<00:00, 79.27s/it]
  7%|▋         | 369/5198 [10:56:45<123:25:26, 92.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.23s/it][A100%|██████████| 1/1 [01:19<00:00, 79.23s/it]
  7%|▋         | 369/5198 [10:56:45<123:24:47, 92.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.24s/it][A100%|██████████| 1/1 [01:19<00:00, 79.24s/it]
  7%|▋         | 369/5198 [10:56:45<123:25:02, 92.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.25s/it][A100%|██████████| 1/1 [01:19<00:00, 79.25s/it]
  7%|▋         | 369/5198 [10:56:47<123:25:07, 92.01s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_346
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.46s/it][A100%|██████████| 1/1 [01:28<00:00, 88.46s/it]
  7%|▋         | 370/5198 [10:58:13<122:18:17, 91.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 06:23:18,949] [INFO] [logging.py:96:log_dist] [Rank 0] step=364, skipped=0, lr=[1.9940646629658112e-05], mom=[(0.9, 0.999)]
steps: 364 loss: 0.6420 iter time (s): 88.153 samples/sec: 1.452

100%|██████████| 1/1 [01:28<00:00, 88.92s/it][A100%|██████████| 1/1 [01:28<00:00, 88.92s/it]
  7%|▋         | 370/5198 [10:58:13<122:13:28, 91.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.98s/it][A100%|██████████| 1/1 [01:28<00:00, 88.98s/it]
  7%|▋         | 370/5198 [10:58:13<122:13:10, 91.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.90s/it][A100%|██████████| 1/1 [01:28<00:00, 88.90s/it]
  7%|▋         | 370/5198 [10:58:14<122:12:49, 91.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.91s/it][A100%|██████████| 1/1 [01:28<00:00, 88.91s/it]
  7%|▋         | 370/5198 [10:58:14<122:12:53, 91.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.91s/it][A100%|██████████| 1/1 [01:28<00:00, 88.91s/it]
  7%|▋         | 370/5198 [10:58:14<122:12:25, 91.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.92s/it][A100%|██████████| 1/1 [01:28<00:00, 88.92s/it]
  7%|▋         | 370/5198 [10:58:14<122:12:48, 91.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.92s/it][A100%|██████████| 1/1 [01:28<00:00, 88.92s/it]
  7%|▋         | 370/5198 [10:58:16<122:12:46, 91.13s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_347
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.03s/it][A100%|██████████| 1/1 [01:22<00:00, 82.03s/it]
  7%|▋         | 371/5198 [10:59:35<118:45:56, 88.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 06:24:40,928] [INFO] [logging.py:96:log_dist] [Rank 0] step=365, skipped=0, lr=[1.9940028859617792e-05], mom=[(0.9, 0.999)]
steps: 365 loss: 0.5870 iter time (s): 81.260 samples/sec: 1.575

100%|██████████| 1/1 [01:22<00:00, 82.01s/it][A100%|██████████| 1/1 [01:22<00:00, 82.01s/it]
  7%|▋         | 371/5198 [10:59:35<118:39:27, 88.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.02s/it][A100%|██████████| 1/1 [01:22<00:00, 82.02s/it]
  7%|▋         | 371/5198 [10:59:35<118:39:21, 88.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.04s/it][A100%|██████████| 1/1 [01:22<00:00, 82.04s/it]
  7%|▋         | 371/5198 [10:59:36<118:39:41, 88.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.06s/it][A100%|██████████| 1/1 [01:22<00:00, 82.06s/it]
  7%|▋         | 371/5198 [10:59:36<118:40:08, 88.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.05s/it][A100%|██████████| 1/1 [01:22<00:00, 82.05s/it]
  7%|▋         | 371/5198 [10:59:36<118:39:31, 88.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.01s/it][A100%|██████████| 1/1 [01:22<00:00, 82.01s/it]
  7%|▋         | 371/5198 [10:59:36<118:38:58, 88.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.03s/it][A100%|██████████| 1/1 [01:22<00:00, 82.03s/it]
  7%|▋         | 371/5198 [10:59:38<118:39:13, 88.49s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_348
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.33s/it][A100%|██████████| 1/1 [01:36<00:00, 96.33s/it]
  7%|▋         | 372/5198 [11:01:11<121:52:22, 90.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 06:26:17,872] [INFO] [logging.py:96:log_dist] [Rank 0] step=366, skipped=0, lr=[1.99394079008903e-05], mom=[(0.9, 0.999)]
steps: 366 loss: 0.6325 iter time (s): 96.118 samples/sec: 1.332

100%|██████████| 1/1 [01:36<00:00, 96.92s/it][A100%|██████████| 1/1 [01:36<00:00, 96.92s/it]
  7%|▋         | 372/5198 [11:01:12<121:56:32, 90.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.90s/it][A100%|██████████| 1/1 [01:36<00:00, 96.90s/it]
  7%|▋         | 372/5198 [11:01:12<121:56:07, 90.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.91s/it][A100%|██████████| 1/1 [01:36<00:00, 96.91s/it]
  7%|▋         | 372/5198 [11:01:13<121:56:31, 90.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.88s/it][A100%|██████████| 1/1 [01:36<00:00, 96.88s/it]
  7%|▋         | 372/5198 [11:01:13<121:56:02, 90.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.91s/it][A100%|██████████| 1/1 [01:36<00:00, 96.91s/it]
  7%|▋         | 372/5198 [11:01:13<121:56:23, 90.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.90s/it][A100%|██████████| 1/1 [01:36<00:00, 96.90s/it]
  7%|▋         | 372/5198 [11:01:13<121:55:46, 90.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.91s/it][A100%|██████████| 1/1 [01:36<00:00, 96.91s/it]
  7%|▋         | 372/5198 [11:01:15<121:56:04, 90.96s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_349
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.01s/it][A100%|██████████| 1/1 [01:27<00:00, 87.01s/it]
  7%|▋         | 373/5198 [11:02:39<120:21:33, 89.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 06:27:44,715] [INFO] [logging.py:96:log_dist] [Rank 0] step=367, skipped=0, lr=[1.993878375367485e-05], mom=[(0.9, 0.999)]
steps: 367 loss: 0.5868 iter time (s): 86.044 samples/sec: 1.488

100%|██████████| 1/1 [01:26<00:00, 86.81s/it][A100%|██████████| 1/1 [01:26<00:00, 86.81s/it]
  7%|▋         | 373/5198 [11:02:39<120:16:45, 89.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.77s/it][A100%|██████████| 1/1 [01:26<00:00, 86.77s/it]
  7%|▋         | 373/5198 [11:02:39<120:15:27, 89.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.69s/it][A100%|██████████| 1/1 [01:26<00:00, 86.69s/it]
  7%|▋         | 373/5198 [11:02:39<120:13:59, 89.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.80s/it][A100%|██████████| 1/1 [01:26<00:00, 86.80s/it]
  7%|▋         | 373/5198 [11:02:39<120:16:14, 89.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.82s/it][A100%|██████████| 1/1 [01:26<00:00, 86.82s/it]
  7%|▋         | 373/5198 [11:02:40<120:16:42, 89.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.80s/it][A100%|██████████| 1/1 [01:26<00:00, 86.80s/it]
  7%|▋         | 373/5198 [11:02:40<120:16:03, 89.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.78s/it][A100%|██████████| 1/1 [01:26<00:00, 86.78s/it]
  7%|▋         | 373/5198 [11:02:42<120:15:44, 89.73s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_350
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.90s/it][A100%|██████████| 1/1 [01:20<00:00, 80.90s/it]
  7%|▋         | 374/5198 [11:04:00<116:51:21, 87.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 06:29:05,604] [INFO] [logging.py:96:log_dist] [Rank 0] step=368, skipped=0, lr=[1.993815641817169e-05], mom=[(0.9, 0.999)]
steps: 368 loss: 0.6364 iter time (s): 80.144 samples/sec: 1.597

100%|██████████| 1/1 [01:20<00:00, 80.89s/it][A100%|██████████| 1/1 [01:20<00:00, 80.89s/it]
  7%|▋         | 374/5198 [11:04:00<116:44:34, 87.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.92s/it][A100%|██████████| 1/1 [01:20<00:00, 80.92s/it]
  7%|▋         | 374/5198 [11:04:00<116:44:24, 87.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.99s/it][A100%|██████████| 1/1 [01:20<00:00, 80.99s/it]
  7%|▋         | 374/5198 [11:04:00<116:44:56, 87.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.84s/it][A100%|██████████| 1/1 [01:20<00:00, 80.84s/it]
  7%|▋         | 374/5198 [11:04:00<116:43:11, 87.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.91s/it][A100%|██████████| 1/1 [01:20<00:00, 80.91s/it]
  7%|▋         | 374/5198 [11:04:00<116:44:43, 87.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.91s/it][A100%|██████████| 1/1 [01:20<00:00, 80.91s/it]
  7%|▋         | 374/5198 [11:04:00<116:44:34, 87.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.93s/it][A100%|██████████| 1/1 [01:20<00:00, 80.93s/it]
  7%|▋         | 374/5198 [11:04:03<116:44:40, 87.12s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_351
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.86s/it][A100%|██████████| 1/1 [01:34<00:00, 94.86s/it]
  7%|▋         | 375/5198 [11:05:35<119:56:40, 89.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 06:30:41,032] [INFO] [logging.py:96:log_dist] [Rank 0] step=369, skipped=0, lr=[1.9937525894582082e-05], mom=[(0.9, 0.999)]
steps: 369 loss: 0.6204 iter time (s): 94.637 samples/sec: 1.353

100%|██████████| 1/1 [01:35<00:00, 95.43s/it][A100%|██████████| 1/1 [01:35<00:00, 95.43s/it]
  7%|▋         | 375/5198 [11:05:35<120:02:06, 89.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.39s/it][A100%|██████████| 1/1 [01:35<00:00, 95.40s/it]
  7%|▋         | 375/5198 [11:05:35<120:01:18, 89.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.45s/it][A100%|██████████| 1/1 [01:35<00:00, 95.45s/it]
  7%|▋         | 375/5198 [11:05:36<120:02:41, 89.60s/it]
100%|██████████| 1/1 [01:35<00:00, 95.37s/it][A100%|██████████| 1/1 [01:35<00:00, 95.37s/it]
  7%|▋         | 375/5198 [11:05:36<120:00:39, 89.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.48s/it][A100%|██████████| 1/1 [01:35<00:00, 95.48s/it]
  7%|▋         | 375/5198 [11:05:36<120:02:12, 89.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.40s/it][A100%|██████████| 1/1 [01:35<00:00, 95.40s/it]
  7%|▋         | 375/5198 [11:05:36<120:01:10, 89.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.41s/it][A100%|██████████| 1/1 [01:35<00:00, 95.41s/it]
  7%|▋         | 375/5198 [11:05:38<120:01:25, 89.59s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_352
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.86s/it][A100%|██████████| 1/1 [01:28<00:00, 88.86s/it]
  7%|▋         | 376/5198 [11:07:04<119:43:15, 89.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 06:32:09,936] [INFO] [logging.py:96:log_dist] [Rank 0] step=370, skipped=0, lr=[1.9936892183108313e-05], mom=[(0.9, 0.999)]
steps: 370 loss: 0.5983 iter time (s): 88.127 samples/sec: 1.452

100%|██████████| 1/1 [01:28<00:00, 88.99s/it][A100%|██████████| 1/1 [01:28<00:00, 88.99s/it]
  7%|▋         | 376/5198 [11:07:04<119:46:25, 89.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.20s/it][A100%|██████████| 1/1 [01:29<00:00, 89.20s/it]
  7%|▋         | 376/5198 [11:07:04<119:50:43, 89.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.02s/it][A100%|██████████| 1/1 [01:29<00:00, 89.02s/it]
  7%|▋         | 376/5198 [11:07:05<119:45:59, 89.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.08s/it][A100%|██████████| 1/1 [01:29<00:00, 89.08s/it]
  7%|▋         | 376/5198 [11:07:05<119:48:47, 89.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.10s/it][A100%|██████████| 1/1 [01:29<00:00, 89.10s/it]
  7%|▋         | 376/5198 [11:07:05<119:49:05, 89.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.21s/it][A100%|██████████| 1/1 [01:29<00:00, 89.21s/it]
  7%|▋         | 376/5198 [11:07:05<119:50:57, 89.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.47s/it][A100%|██████████| 1/1 [01:29<00:00, 89.47s/it]
  7%|▋         | 376/5198 [11:07:08<119:57:20, 89.56s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_353
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.53s/it][A100%|██████████| 1/1 [01:37<00:00, 97.53s/it]
  7%|▋         | 377/5198 [11:08:41<123:02:43, 91.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 06:33:47,885] [INFO] [logging.py:96:log_dist] [Rank 0] step=371, skipped=0, lr=[1.9936255283953695e-05], mom=[(0.9, 0.999)]
steps: 371 loss: 0.6165 iter time (s): 96.596 samples/sec: 1.325

100%|██████████| 1/1 [01:37<00:00, 97.80s/it][A100%|██████████| 1/1 [01:37<00:00, 97.80s/it]
  7%|▋         | 377/5198 [11:08:42<123:06:57, 91.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.60s/it][A100%|██████████| 1/1 [01:37<00:00, 97.60s/it]
  7%|▋         | 377/5198 [11:08:42<123:04:41, 91.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.71s/it][A100%|██████████| 1/1 [01:37<00:00, 97.71s/it]
  7%|▋         | 377/5198 [11:08:42<123:05:50, 91.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.88s/it][A100%|██████████| 1/1 [01:37<00:00, 97.88s/it]
  7%|▋         | 377/5198 [11:08:43<123:07:45, 91.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.77s/it][A100%|██████████| 1/1 [01:37<00:00, 97.77s/it]
  7%|▋         | 377/5198 [11:08:43<123:07:31, 91.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.75s/it][A100%|██████████| 1/1 [01:37<00:00, 97.75s/it]
  7%|▋         | 377/5198 [11:08:43<123:08:22, 91.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.49s/it][A100%|██████████| 1/1 [01:37<00:00, 97.49s/it]
  7%|▋         | 377/5198 [11:08:45<123:06:20, 91.93s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_354
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.05s/it][A100%|██████████| 1/1 [01:44<00:00, 104.05s/it]
  7%|▋         | 378/5198 [11:10:26<127:56:55, 95.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 06:35:32,248] [INFO] [logging.py:96:log_dist] [Rank 0] step=372, skipped=0, lr=[1.9935615197322563e-05], mom=[(0.9, 0.999)]
steps: 372 loss: 0.6603 iter time (s): 103.469 samples/sec: 1.237

100%|██████████| 1/1 [01:44<00:00, 104.37s/it][A100%|██████████| 1/1 [01:44<00:00, 104.38s/it]
  7%|▋         | 378/5198 [11:10:26<128:04:43, 95.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.42s/it][A100%|██████████| 1/1 [01:44<00:00, 104.42s/it]
  7%|▋         | 378/5198 [11:10:26<128:04:04, 95.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.45s/it][A100%|██████████| 1/1 [01:44<00:00, 104.46s/it]
  7%|▋         | 378/5198 [11:10:27<128:05:49, 95.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.39s/it][A100%|██████████| 1/1 [01:44<00:00, 104.39s/it]
  7%|▋         | 378/5198 [11:10:27<128:05:35, 95.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.35s/it][A100%|██████████| 1/1 [01:44<00:00, 104.35s/it]
  7%|▋         | 378/5198 [11:10:27<128:04:26, 95.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.32s/it][A100%|██████████| 1/1 [01:44<00:00, 104.32s/it]
  7%|▋         | 378/5198 [11:10:27<128:04:16, 95.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.32s/it][A100%|██████████| 1/1 [01:44<00:00, 104.32s/it]
  7%|▋         | 378/5198 [11:10:29<128:02:44, 95.64s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_355
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.94s/it][A100%|██████████| 1/1 [01:38<00:00, 98.94s/it]
  7%|▋         | 379/5198 [11:12:05<129:21:35, 96.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 06:37:11,262] [INFO] [logging.py:96:log_dist] [Rank 0] step=373, skipped=0, lr=[1.9934971923420264e-05], mom=[(0.9, 0.999)]
steps: 373 loss: 0.6269 iter time (s): 98.155 samples/sec: 1.304

100%|██████████| 1/1 [01:39<00:00, 99.04s/it][A100%|██████████| 1/1 [01:39<00:00, 99.04s/it]
  7%|▋         | 379/5198 [11:12:05<129:24:40, 96.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.06s/it][A100%|██████████| 1/1 [01:39<00:00, 99.06s/it]
  7%|▋         | 379/5198 [11:12:06<129:24:42, 96.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.93s/it][A100%|██████████| 1/1 [01:38<00:00, 98.93s/it]
  7%|▋         | 379/5198 [11:12:06<129:22:43, 96.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.02s/it][A100%|██████████| 1/1 [01:39<00:00, 99.02s/it]
  7%|▋         | 379/5198 [11:12:06<129:24:41, 96.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.01s/it][A100%|██████████| 1/1 [01:39<00:00, 99.01s/it]
  7%|▋         | 379/5198 [11:12:06<129:23:36, 96.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.98s/it][A100%|██████████| 1/1 [01:38<00:00, 98.98s/it]
  7%|▋         | 379/5198 [11:12:06<129:22:53, 96.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 99.00s/it][A100%|██████████| 1/1 [01:38<00:00, 99.00s/it]
  7%|▋         | 379/5198 [11:12:08<129:22:07, 96.64s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_356
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.83s/it][A100%|██████████| 1/1 [01:54<00:00, 114.83s/it]
  7%|▋         | 380/5198 [11:14:00<136:43:24, 102.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 06:39:06,782] [INFO] [logging.py:96:log_dist] [Rank 0] step=374, skipped=0, lr=[1.9934325462453184e-05], mom=[(0.9, 0.999)]
steps: 374 loss: 0.5967 iter time (s): 114.671 samples/sec: 1.116

100%|██████████| 1/1 [01:55<00:00, 115.44s/it][A100%|██████████| 1/1 [01:55<00:00, 115.44s/it]
  7%|▋         | 380/5198 [11:14:01<136:54:37, 102.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.46s/it][A100%|██████████| 1/1 [01:55<00:00, 115.46s/it]
  7%|▋         | 380/5198 [11:14:01<136:55:09, 102.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.45s/it][A100%|██████████| 1/1 [01:55<00:00, 115.45s/it]
  7%|▋         | 380/5198 [11:14:01<136:53:35, 102.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.44s/it][A100%|██████████| 1/1 [01:55<00:00, 115.44s/it]
  7%|▋         | 380/5198 [11:14:01<136:54:44, 102.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.49s/it][A100%|██████████| 1/1 [01:55<00:00, 115.49s/it]
  7%|▋         | 380/5198 [11:14:02<136:55:09, 102.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.46s/it][A100%|██████████| 1/1 [01:55<00:00, 115.46s/it]
  7%|▋         | 380/5198 [11:14:04<136:53:25, 102.28s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_357

100%|██████████| 1/1 [01:55<00:00, 115.49s/it][A100%|██████████| 1/1 [01:55<00:00, 115.49s/it]
  7%|▋         | 380/5198 [11:14:02<136:54:34, 102.30s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.48s/it][A100%|██████████| 1/1 [01:22<00:00, 82.48s/it]
  7%|▋         | 381/5198 [11:15:22<128:51:48, 96.31s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 06:40:28,460] [INFO] [logging.py:96:log_dist] [Rank 0] step=375, skipped=0, lr=[1.9933675814628723e-05], mom=[(0.9, 0.999)]
steps: 375 loss: 0.5957 iter time (s): 80.880 samples/sec: 1.583

100%|██████████| 1/1 [01:21<00:00, 81.69s/it][A100%|██████████| 1/1 [01:21<00:00, 81.69s/it]
  7%|▋         | 381/5198 [11:15:23<128:37:19, 96.13s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.73s/it][A100%|██████████| 1/1 [01:21<00:00, 81.73s/it]
  7%|▋         | 381/5198 [11:15:23<128:38:43, 96.14s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.78s/it][A100%|██████████| 1/1 [01:21<00:00, 81.78s/it]
  7%|▋         | 381/5198 [11:15:23<128:38:39, 96.14s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.69s/it][A100%|██████████| 1/1 [01:21<00:00, 81.69s/it]
  7%|▋         | 381/5198 [11:15:23<128:37:16, 96.13s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.67s/it][A100%|██████████| 1/1 [01:21<00:00, 81.67s/it]
  7%|▋         | 381/5198 [11:15:23<128:37:08, 96.12s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.70s/it][A100%|██████████| 1/1 [01:21<00:00, 81.70s/it]
  7%|▋         | 381/5198 [11:15:23<128:37:26, 96.13s/it] 
100%|██████████| 1/1 [01:21<00:00, 81.70s/it][A100%|██████████| 1/1 [01:21<00:00, 81.70s/it]
  7%|▋         | 381/5198 [11:15:26<128:36:41, 96.12s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_358

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.75s/it][A100%|██████████| 1/1 [01:30<00:00, 90.75s/it]
  7%|▋         | 382/5198 [11:16:53<126:40:08, 94.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 06:41:59,676] [INFO] [logging.py:96:log_dist] [Rank 0] step=376, skipped=0, lr=[1.9933022980155302e-05], mom=[(0.9, 0.999)]
steps: 376 loss: 0.5972 iter time (s): 90.387 samples/sec: 1.416

100%|██████████| 1/1 [01:31<00:00, 91.16s/it][A100%|██████████| 1/1 [01:31<00:00, 91.16s/it]
  7%|▋         | 382/5198 [11:16:54<126:36:28, 94.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.09s/it][A100%|██████████| 1/1 [01:31<00:00, 91.09s/it]
  7%|▋         | 382/5198 [11:16:54<126:35:36, 94.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.16s/it][A100%|██████████| 1/1 [01:31<00:00, 91.16s/it]
  7%|▋         | 382/5198 [11:16:54<126:37:15, 94.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.15s/it][A100%|██████████| 1/1 [01:31<00:00, 91.15s/it]
  7%|▋         | 382/5198 [11:16:54<126:36:07, 94.64s/it]
100%|██████████| 1/1 [01:31<00:00, 91.21s/it][A100%|██████████| 1/1 [01:31<00:00, 91.21s/it]
  7%|▋         | 382/5198 [11:16:54<126:37:42, 94.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.14s/it][A100%|██████████| 1/1 [01:31<00:00, 91.14s/it]
  7%|▋         | 382/5198 [11:16:55<126:36:00, 94.63s/it]
100%|██████████| 1/1 [01:31<00:00, 91.14s/it][A100%|██████████| 1/1 [01:31<00:00, 91.14s/it]
  7%|▋         | 382/5198 [11:16:57<126:35:28, 94.63s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_359
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.41s/it][A100%|██████████| 1/1 [01:24<00:00, 84.41s/it]
  7%|▋         | 383/5198 [11:18:18<122:34:40, 91.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 06:43:23,962] [INFO] [logging.py:96:log_dist] [Rank 0] step=377, skipped=0, lr=[1.9932366959242366e-05], mom=[(0.9, 0.999)]
steps: 377 loss: 0.5745 iter time (s): 83.525 samples/sec: 1.532

100%|██████████| 1/1 [01:24<00:00, 84.24s/it][A100%|██████████| 1/1 [01:24<00:00, 84.24s/it]
  7%|▋         | 383/5198 [11:18:18<122:24:55, 91.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.30s/it][A100%|██████████| 1/1 [01:24<00:00, 84.30s/it]
  7%|▋         | 383/5198 [11:18:18<122:25:33, 91.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.25s/it][A100%|██████████| 1/1 [01:24<00:00, 84.25s/it]
  7%|▋         | 383/5198 [11:18:19<122:25:47, 91.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.26s/it][A100%|██████████| 1/1 [01:24<00:00, 84.26s/it]
  7%|▋         | 383/5198 [11:18:19<122:25:02, 91.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.26s/it][A100%|██████████| 1/1 [01:24<00:00, 84.26s/it]
  7%|▋         | 383/5198 [11:18:19<122:26:10, 91.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.27s/it][A100%|██████████| 1/1 [01:24<00:00, 84.27s/it]
  7%|▋         | 383/5198 [11:18:19<122:25:13, 91.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.28s/it][A100%|██████████| 1/1 [01:24<00:00, 84.28s/it]
  7%|▋         | 383/5198 [11:18:21<122:25:06, 91.53s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_23
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.33s/it][A100%|██████████| 1/1 [01:58<00:00, 118.33s/it]
  7%|▋         | 384/5198 [11:20:16<133:17:35, 99.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 06:45:23,110] [INFO] [logging.py:96:log_dist] [Rank 0] step=378, skipped=0, lr=[1.9931707752100388e-05], mom=[(0.9, 0.999)]
steps: 378 loss: 0.8248 iter time (s): 118.617 samples/sec: 1.079

100%|██████████| 1/1 [01:59<00:00, 119.42s/it][A100%|██████████| 1/1 [01:59<00:00, 119.42s/it]
  7%|▋         | 384/5198 [11:20:17<133:34:51, 99.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.40s/it][A100%|██████████| 1/1 [01:59<00:00, 119.40s/it]
  7%|▋         | 384/5198 [11:20:18<133:34:51, 99.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.40s/it][A100%|██████████| 1/1 [01:59<00:00, 119.40s/it]
  7%|▋         | 384/5198 [11:20:18<133:34:52, 99.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.43s/it][A100%|██████████| 1/1 [01:59<00:00, 119.43s/it]
  7%|▋         | 384/5198 [11:20:18<133:36:13, 99.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.48s/it][A100%|██████████| 1/1 [01:59<00:00, 119.48s/it]
  7%|▋         | 384/5198 [11:20:18<133:36:22, 99.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.45s/it][A100%|██████████| 1/1 [01:59<00:00, 119.45s/it]
  7%|▋         | 384/5198 [11:20:18<133:35:44, 99.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.46s/it][A100%|██████████| 1/1 [01:59<00:00, 119.46s/it]
  7%|▋         | 384/5198 [11:20:20<133:35:46, 99.91s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_360
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.88s/it][A100%|██████████| 1/1 [01:27<00:00, 87.88s/it]
  7%|▋         | 385/5198 [11:21:44<128:34:53, 96.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 06:46:50,540] [INFO] [logging.py:96:log_dist] [Rank 0] step=379, skipped=0, lr=[1.993104535894085e-05], mom=[(0.9, 0.999)]
steps: 379 loss: 0.5852 iter time (s): 86.355 samples/sec: 1.482

100%|██████████| 1/1 [01:27<00:00, 87.14s/it][A100%|██████████| 1/1 [01:27<00:00, 87.14s/it]
  7%|▋         | 385/5198 [11:21:45<128:26:25, 96.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.12s/it][A100%|██████████| 1/1 [01:27<00:00, 87.12s/it]
  7%|▋         | 385/5198 [11:21:45<128:25:57, 96.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.18s/it][A100%|██████████| 1/1 [01:27<00:00, 87.18s/it]
  7%|▋         | 385/5198 [11:21:45<128:27:40, 96.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.14s/it][A100%|██████████| 1/1 [01:27<00:00, 87.14s/it]
  7%|▋         | 385/5198 [11:21:45<128:27:30, 96.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.18s/it][A100%|██████████| 1/1 [01:27<00:00, 87.18s/it]
  7%|▋         | 385/5198 [11:21:45<128:28:31, 96.10s/it]
100%|██████████| 1/1 [01:27<00:00, 87.15s/it][A100%|██████████| 1/1 [01:27<00:00, 87.15s/it]
  7%|▋         | 385/5198 [11:21:45<128:27:23, 96.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.15s/it][A100%|██████████| 1/1 [01:27<00:00, 87.15s/it]
  7%|▋         | 385/5198 [11:21:48<128:27:19, 96.08s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_361
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.90s/it][A100%|██████████| 1/1 [01:24<00:00, 84.90s/it]
  7%|▋         | 386/5198 [11:23:09<124:05:54, 92.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 06:48:15,537] [INFO] [logging.py:96:log_dist] [Rank 0] step=380, skipped=0, lr=[1.9930379779976267e-05], mom=[(0.9, 0.999)]
steps: 380 loss: 0.6143 iter time (s): 84.191 samples/sec: 1.520

100%|██████████| 1/1 [01:25<00:00, 85.02s/it][A100%|██████████| 1/1 [01:25<00:00, 85.02s/it]
  7%|▋         | 386/5198 [11:23:10<123:59:10, 92.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.08s/it][A100%|██████████| 1/1 [01:25<00:00, 85.08s/it]
  7%|▋         | 386/5198 [11:23:10<124:00:32, 92.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 85.00s/it][A100%|██████████| 1/1 [01:24<00:00, 85.00s/it]
  7%|▋         | 386/5198 [11:23:10<123:59:33, 92.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.99s/it][A100%|██████████| 1/1 [01:24<00:00, 84.99s/it]
  7%|▋         | 386/5198 [11:23:10<123:59:13, 92.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.96s/it][A100%|██████████| 1/1 [01:24<00:00, 84.96s/it]
  7%|▋         | 386/5198 [11:23:10<123:59:16, 92.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.01s/it][A100%|██████████| 1/1 [01:25<00:00, 85.01s/it]
  7%|▋         | 386/5198 [11:23:10<123:59:35, 92.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.01s/it][A100%|██████████| 1/1 [01:25<00:00, 85.01s/it]
  7%|▋         | 386/5198 [11:23:13<123:59:36, 92.76s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_362
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.44s/it][A100%|██████████| 1/1 [01:26<00:00, 86.44s/it]
  7%|▋         | 387/5198 [11:24:36<121:34:31, 90.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 06:49:42,172] [INFO] [logging.py:96:log_dist] [Rank 0] step=381, skipped=0, lr=[1.9929711015420177e-05], mom=[(0.9, 0.999)]
steps: 381 loss: 0.5868 iter time (s): 85.804 samples/sec: 1.492

100%|██████████| 1/1 [01:26<00:00, 86.63s/it][A100%|██████████| 1/1 [01:26<00:00, 86.63s/it]
  7%|▋         | 387/5198 [11:24:36<121:30:25, 90.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.59s/it][A100%|██████████| 1/1 [01:26<00:00, 86.59s/it]
  7%|▋         | 387/5198 [11:24:36<121:30:34, 90.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.51s/it][A100%|██████████| 1/1 [01:26<00:00, 86.51s/it]
  7%|▋         | 387/5198 [11:24:37<121:27:52, 90.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.55s/it][A100%|██████████| 1/1 [01:26<00:00, 86.55s/it]
  7%|▋         | 387/5198 [11:24:37<121:28:36, 90.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.60s/it][A100%|██████████| 1/1 [01:26<00:00, 86.60s/it]
  7%|▋         | 387/5198 [11:24:37<121:29:43, 90.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.59s/it][A100%|██████████| 1/1 [01:26<00:00, 86.59s/it]
  7%|▋         | 387/5198 [11:24:37<121:29:39, 90.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.59s/it][A100%|██████████| 1/1 [01:26<00:00, 86.59s/it]
  7%|▋         | 387/5198 [11:24:39<121:29:46, 90.91s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_363
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:06<00:00, 126.58s/it][A100%|██████████| 1/1 [02:06<00:00, 126.58s/it]
  7%|▋         | 388/5198 [11:26:43<135:52:49, 101.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 06:51:49,993] [INFO] [logging.py:96:log_dist] [Rank 0] step=382, skipped=0, lr=[1.9929039065487134e-05], mom=[(0.9, 0.999)]
steps: 382 loss: 0.5986 iter time (s): 127.030 samples/sec: 1.008

100%|██████████| 1/1 [02:07<00:00, 127.78s/it][A100%|██████████| 1/1 [02:07<00:00, 127.78s/it]
  7%|▋         | 388/5198 [11:26:44<136:15:30, 101.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:07<00:00, 127.75s/it][A100%|██████████| 1/1 [02:07<00:00, 127.75s/it]
  7%|▋         | 388/5198 [11:26:44<136:14:57, 101.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:07<00:00, 127.79s/it][A100%|██████████| 1/1 [02:07<00:00, 127.79s/it]
  7%|▋         | 388/5198 [11:26:45<136:13:55, 101.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:07<00:00, 127.77s/it][A100%|██████████| 1/1 [02:07<00:00, 127.77s/it]
  7%|▋         | 388/5198 [11:26:45<136:13:58, 101.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:07<00:00, 127.76s/it][A100%|██████████| 1/1 [02:07<00:00, 127.76s/it]
  7%|▋         | 388/5198 [11:26:45<136:14:34, 101.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:07<00:00, 127.75s/it][A100%|██████████| 1/1 [02:07<00:00, 127.75s/it]
  7%|▋         | 388/5198 [11:26:47<136:14:19, 101.97s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_364

100%|██████████| 1/1 [02:07<00:00, 127.77s/it][A100%|██████████| 1/1 [02:07<00:00, 127.77s/it]
  7%|▋         | 388/5198 [11:26:45<136:14:44, 101.97s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.66s/it][A100%|██████████| 1/1 [01:26<00:00, 86.67s/it]
  7%|▋         | 389/5198 [11:28:10<129:52:42, 97.23s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 06:53:15,520] [INFO] [logging.py:96:log_dist] [Rank 0] step=383, skipped=0, lr=[1.9928363930392715e-05], mom=[(0.9, 0.999)]
steps: 383 loss: 0.5958 iter time (s): 85.065 samples/sec: 1.505

100%|██████████| 1/1 [01:25<00:00, 85.84s/it][A100%|██████████| 1/1 [01:25<00:00, 85.84s/it]
  7%|▋         | 389/5198 [11:28:10<129:45:50, 97.14s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.81s/it][A100%|██████████| 1/1 [01:25<00:00, 85.81s/it]
  7%|▋         | 389/5198 [11:28:10<129:44:51, 97.13s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.90s/it][A100%|██████████| 1/1 [01:25<00:00, 85.90s/it]
  7%|▋         | 389/5198 [11:28:10<129:46:19, 97.15s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.91s/it][A100%|██████████| 1/1 [01:25<00:00, 85.91s/it]
  7%|▋         | 389/5198 [11:28:11<129:46:32, 97.15s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.87s/it][A100%|██████████| 1/1 [01:25<00:00, 85.87s/it]
  7%|▋         | 389/5198 [11:28:11<129:46:02, 97.14s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.83s/it][A100%|██████████| 1/1 [01:25<00:00, 85.83s/it]
  7%|▋         | 389/5198 [11:28:11<129:45:11, 97.13s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.90s/it][A100%|██████████| 1/1 [01:25<00:00, 85.90s/it]
  7%|▋         | 389/5198 [11:28:13<129:46:28, 97.15s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_365
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:09<00:00, 129.10s/it][A100%|██████████| 1/1 [02:09<00:00, 129.10s/it]
  8%|▊         | 390/5198 [11:30:19<142:57:57, 107.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 06:55:26,310] [INFO] [logging.py:96:log_dist] [Rank 0] step=384, skipped=0, lr=[1.9927685610353525e-05], mom=[(0.9, 0.999)]
steps: 384 loss: 0.6663 iter time (s): 129.709 samples/sec: 0.987

100%|██████████| 1/1 [02:10<00:00, 130.54s/it][A100%|██████████| 1/1 [02:10<00:00, 130.54s/it]
  8%|▊         | 390/5198 [11:30:20<143:07:18, 107.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:10<00:00, 130.69s/it][A100%|██████████| 1/1 [02:10<00:00, 130.69s/it]
  8%|▊         | 390/5198 [11:30:21<143:10:20, 107.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:10<00:00, 130.64s/it][A100%|██████████| 1/1 [02:10<00:00, 130.64s/it]
  8%|▊         | 390/5198 [11:30:21<143:10:06, 107.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:10<00:00, 130.57s/it][A100%|██████████| 1/1 [02:10<00:00, 130.57s/it]
  8%|▊         | 390/5198 [11:30:21<143:08:33, 107.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:10<00:00, 130.55s/it][A100%|██████████| 1/1 [02:10<00:00, 130.55s/it]
  8%|▊         | 390/5198 [11:30:21<143:07:46, 107.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:10<00:00, 130.60s/it][A100%|██████████| 1/1 [02:10<00:00, 130.60s/it]
  8%|▊         | 390/5198 [11:30:21<143:08:14, 107.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:10<00:00, 130.55s/it][A100%|██████████| 1/1 [02:10<00:00, 130.55s/it]
  8%|▊         | 390/5198 [11:30:23<143:08:00, 107.17s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_366
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.88s/it][A100%|██████████| 1/1 [01:34<00:00, 94.88s/it]
  8%|▊         | 391/5198 [11:31:55<138:09:34, 103.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 06:57:00,837] [INFO] [logging.py:96:log_dist] [Rank 0] step=385, skipped=0, lr=[1.992700410558718e-05], mom=[(0.9, 0.999)]
steps: 385 loss: 0.6262 iter time (s): 93.649 samples/sec: 1.367

100%|██████████| 1/1 [01:34<00:00, 94.49s/it][A100%|██████████| 1/1 [01:34<00:00, 94.49s/it]
  8%|▊         | 391/5198 [11:31:55<138:01:11, 103.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.35s/it][A100%|██████████| 1/1 [01:34<00:00, 94.35s/it]
  8%|▊         | 391/5198 [11:31:55<138:00:03, 103.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.38s/it][A100%|██████████| 1/1 [01:34<00:00, 94.39s/it]
  8%|▊         | 391/5198 [11:31:55<138:00:34, 103.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.40s/it][A100%|██████████| 1/1 [01:34<00:00, 94.40s/it]
  8%|▊         | 391/5198 [11:31:56<137:59:53, 103.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.42s/it][A100%|██████████| 1/1 [01:34<00:00, 94.42s/it]
  8%|▊         | 391/5198 [11:31:56<138:00:08, 103.35s/it]
100%|██████████| 1/1 [01:34<00:00, 94.39s/it][A100%|██████████| 1/1 [01:34<00:00, 94.39s/it]
  8%|▊         | 391/5198 [11:31:56<137:59:21, 103.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.40s/it][A100%|██████████| 1/1 [01:34<00:00, 94.40s/it]
  8%|▊         | 391/5198 [11:31:58<137:59:31, 103.34s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_367
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:21<00:00, 141.38s/it][A100%|██████████| 1/1 [02:21<00:00, 141.38s/it]
  8%|▊         | 392/5198 [11:34:16<153:22:47, 114.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 06:59:23,816] [INFO] [logging.py:96:log_dist] [Rank 0] step=386, skipped=0, lr=[1.9926319416312324e-05], mom=[(0.9, 0.999)]
steps: 386 loss: 0.5864 iter time (s): 142.218 samples/sec: 0.900

100%|██████████| 1/1 [02:23<00:00, 143.10s/it][A100%|██████████| 1/1 [02:23<00:00, 143.10s/it]
  8%|▊         | 392/5198 [11:34:18<153:54:42, 115.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:23<00:00, 143.06s/it][A100%|██████████| 1/1 [02:23<00:00, 143.06s/it]
  8%|▊         | 392/5198 [11:34:18<153:52:51, 115.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:23<00:00, 143.10s/it][A100%|██████████| 1/1 [02:23<00:00, 143.10s/it]
  8%|▊         | 392/5198 [11:34:19<153:54:10, 115.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:23<00:00, 143.11s/it][A100%|██████████| 1/1 [02:23<00:00, 143.11s/it]
  8%|▊         | 392/5198 [11:34:19<153:53:49, 115.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:23<00:00, 143.08s/it][A100%|██████████| 1/1 [02:23<00:00, 143.08s/it]
  8%|▊         | 392/5198 [11:34:19<153:53:19, 115.27s/it]
100%|██████████| 1/1 [02:23<00:00, 143.06s/it][A100%|██████████| 1/1 [02:23<00:00, 143.06s/it]
  8%|▊         | 392/5198 [11:34:21<153:52:20, 115.26s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_368

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:23<00:00, 143.10s/it][A100%|██████████| 1/1 [02:23<00:00, 143.10s/it]
  8%|▊         | 392/5198 [11:34:19<153:53:13, 115.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.45s/it][A100%|██████████| 1/1 [01:30<00:00, 90.45s/it]
  8%|▊         | 393/5198 [11:35:47<143:37:24, 107.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 07:00:53,003] [INFO] [logging.py:96:log_dist] [Rank 0] step=387, skipped=0, lr=[1.9925631542748625e-05], mom=[(0.9, 0.999)]
steps: 387 loss: 0.5903 iter time (s): 88.338 samples/sec: 1.449

100%|██████████| 1/1 [01:29<00:00, 89.03s/it][A100%|██████████| 1/1 [01:29<00:00, 89.03s/it]
  8%|▊         | 393/5198 [11:35:47<143:22:12, 107.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.17s/it][A100%|██████████| 1/1 [01:29<00:00, 89.17s/it]
  8%|▊         | 393/5198 [11:35:47<143:24:06, 107.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 89.00s/it][A100%|██████████| 1/1 [01:28<00:00, 89.00s/it]
  8%|▊         | 393/5198 [11:35:48<143:20:58, 107.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.08s/it][A100%|██████████| 1/1 [01:29<00:00, 89.08s/it]
  8%|▊         | 393/5198 [11:35:48<143:22:47, 107.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.07s/it][A100%|██████████| 1/1 [01:29<00:00, 89.07s/it]
  8%|▊         | 393/5198 [11:35:48<143:22:24, 107.42s/it]
100%|██████████| 1/1 [01:29<00:00, 89.06s/it][A100%|██████████| 1/1 [01:29<00:00, 89.06s/it]
  8%|▊         | 393/5198 [11:35:48<143:21:48, 107.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.11s/it][A100%|██████████| 1/1 [01:29<00:00, 89.11s/it]
  8%|▊         | 393/5198 [11:35:50<143:22:20, 107.42s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_369
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.69s/it][A100%|██████████| 1/1 [01:38<00:00, 98.69s/it]
  8%|▊         | 394/5198 [11:37:26<140:05:52, 104.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 07:02:32,124] [INFO] [logging.py:96:log_dist] [Rank 0] step=388, skipped=0, lr=[1.9924940485116768e-05], mom=[(0.9, 0.999)]
steps: 388 loss: 0.6108 iter time (s): 98.341 samples/sec: 1.302

100%|██████████| 1/1 [01:39<00:00, 99.12s/it][A100%|██████████| 1/1 [01:39<00:00, 99.12s/it]
  8%|▊         | 394/5198 [11:37:26<140:01:27, 104.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.04s/it][A100%|██████████| 1/1 [01:39<00:00, 99.04s/it]
  8%|▊         | 394/5198 [11:37:26<140:00:47, 104.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.12s/it][A100%|██████████| 1/1 [01:39<00:00, 99.12s/it]
  8%|▊         | 394/5198 [11:37:27<140:00:31, 104.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.05s/it][A100%|██████████| 1/1 [01:39<00:00, 99.05s/it]
  8%|▊         | 394/5198 [11:37:27<140:00:09, 104.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.11s/it][A100%|██████████| 1/1 [01:39<00:00, 99.11s/it]
  8%|▊         | 394/5198 [11:37:27<140:01:10, 104.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.14s/it][A100%|██████████| 1/1 [01:39<00:00, 99.14s/it]
  8%|▊         | 394/5198 [11:37:27<140:01:33, 104.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.12s/it][A100%|██████████| 1/1 [01:39<00:00, 99.12s/it]
  8%|▊         | 394/5198 [11:37:29<140:01:32, 104.93s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_370
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.56s/it][A100%|██████████| 1/1 [01:27<00:00, 87.56s/it]
  8%|▊         | 395/5198 [11:38:53<133:09:24, 99.81s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 07:03:59,535] [INFO] [logging.py:96:log_dist] [Rank 0] step=389, skipped=0, lr=[1.9924246243638464e-05], mom=[(0.9, 0.999)]
steps: 389 loss: 0.6347 iter time (s): 86.621 samples/sec: 1.478

100%|██████████| 1/1 [01:27<00:00, 87.43s/it][A100%|██████████| 1/1 [01:27<00:00, 87.43s/it]
  8%|▊         | 395/5198 [11:38:54<132:59:44, 99.68s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.42s/it][A100%|██████████| 1/1 [01:27<00:00, 87.42s/it]
  8%|▊         | 395/5198 [11:38:54<132:58:58, 99.67s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.42s/it][A100%|██████████| 1/1 [01:27<00:00, 87.42s/it]
  8%|▊         | 395/5198 [11:38:54<132:58:49, 99.67s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.42s/it][A100%|██████████| 1/1 [01:27<00:00, 87.42s/it]
  8%|▊         | 395/5198 [11:38:54<132:58:32, 99.67s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.42s/it][A100%|██████████| 1/1 [01:27<00:00, 87.42s/it]
  8%|▊         | 395/5198 [11:38:54<132:59:08, 99.68s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.42s/it][A100%|██████████| 1/1 [01:27<00:00, 87.42s/it]
  8%|▊         | 395/5198 [11:38:54<132:59:25, 99.68s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.41s/it][A100%|██████████| 1/1 [01:27<00:00, 87.41s/it]
  8%|▊         | 395/5198 [11:38:57<132:59:12, 99.68s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_371
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.21s/it][A100%|██████████| 1/1 [01:23<00:00, 83.21s/it]
  8%|▊         | 396/5198 [11:40:17<126:32:58, 94.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 07:05:22,795] [INFO] [logging.py:96:log_dist] [Rank 0] step=390, skipped=0, lr=[1.992354881853644e-05], mom=[(0.9, 0.999)]
steps: 390 loss: 0.5568 iter time (s): 82.465 samples/sec: 1.552

100%|██████████| 1/1 [01:23<00:00, 83.17s/it][A100%|██████████| 1/1 [01:23<00:00, 83.17s/it]
  8%|▊         | 396/5198 [11:40:17<126:21:49, 94.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.27s/it][A100%|██████████| 1/1 [01:23<00:00, 83.27s/it]
  8%|▊         | 396/5198 [11:40:17<126:23:45, 94.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.22s/it][A100%|██████████| 1/1 [01:23<00:00, 83.22s/it]
  8%|▊         | 396/5198 [11:40:17<126:22:17, 94.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.24s/it][A100%|██████████| 1/1 [01:23<00:00, 83.24s/it]
  8%|▊         | 396/5198 [11:40:17<126:22:29, 94.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.17s/it][A100%|██████████| 1/1 [01:23<00:00, 83.17s/it]
  8%|▊         | 396/5198 [11:40:18<126:21:33, 94.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.21s/it][A100%|██████████| 1/1 [01:23<00:00, 83.21s/it]
  8%|▊         | 396/5198 [11:40:20<126:22:24, 94.74s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_372

100%|██████████| 1/1 [01:23<00:00, 83.23s/it][A100%|██████████| 1/1 [01:23<00:00, 83.23s/it]
  8%|▊         | 396/5198 [11:40:18<126:22:54, 94.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:01<00:00, 121.17s/it][A100%|██████████| 1/1 [02:01<00:00, 121.17s/it]
  8%|▊         | 397/5198 [11:42:18<137:04:52, 102.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 07:07:25,078] [INFO] [logging.py:96:log_dist] [Rank 0] step=391, skipped=0, lr=[1.992284821003445e-05], mom=[(0.9, 0.999)]
steps: 391 loss: 0.5951 iter time (s): 121.523 samples/sec: 1.053

100%|██████████| 1/1 [02:02<00:00, 122.30s/it][A100%|██████████| 1/1 [02:02<00:00, 122.30s/it]
  8%|▊         | 397/5198 [11:42:19<137:22:25, 103.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:02<00:00, 122.25s/it][A100%|██████████| 1/1 [02:02<00:00, 122.26s/it]
  8%|▊         | 397/5198 [11:42:19<137:22:36, 103.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:02<00:00, 122.32s/it][A100%|██████████| 1/1 [02:02<00:00, 122.32s/it]
  8%|▊         | 397/5198 [11:42:20<137:22:54, 103.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:02<00:00, 122.42s/it][A100%|██████████| 1/1 [02:02<00:00, 122.42s/it]
  8%|▊         | 397/5198 [11:42:20<137:25:28, 103.05s/it]
100%|██████████| 1/1 [02:02<00:00, 122.41s/it][A100%|██████████| 1/1 [02:02<00:00, 122.41s/it]
  8%|▊         | 397/5198 [11:42:20<137:24:31, 103.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:02<00:00, 122.37s/it][A100%|██████████| 1/1 [02:02<00:00, 122.37s/it]
  8%|▊         | 397/5198 [11:42:20<137:24:37, 103.04s/it]
100%|██████████| 1/1 [02:02<00:00, 122.38s/it][A100%|██████████| 1/1 [02:02<00:00, 122.38s/it]
  8%|▊         | 397/5198 [11:42:22<137:24:26, 103.03s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_373

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.62s/it][A100%|██████████| 1/1 [01:25<00:00, 85.62s/it]
  8%|▊         | 398/5198 [11:43:44<130:14:52, 97.69s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 07:08:49,877] [INFO] [logging.py:96:log_dist] [Rank 0] step=392, skipped=0, lr=[1.9922144418357264e-05], mom=[(0.9, 0.999)]
steps: 392 loss: 0.5993 iter time (s): 83.941 samples/sec: 1.525

100%|██████████| 1/1 [01:24<00:00, 84.78s/it][A100%|██████████| 1/1 [01:24<00:00, 84.78s/it]
  8%|▊         | 398/5198 [11:43:44<130:03:19, 97.54s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.76s/it][A100%|██████████| 1/1 [01:24<00:00, 84.76s/it]
  8%|▊         | 398/5198 [11:43:44<130:03:09, 97.54s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.59s/it][A100%|██████████| 1/1 [01:24<00:00, 84.59s/it]
  8%|▊         | 398/5198 [11:43:44<130:00:57, 97.51s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.81s/it][A100%|██████████| 1/1 [01:24<00:00, 84.81s/it]
  8%|▊         | 398/5198 [11:43:45<130:04:21, 97.55s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.67s/it][A100%|██████████| 1/1 [01:24<00:00, 84.67s/it]
  8%|▊         | 398/5198 [11:43:45<130:02:11, 97.53s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.71s/it][A100%|██████████| 1/1 [01:24<00:00, 84.71s/it]
  8%|▊         | 398/5198 [11:43:45<130:03:15, 97.54s/it] 
100%|██████████| 1/1 [01:24<00:00, 84.71s/it][A100%|██████████| 1/1 [01:24<00:00, 84.71s/it]
  8%|▊         | 398/5198 [11:43:47<130:03:07, 97.54s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_374

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.66s/it][A100%|██████████| 1/1 [01:22<00:00, 82.66s/it]
  8%|▊         | 399/5198 [11:45:07<124:17:49, 93.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 07:10:12,032] [INFO] [logging.py:96:log_dist] [Rank 0] step=393, skipped=0, lr=[1.992143744373068e-05], mom=[(0.9, 0.999)]
steps: 393 loss: 0.5818 iter time (s): 81.378 samples/sec: 1.573

100%|██████████| 1/1 [01:22<00:00, 82.18s/it][A100%|██████████| 1/1 [01:22<00:00, 82.18s/it]
  8%|▊         | 399/5198 [11:45:06<123:53:13, 92.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.16s/it][A100%|██████████| 1/1 [01:22<00:00, 82.16s/it]
  8%|▊         | 399/5198 [11:45:06<123:52:46, 92.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.10s/it][A100%|██████████| 1/1 [01:22<00:00, 82.11s/it]
  8%|▊         | 399/5198 [11:45:07<123:52:14, 92.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.22s/it][A100%|██████████| 1/1 [01:22<00:00, 82.22s/it]
  8%|▊         | 399/5198 [11:45:07<123:52:37, 92.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.18s/it][A100%|██████████| 1/1 [01:22<00:00, 82.18s/it]
  8%|▊         | 399/5198 [11:45:07<123:52:26, 92.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.13s/it][A100%|██████████| 1/1 [01:22<00:00, 82.13s/it]
  8%|▊         | 399/5198 [11:45:07<123:51:59, 92.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.15s/it][A100%|██████████| 1/1 [01:22<00:00, 82.15s/it]
  8%|▊         | 399/5198 [11:45:09<123:52:22, 92.92s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_24
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:04<00:00, 124.80s/it][A100%|██████████| 1/1 [02:04<00:00, 124.80s/it]
[2024-06-30 07:12:18,517] [INFO] [logging.py:96:log_dist] [Rank 0] step=394, skipped=0, lr=[1.9920727286381505e-05], mom=[(0.9, 0.999)]
steps: 394 loss: 0.8091 iter time (s): 126.012 samples/sec: 1.016

100%|██████████| 1/1 [02:06<00:00, 126.88s/it][A100%|██████████| 1/1 [02:06<00:00, 126.88s/it]

100%|██████████| 1/1 [02:07<00:00, 127.00s/it][A100%|██████████| 1/1 [02:07<00:00, 127.01s/it]

100%|██████████| 1/1 [02:07<00:00, 127.01s/it][A100%|██████████| 1/1 [02:07<00:00, 127.01s/it]

100%|██████████| 1/1 [02:07<00:00, 127.04s/it][A100%|██████████| 1/1 [02:07<00:00, 127.04s/it]

100%|██████████| 1/1 [02:07<00:00, 127.07s/it][A100%|██████████| 1/1 [02:07<00:00, 127.07s/it]

100%|██████████| 1/1 [02:07<00:00, 127.02s/it][A100%|██████████| 1/1 [02:07<00:00, 127.02s/it]
Checkpointing at shard 399

100%|██████████| 1/1 [02:07<00:00, 127.05s/it][A100%|██████████| 1/1 [02:07<00:00, 127.05s/it]
[2024-06-30 07:12:19,829] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step394 is about to be saved!
[2024-06-30 07:12:20,665] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step394/layer_00-model_states.pt...
[2024-06-30 07:12:24,515] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step394/layer_07-model_states.pt...
[2024-06-30 07:12:24,940] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step394/layer_06-model_states.pt...
[2024-06-30 07:12:25,879] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step394/layer_02-model_states.pt...
[2024-06-30 07:12:26,029] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step394/layer_05-model_states.pt...
[2024-06-30 07:12:26,429] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step394/layer_08-model_states.pt...
[2024-06-30 07:12:28,135] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step394/layer_00-model_states.pt.
[2024-06-30 07:12:34,546] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step394/layer_04-model_states.pt...
[2024-06-30 07:12:35,423] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step394/layer_01-model_states.pt...
[2024-06-30 07:12:35,587] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step394/layer_03-model_states.pt...
[2024-06-30 07:14:19,576] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step394/layer_06-model_states.pt.
[2024-06-30 07:14:19,639] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step394/mp_rank_05_model_states.pt...
[2024-06-30 07:14:19,781] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step394/mp_rank_05_model_states.pt.
[2024-06-30 07:14:19,781] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step394 is ready now!
[2024-06-30 07:14:29,020] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step394/layer_07-model_states.pt.
[2024-06-30 07:14:29,056] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step394/mp_rank_06_model_states.pt...
[2024-06-30 07:14:29,176] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step394/mp_rank_06_model_states.pt.
[2024-06-30 07:14:29,177] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step394 is ready now!
[2024-06-30 07:14:43,866] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step394/layer_05-model_states.pt.
[2024-06-30 07:14:44,065] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step394/mp_rank_04_model_states.pt...
[2024-06-30 07:14:44,588] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step394/mp_rank_04_model_states.pt.
[2024-06-30 07:14:44,588] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step394 is ready now!
[2024-06-30 07:14:51,922] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step394/layer_08-model_states.pt.
[2024-06-30 07:14:52,350] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step394/layer_09-model_states.pt...
[2024-06-30 07:14:55,554] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step394/layer_09-model_states.pt.
[2024-06-30 07:14:55,557] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step394/mp_rank_07_model_states.pt...
[2024-06-30 07:14:55,637] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step394/mp_rank_07_model_states.pt.
[2024-06-30 07:14:55,637] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step394 is ready now!
[2024-06-30 07:15:18,437] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step394/layer_01-model_states.pt.
[2024-06-30 07:15:18,761] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step394/layer_04-model_states.pt.
[2024-06-30 07:15:18,876] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step394/mp_rank_00_model_states.pt
[2024-06-30 07:15:18,876] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step394/mp_rank_00_model_states.pt...
[2024-06-30 07:15:19,017] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step394/mp_rank_03_model_states.pt...
[2024-06-30 07:15:19,679] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step394/mp_rank_00_model_states.pt.
[2024-06-30 07:15:19,680] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step394 is ready now!
[2024-06-30 07:15:30,102] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step394/mp_rank_03_model_states.pt.
[2024-06-30 07:15:30,102] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step394 is ready now!
[2024-06-30 07:15:30,161] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step394/layer_02-model_states.pt.
[2024-06-30 07:15:30,167] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step394/layer_03-model_states.pt.
[2024-06-30 07:15:30,520] [INFO] [logging.py:96:log_dist] [Rank 1] Saving model checkpoint: /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step394/mp_rank_01_model_states.pt
[2024-06-30 07:15:30,520] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step394/mp_rank_01_model_states.pt...
[2024-06-30 07:15:30,581] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step394/mp_rank_01_model_states.pt.
[2024-06-30 07:15:30,581] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step394 is ready now!
[2024-06-30 07:15:30,665] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step394/mp_rank_02_model_states.pt...
[2024-06-30 07:15:30,736] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step394/mp_rank_02_model_states.pt.
[2024-06-30 07:15:30,737] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step394 is ready now!
  8%|▊         | 400/5198 [11:50:25<213:51:39, 160.46s/it]Checkpoint saved using --- 190.91559529304504 seconds ---
  8%|▊         | 400/5198 [11:50:25<213:49:14, 160.43s/it]  8%|▊         | 400/5198 [11:50:25<213:50:34, 160.45s/it]  8%|▊         | 400/5198 [11:50:27<214:55:00, 161.25s/it]  8%|▊         | 400/5198 [11:50:27<213:48:54, 160.43s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_375
  8%|▊         | 400/5198 [11:50:25<213:56:14, 160.52s/it]  8%|▊         | 400/5198 [11:50:25<213:59:35, 160.56s/it]  8%|▊         | 400/5198 [11:50:25<213:53:43, 160.49s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A

  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:17<00:00, 77.97s/it][A100%|██████████| 1/1 [01:17<00:00, 77.97s/it]
  8%|▊         | 401/5198 [11:51:45<181:39:53, 136.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 07:16:50,761] [INFO] [logging.py:96:log_dist] [Rank 0] step=395, skipped=0, lr=[1.9920013946537585e-05], mom=[(0.9, 0.999)]
steps: 395 loss: 0.6018 iter time (s): 79.826 samples/sec: 1.603

100%|██████████| 1/1 [01:20<00:00, 80.11s/it][A100%|██████████| 1/1 [01:20<00:00, 80.11s/it]
  8%|▊         | 401/5198 [11:51:45<181:52:20, 136.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.27s/it][A100%|██████████| 1/1 [01:20<00:00, 80.27s/it]
  8%|▊         | 401/5198 [11:51:45<181:53:59, 136.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.43s/it][A100%|██████████| 1/1 [01:20<00:00, 80.44s/it]
  8%|▊         | 401/5198 [11:51:45<181:56:01, 136.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.46s/it][A100%|██████████| 1/1 [01:20<00:00, 80.46s/it]
  8%|▊         | 401/5198 [11:51:45<181:55:13, 136.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.53s/it][A100%|██████████| 1/1 [01:20<00:00, 80.53s/it]
  8%|▊         | 401/5198 [11:51:46<181:56:00, 136.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.57s/it][A100%|██████████| 1/1 [01:20<00:00, 80.57s/it]
  8%|▊         | 401/5198 [11:51:46<181:56:06, 136.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.59s/it][A100%|██████████| 1/1 [01:20<00:00, 80.59s/it]
  8%|▊         | 401/5198 [11:51:48<181:56:21, 136.54s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_376
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:23<00:00, 143.64s/it][A100%|██████████| 1/1 [02:23<00:00, 143.64s/it]
  8%|▊         | 402/5198 [11:54:09<184:36:28, 138.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 07:19:16,269] [INFO] [logging.py:96:log_dist] [Rank 0] step=396, skipped=0, lr=[1.991929742442777e-05], mom=[(0.9, 0.999)]
steps: 396 loss: 0.5392 iter time (s): 144.709 samples/sec: 0.885

100%|██████████| 1/1 [02:25<00:00, 145.52s/it][A100%|██████████| 1/1 [02:25<00:00, 145.52s/it]
  8%|▊         | 402/5198 [11:54:10<185:26:43, 139.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:25<00:00, 145.43s/it][A100%|██████████| 1/1 [02:25<00:00, 145.43s/it]
  8%|▊         | 402/5198 [11:54:10<185:25:49, 139.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:25<00:00, 145.42s/it][A100%|██████████| 1/1 [02:25<00:00, 145.42s/it]
  8%|▊         | 402/5198 [11:54:11<185:26:57, 139.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:25<00:00, 145.47s/it][A100%|██████████| 1/1 [02:25<00:00, 145.47s/it]
  8%|▊         | 402/5198 [11:54:11<185:27:41, 139.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:25<00:00, 145.49s/it][A100%|██████████| 1/1 [02:25<00:00, 145.49s/it]
  8%|▊         | 402/5198 [11:54:11<185:28:39, 139.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:25<00:00, 145.46s/it][A100%|██████████| 1/1 [02:25<00:00, 145.46s/it]
  8%|▊         | 402/5198 [11:54:11<185:28:00, 139.22s/it]
100%|██████████| 1/1 [02:25<00:00, 145.45s/it][A100%|██████████| 1/1 [02:25<00:00, 145.45s/it]
  8%|▊         | 402/5198 [11:54:13<185:27:49, 139.21s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_377

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.19s/it][A100%|██████████| 1/1 [01:21<00:00, 81.19s/it]
  8%|▊         | 403/5198 [11:55:30<161:41:45, 121.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 07:20:35,859] [INFO] [logging.py:96:log_dist] [Rank 0] step=397, skipped=0, lr=[1.991857772028194e-05], mom=[(0.9, 0.999)]
steps: 397 loss: 0.5887 iter time (s): 78.850 samples/sec: 1.623

100%|██████████| 1/1 [01:19<00:00, 79.66s/it][A100%|██████████| 1/1 [01:19<00:00, 79.66s/it]
  8%|▊         | 403/5198 [11:55:30<161:37:07, 121.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.72s/it][A100%|██████████| 1/1 [01:19<00:00, 79.72s/it]
  8%|▊         | 403/5198 [11:55:30<161:38:02, 121.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.64s/it][A100%|██████████| 1/1 [01:19<00:00, 79.64s/it]
  8%|▊         | 403/5198 [11:55:30<161:36:49, 121.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.64s/it][A100%|██████████| 1/1 [01:19<00:00, 79.64s/it]
  8%|▊         | 403/5198 [11:55:31<161:37:27, 121.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.57s/it][A100%|██████████| 1/1 [01:19<00:00, 79.57s/it]
  8%|▊         | 403/5198 [11:55:31<161:36:26, 121.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.64s/it][A100%|██████████| 1/1 [01:19<00:00, 79.64s/it]
  8%|▊         | 403/5198 [11:55:31<161:37:32, 121.35s/it]
100%|██████████| 1/1 [01:19<00:00, 79.64s/it][A100%|██████████| 1/1 [01:19<00:00, 79.64s/it]
  8%|▊         | 403/5198 [11:55:33<161:37:25, 121.34s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_378

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.99s/it][A100%|██████████| 1/1 [01:47<00:00, 107.99s/it]
  8%|▊         | 404/5198 [11:57:18<156:22:08, 117.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 07:22:24,789] [INFO] [logging.py:96:log_dist] [Rank 0] step=398, skipped=0, lr=[1.9917854834330996e-05], mom=[(0.9, 0.999)]
steps: 398 loss: 0.6260 iter time (s): 108.128 samples/sec: 1.184

100%|██████████| 1/1 [01:48<00:00, 108.86s/it][A100%|██████████| 1/1 [01:48<00:00, 108.87s/it]
  8%|▊         | 404/5198 [11:57:19<156:36:24, 117.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.86s/it][A100%|██████████| 1/1 [01:48<00:00, 108.86s/it]
  8%|▊         | 404/5198 [11:57:19<156:36:59, 117.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.95s/it][A100%|██████████| 1/1 [01:48<00:00, 108.95s/it]
  8%|▊         | 404/5198 [11:57:19<156:38:15, 117.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.95s/it][A100%|██████████| 1/1 [01:48<00:00, 108.95s/it]
  8%|▊         | 404/5198 [11:57:20<156:38:37, 117.63s/it]
100%|██████████| 1/1 [01:48<00:00, 108.95s/it][A100%|██████████| 1/1 [01:48<00:00, 108.95s/it]
  8%|▊         | 404/5198 [11:57:20<156:37:46, 117.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.91s/it][A100%|██████████| 1/1 [01:48<00:00, 108.91s/it]
  8%|▊         | 404/5198 [11:57:20<156:37:41, 117.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.93s/it][A100%|██████████| 1/1 [01:48<00:00, 108.93s/it]
  8%|▊         | 404/5198 [11:57:22<156:37:52, 117.62s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_379
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.59s/it][A100%|██████████| 1/1 [01:19<00:00, 79.59s/it]
  8%|▊         | 405/5198 [11:58:38<141:17:08, 106.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 07:23:43,759] [INFO] [logging.py:96:log_dist] [Rank 0] step=399, skipped=0, lr=[1.991712876680685e-05], mom=[(0.9, 0.999)]
steps: 399 loss: 0.5944 iter time (s): 78.170 samples/sec: 1.637

100%|██████████| 1/1 [01:18<00:00, 78.96s/it][A100%|██████████| 1/1 [01:18<00:00, 78.96s/it]
  8%|▊         | 405/5198 [11:58:38<141:08:48, 106.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.90s/it][A100%|██████████| 1/1 [01:18<00:00, 78.90s/it]
  8%|▊         | 405/5198 [11:58:38<141:07:31, 106.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.88s/it][A100%|██████████| 1/1 [01:18<00:00, 78.88s/it]
  8%|▊         | 405/5198 [11:58:38<141:07:57, 106.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.88s/it][A100%|██████████| 1/1 [01:18<00:00, 78.88s/it]
  8%|▊         | 405/5198 [11:58:38<141:08:18, 106.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.94s/it][A100%|██████████| 1/1 [01:18<00:00, 78.94s/it]
  8%|▊         | 405/5198 [11:58:39<141:08:59, 106.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.93s/it][A100%|██████████| 1/1 [01:18<00:00, 78.93s/it]
  8%|▊         | 405/5198 [11:58:39<141:08:43, 106.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.93s/it][A100%|██████████| 1/1 [01:18<00:00, 78.93s/it]
  8%|▊         | 405/5198 [11:58:41<141:08:55, 106.02s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_380
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.67s/it][A100%|██████████| 1/1 [01:31<00:00, 91.67s/it]
  8%|▊         | 406/5198 [12:00:10<135:33:15, 101.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 07:25:15,924] [INFO] [logging.py:96:log_dist] [Rank 0] step=400, skipped=0, lr=[1.9916399517942458e-05], mom=[(0.9, 0.999)]
steps: 400 loss: 0.6195 iter time (s): 91.398 samples/sec: 1.400

100%|██████████| 1/1 [01:32<00:00, 92.13s/it][A100%|██████████| 1/1 [01:32<00:00, 92.14s/it]
  8%|▊         | 406/5198 [12:00:10<135:34:45, 101.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.14s/it][A100%|██████████| 1/1 [01:32<00:00, 92.14s/it]
  8%|▊         | 406/5198 [12:00:10<135:33:51, 101.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.21s/it][A100%|██████████| 1/1 [01:32<00:00, 92.21s/it]
  8%|▊         | 406/5198 [12:00:11<135:35:53, 101.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.21s/it][A100%|██████████| 1/1 [01:32<00:00, 92.21s/it]
  8%|▊         | 406/5198 [12:00:11<135:35:59, 101.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.16s/it][A100%|██████████| 1/1 [01:32<00:00, 92.16s/it]
  8%|▊         | 406/5198 [12:00:11<135:35:27, 101.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.19s/it][A100%|██████████| 1/1 [01:32<00:00, 92.19s/it]
  8%|▊         | 406/5198 [12:00:11<135:35:55, 101.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.19s/it][A100%|██████████| 1/1 [01:32<00:00, 92.19s/it]
  8%|▊         | 406/5198 [12:00:13<135:35:55, 101.87s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_381
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.21s/it][A100%|██████████| 1/1 [01:30<00:00, 90.21s/it]
  8%|▊         | 407/5198 [12:01:40<130:56:04, 98.39s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 07:26:46,222] [INFO] [logging.py:96:log_dist] [Rank 0] step=401, skipped=0, lr=[1.9915667087971767e-05], mom=[(0.9, 0.999)]
steps: 401 loss: 0.5858 iter time (s): 89.506 samples/sec: 1.430

100%|██████████| 1/1 [01:30<00:00, 90.30s/it][A100%|██████████| 1/1 [01:30<00:00, 90.30s/it]
  8%|▊         | 407/5198 [12:01:40<130:55:59, 98.38s/it] 
100%|██████████| 1/1 [01:30<00:00, 90.39s/it][A100%|██████████| 1/1 [01:30<00:00, 90.39s/it]
  8%|▊         | 407/5198 [12:01:40<130:58:35, 98.42s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.37s/it][A100%|██████████| 1/1 [01:30<00:00, 90.37s/it]
  8%|▊         | 407/5198 [12:01:41<130:59:08, 98.42s/it] 
100%|██████████| 1/1 [01:30<00:00, 90.30s/it][A100%|██████████| 1/1 [01:30<00:00, 90.30s/it]
  8%|▊         | 407/5198 [12:01:41<130:57:21, 98.40s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.34s/it][A100%|██████████| 1/1 [01:30<00:00, 90.34s/it]
  8%|▊         | 407/5198 [12:01:41<130:57:59, 98.41s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.35s/it][A100%|██████████| 1/1 [01:30<00:00, 90.36s/it]
  8%|▊         | 407/5198 [12:01:41<130:58:35, 98.42s/it] 

  0%|          | 0/1 [00:00<?, ?it/s][A100%|██████████| 1/1 [01:30<00:00, 90.35s/it][A100%|██████████| 1/1 [01:30<00:00, 90.35s/it]
  8%|▊         | 407/5198 [12:01:43<130:58:26, 98.42s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_382
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.89s/it][A100%|██████████| 1/1 [01:44<00:00, 104.89s/it]
  8%|▊         | 408/5198 [12:03:25<133:33:07, 100.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 07:28:31,641] [INFO] [logging.py:96:log_dist] [Rank 0] step=402, skipped=0, lr=[1.9914931477129762e-05], mom=[(0.9, 0.999)]
steps: 402 loss: 0.5604 iter time (s): 104.561 samples/sec: 1.224

100%|██████████| 1/1 [01:45<00:00, 105.35s/it][A100%|██████████| 1/1 [01:45<00:00, 105.35s/it]
  8%|▊         | 408/5198 [12:03:26<133:43:12, 100.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.53s/it][A100%|██████████| 1/1 [01:45<00:00, 105.53s/it]
  8%|▊         | 408/5198 [12:03:26<133:46:01, 100.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.31s/it][A100%|██████████| 1/1 [01:45<00:00, 105.31s/it]
  8%|▊         | 408/5198 [12:03:26<133:42:36, 100.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.40s/it][A100%|██████████| 1/1 [01:45<00:00, 105.40s/it]
  8%|▊         | 408/5198 [12:03:26<133:43:24, 100.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.43s/it][A100%|██████████| 1/1 [01:45<00:00, 105.43s/it]
  8%|▊         | 408/5198 [12:03:27<133:44:38, 100.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.39s/it][A100%|██████████| 1/1 [01:45<00:00, 105.39s/it]
  8%|▊         | 408/5198 [12:03:27<133:44:14, 100.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.41s/it][A100%|██████████| 1/1 [01:45<00:00, 105.41s/it]
  8%|▊         | 408/5198 [12:03:29<133:44:28, 100.52s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_383
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.51s/it][A100%|██████████| 1/1 [01:22<00:00, 82.51s/it]
  8%|▊         | 409/5198 [12:04:48<126:26:29, 95.05s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 07:29:53,629] [INFO] [logging.py:96:log_dist] [Rank 0] step=403, skipped=0, lr=[1.991419268565245e-05], mom=[(0.9, 0.999)]
steps: 403 loss: 0.5237 iter time (s): 81.136 samples/sec: 1.578

100%|██████████| 1/1 [01:21<00:00, 81.99s/it][A100%|██████████| 1/1 [01:21<00:00, 81.99s/it]
  8%|▊         | 409/5198 [12:04:48<126:18:37, 94.95s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.95s/it][A100%|██████████| 1/1 [01:21<00:00, 81.95s/it]
  8%|▊         | 409/5198 [12:04:48<126:19:29, 94.96s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.92s/it][A100%|██████████| 1/1 [01:21<00:00, 81.92s/it]
  8%|▊         | 409/5198 [12:04:48<126:16:38, 94.93s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.93s/it][A100%|██████████| 1/1 [01:21<00:00, 81.93s/it]
  8%|▊         | 409/5198 [12:04:48<126:17:09, 94.93s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.94s/it][A100%|██████████| 1/1 [01:21<00:00, 81.94s/it]
  8%|▊         | 409/5198 [12:04:48<126:18:25, 94.95s/it] 
100%|██████████| 1/1 [01:21<00:00, 81.91s/it][A100%|██████████| 1/1 [01:21<00:00, 81.91s/it]
  8%|▊         | 409/5198 [12:04:48<126:17:23, 94.93s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.92s/it][A100%|██████████| 1/1 [01:21<00:00, 81.92s/it]
  8%|▊         | 409/5198 [12:04:51<126:17:39, 94.94s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_384
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.54s/it][A100%|██████████| 1/1 [01:36<00:00, 96.54s/it]
  8%|▊         | 410/5198 [12:06:24<127:04:47, 95.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 07:31:30,748] [INFO] [logging.py:96:log_dist] [Rank 0] step=404, skipped=0, lr=[1.9913450713776848e-05], mom=[(0.9, 0.999)]
steps: 404 loss: 0.6315 iter time (s): 96.333 samples/sec: 1.329

100%|██████████| 1/1 [01:37<00:00, 97.14s/it][A100%|██████████| 1/1 [01:37<00:00, 97.14s/it]
  8%|▊         | 410/5198 [12:06:25<127:09:52, 95.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.16s/it][A100%|██████████| 1/1 [01:37<00:00, 97.16s/it]
  8%|▊         | 410/5198 [12:06:25<127:10:41, 95.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.22s/it][A100%|██████████| 1/1 [01:37<00:00, 97.23s/it]
  8%|▊         | 410/5198 [12:06:25<127:10:20, 95.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.11s/it][A100%|██████████| 1/1 [01:37<00:00, 97.11s/it]
  8%|▊         | 410/5198 [12:06:26<127:08:53, 95.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.27s/it][A100%|██████████| 1/1 [01:37<00:00, 97.27s/it]
  8%|▊         | 410/5198 [12:06:26<127:11:46, 95.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.20s/it][A100%|██████████| 1/1 [01:37<00:00, 97.20s/it]
  8%|▊         | 410/5198 [12:06:28<127:10:23, 95.62s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_385

100%|██████████| 1/1 [01:37<00:00, 97.23s/it][A100%|██████████| 1/1 [01:37<00:00, 97.23s/it]
  8%|▊         | 410/5198 [12:06:26<127:10:54, 95.63s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.35s/it][A100%|██████████| 1/1 [01:27<00:00, 87.35s/it]
  8%|▊         | 411/5198 [12:07:52<123:50:33, 93.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 07:32:57,888] [INFO] [logging.py:96:log_dist] [Rank 0] step=405, skipped=0, lr=[1.9912705561741002e-05], mom=[(0.9, 0.999)]
steps: 405 loss: 0.5661 iter time (s): 86.262 samples/sec: 1.484

100%|██████████| 1/1 [01:27<00:00, 87.09s/it][A100%|██████████| 1/1 [01:27<00:00, 87.09s/it]
  8%|▊         | 411/5198 [12:07:52<123:44:35, 93.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.08s/it][A100%|██████████| 1/1 [01:27<00:00, 87.08s/it]
  8%|▊         | 411/5198 [12:07:52<123:44:49, 93.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.10s/it][A100%|██████████| 1/1 [01:27<00:00, 87.10s/it]
  8%|▊         | 411/5198 [12:07:53<123:45:06, 93.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.03s/it][A100%|██████████| 1/1 [01:27<00:00, 87.03s/it]
  8%|▊         | 411/5198 [12:07:53<123:44:27, 93.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.15s/it][A100%|██████████| 1/1 [01:27<00:00, 87.15s/it]
  8%|▊         | 411/5198 [12:07:53<123:45:18, 93.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.08s/it][A100%|██████████| 1/1 [01:27<00:00, 87.08s/it]
  8%|▊         | 411/5198 [12:07:53<123:44:57, 93.06s/it]
100%|██████████| 1/1 [01:27<00:00, 87.09s/it][A100%|██████████| 1/1 [01:27<00:00, 87.09s/it]
  8%|▊         | 411/5198 [12:07:55<123:44:49, 93.06s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_386

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.09s/it][A100%|██████████| 1/1 [01:27<00:00, 87.09s/it]
  8%|▊         | 412/5198 [12:09:19<121:27:49, 91.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 07:34:25,248] [INFO] [logging.py:96:log_dist] [Rank 0] step=406, skipped=0, lr=[1.9911957229783973e-05], mom=[(0.9, 0.999)]
steps: 406 loss: 0.5547 iter time (s): 86.526 samples/sec: 1.479

100%|██████████| 1/1 [01:27<00:00, 87.31s/it][A100%|██████████| 1/1 [01:27<00:00, 87.31s/it]
  8%|▊         | 412/5198 [12:09:19<121:25:46, 91.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.24s/it][A100%|██████████| 1/1 [01:27<00:00, 87.24s/it]
  8%|▊         | 412/5198 [12:09:19<121:24:15, 91.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.26s/it][A100%|██████████| 1/1 [01:27<00:00, 87.26s/it]
  8%|▊         | 412/5198 [12:09:20<121:24:48, 91.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.29s/it][A100%|██████████| 1/1 [01:27<00:00, 87.29s/it]
  8%|▊         | 412/5198 [12:09:20<121:25:03, 91.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.26s/it][A100%|██████████| 1/1 [01:27<00:00, 87.26s/it]
  8%|▊         | 412/5198 [12:09:20<121:25:04, 91.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.29s/it][A100%|██████████| 1/1 [01:27<00:00, 87.29s/it]
  8%|▊         | 412/5198 [12:09:20<121:25:26, 91.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.29s/it][A100%|██████████| 1/1 [01:27<00:00, 87.29s/it]
  8%|▊         | 412/5198 [12:09:22<121:25:21, 91.33s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_387
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.64s/it][A100%|██████████| 1/1 [01:33<00:00, 93.64s/it]
  8%|▊         | 413/5198 [12:10:53<122:25:27, 92.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 07:35:59,269] [INFO] [logging.py:96:log_dist] [Rank 0] step=407, skipped=0, lr=[1.9911205718145846e-05], mom=[(0.9, 0.999)]
steps: 407 loss: 0.6109 iter time (s): 93.250 samples/sec: 1.373

100%|██████████| 1/1 [01:34<00:00, 94.01s/it][A100%|██████████| 1/1 [01:34<00:00, 94.01s/it]
  8%|▊         | 413/5198 [12:10:53<122:28:22, 92.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.02s/it][A100%|██████████| 1/1 [01:34<00:00, 94.02s/it]
  8%|▊         | 413/5198 [12:10:53<122:27:37, 92.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.07s/it][A100%|██████████| 1/1 [01:34<00:00, 94.07s/it]
  8%|▊         | 413/5198 [12:10:54<122:29:12, 92.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.06s/it][A100%|██████████| 1/1 [01:34<00:00, 94.06s/it]
  8%|▊         | 413/5198 [12:10:54<122:28:58, 92.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.05s/it][A100%|██████████| 1/1 [01:34<00:00, 94.05s/it]
  8%|▊         | 413/5198 [12:10:54<122:28:44, 92.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.03s/it][A
100%|██████████| 1/1 [01:34<00:00, 94.03s/it]
  8%|▊         | 413/5198 [12:10:54<122:28:31, 92.14s/it]100%|██████████| 1/1 [01:34<00:00, 94.02s/it][A100%|██████████| 1/1 [01:34<00:00, 94.02s/it]
  8%|▊         | 413/5198 [12:10:56<122:28:18, 92.14s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_388
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.14s/it][A100%|██████████| 1/1 [01:36<00:00, 96.14s/it]
  8%|▊         | 414/5198 [12:12:29<124:04:48, 93.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 07:37:35,627] [INFO] [logging.py:96:log_dist] [Rank 0] step=408, skipped=0, lr=[1.991045102706772e-05], mom=[(0.9, 0.999)]
steps: 408 loss: 0.5897 iter time (s): 95.577 samples/sec: 1.339

100%|██████████| 1/1 [01:36<00:00, 96.30s/it][A100%|██████████| 1/1 [01:36<00:00, 96.30s/it]
  8%|▊         | 414/5198 [12:12:30<124:06:31, 93.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.40s/it][A100%|██████████| 1/1 [01:36<00:00, 96.40s/it]
  8%|▊         | 414/5198 [12:12:30<124:08:25, 93.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.35s/it][A100%|██████████| 1/1 [01:36<00:00, 96.35s/it]
  8%|▊         | 414/5198 [12:12:30<124:08:29, 93.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.37s/it][A100%|██████████| 1/1 [01:36<00:00, 96.37s/it]
  8%|▊         | 414/5198 [12:12:30<124:08:35, 93.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.35s/it][A100%|██████████| 1/1 [01:36<00:00, 96.35s/it]
  8%|▊         | 414/5198 [12:12:30<124:07:51, 93.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.37s/it][A100%|██████████| 1/1 [01:36<00:00, 96.37s/it]
  8%|▊         | 414/5198 [12:12:30<124:08:08, 93.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.38s/it][A100%|██████████| 1/1 [01:36<00:00, 96.38s/it]
  8%|▊         | 414/5198 [12:12:33<124:08:15, 93.41s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_389
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.80s/it][A100%|██████████| 1/1 [01:39<00:00, 99.80s/it]
  8%|▊         | 415/5198 [12:14:09<126:42:24, 95.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 07:39:15,744] [INFO] [logging.py:96:log_dist] [Rank 0] step=409, skipped=0, lr=[1.9909693156791736e-05], mom=[(0.9, 0.999)]
steps: 409 loss: 0.6295 iter time (s): 99.310 samples/sec: 1.289

100%|██████████| 1/1 [01:40<00:00, 100.10s/it][A100%|██████████| 1/1 [01:40<00:00, 100.10s/it]
  8%|▊         | 415/5198 [12:14:10<126:45:49, 95.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.02s/it][A100%|██████████| 1/1 [01:40<00:00, 100.02s/it]
  8%|▊         | 415/5198 [12:14:10<126:45:05, 95.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.14s/it][A100%|██████████| 1/1 [01:40<00:00, 100.14s/it]
  8%|▊         | 415/5198 [12:14:10<126:47:47, 95.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.08s/it][A100%|██████████| 1/1 [01:40<00:00, 100.08s/it]
  8%|▊         | 415/5198 [12:14:10<126:46:32, 95.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.15s/it][A100%|██████████| 1/1 [01:40<00:00, 100.15s/it]
  8%|▊         | 415/5198 [12:14:11<126:47:48, 95.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.12s/it][A100%|██████████| 1/1 [01:40<00:00, 100.12s/it]
  8%|▊         | 415/5198 [12:14:13<126:47:07, 95.43s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_25

100%|██████████| 1/1 [01:40<00:00, 100.13s/it][A100%|██████████| 1/1 [01:40<00:00, 100.13s/it]
  8%|▊         | 415/5198 [12:14:11<126:47:27, 95.43s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.04s/it][A100%|██████████| 1/1 [01:58<00:00, 118.04s/it]
  8%|▊         | 416/5198 [12:16:07<135:45:23, 102.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 07:41:14,095] [INFO] [logging.py:96:log_dist] [Rank 0] step=410, skipped=0, lr=[1.9908932107561017e-05], mom=[(0.9, 0.999)]
steps: 410 loss: 0.7847 iter time (s): 117.818 samples/sec: 1.086

100%|██████████| 1/1 [01:58<00:00, 118.94s/it][A100%|██████████| 1/1 [01:58<00:00, 118.94s/it]
  8%|▊         | 416/5198 [12:16:09<136:07:06, 102.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.97s/it][A100%|██████████| 1/1 [01:58<00:00, 118.97s/it]
  8%|▊         | 416/5198 [12:16:09<136:07:10, 102.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.96s/it][A100%|██████████| 1/1 [01:58<00:00, 118.96s/it]
  8%|▊         | 416/5198 [12:16:09<136:08:49, 102.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.97s/it][A100%|██████████| 1/1 [01:58<00:00, 118.97s/it]
  8%|▊         | 416/5198 [12:16:09<136:08:08, 102.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.00s/it][A100%|██████████| 1/1 [01:59<00:00, 119.00s/it]
  8%|▊         | 416/5198 [12:16:10<136:09:54, 102.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.99s/it][A100%|██████████| 1/1 [01:58<00:00, 118.99s/it]
  8%|▊         | 416/5198 [12:16:12<136:09:00, 102.50s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_390

100%|██████████| 1/1 [01:58<00:00, 118.98s/it][A100%|██████████| 1/1 [01:58<00:00, 118.98s/it]
  8%|▊         | 416/5198 [12:16:10<136:09:07, 102.50s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.65s/it][A100%|██████████| 1/1 [01:32<00:00, 92.65s/it]
  8%|▊         | 417/5198 [12:17:40<132:01:59, 99.42s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 07:42:46,606] [INFO] [logging.py:96:log_dist] [Rank 0] step=411, skipped=0, lr=[1.9908167879619734e-05], mom=[(0.9, 0.999)]
steps: 411 loss: 0.5849 iter time (s): 91.118 samples/sec: 1.405

100%|██████████| 1/1 [01:32<00:00, 92.15s/it][A100%|██████████| 1/1 [01:32<00:00, 92.15s/it]
  8%|▊         | 417/5198 [12:17:41<131:59:10, 99.38s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.09s/it][A100%|██████████| 1/1 [01:32<00:00, 92.09s/it]
  8%|▊         | 417/5198 [12:17:41<131:58:05, 99.37s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.96s/it][A100%|██████████| 1/1 [01:31<00:00, 91.96s/it]
  8%|▊         | 417/5198 [12:17:41<131:55:31, 99.34s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.07s/it][A100%|██████████| 1/1 [01:32<00:00, 92.07s/it]
  8%|▊         | 417/5198 [12:17:41<131:57:35, 99.36s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.95s/it][A100%|██████████| 1/1 [01:31<00:00, 91.95s/it]
  8%|▊         | 417/5198 [12:17:42<131:56:03, 99.34s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.99s/it][A100%|██████████| 1/1 [01:31<00:00, 91.99s/it]
  8%|▊         | 417/5198 [12:17:42<131:56:22, 99.35s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.00s/it][A100%|██████████| 1/1 [01:32<00:00, 92.00s/it]
  8%|▊         | 417/5198 [12:17:44<131:56:33, 99.35s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_391
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.86s/it][A100%|██████████| 1/1 [01:52<00:00, 112.86s/it]
  8%|▊         | 418/5198 [12:19:33<137:28:16, 103.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 07:44:40,299] [INFO] [logging.py:96:log_dist] [Rank 0] step=412, skipped=0, lr=[1.990740047321307e-05], mom=[(0.9, 0.999)]
steps: 412 loss: 0.5815 iter time (s): 112.743 samples/sec: 1.135

100%|██████████| 1/1 [01:53<00:00, 113.52s/it][A100%|██████████| 1/1 [01:53<00:00, 113.52s/it]
  8%|▊         | 418/5198 [12:19:34<137:35:42, 103.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.52s/it][A100%|██████████| 1/1 [01:53<00:00, 113.52s/it]
  8%|▊         | 418/5198 [12:19:35<137:34:55, 103.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.61s/it][A100%|██████████| 1/1 [01:53<00:00, 113.61s/it]
  8%|▊         | 418/5198 [12:19:35<137:35:07, 103.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.50s/it][A100%|██████████| 1/1 [01:53<00:00, 113.50s/it]
  8%|▊         | 418/5198 [12:19:35<137:34:02, 103.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.52s/it][A100%|██████████| 1/1 [01:53<00:00, 113.52s/it]
  8%|▊         | 418/5198 [12:19:35<137:33:29, 103.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.53s/it][A100%|██████████| 1/1 [01:53<00:00, 113.53s/it]
  8%|▊         | 418/5198 [12:19:37<137:33:56, 103.61s/it]Shard 418 in [76, 158, 182, 242, 293, 363, 418, 421, 752, 814, 842, 991, 1266, 1366, 1425, 1464, 1574, 1728, 2166, 2441, 2563, 2739, 2854, 2894, 3089, 3181, 3395, 3576, 3831, 4300, 4589, 4947, 4950]: file /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_392 skipped to avoid exceeding cuda memory
Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_393
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.54s/it][A100%|██████████| 1/1 [01:53<00:00, 113.55s/it]
  8%|▊         | 418/5198 [12:19:35<137:34:12, 103.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.35s/it][A100%|██████████| 1/1 [01:29<00:00, 89.35s/it]
  8%|▊         | 420/5198 [12:21:03<101:25:29, 76.42s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 07:46:09,219] [INFO] [logging.py:96:log_dist] [Rank 0] step=413, skipped=0, lr=[1.990662988858723e-05], mom=[(0.9, 0.999)]
steps: 413 loss: 0.5541 iter time (s): 88.128 samples/sec: 1.452

100%|██████████| 1/1 [01:28<00:00, 88.86s/it][A100%|██████████| 1/1 [01:28<00:00, 88.86s/it]
  8%|▊         | 420/5198 [12:21:03<101:16:36, 76.31s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.11s/it][A100%|██████████| 1/1 [01:29<00:00, 89.11s/it]
  8%|▊         | 420/5198 [12:21:04<101:20:50, 76.36s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.08s/it][A100%|██████████| 1/1 [01:29<00:00, 89.08s/it]
  8%|▊         | 420/5198 [12:21:04<101:19:48, 76.35s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.19s/it][A100%|██████████| 1/1 [01:29<00:00, 89.20s/it]
  8%|▊         | 420/5198 [12:21:04<101:22:30, 76.38s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.17s/it][A100%|██████████| 1/1 [01:29<00:00, 89.17s/it]
  8%|▊         | 420/5198 [12:21:04<101:21:10, 76.36s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.51s/it][A100%|██████████| 1/1 [01:29<00:00, 89.51s/it]
  8%|▊         | 420/5198 [12:21:05<101:27:47, 76.45s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.64s/it][A100%|██████████| 1/1 [01:29<00:00, 89.64s/it]
  8%|▊         | 420/5198 [12:21:07<101:29:57, 76.48s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_394
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.82s/it][A100%|██████████| 1/1 [01:37<00:00, 97.82s/it]
  8%|▊         | 421/5198 [12:22:41<108:30:41, 81.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 07:47:47,504] [INFO] [logging.py:96:log_dist] [Rank 0] step=414, skipped=0, lr=[1.9905856125989437e-05], mom=[(0.9, 0.999)]
steps: 414 loss: 0.5770 iter time (s): 96.763 samples/sec: 1.323

100%|██████████| 1/1 [01:38<00:00, 98.19s/it][A100%|██████████| 1/1 [01:38<00:00, 98.19s/it]
  8%|▊         | 421/5198 [12:22:42<108:27:42, 81.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.14s/it][A100%|██████████| 1/1 [01:38<00:00, 98.14s/it]
  8%|▊         | 421/5198 [12:22:42<108:29:44, 81.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.91s/it][A100%|██████████| 1/1 [01:37<00:00, 97.91s/it]
  8%|▊         | 421/5198 [12:22:42<108:26:40, 81.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.08s/it][A100%|██████████| 1/1 [01:38<00:00, 98.08s/it]
  8%|▊         | 421/5198 [12:22:42<108:28:17, 81.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.03s/it][A100%|██████████| 1/1 [01:38<00:00, 98.03s/it]
  8%|▊         | 421/5198 [12:22:42<108:28:00, 81.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.55s/it][A100%|██████████| 1/1 [01:37<00:00, 97.55s/it]
  8%|▊         | 421/5198 [12:22:45<108:24:51, 81.70s/it]Shard 421 in [76, 158, 182, 242, 293, 363, 418, 421, 752, 814, 842, 991, 1266, 1366, 1425, 1464, 1574, 1728, 2166, 2441, 2563, 2739, 2854, 2894, 3089, 3181, 3395, 3576, 3831, 4300, 4589, 4947, 4950]: file /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_395 skipped to avoid exceeding cuda memory
Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_396

100%|██████████| 1/1 [01:37<00:00, 97.67s/it][A100%|██████████| 1/1 [01:37<00:00, 97.67s/it]
  8%|▊         | 421/5198 [12:22:42<108:25:39, 81.71s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.79s/it][A100%|██████████| 1/1 [01:24<00:00, 84.79s/it]
  8%|▊         | 423/5198 [12:24:06<86:51:24, 65.48s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 07:49:11,646] [INFO] [logging.py:96:log_dist] [Rank 0] step=415, skipped=0, lr=[1.990507918566793e-05], mom=[(0.9, 0.999)]
steps: 415 loss: 0.6230 iter time (s): 83.352 samples/sec: 1.536

100%|██████████| 1/1 [01:24<00:00, 84.26s/it][A100%|██████████| 1/1 [01:24<00:00, 84.26s/it]
  8%|▊         | 423/5198 [12:24:06<86:38:08, 65.32s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.19s/it][A100%|██████████| 1/1 [01:24<00:00, 84.19s/it]
  8%|▊         | 423/5198 [12:24:06<86:38:11, 65.32s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.27s/it][A100%|██████████| 1/1 [01:24<00:00, 84.27s/it]
  8%|▊         | 423/5198 [12:24:06<86:37:37, 65.31s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.19s/it][A100%|██████████| 1/1 [01:24<00:00, 84.19s/it]
  8%|▊         | 423/5198 [12:24:06<86:37:20, 65.31s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.22s/it][A100%|██████████| 1/1 [01:24<00:00, 84.22s/it]
  8%|▊         | 423/5198 [12:24:07<86:37:38, 65.31s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.23s/it][A100%|██████████| 1/1 [01:24<00:00, 84.23s/it]
  8%|▊         | 423/5198 [12:24:07<86:36:20, 65.29s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.27s/it][A100%|██████████| 1/1 [01:24<00:00, 84.27s/it]
  8%|▊         | 423/5198 [12:24:09<86:36:31, 65.30s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_397
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.62s/it][A100%|██████████| 1/1 [01:40<00:00, 100.62s/it]
  8%|▊         | 424/5198 [12:25:47<97:33:32, 73.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 07:50:53,402] [INFO] [logging.py:96:log_dist] [Rank 0] step=416, skipped=0, lr=[1.990429906787197e-05], mom=[(0.9, 0.999)]
steps: 416 loss: 0.5682 iter time (s): 100.832 samples/sec: 1.269

100%|██████████| 1/1 [01:41<00:00, 101.70s/it][A100%|██████████| 1/1 [01:41<00:00, 101.70s/it]
  8%|▊         | 424/5198 [12:25:48<97:38:47, 73.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.63s/it][A100%|██████████| 1/1 [01:41<00:00, 101.63s/it]
  8%|▊         | 424/5198 [12:25:48<97:37:30, 73.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.63s/it][A100%|██████████| 1/1 [01:41<00:00, 101.63s/it]
  8%|▊         | 424/5198 [12:25:48<97:36:58, 73.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.67s/it][A100%|██████████| 1/1 [01:41<00:00, 101.67s/it]
  8%|▊         | 424/5198 [12:25:48<97:37:33, 73.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.60s/it][A100%|██████████| 1/1 [01:41<00:00, 101.60s/it]
  8%|▊         | 424/5198 [12:25:48<97:36:33, 73.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.64s/it][A100%|██████████| 1/1 [01:41<00:00, 101.64s/it]
  8%|▊         | 424/5198 [12:25:48<97:36:15, 73.60s/it]
100%|██████████| 1/1 [01:41<00:00, 101.61s/it][A100%|██████████| 1/1 [01:41<00:00, 101.61s/it]
  8%|▊         | 424/5198 [12:25:50<97:35:50, 73.60s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_398

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.55s/it][A100%|██████████| 1/1 [01:49<00:00, 109.55s/it]
  8%|▊         | 425/5198 [12:27:37<109:19:50, 82.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 07:52:43,357] [INFO] [logging.py:96:log_dist] [Rank 0] step=417, skipped=0, lr=[1.9903515772851843e-05], mom=[(0.9, 0.999)]
steps: 417 loss: 0.5942 iter time (s): 109.168 samples/sec: 1.173

100%|██████████| 1/1 [01:49<00:00, 109.85s/it][A100%|██████████| 1/1 [01:49<00:00, 109.85s/it]
  8%|▊         | 425/5198 [12:27:37<109:26:44, 82.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.89s/it][A100%|██████████| 1/1 [01:49<00:00, 109.89s/it]
  8%|▊         | 425/5198 [12:27:38<109:26:37, 82.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.03s/it][A100%|██████████| 1/1 [01:50<00:00, 110.03s/it]
  8%|▊         | 425/5198 [12:27:38<109:28:58, 82.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.00s/it][A100%|██████████| 1/1 [01:50<00:00, 110.01s/it]
  8%|▊         | 425/5198 [12:27:38<109:28:06, 82.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.05s/it][A100%|██████████| 1/1 [01:50<00:00, 110.05s/it]
  8%|▊         | 425/5198 [12:27:38<109:29:39, 82.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.01s/it][A100%|██████████| 1/1 [01:50<00:00, 110.01s/it]
  8%|▊         | 425/5198 [12:27:38<109:27:56, 82.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.02s/it][A100%|██████████| 1/1 [01:50<00:00, 110.02s/it]
  8%|▊         | 425/5198 [12:27:41<109:27:49, 82.56s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_399
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.50s/it][A100%|██████████| 1/1 [01:54<00:00, 114.50s/it]
  8%|▊         | 426/5198 [12:29:31<120:24:20, 90.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 07:54:38,163] [INFO] [logging.py:96:log_dist] [Rank 0] step=418, skipped=0, lr=[1.9902729300858847e-05], mom=[(0.9, 0.999)]
steps: 418 loss: 0.6390 iter time (s): 113.946 samples/sec: 1.123

100%|██████████| 1/1 [01:54<00:00, 114.89s/it][A100%|██████████| 1/1 [01:54<00:00, 114.89s/it]
  8%|▊         | 426/5198 [12:29:32<120:34:46, 90.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.89s/it][A100%|██████████| 1/1 [01:54<00:00, 114.89s/it]
  8%|▊         | 426/5198 [12:29:32<120:34:48, 90.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.73s/it][A100%|██████████| 1/1 [01:54<00:00, 114.73s/it]
  8%|▊         | 426/5198 [12:29:33<120:32:59, 90.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.79s/it][A100%|██████████| 1/1 [01:54<00:00, 114.79s/it]
  8%|▊         | 426/5198 [12:29:33<120:33:40, 90.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.79s/it][A100%|██████████| 1/1 [01:54<00:00, 114.79s/it]
  8%|▊         | 426/5198 [12:29:33<120:34:46, 90.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.76s/it][A100%|██████████| 1/1 [01:54<00:00, 114.76s/it]
  8%|▊         | 426/5198 [12:29:33<120:32:43, 90.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.76s/it][A100%|██████████| 1/1 [01:54<00:00, 114.76s/it]
  8%|▊         | 426/5198 [12:29:35<120:32:39, 90.94s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_400
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.47s/it][A100%|██████████| 1/1 [01:52<00:00, 112.47s/it]
  8%|▊         | 427/5198 [12:31:24<128:12:11, 96.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 07:56:30,696] [INFO] [logging.py:96:log_dist] [Rank 0] step=419, skipped=0, lr=[1.9901939652145303e-05], mom=[(0.9, 0.999)]
steps: 419 loss: 0.5837 iter time (s): 111.713 samples/sec: 1.146

100%|██████████| 1/1 [01:52<00:00, 112.56s/it][A100%|██████████| 1/1 [01:52<00:00, 112.56s/it]
  8%|▊         | 427/5198 [12:31:25<128:18:55, 96.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.52s/it][A100%|██████████| 1/1 [01:52<00:00, 112.52s/it]
  8%|▊         | 427/5198 [12:31:25<128:17:45, 96.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.54s/it][A100%|██████████| 1/1 [01:52<00:00, 112.54s/it]
  8%|▊         | 427/5198 [12:31:25<128:16:50, 96.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.53s/it][A100%|██████████| 1/1 [01:52<00:00, 112.53s/it]
  8%|▊         | 427/5198 [12:31:25<128:18:01, 96.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.62s/it][A100%|██████████| 1/1 [01:52<00:00, 112.62s/it]
  8%|▊         | 427/5198 [12:31:26<128:19:02, 96.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.57s/it][A100%|██████████| 1/1 [01:52<00:00, 112.57s/it]
  8%|▊         | 427/5198 [12:31:26<128:17:22, 96.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.58s/it][A100%|██████████| 1/1 [01:52<00:00, 112.58s/it]
  8%|▊         | 427/5198 [12:31:28<128:17:35, 96.80s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_401
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.60s/it][A100%|██████████| 1/1 [01:46<00:00, 106.60s/it]
  8%|▊         | 428/5198 [12:33:11<131:51:42, 99.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 07:58:17,243] [INFO] [logging.py:96:log_dist] [Rank 0] step=420, skipped=0, lr=[1.9901146826964545e-05], mom=[(0.9, 0.999)]
steps: 420 loss: 0.5682 iter time (s): 105.670 samples/sec: 1.211

100%|██████████| 1/1 [01:46<00:00, 106.44s/it][A100%|██████████| 1/1 [01:46<00:00, 106.44s/it]
  8%|▊         | 428/5198 [12:33:11<131:50:52, 99.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.53s/it][A100%|██████████| 1/1 [01:46<00:00, 106.53s/it]
  8%|▊         | 428/5198 [12:33:12<131:52:03, 99.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.53s/it][A100%|██████████| 1/1 [01:46<00:00, 106.53s/it]
  8%|▊         | 428/5198 [12:33:12<131:51:24, 99.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.45s/it][A100%|██████████| 1/1 [01:46<00:00, 106.45s/it]
  8%|▊         | 428/5198 [12:33:12<131:50:32, 99.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.50s/it][A100%|██████████| 1/1 [01:46<00:00, 106.50s/it]
  8%|▊         | 428/5198 [12:33:12<131:52:19, 99.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.51s/it][A100%|██████████| 1/1 [01:46<00:00, 106.51s/it]
  8%|▊         | 428/5198 [12:33:14<131:51:27, 99.52s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_402

100%|██████████| 1/1 [01:46<00:00, 106.54s/it][A100%|██████████| 1/1 [01:46<00:00, 106.54s/it]
  8%|▊         | 428/5198 [12:33:12<131:51:57, 99.52s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.26s/it][A100%|██████████| 1/1 [01:29<00:00, 89.26s/it]
  8%|▊         | 429/5198 [12:34:40<128:01:19, 96.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 07:59:46,182] [INFO] [logging.py:96:log_dist] [Rank 0] step=421, skipped=0, lr=[1.9900350825570938e-05], mom=[(0.9, 0.999)]
steps: 421 loss: 0.5841 iter time (s): 88.093 samples/sec: 1.453

100%|██████████| 1/1 [01:29<00:00, 89.03s/it][A100%|██████████| 1/1 [01:29<00:00, 89.03s/it]
  8%|▊         | 429/5198 [12:34:40<127:52:00, 96.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.87s/it][A100%|██████████| 1/1 [01:28<00:00, 88.87s/it]
  8%|▊         | 429/5198 [12:34:40<127:49:20, 96.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.89s/it][A100%|██████████| 1/1 [01:28<00:00, 88.89s/it]
  8%|▊         | 429/5198 [12:34:41<127:49:13, 96.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.97s/it][A100%|██████████| 1/1 [01:28<00:00, 88.97s/it]
  8%|▊         | 429/5198 [12:34:41<127:50:45, 96.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.89s/it][A100%|██████████| 1/1 [01:28<00:00, 88.90s/it]
  8%|▊         | 429/5198 [12:34:41<127:49:59, 96.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.90s/it][A100%|██████████| 1/1 [01:28<00:00, 88.90s/it]
  8%|▊         | 429/5198 [12:34:41<127:49:45, 96.50s/it]
100%|██████████| 1/1 [01:28<00:00, 88.90s/it][A100%|██████████| 1/1 [01:28<00:00, 88.90s/it]
  8%|▊         | 429/5198 [12:34:43<127:49:26, 96.49s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_403
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.07s/it][A100%|██████████| 1/1 [01:39<00:00, 99.07s/it]
  8%|▊         | 430/5198 [12:36:19<128:59:06, 97.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 08:01:25,707] [INFO] [logging.py:96:log_dist] [Rank 0] step=422, skipped=0, lr=[1.989955164821985e-05], mom=[(0.9, 0.999)]
steps: 422 loss: 0.5647 iter time (s): 98.712 samples/sec: 1.297

100%|██████████| 1/1 [01:39<00:00, 99.42s/it][A100%|██████████| 1/1 [01:39<00:00, 99.42s/it]
  8%|▊         | 430/5198 [12:36:20<128:57:19, 97.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.49s/it][A100%|██████████| 1/1 [01:39<00:00, 99.49s/it]
  8%|▊         | 430/5198 [12:36:20<128:57:01, 97.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.59s/it][A100%|██████████| 1/1 [01:39<00:00, 99.59s/it]
  8%|▊         | 430/5198 [12:36:20<128:59:20, 97.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.49s/it][A100%|██████████| 1/1 [01:39<00:00, 99.49s/it]
  8%|▊         | 430/5198 [12:36:20<128:57:59, 97.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.50s/it][A100%|██████████| 1/1 [01:39<00:00, 99.50s/it]
  8%|▊         | 430/5198 [12:36:21<128:57:41, 97.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.54s/it][A100%|██████████| 1/1 [01:39<00:00, 99.54s/it]
  8%|▊         | 430/5198 [12:36:21<128:58:14, 97.38s/it]
100%|██████████| 1/1 [01:39<00:00, 99.54s/it][A100%|██████████| 1/1 [01:39<00:00, 99.54s/it]
  8%|▊         | 430/5198 [12:36:23<128:58:03, 97.37s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_404

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.59s/it][A100%|██████████| 1/1 [01:31<00:00, 91.59s/it]
  8%|▊         | 431/5198 [12:37:51<126:45:42, 95.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 08:02:57,213] [INFO] [logging.py:96:log_dist] [Rank 0] step=423, skipped=0, lr=[1.989874929516769e-05], mom=[(0.9, 0.999)]
steps: 423 loss: 0.5725 iter time (s): 90.672 samples/sec: 1.412

100%|██████████| 1/1 [01:31<00:00, 91.57s/it][A100%|██████████| 1/1 [01:31<00:00, 91.57s/it]
  8%|▊         | 431/5198 [12:37:51<126:41:14, 95.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.52s/it][A100%|██████████| 1/1 [01:31<00:00, 91.52s/it]
  8%|▊         | 431/5198 [12:37:51<126:39:53, 95.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.41s/it][A100%|██████████| 1/1 [01:31<00:00, 91.41s/it]
  8%|▊         | 431/5198 [12:37:52<126:39:06, 95.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.43s/it][A100%|██████████| 1/1 [01:31<00:00, 91.43s/it]
  8%|▊         | 431/5198 [12:37:52<126:38:37, 95.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.47s/it][A100%|██████████| 1/1 [01:31<00:00, 91.47s/it]
  8%|▊         | 431/5198 [12:37:52<126:39:12, 95.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.45s/it][A100%|██████████| 1/1 [01:31<00:00, 91.45s/it]
  8%|▊         | 431/5198 [12:37:52<126:39:00, 95.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.47s/it][A100%|██████████| 1/1 [01:31<00:00, 91.47s/it]
  8%|▊         | 431/5198 [12:37:54<126:39:18, 95.65s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_26
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:57<00:00, 117.81s/it][A100%|██████████| 1/1 [01:57<00:00, 117.81s/it]
  8%|▊         | 432/5198 [12:39:49<135:24:10, 102.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 08:04:55,624] [INFO] [logging.py:96:log_dist] [Rank 0] step=424, skipped=0, lr=[1.9897943766671857e-05], mom=[(0.9, 0.999)]
steps: 424 loss: 0.7950 iter time (s): 117.835 samples/sec: 1.086

100%|██████████| 1/1 [01:58<00:00, 118.63s/it][A100%|██████████| 1/1 [01:58<00:00, 118.63s/it]
  8%|▊         | 432/5198 [12:39:50<135:37:15, 102.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.71s/it][A100%|██████████| 1/1 [01:58<00:00, 118.71s/it]
  8%|▊         | 432/5198 [12:39:50<135:38:17, 102.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.79s/it][A100%|██████████| 1/1 [01:58<00:00, 118.79s/it]
  8%|▊         | 432/5198 [12:39:51<135:39:27, 102.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.86s/it][A100%|██████████| 1/1 [01:58<00:00, 118.86s/it]
  8%|▊         | 432/5198 [12:39:51<135:40:43, 102.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.85s/it][A100%|██████████| 1/1 [01:58<00:00, 118.85s/it]
  8%|▊         | 432/5198 [12:39:51<135:41:00, 102.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.81s/it][A100%|██████████| 1/1 [01:58<00:00, 118.81s/it]
  8%|▊         | 432/5198 [12:39:53<135:39:53, 102.47s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_405
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.84s/it][A100%|██████████| 1/1 [01:58<00:00, 118.84s/it]
  8%|▊         | 432/5198 [12:39:51<135:40:36, 102.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.57s/it][A100%|██████████| 1/1 [01:54<00:00, 114.57s/it]
  8%|▊         | 433/5198 [12:41:44<140:14:53, 105.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 08:06:50,486] [INFO] [logging.py:96:log_dist] [Rank 0] step=425, skipped=0, lr=[1.9897135062990803e-05], mom=[(0.9, 0.999)]
steps: 425 loss: 0.6104 iter time (s): 113.668 samples/sec: 1.126

100%|██████████| 1/1 [01:54<00:00, 114.61s/it][A100%|██████████| 1/1 [01:54<00:00, 114.61s/it]
  8%|▊         | 433/5198 [12:41:45<140:22:14, 106.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.49s/it][A100%|██████████| 1/1 [01:54<00:00, 114.49s/it]
  8%|▊         | 433/5198 [12:41:45<140:19:59, 106.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.48s/it][A100%|██████████| 1/1 [01:54<00:00, 114.49s/it]
  8%|▊         | 433/5198 [12:41:45<140:20:46, 106.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.46s/it][A100%|██████████| 1/1 [01:54<00:00, 114.46s/it]
  8%|▊         | 433/5198 [12:41:45<140:21:13, 106.04s/it]
100%|██████████| 1/1 [01:54<00:00, 114.52s/it][A100%|██████████| 1/1 [01:54<00:00, 114.52s/it]
  8%|▊         | 433/5198 [12:41:45<140:22:27, 106.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.45s/it][A100%|██████████| 1/1 [01:54<00:00, 114.45s/it]
  8%|▊         | 433/5198 [12:41:45<140:20:42, 106.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.49s/it][A100%|██████████| 1/1 [01:54<00:00, 114.49s/it]
  8%|▊         | 433/5198 [12:41:48<140:21:02, 106.04s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_406
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.77s/it][A100%|██████████| 1/1 [01:36<00:00, 96.77s/it]
  8%|▊         | 434/5198 [12:43:21<136:44:17, 103.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 08:08:26,761] [INFO] [logging.py:96:log_dist] [Rank 0] step=426, skipped=0, lr=[1.9896323184383962e-05], mom=[(0.9, 0.999)]
steps: 426 loss: 0.5768 iter time (s): 95.435 samples/sec: 1.341

100%|██████████| 1/1 [01:36<00:00, 96.32s/it][A100%|██████████| 1/1 [01:36<00:00, 96.32s/it]
  8%|▊         | 434/5198 [12:43:21<136:31:07, 103.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.42s/it][A100%|██████████| 1/1 [01:36<00:00, 96.42s/it]
  8%|▊         | 434/5198 [12:43:21<136:31:48, 103.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.34s/it][A100%|██████████| 1/1 [01:36<00:00, 96.34s/it]
  8%|▊         | 434/5198 [12:43:21<136:30:39, 103.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.28s/it][A100%|██████████| 1/1 [01:36<00:00, 96.28s/it]
  8%|▊         | 434/5198 [12:43:22<136:30:09, 103.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.31s/it][A100%|██████████| 1/1 [01:36<00:00, 96.31s/it]
  8%|▊         | 434/5198 [12:43:22<136:29:58, 103.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.33s/it][A100%|██████████| 1/1 [01:36<00:00, 96.33s/it]
  8%|▊         | 434/5198 [12:43:22<136:30:06, 103.15s/it]
100%|██████████| 1/1 [01:36<00:00, 96.32s/it][A100%|██████████| 1/1 [01:36<00:00, 96.32s/it]
  8%|▊         | 434/5198 [12:43:24<136:29:59, 103.15s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_407
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.69s/it][A100%|██████████| 1/1 [01:54<00:00, 114.70s/it]
  8%|▊         | 435/5198 [12:45:16<141:16:06, 106.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 08:10:22,058] [INFO] [logging.py:96:log_dist] [Rank 0] step=427, skipped=0, lr=[1.9895508131111815e-05], mom=[(0.9, 0.999)]
steps: 427 loss: 0.5747 iter time (s): 114.507 samples/sec: 1.118

100%|██████████| 1/1 [01:55<00:00, 115.25s/it][A100%|██████████| 1/1 [01:55<00:00, 115.25s/it]
  8%|▊         | 435/5198 [12:45:16<141:15:48, 106.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.24s/it][A100%|██████████| 1/1 [01:55<00:00, 115.24s/it]
  8%|▊         | 435/5198 [12:45:16<141:16:08, 106.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.19s/it][A100%|██████████| 1/1 [01:55<00:00, 115.19s/it]
  8%|▊         | 435/5198 [12:45:17<141:13:55, 106.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.21s/it][A100%|██████████| 1/1 [01:55<00:00, 115.21s/it]
  8%|▊         | 435/5198 [12:45:17<141:14:00, 106.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.21s/it][A100%|██████████| 1/1 [01:55<00:00, 115.21s/it]
  8%|▊         | 435/5198 [12:45:17<141:14:02, 106.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.22s/it][A100%|██████████| 1/1 [01:55<00:00, 115.23s/it]
  8%|▊         | 435/5198 [12:45:17<141:14:21, 106.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.26s/it][A100%|██████████| 1/1 [01:55<00:00, 115.26s/it]
  8%|▊         | 435/5198 [12:45:19<141:15:01, 106.76s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_408
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.97s/it][A100%|██████████| 1/1 [01:28<00:00, 88.97s/it]
  8%|▊         | 436/5198 [12:46:45<134:21:15, 101.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 08:11:50,896] [INFO] [logging.py:96:log_dist] [Rank 0] step=428, skipped=0, lr=[1.9894689903435852e-05], mom=[(0.9, 0.999)]
steps: 428 loss: 0.5448 iter time (s): 87.988 samples/sec: 1.455

100%|██████████| 1/1 [01:28<00:00, 88.86s/it][A100%|██████████| 1/1 [01:28<00:00, 88.86s/it]
  8%|▊         | 436/5198 [12:46:45<134:09:37, 101.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.87s/it][A100%|██████████| 1/1 [01:28<00:00, 88.87s/it]
  8%|▊         | 436/5198 [12:46:45<134:10:06, 101.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.87s/it][A100%|██████████| 1/1 [01:28<00:00, 88.87s/it]
  8%|▊         | 436/5198 [12:46:46<134:08:40, 101.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.83s/it][A100%|██████████| 1/1 [01:28<00:00, 88.83s/it]
  8%|▊         | 436/5198 [12:46:46<134:07:34, 101.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.86s/it][A100%|██████████| 1/1 [01:28<00:00, 88.86s/it]
  8%|▊         | 436/5198 [12:46:46<134:08:16, 101.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.83s/it][A100%|██████████| 1/1 [01:28<00:00, 88.83s/it]
  8%|▊         | 436/5198 [12:46:46<134:07:51, 101.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.81s/it][A100%|██████████| 1/1 [01:28<00:00, 88.81s/it]
  8%|▊         | 436/5198 [12:46:48<134:07:44, 101.40s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_409
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.66s/it][A100%|██████████| 1/1 [01:28<00:00, 88.66s/it]
  8%|▊         | 437/5198 [12:48:14<129:17:19, 97.76s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 08:13:19,961] [INFO] [logging.py:96:log_dist] [Rank 0] step=429, skipped=0, lr=[1.9893868501618575e-05], mom=[(0.9, 0.999)]
steps: 429 loss: 0.5806 iter time (s): 88.237 samples/sec: 1.451

100%|██████████| 1/1 [01:29<00:00, 89.00s/it][A100%|██████████| 1/1 [01:29<00:00, 89.00s/it]
  8%|▊         | 437/5198 [12:48:14<129:13:19, 97.71s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.93s/it][A100%|██████████| 1/1 [01:28<00:00, 88.93s/it]
  8%|▊         | 437/5198 [12:48:14<129:12:05, 97.69s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.05s/it][A100%|██████████| 1/1 [01:29<00:00, 89.05s/it]
  8%|▊         | 437/5198 [12:48:15<129:13:52, 97.72s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.02s/it][A100%|██████████| 1/1 [01:29<00:00, 89.02s/it]
  8%|▊         | 437/5198 [12:48:15<129:12:20, 97.70s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.02s/it][A100%|██████████| 1/1 [01:29<00:00, 89.02s/it]
  8%|▊         | 437/5198 [12:48:15<129:12:45, 97.70s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.04s/it][A100%|██████████| 1/1 [01:29<00:00, 89.04s/it]
  8%|▊         | 437/5198 [12:48:15<129:12:55, 97.71s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.04s/it][A100%|██████████| 1/1 [01:29<00:00, 89.04s/it]
  8%|▊         | 437/5198 [12:48:17<129:12:49, 97.70s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_410
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.77s/it][A100%|██████████| 1/1 [01:37<00:00, 97.77s/it]
  8%|▊         | 438/5198 [12:49:52<129:20:41, 97.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 08:14:58,202] [INFO] [logging.py:96:log_dist] [Rank 0] step=430, skipped=0, lr=[1.989304392592351e-05], mom=[(0.9, 0.999)]
steps: 430 loss: 0.6042 iter time (s): 97.435 samples/sec: 1.314

100%|██████████| 1/1 [01:38<00:00, 98.23s/it][A100%|██████████| 1/1 [01:38<00:00, 98.23s/it]
  8%|▊         | 438/5198 [12:49:52<129:24:11, 97.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.26s/it][A100%|██████████| 1/1 [01:38<00:00, 98.26s/it]
  8%|▊         | 438/5198 [12:49:52<129:24:03, 97.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.25s/it][A100%|██████████| 1/1 [01:38<00:00, 98.25s/it]
  8%|▊         | 438/5198 [12:49:53<129:25:03, 97.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.20s/it][A100%|██████████| 1/1 [01:38<00:00, 98.20s/it]
  8%|▊         | 438/5198 [12:49:53<129:23:08, 97.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.30s/it][A100%|██████████| 1/1 [01:38<00:00, 98.30s/it]
  8%|▊         | 438/5198 [12:49:53<129:25:08, 97.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.23s/it][A100%|██████████| 1/1 [01:38<00:00, 98.23s/it]
  8%|▊         | 438/5198 [12:49:53<129:23:55, 97.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.25s/it][A100%|██████████| 1/1 [01:38<00:00, 98.25s/it]
  8%|▊         | 438/5198 [12:49:55<129:24:12, 97.87s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_411
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.63s/it][A100%|██████████| 1/1 [01:37<00:00, 97.63s/it]
  8%|▊         | 439/5198 [12:51:30<129:19:05, 97.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 08:16:36,011] [INFO] [logging.py:96:log_dist] [Rank 0] step=431, skipped=0, lr=[1.989221617661521e-05], mom=[(0.9, 0.999)]
steps: 431 loss: 0.5767 iter time (s): 96.990 samples/sec: 1.320

100%|██████████| 1/1 [01:37<00:00, 97.77s/it][A100%|██████████| 1/1 [01:37<00:00, 97.77s/it]
  8%|▊         | 439/5198 [12:51:30<129:20:27, 97.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.82s/it][A100%|██████████| 1/1 [01:37<00:00, 97.82s/it]
  8%|▊         | 439/5198 [12:51:30<129:21:37, 97.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.75s/it][A100%|██████████| 1/1 [01:37<00:00, 97.75s/it]
  8%|▊         | 439/5198 [12:51:31<129:20:29, 97.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.78s/it][A100%|██████████| 1/1 [01:37<00:00, 97.78s/it]
  8%|▊         | 439/5198 [12:51:31<129:21:20, 97.85s/it]
100%|██████████| 1/1 [01:37<00:00, 97.82s/it][A100%|██████████| 1/1 [01:37<00:00, 97.82s/it]
  8%|▊         | 439/5198 [12:51:31<129:20:56, 97.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.79s/it][A100%|██████████| 1/1 [01:37<00:00, 97.79s/it]
  8%|▊         | 439/5198 [12:51:31<129:20:47, 97.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.79s/it][A100%|██████████| 1/1 [01:37<00:00, 97.79s/it]
  8%|▊         | 439/5198 [12:51:33<129:20:49, 97.85s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_412
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.92s/it][A100%|██████████| 1/1 [01:26<00:00, 86.92s/it]
  8%|▊         | 440/5198 [12:52:57<125:02:14, 94.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 08:18:02,777] [INFO] [logging.py:96:log_dist] [Rank 0] step=432, skipped=0, lr=[1.989138525395923e-05], mom=[(0.9, 0.999)]
steps: 432 loss: 0.5668 iter time (s): 85.963 samples/sec: 1.489

100%|██████████| 1/1 [01:26<00:00, 86.70s/it][A100%|██████████| 1/1 [01:26<00:00, 86.70s/it]
  8%|▊         | 440/5198 [12:52:57<124:54:21, 94.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.66s/it][A100%|██████████| 1/1 [01:26<00:00, 86.66s/it]
  8%|▊         | 440/5198 [12:52:57<124:54:02, 94.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.78s/it][A100%|██████████| 1/1 [01:26<00:00, 86.78s/it]
  8%|▊         | 440/5198 [12:52:57<124:56:08, 94.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.69s/it][A100%|██████████| 1/1 [01:26<00:00, 86.69s/it]
  8%|▊         | 440/5198 [12:52:57<124:54:40, 94.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.73s/it][A100%|██████████| 1/1 [01:26<00:00, 86.73s/it]
  8%|▊         | 440/5198 [12:52:58<124:55:19, 94.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.72s/it][A100%|██████████| 1/1 [01:26<00:00, 86.72s/it]
  8%|▊         | 440/5198 [12:52:58<124:54:57, 94.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.72s/it][A100%|██████████| 1/1 [01:26<00:00, 86.72s/it]
  8%|▊         | 440/5198 [12:53:00<124:55:02, 94.52s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_413
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.81s/it][A100%|██████████| 1/1 [01:35<00:00, 95.81s/it]
  8%|▊         | 441/5198 [12:54:33<125:32:31, 95.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 08:19:39,014] [INFO] [logging.py:96:log_dist] [Rank 0] step=433, skipped=0, lr=[1.989055115822215e-05], mom=[(0.9, 0.999)]
steps: 433 loss: 0.5906 iter time (s): 95.473 samples/sec: 1.341

100%|██████████| 1/1 [01:36<00:00, 96.31s/it][A100%|██████████| 1/1 [01:36<00:00, 96.31s/it]
  8%|▊         | 441/5198 [12:54:33<125:35:57, 95.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.29s/it][A100%|██████████| 1/1 [01:36<00:00, 96.29s/it]
  8%|▊         | 441/5198 [12:54:33<125:35:11, 95.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.21s/it][A100%|██████████| 1/1 [01:36<00:00, 96.21s/it]
  8%|▊         | 441/5198 [12:54:34<125:34:40, 95.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.25s/it][A100%|██████████| 1/1 [01:36<00:00, 96.25s/it]
  8%|▊         | 441/5198 [12:54:34<125:34:30, 95.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.26s/it][A100%|██████████| 1/1 [01:36<00:00, 96.26s/it]
  8%|▊         | 441/5198 [12:54:34<125:35:24, 95.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.26s/it][A100%|██████████| 1/1 [01:36<00:00, 96.26s/it]
  8%|▊         | 441/5198 [12:54:34<125:35:03, 95.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.25s/it][A100%|██████████| 1/1 [01:36<00:00, 96.25s/it]
  8%|▊         | 441/5198 [12:54:36<125:34:57, 95.04s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_414
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.39s/it][A100%|██████████| 1/1 [01:25<00:00, 85.39s/it]
  9%|▊         | 442/5198 [12:55:58<121:46:20, 92.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 08:21:04,239] [INFO] [logging.py:96:log_dist] [Rank 0] step=434, skipped=0, lr=[1.9889713889671575e-05], mom=[(0.9, 0.999)]
steps: 434 loss: 0.5969 iter time (s): 84.432 samples/sec: 1.516

100%|██████████| 1/1 [01:25<00:00, 85.17s/it][A100%|██████████| 1/1 [01:25<00:00, 85.17s/it]
  9%|▊         | 442/5198 [12:55:58<121:39:40, 92.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.21s/it][A100%|██████████| 1/1 [01:25<00:00, 85.21s/it]
  9%|▊         | 442/5198 [12:55:58<121:40:14, 92.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.21s/it][A100%|██████████| 1/1 [01:25<00:00, 85.21s/it]
  9%|▊         | 442/5198 [12:55:59<121:39:48, 92.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.21s/it][A100%|██████████| 1/1 [01:25<00:00, 85.21s/it]
  9%|▊         | 442/5198 [12:55:59<121:39:32, 92.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.23s/it][A100%|██████████| 1/1 [01:25<00:00, 85.23s/it]
  9%|▊         | 442/5198 [12:55:59<121:40:46, 92.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.24s/it][A100%|██████████| 1/1 [01:25<00:00, 85.24s/it]
  9%|▊         | 442/5198 [12:55:59<121:40:44, 92.10s/it]
100%|██████████| 1/1 [01:25<00:00, 85.23s/it][A100%|██████████| 1/1 [01:25<00:00, 85.23s/it]
  9%|▊         | 442/5198 [12:56:01<121:40:27, 92.10s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_415

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.25s/it][A100%|██████████| 1/1 [01:27<00:00, 87.25s/it]
  9%|▊         | 443/5198 [12:57:26<119:51:23, 90.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 08:22:31,733] [INFO] [logging.py:96:log_dist] [Rank 0] step=435, skipped=0, lr=[1.9888873448576114e-05], mom=[(0.9, 0.999)]
steps: 435 loss: 0.6068 iter time (s): 86.689 samples/sec: 1.477

100%|██████████| 1/1 [01:27<00:00, 87.49s/it][A100%|██████████| 1/1 [01:27<00:00, 87.49s/it]
  9%|▊         | 443/5198 [12:57:26<119:49:09, 90.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.44s/it][A100%|██████████| 1/1 [01:27<00:00, 87.44s/it]
  9%|▊         | 443/5198 [12:57:26<119:48:17, 90.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.47s/it][A100%|██████████| 1/1 [01:27<00:00, 87.47s/it]
  9%|▊         | 443/5198 [12:57:26<119:48:44, 90.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.57s/it][A100%|██████████| 1/1 [01:27<00:00, 87.57s/it]
  9%|▊         | 443/5198 [12:57:26<119:50:49, 90.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.50s/it][A100%|██████████| 1/1 [01:27<00:00, 87.50s/it]
  9%|▊         | 443/5198 [12:57:27<119:50:14, 90.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.49s/it][A100%|██████████| 1/1 [01:27<00:00, 87.49s/it]
  9%|▊         | 443/5198 [12:57:27<119:49:43, 90.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.50s/it][A100%|██████████| 1/1 [01:27<00:00, 87.50s/it]
  9%|▊         | 443/5198 [12:57:29<119:49:38, 90.72s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_416
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.14s/it][A100%|██████████| 1/1 [01:53<00:00, 113.14s/it]
  9%|▊         | 444/5198 [12:59:19<128:47:02, 97.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 08:24:25,788] [INFO] [logging.py:96:log_dist] [Rank 0] step=436, skipped=0, lr=[1.988802983520541e-05], mom=[(0.9, 0.999)]
steps: 436 loss: 0.5996 iter time (s): 113.242 samples/sec: 1.130

100%|██████████| 1/1 [01:54<00:00, 114.01s/it][A100%|██████████| 1/1 [01:54<00:00, 114.01s/it]
  9%|▊         | 444/5198 [12:59:20<129:01:21, 97.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.06s/it][A100%|██████████| 1/1 [01:54<00:00, 114.06s/it]
  9%|▊         | 444/5198 [12:59:20<129:01:56, 97.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.09s/it][A100%|██████████| 1/1 [01:54<00:00, 114.09s/it]
  9%|▊         | 444/5198 [12:59:20<129:03:04, 97.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.95s/it][A100%|██████████| 1/1 [01:53<00:00, 113.95s/it]
  9%|▊         | 444/5198 [12:59:20<129:01:14, 97.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.01s/it][A100%|██████████| 1/1 [01:54<00:00, 114.01s/it]
  9%|▊         | 444/5198 [12:59:21<129:02:13, 97.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.00s/it][A100%|██████████| 1/1 [01:54<00:00, 114.00s/it]
  9%|▊         | 444/5198 [12:59:21<129:01:36, 97.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.02s/it][A100%|██████████| 1/1 [01:54<00:00, 114.02s/it]
  9%|▊         | 444/5198 [12:59:23<129:02:01, 97.71s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_417
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.71s/it][A100%|██████████| 1/1 [01:58<00:00, 118.71s/it]
  9%|▊         | 445/5198 [13:01:18<137:13:01, 103.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 08:26:24,818] [INFO] [logging.py:96:log_dist] [Rank 0] step=437, skipped=0, lr=[1.9887183049830106e-05], mom=[(0.9, 0.999)]
steps: 437 loss: 0.5741 iter time (s): 118.243 samples/sec: 1.083

100%|██████████| 1/1 [01:59<00:00, 119.05s/it][A100%|██████████| 1/1 [01:59<00:00, 119.05s/it]
  9%|▊         | 445/5198 [13:01:19<137:27:36, 104.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.19s/it][A100%|██████████| 1/1 [01:59<00:00, 119.19s/it]
  9%|▊         | 445/5198 [13:01:19<137:30:24, 104.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.98s/it][A100%|██████████| 1/1 [01:58<00:00, 118.98s/it]
  9%|▊         | 445/5198 [13:01:19<137:26:45, 104.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.07s/it][A100%|██████████| 1/1 [01:59<00:00, 119.07s/it]
  9%|▊         | 445/5198 [13:01:20<137:27:30, 104.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.00s/it][A100%|██████████| 1/1 [01:59<00:00, 119.00s/it]
  9%|▊         | 445/5198 [13:01:20<137:26:36, 104.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.04s/it][A100%|██████████| 1/1 [01:59<00:00, 119.04s/it]
  9%|▊         | 445/5198 [13:01:20<137:27:01, 104.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.02s/it][A100%|██████████| 1/1 [01:59<00:00, 119.02s/it]
  9%|▊         | 445/5198 [13:01:22<137:26:55, 104.11s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_418
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:17<00:00, 137.95s/it][A100%|██████████| 1/1 [02:17<00:00, 137.95s/it]
  9%|▊         | 446/5198 [13:03:36<150:42:19, 114.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 08:28:43,399] [INFO] [logging.py:96:log_dist] [Rank 0] step=438, skipped=0, lr=[1.9886333092721878e-05], mom=[(0.9, 0.999)]
steps: 438 loss: 0.6076 iter time (s): 137.797 samples/sec: 0.929

100%|██████████| 1/1 [02:18<00:00, 138.45s/it][A100%|██████████| 1/1 [02:18<00:00, 138.45s/it]
  9%|▊         | 446/5198 [13:03:38<151:03:40, 114.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:18<00:00, 138.58s/it][A100%|██████████| 1/1 [02:18<00:00, 138.58s/it]
  9%|▊         | 446/5198 [13:03:38<151:04:47, 114.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:18<00:00, 138.58s/it][A100%|██████████| 1/1 [02:18<00:00, 138.58s/it]
  9%|▊         | 446/5198 [13:03:38<151:04:12, 114.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:18<00:00, 138.58s/it][A100%|██████████| 1/1 [02:18<00:00, 138.59s/it]
  9%|▊         | 446/5198 [13:03:38<151:04:54, 114.46s/it]
100%|██████████| 1/1 [02:18<00:00, 138.58s/it][A100%|██████████| 1/1 [02:18<00:00, 138.58s/it]
  9%|▊         | 446/5198 [13:03:38<151:04:07, 114.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:18<00:00, 138.58s/it][A100%|██████████| 1/1 [02:18<00:00, 138.58s/it]
  9%|▊         | 446/5198 [13:03:38<151:04:27, 114.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:18<00:00, 138.59s/it][A100%|██████████| 1/1 [02:18<00:00, 138.59s/it]
  9%|▊         | 446/5198 [13:03:41<151:04:30, 114.45s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_419
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.04s/it][A100%|██████████| 1/1 [01:19<00:00, 79.04s/it]
  9%|▊         | 447/5198 [13:04:55<136:49:53, 103.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 08:30:00,947] [INFO] [logging.py:96:log_dist] [Rank 0] step=439, skipped=0, lr=[1.988547996415341e-05], mom=[(0.9, 0.999)]
steps: 439 loss: 0.5814 iter time (s): 76.750 samples/sec: 1.668

100%|██████████| 1/1 [01:17<00:00, 77.47s/it][A100%|██████████| 1/1 [01:17<00:00, 77.47s/it]
  9%|▊         | 447/5198 [13:04:55<136:23:55, 103.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:17<00:00, 77.64s/it][A100%|██████████| 1/1 [01:17<00:00, 77.64s/it]
  9%|▊         | 447/5198 [13:04:55<136:28:32, 103.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:17<00:00, 77.67s/it][A100%|██████████| 1/1 [01:17<00:00, 77.67s/it]
  9%|▊         | 447/5198 [13:04:56<136:28:58, 103.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:17<00:00, 77.72s/it][A100%|██████████| 1/1 [01:17<00:00, 77.72s/it]
  9%|▊         | 447/5198 [13:04:56<136:30:42, 103.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:17<00:00, 77.73s/it][A100%|██████████| 1/1 [01:17<00:00, 77.73s/it]
  9%|▊         | 447/5198 [13:04:56<136:30:22, 103.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:17<00:00, 77.75s/it][A100%|██████████| 1/1 [01:17<00:00, 77.75s/it]
  9%|▊         | 447/5198 [13:04:58<136:31:03, 103.44s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_27
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:17<00:00, 77.78s/it][A100%|██████████| 1/1 [01:17<00:00, 77.78s/it]
  9%|▊         | 447/5198 [13:04:56<136:31:39, 103.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.57s/it][A100%|██████████| 1/1 [01:51<00:00, 111.57s/it]
  9%|▊         | 448/5198 [13:06:47<139:58:29, 106.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 08:31:53,355] [INFO] [logging.py:96:log_dist] [Rank 0] step=440, skipped=0, lr=[1.9884623664398406e-05], mom=[(0.9, 0.999)]
steps: 440 loss: 0.7793 iter time (s): 111.612 samples/sec: 1.147

100%|██████████| 1/1 [01:52<00:00, 112.67s/it][A100%|██████████| 1/1 [01:52<00:00, 112.67s/it]
  9%|▊         | 448/5198 [13:06:48<140:03:36, 106.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.59s/it][A100%|██████████| 1/1 [01:52<00:00, 112.59s/it]
  9%|▊         | 448/5198 [13:06:48<140:04:58, 106.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.56s/it][A100%|██████████| 1/1 [01:52<00:00, 112.56s/it]
  9%|▊         | 448/5198 [13:06:48<140:05:45, 106.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.52s/it][A100%|██████████| 1/1 [01:52<00:00, 112.52s/it]
  9%|▊         | 448/5198 [13:06:48<140:04:45, 106.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.60s/it][A100%|██████████| 1/1 [01:52<00:00, 112.60s/it]
  9%|▊         | 448/5198 [13:06:49<140:06:26, 106.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.52s/it][A100%|██████████| 1/1 [01:52<00:00, 112.52s/it]
  9%|▊         | 448/5198 [13:06:49<140:05:22, 106.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.55s/it][A100%|██████████| 1/1 [01:52<00:00, 112.55s/it]
  9%|▊         | 448/5198 [13:06:51<140:05:46, 106.18s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_420
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.81s/it][A100%|██████████| 1/1 [01:20<00:00, 80.81s/it]
  9%|▊         | 449/5198 [13:08:08<130:00:12, 98.55s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 08:33:13,692] [INFO] [logging.py:96:log_dist] [Rank 0] step=441, skipped=0, lr=[1.9883764193731593e-05], mom=[(0.9, 0.999)]
steps: 441 loss: 0.5973 iter time (s): 79.186 samples/sec: 1.616

100%|██████████| 1/1 [01:20<00:00, 80.11s/it][A100%|██████████| 1/1 [01:20<00:00, 80.11s/it]
  9%|▊         | 449/5198 [13:08:08<129:43:50, 98.34s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.08s/it][A100%|██████████| 1/1 [01:20<00:00, 80.08s/it]
  9%|▊         | 449/5198 [13:08:08<129:43:59, 98.34s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.11s/it][A100%|██████████| 1/1 [01:20<00:00, 80.11s/it]
  9%|▊         | 449/5198 [13:08:08<129:45:11, 98.36s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.09s/it][A100%|██████████| 1/1 [01:20<00:00, 80.09s/it]
  9%|▊         | 449/5198 [13:08:08<129:43:59, 98.34s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.03s/it][A100%|██████████| 1/1 [01:20<00:00, 80.03s/it]
  9%|▊         | 449/5198 [13:08:09<129:43:46, 98.34s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.05s/it][A100%|██████████| 1/1 [01:20<00:00, 80.05s/it]
  9%|▊         | 449/5198 [13:08:09<129:43:25, 98.34s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.04s/it][A100%|██████████| 1/1 [01:20<00:00, 80.04s/it]
  9%|▊         | 449/5198 [13:08:11<129:43:35, 98.34s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_421
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:02<00:00, 122.73s/it][A100%|██████████| 1/1 [02:02<00:00, 122.73s/it]
  9%|▊         | 450/5198 [13:10:11<139:35:34, 105.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 08:35:17,701] [INFO] [logging.py:96:log_dist] [Rank 0] step=442, skipped=0, lr=[1.988290155242871e-05], mom=[(0.9, 0.999)]
steps: 442 loss: 0.6132 iter time (s): 123.136 samples/sec: 1.039

100%|██████████| 1/1 [02:03<00:00, 123.98s/it][A100%|██████████| 1/1 [02:03<00:00, 123.98s/it]
  9%|▊         | 450/5198 [13:10:12<139:51:06, 106.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.94s/it][A100%|██████████| 1/1 [02:03<00:00, 123.94s/it]
  9%|▊         | 450/5198 [13:10:12<139:50:22, 106.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.89s/it][A100%|██████████| 1/1 [02:03<00:00, 123.89s/it]
  9%|▊         | 450/5198 [13:10:12<139:49:51, 106.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.95s/it][A100%|██████████| 1/1 [02:03<00:00, 123.95s/it]
  9%|▊         | 450/5198 [13:10:12<139:50:29, 106.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.96s/it][A100%|██████████| 1/1 [02:03<00:00, 123.96s/it]
  9%|▊         | 450/5198 [13:10:13<139:50:23, 106.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.95s/it][A100%|██████████| 1/1 [02:03<00:00, 123.95s/it]
  9%|▊         | 450/5198 [13:10:13<139:49:56, 106.02s/it]
100%|██████████| 1/1 [02:03<00:00, 123.93s/it][A100%|██████████| 1/1 [02:03<00:00, 123.93s/it]
  9%|▊         | 450/5198 [13:10:15<139:49:38, 106.02s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_422
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.42s/it][A100%|██████████| 1/1 [01:22<00:00, 82.42s/it]
  9%|▊         | 451/5198 [13:11:33<130:21:15, 98.86s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 08:36:39,111] [INFO] [logging.py:96:log_dist] [Rank 0] step=443, skipped=0, lr=[1.9882035740766504e-05], mom=[(0.9, 0.999)]
steps: 443 loss: 0.5692 iter time (s): 80.609 samples/sec: 1.588

100%|██████████| 1/1 [01:21<00:00, 81.39s/it][A100%|██████████| 1/1 [01:21<00:00, 81.39s/it]
  9%|▊         | 451/5198 [13:11:33<130:04:44, 98.65s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.43s/it][A100%|██████████| 1/1 [01:21<00:00, 81.43s/it]
  9%|▊         | 451/5198 [13:11:33<130:04:53, 98.65s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.38s/it][A100%|██████████| 1/1 [01:21<00:00, 81.38s/it]
  9%|▊         | 451/5198 [13:11:34<130:03:27, 98.63s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.36s/it][A100%|██████████| 1/1 [01:21<00:00, 81.36s/it]
  9%|▊         | 451/5198 [13:11:34<130:03:17, 98.63s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.37s/it][A100%|██████████| 1/1 [01:21<00:00, 81.37s/it]
  9%|▊         | 451/5198 [13:11:34<130:03:37, 98.63s/it] 
100%|██████████| 1/1 [01:21<00:00, 81.35s/it][A100%|██████████| 1/1 [01:21<00:00, 81.35s/it]
  9%|▊         | 451/5198 [13:11:34<130:02:48, 98.62s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.38s/it][A100%|██████████| 1/1 [01:21<00:00, 81.38s/it]
  9%|▊         | 451/5198 [13:11:36<130:03:09, 98.63s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_423
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.72s/it][A100%|██████████| 1/1 [01:24<00:00, 84.72s/it]
  9%|▊         | 452/5198 [13:12:58<124:48:51, 94.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 08:38:04,159] [INFO] [logging.py:96:log_dist] [Rank 0] step=444, skipped=0, lr=[1.9881166759022764e-05], mom=[(0.9, 0.999)]
steps: 444 loss: 0.6207 iter time (s): 84.274 samples/sec: 1.519

100%|██████████| 1/1 [01:25<00:00, 85.07s/it][A100%|██████████| 1/1 [01:25<00:00, 85.07s/it]
  9%|▊         | 452/5198 [13:12:58<124:41:18, 94.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.00s/it][A100%|██████████| 1/1 [01:25<00:00, 85.00s/it]
  9%|▊         | 452/5198 [13:12:58<124:39:34, 94.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.96s/it][A100%|██████████| 1/1 [01:24<00:00, 84.96s/it]
  9%|▊         | 452/5198 [13:12:59<124:37:32, 94.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.07s/it][A100%|██████████| 1/1 [01:25<00:00, 85.07s/it]
  9%|▊         | 452/5198 [13:12:59<124:40:10, 94.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.02s/it][A100%|██████████| 1/1 [01:25<00:00, 85.02s/it]
  9%|▊         | 452/5198 [13:12:59<124:39:03, 94.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.06s/it][A100%|██████████| 1/1 [01:25<00:00, 85.06s/it]
  9%|▊         | 452/5198 [13:12:59<124:39:21, 94.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.06s/it][A100%|██████████| 1/1 [01:25<00:00, 85.06s/it]
  9%|▊         | 452/5198 [13:13:01<124:39:39, 94.56s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_424
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.78s/it][A100%|██████████| 1/1 [01:39<00:00, 99.78s/it]
  9%|▊         | 453/5198 [13:14:38<126:52:36, 96.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 08:39:44,536] [INFO] [logging.py:96:log_dist] [Rank 0] step=445, skipped=0, lr=[1.988029460747627e-05], mom=[(0.9, 0.999)]
steps: 445 loss: 0.5775 iter time (s): 99.587 samples/sec: 1.285

100%|██████████| 1/1 [01:40<00:00, 100.33s/it][A100%|██████████| 1/1 [01:40<00:00, 100.33s/it]
  9%|▊         | 453/5198 [13:14:39<126:56:17, 96.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.36s/it][A100%|██████████| 1/1 [01:40<00:00, 100.36s/it]
  9%|▊         | 453/5198 [13:14:39<126:55:55, 96.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.39s/it][A100%|██████████| 1/1 [01:40<00:00, 100.39s/it]
  9%|▊         | 453/5198 [13:14:39<126:56:53, 96.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.43s/it][A100%|██████████| 1/1 [01:40<00:00, 100.43s/it]
  9%|▊         | 453/5198 [13:14:39<126:55:58, 96.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.38s/it][A100%|██████████| 1/1 [01:40<00:00, 100.38s/it]
  9%|▊         | 453/5198 [13:14:39<126:55:59, 96.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.37s/it][A100%|██████████| 1/1 [01:40<00:00, 100.37s/it]
  9%|▊         | 453/5198 [13:14:39<126:55:54, 96.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.37s/it][A100%|██████████| 1/1 [01:40<00:00, 100.37s/it]
  9%|▊         | 453/5198 [13:14:42<126:56:02, 96.30s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_425
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.69s/it][A100%|██████████| 1/1 [01:48<00:00, 108.69s/it]
  9%|▊         | 454/5198 [13:16:27<131:49:19, 100.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 08:41:33,579] [INFO] [logging.py:96:log_dist] [Rank 0] step=446, skipped=0, lr=[1.9879419286406834e-05], mom=[(0.9, 0.999)]
steps: 446 loss: 0.6152 iter time (s): 108.253 samples/sec: 1.182

100%|██████████| 1/1 [01:49<00:00, 109.11s/it][A100%|██████████| 1/1 [01:49<00:00, 109.11s/it]
  9%|▊         | 454/5198 [13:16:28<131:58:36, 100.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.16s/it][A100%|██████████| 1/1 [01:49<00:00, 109.16s/it]
  9%|▊         | 454/5198 [13:16:28<131:59:34, 100.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.09s/it][A100%|██████████| 1/1 [01:49<00:00, 109.09s/it]
  9%|▊         | 454/5198 [13:16:28<131:58:28, 100.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.10s/it][A100%|██████████| 1/1 [01:49<00:00, 109.10s/it]
  9%|▊         | 454/5198 [13:16:28<131:58:11, 100.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.10s/it][A100%|██████████| 1/1 [01:49<00:00, 109.10s/it]
  9%|▊         | 454/5198 [13:16:28<131:58:07, 100.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.10s/it][A100%|██████████| 1/1 [01:49<00:00, 109.10s/it]
  9%|▊         | 454/5198 [13:16:28<131:58:04, 100.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.09s/it][A100%|██████████| 1/1 [01:49<00:00, 109.09s/it]
  9%|▊         | 454/5198 [13:16:31<131:57:52, 100.14s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_426
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.07s/it][A100%|██████████| 1/1 [01:21<00:00, 81.07s/it]
  9%|▉         | 455/5198 [13:17:48<124:22:35, 94.40s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 08:42:54,050] [INFO] [logging.py:96:log_dist] [Rank 0] step=447, skipped=0, lr=[1.9878540796095278e-05], mom=[(0.9, 0.999)]
steps: 447 loss: 0.5929 iter time (s): 79.624 samples/sec: 1.608

100%|██████████| 1/1 [01:20<00:00, 80.45s/it][A100%|██████████| 1/1 [01:20<00:00, 80.45s/it]
  9%|▉         | 455/5198 [13:17:48<124:09:50, 94.24s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.43s/it][A100%|██████████| 1/1 [01:20<00:00, 80.43s/it]
  9%|▉         | 455/5198 [13:17:48<124:10:09, 94.25s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.33s/it][A100%|██████████| 1/1 [01:20<00:00, 80.33s/it]
  9%|▉         | 455/5198 [13:17:49<124:07:08, 94.21s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.43s/it][A100%|██████████| 1/1 [01:20<00:00, 80.43s/it]
  9%|▉         | 455/5198 [13:17:49<124:09:04, 94.23s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.40s/it][A100%|██████████| 1/1 [01:20<00:00, 80.41s/it]
  9%|▉         | 455/5198 [13:17:49<124:08:32, 94.23s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.41s/it][A100%|██████████| 1/1 [01:20<00:00, 80.41s/it]
  9%|▉         | 455/5198 [13:17:49<124:08:32, 94.23s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.43s/it][A100%|██████████| 1/1 [01:20<00:00, 80.43s/it]
  9%|▉         | 455/5198 [13:17:51<124:08:47, 94.23s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_427
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.32s/it][A100%|██████████| 1/1 [01:40<00:00, 100.32s/it]
  9%|▉         | 456/5198 [13:19:29<126:44:04, 96.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 08:44:35,092] [INFO] [logging.py:96:log_dist] [Rank 0] step=448, skipped=0, lr=[1.9877659136823447e-05], mom=[(0.9, 0.999)]
steps: 448 loss: 0.5568 iter time (s): 100.236 samples/sec: 1.277

100%|██████████| 1/1 [01:40<00:00, 100.95s/it][A100%|██████████| 1/1 [01:40<00:00, 100.95s/it]
  9%|▉         | 456/5198 [13:19:29<126:47:28, 96.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.93s/it][A100%|██████████| 1/1 [01:40<00:00, 100.93s/it]
  9%|▉         | 456/5198 [13:19:29<126:47:11, 96.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.01s/it][A100%|██████████| 1/1 [01:41<00:00, 101.01s/it]
  9%|▉         | 456/5198 [13:19:30<126:46:56, 96.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.98s/it][A100%|██████████| 1/1 [01:40<00:00, 100.98s/it]
  9%|▉         | 456/5198 [13:19:30<126:47:42, 96.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.00s/it][A100%|██████████| 1/1 [01:41<00:00, 101.00s/it]
  9%|▉         | 456/5198 [13:19:30<126:47:54, 96.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.99s/it][A100%|██████████| 1/1 [01:40<00:00, 100.99s/it]
  9%|▉         | 456/5198 [13:19:30<126:47:30, 96.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.97s/it][A100%|██████████| 1/1 [01:40<00:00, 100.97s/it]
  9%|▉         | 456/5198 [13:19:32<126:47:14, 96.25s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_428
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.64s/it][A100%|██████████| 1/1 [01:28<00:00, 88.64s/it]
  9%|▉         | 457/5198 [13:20:57<123:49:47, 94.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 08:46:03,599] [INFO] [logging.py:96:log_dist] [Rank 0] step=449, skipped=0, lr=[1.9876774308874198e-05], mom=[(0.9, 0.999)]
steps: 449 loss: 0.6146 iter time (s): 87.874 samples/sec: 1.457

100%|██████████| 1/1 [01:28<00:00, 88.73s/it][A100%|██████████| 1/1 [01:28<00:00, 88.74s/it]
  9%|▉         | 457/5198 [13:20:58<123:47:50, 94.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.76s/it][A100%|██████████| 1/1 [01:28<00:00, 88.76s/it]
  9%|▉         | 457/5198 [13:20:58<123:48:09, 94.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.80s/it][A100%|██████████| 1/1 [01:28<00:00, 88.80s/it]
  9%|▉         | 457/5198 [13:20:58<123:49:14, 94.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.81s/it][A100%|██████████| 1/1 [01:28<00:00, 88.81s/it]
  9%|▉         | 457/5198 [13:20:59<123:49:46, 94.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.76s/it][A100%|██████████| 1/1 [01:28<00:00, 88.76s/it]
  9%|▉         | 457/5198 [13:20:59<123:48:36, 94.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.80s/it][A100%|██████████| 1/1 [01:28<00:00, 88.80s/it]
  9%|▉         | 457/5198 [13:21:01<123:49:07, 94.02s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_429

100%|██████████| 1/1 [01:28<00:00, 88.81s/it][A100%|██████████| 1/1 [01:28<00:00, 88.81s/it]
  9%|▉         | 457/5198 [13:20:59<123:49:34, 94.03s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 101.00s/it][A100%|██████████| 1/1 [01:40<00:00, 101.00s/it]
  9%|▉         | 458/5198 [13:22:39<126:43:50, 96.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 08:47:45,102] [INFO] [logging.py:96:log_dist] [Rank 0] step=450, skipped=0, lr=[1.9875886312531406e-05], mom=[(0.9, 0.999)]
steps: 450 loss: 0.6111 iter time (s): 100.459 samples/sec: 1.274

100%|██████████| 1/1 [01:41<00:00, 101.33s/it][A100%|██████████| 1/1 [01:41<00:00, 101.33s/it]
  9%|▉         | 458/5198 [13:22:39<126:40:16, 96.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.30s/it][A100%|██████████| 1/1 [01:41<00:00, 101.30s/it]
  9%|▉         | 458/5198 [13:22:39<126:39:41, 96.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.28s/it][A100%|██████████| 1/1 [01:41<00:00, 101.28s/it]
  9%|▉         | 458/5198 [13:22:40<126:40:02, 96.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.25s/it][A100%|██████████| 1/1 [01:41<00:00, 101.25s/it]
  9%|▉         | 458/5198 [13:22:40<126:39:33, 96.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.28s/it][A100%|██████████| 1/1 [01:41<00:00, 101.28s/it]
  9%|▉         | 458/5198 [13:22:40<126:39:31, 96.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.23s/it][A100%|██████████| 1/1 [01:41<00:00, 101.23s/it]
  9%|▉         | 458/5198 [13:22:40<126:38:51, 96.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.26s/it][A100%|██████████| 1/1 [01:41<00:00, 101.26s/it]
  9%|▉         | 458/5198 [13:22:42<126:39:18, 96.19s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_430
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.98s/it][A100%|██████████| 1/1 [01:27<00:00, 87.98s/it]
  9%|▉         | 459/5198 [13:24:07<123:32:40, 93.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 08:49:13,310] [INFO] [logging.py:96:log_dist] [Rank 0] step=451, skipped=0, lr=[1.9874995148079958e-05], mom=[(0.9, 0.999)]
steps: 451 loss: 0.6076 iter time (s): 87.407 samples/sec: 1.464

100%|██████████| 1/1 [01:28<00:00, 88.13s/it][A100%|██████████| 1/1 [01:28<00:00, 88.13s/it]
  9%|▉         | 459/5198 [13:24:07<123:27:32, 93.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.15s/it][A100%|██████████| 1/1 [01:28<00:00, 88.15s/it]
  9%|▉         | 459/5198 [13:24:08<123:27:45, 93.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.18s/it][A100%|██████████| 1/1 [01:28<00:00, 88.18s/it]
  9%|▉         | 459/5198 [13:24:08<123:28:29, 93.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.15s/it][A100%|██████████| 1/1 [01:28<00:00, 88.15s/it]
  9%|▉         | 459/5198 [13:24:08<123:27:40, 93.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.13s/it][A100%|██████████| 1/1 [01:28<00:00, 88.13s/it]
  9%|▉         | 459/5198 [13:24:08<123:26:58, 93.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.14s/it][A100%|██████████| 1/1 [01:28<00:00, 88.15s/it]
  9%|▉         | 459/5198 [13:24:10<123:27:07, 93.78s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_431
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.19s/it][A100%|██████████| 1/1 [01:28<00:00, 88.19s/it]
  9%|▉         | 459/5198 [13:24:08<123:27:52, 93.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.85s/it][A100%|██████████| 1/1 [01:50<00:00, 110.85s/it]
  9%|▉         | 460/5198 [13:25:58<130:19:08, 99.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 08:51:05,058] [INFO] [logging.py:96:log_dist] [Rank 0] step=452, skipped=0, lr=[1.9874100815805766e-05], mom=[(0.9, 0.999)]
steps: 452 loss: 0.5860 iter time (s): 111.002 samples/sec: 1.153

100%|██████████| 1/1 [01:51<00:00, 111.86s/it][A100%|██████████| 1/1 [01:51<00:00, 111.86s/it]
  9%|▉         | 460/5198 [13:25:59<130:34:28, 99.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.94s/it][A100%|██████████| 1/1 [01:51<00:00, 111.94s/it]
  9%|▉         | 460/5198 [13:26:00<130:36:31, 99.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.96s/it][A100%|██████████| 1/1 [01:51<00:00, 111.96s/it]
  9%|▉         | 460/5198 [13:26:00<130:37:19, 99.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.92s/it][A100%|██████████| 1/1 [01:51<00:00, 111.92s/it]
  9%|▉         | 460/5198 [13:26:00<130:35:25, 99.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.96s/it][A100%|██████████| 1/1 [01:51<00:00, 111.97s/it]
  9%|▉         | 460/5198 [13:26:00<130:36:53, 99.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.95s/it][A100%|██████████| 1/1 [01:51<00:00, 111.95s/it]
  9%|▉         | 460/5198 [13:26:00<130:36:43, 99.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.99s/it][A100%|██████████| 1/1 [01:51<00:00, 111.99s/it]
  9%|▉         | 460/5198 [13:26:02<130:37:00, 99.24s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_432
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.82s/it][A100%|██████████| 1/1 [01:20<00:00, 80.82s/it]
  9%|▉         | 461/5198 [13:27:19<123:10:26, 93.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 08:52:25,196] [INFO] [logging.py:96:log_dist] [Rank 0] step=453, skipped=0, lr=[1.9873203315995758e-05], mom=[(0.9, 0.999)]
steps: 453 loss: 0.5589 iter time (s): 79.150 samples/sec: 1.617

100%|██████████| 1/1 [01:19<00:00, 79.98s/it][A100%|██████████| 1/1 [01:19<00:00, 79.98s/it]
  9%|▉         | 461/5198 [13:27:19<122:57:43, 93.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.86s/it][A100%|██████████| 1/1 [01:19<00:00, 79.86s/it]
  9%|▉         | 461/5198 [13:27:19<122:56:11, 93.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.82s/it][A100%|██████████| 1/1 [01:19<00:00, 79.82s/it]
  9%|▉         | 461/5198 [13:27:20<122:55:43, 93.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.91s/it][A100%|██████████| 1/1 [01:19<00:00, 79.91s/it]
  9%|▉         | 461/5198 [13:27:20<122:57:39, 93.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.99s/it][A100%|██████████| 1/1 [01:19<00:00, 79.99s/it]
  9%|▉         | 461/5198 [13:27:20<122:59:15, 93.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.09s/it][A100%|██████████| 1/1 [01:20<00:00, 80.09s/it]
  9%|▉         | 461/5198 [13:27:20<123:00:52, 93.49s/it]
100%|██████████| 1/1 [01:19<00:00, 79.98s/it][A100%|██████████| 1/1 [01:19<00:00, 79.98s/it]
  9%|▉         | 461/5198 [13:27:22<122:59:17, 93.47s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_433

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.13s/it][A100%|██████████| 1/1 [01:32<00:00, 92.13s/it]
  9%|▉         | 462/5198 [13:28:51<122:37:48, 93.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 08:53:57,868] [INFO] [logging.py:96:log_dist] [Rank 0] step=454, skipped=0, lr=[1.9872302648937865e-05], mom=[(0.9, 0.999)]
steps: 454 loss: 0.5816 iter time (s): 91.834 samples/sec: 1.394

100%|██████████| 1/1 [01:32<00:00, 92.62s/it][A100%|██████████| 1/1 [01:32<00:00, 92.62s/it]
  9%|▉         | 462/5198 [13:28:52<122:36:47, 93.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.68s/it][A100%|██████████| 1/1 [01:32<00:00, 92.68s/it]
  9%|▉         | 462/5198 [13:28:52<122:37:06, 93.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.70s/it][A100%|██████████| 1/1 [01:32<00:00, 92.70s/it]
  9%|▉         | 462/5198 [13:28:52<122:37:22, 93.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.64s/it][A100%|██████████| 1/1 [01:32<00:00, 92.64s/it]
  9%|▉         | 462/5198 [13:28:53<122:37:10, 93.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.52s/it][A100%|██████████| 1/1 [01:32<00:00, 92.52s/it]
  9%|▉         | 462/5198 [13:28:53<122:36:33, 93.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.56s/it][A100%|██████████| 1/1 [01:32<00:00, 92.56s/it]
  9%|▉         | 462/5198 [13:28:55<122:36:23, 93.20s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_434
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.58s/it][A100%|██████████| 1/1 [01:32<00:00, 92.58s/it]
  9%|▉         | 462/5198 [13:28:53<122:36:55, 93.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.09s/it][A100%|██████████| 1/1 [01:30<00:00, 90.09s/it]
  9%|▉         | 463/5198 [13:30:22<121:25:30, 92.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 08:55:27,983] [INFO] [logging.py:96:log_dist] [Rank 0] step=455, skipped=0, lr=[1.987139881492105e-05], mom=[(0.9, 0.999)]
steps: 455 loss: 0.6470 iter time (s): 89.378 samples/sec: 1.432

100%|██████████| 1/1 [01:30<00:00, 90.19s/it][A100%|██████████| 1/1 [01:30<00:00, 90.19s/it]
  9%|▉         | 463/5198 [13:30:22<121:24:11, 92.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.19s/it][A100%|██████████| 1/1 [01:30<00:00, 90.19s/it]
  9%|▉         | 463/5198 [13:30:22<121:24:15, 92.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.16s/it][A100%|██████████| 1/1 [01:30<00:00, 90.16s/it]
  9%|▉         | 463/5198 [13:30:23<121:23:46, 92.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.12s/it][A100%|██████████| 1/1 [01:30<00:00, 90.12s/it]
  9%|▉         | 463/5198 [13:30:23<121:22:41, 92.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.14s/it][A100%|██████████| 1/1 [01:30<00:00, 90.14s/it]
  9%|▉         | 463/5198 [13:30:23<121:22:47, 92.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.17s/it][A100%|██████████| 1/1 [01:30<00:00, 90.17s/it]
  9%|▉         | 463/5198 [13:30:23<121:23:44, 92.30s/it]
100%|██████████| 1/1 [01:30<00:00, 90.18s/it][A100%|██████████| 1/1 [01:30<00:00, 90.18s/it]
  9%|▉         | 463/5198 [13:30:25<121:23:37, 92.30s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_28
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:57<00:00, 117.21s/it][A100%|██████████| 1/1 [01:57<00:00, 117.21s/it]
  9%|▉         | 464/5198 [13:32:19<131:16:53, 99.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 08:57:25,823] [INFO] [logging.py:96:log_dist] [Rank 0] step=456, skipped=0, lr=[1.9870491814235284e-05], mom=[(0.9, 0.999)]
steps: 456 loss: 0.7558 iter time (s): 117.286 samples/sec: 1.091

100%|██████████| 1/1 [01:58<00:00, 118.11s/it][A100%|██████████| 1/1 [01:58<00:00, 118.11s/it]
  9%|▉         | 464/5198 [13:32:20<131:33:51, 100.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.12s/it][A100%|██████████| 1/1 [01:58<00:00, 118.12s/it]
  9%|▉         | 464/5198 [13:32:20<131:33:56, 100.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.08s/it][A100%|██████████| 1/1 [01:58<00:00, 118.08s/it]
  9%|▉         | 464/5198 [13:32:21<131:32:48, 100.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.17s/it][A100%|██████████| 1/1 [01:58<00:00, 118.17s/it]
  9%|▉         | 464/5198 [13:32:21<131:34:03, 100.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.14s/it][A100%|██████████| 1/1 [01:58<00:00, 118.14s/it]
  9%|▉         | 464/5198 [13:32:21<131:33:23, 100.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.08s/it][A100%|██████████| 1/1 [01:58<00:00, 118.08s/it]
  9%|▉         | 464/5198 [13:32:21<131:32:41, 100.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.10s/it][A100%|██████████| 1/1 [01:58<00:00, 118.10s/it]
  9%|▉         | 464/5198 [13:32:23<131:32:59, 100.04s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_435
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.29s/it][A100%|██████████| 1/1 [01:37<00:00, 97.29s/it]
  9%|▉         | 465/5198 [13:33:57<130:18:45, 99.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 08:59:02,992] [INFO] [logging.py:96:log_dist] [Rank 0] step=457, skipped=0, lr=[1.9869581647171554e-05], mom=[(0.9, 0.999)]
steps: 457 loss: 0.5671 iter time (s): 96.103 samples/sec: 1.332

100%|██████████| 1/1 [01:36<00:00, 96.91s/it][A100%|██████████| 1/1 [01:36<00:00, 96.91s/it]
  9%|▉         | 465/5198 [13:33:57<130:18:16, 99.11s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.91s/it][A100%|██████████| 1/1 [01:36<00:00, 96.91s/it]
  9%|▉         | 465/5198 [13:33:57<130:18:21, 99.11s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.97s/it][A100%|██████████| 1/1 [01:36<00:00, 96.97s/it]
  9%|▉         | 465/5198 [13:33:58<130:18:42, 99.12s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.94s/it][A100%|██████████| 1/1 [01:36<00:00, 96.94s/it]
  9%|▉         | 465/5198 [13:33:58<130:19:02, 99.12s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.97s/it][A100%|██████████| 1/1 [01:36<00:00, 96.97s/it]
  9%|▉         | 465/5198 [13:33:58<130:19:10, 99.12s/it] 
100%|██████████| 1/1 [01:36<00:00, 96.95s/it][A100%|██████████| 1/1 [01:36<00:00, 96.95s/it]
  9%|▉         | 465/5198 [13:33:58<130:18:08, 99.11s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.94s/it][A100%|██████████| 1/1 [01:36<00:00, 96.94s/it]
  9%|▉         | 465/5198 [13:34:00<130:18:11, 99.11s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_436
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.57s/it][A100%|██████████| 1/1 [01:30<00:00, 90.57s/it]
  9%|▉         | 466/5198 [13:35:27<126:58:42, 96.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 09:00:33,551] [INFO] [logging.py:96:log_dist] [Rank 0] step=458, skipped=0, lr=[1.986866831402186e-05], mom=[(0.9, 0.999)]
steps: 458 loss: 0.5681 iter time (s): 89.706 samples/sec: 1.427

100%|██████████| 1/1 [01:30<00:00, 90.49s/it][A100%|██████████| 1/1 [01:30<00:00, 90.49s/it]
  9%|▉         | 466/5198 [13:35:28<126:52:44, 96.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.46s/it][A100%|██████████| 1/1 [01:30<00:00, 90.46s/it]
  9%|▉         | 466/5198 [13:35:28<126:52:04, 96.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.49s/it][A100%|██████████| 1/1 [01:30<00:00, 90.49s/it]
  9%|▉         | 466/5198 [13:35:28<126:53:23, 96.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.44s/it][A100%|██████████| 1/1 [01:30<00:00, 90.44s/it]
  9%|▉         | 466/5198 [13:35:28<126:52:17, 96.52s/it]
100%|██████████| 1/1 [01:30<00:00, 90.50s/it][A100%|██████████| 1/1 [01:30<00:00, 90.50s/it]
  9%|▉         | 466/5198 [13:35:28<126:53:37, 96.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.49s/it][A100%|██████████| 1/1 [01:30<00:00, 90.49s/it]
  9%|▉         | 466/5198 [13:35:28<126:52:41, 96.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.49s/it][A100%|██████████| 1/1 [01:30<00:00, 90.49s/it]
  9%|▉         | 466/5198 [13:35:31<126:52:41, 96.53s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_437
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.08s/it][A100%|██████████| 1/1 [01:32<00:00, 92.08s/it]
  9%|▉         | 467/5198 [13:37:00<125:13:54, 95.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 09:02:05,670] [INFO] [logging.py:96:log_dist] [Rank 0] step=459, skipped=0, lr=[1.986775181507923e-05], mom=[(0.9, 0.999)]
steps: 459 loss: 0.5775 iter time (s): 91.332 samples/sec: 1.401

100%|██████████| 1/1 [01:32<00:00, 92.23s/it][A100%|██████████| 1/1 [01:32<00:00, 92.23s/it]
  9%|▉         | 467/5198 [13:37:00<125:09:46, 95.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.13s/it][A100%|██████████| 1/1 [01:32<00:00, 92.13s/it]
  9%|▉         | 467/5198 [13:37:00<125:07:05, 95.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.09s/it][A100%|██████████| 1/1 [01:32<00:00, 92.09s/it]
  9%|▉         | 467/5198 [13:37:00<125:06:52, 95.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.10s/it][A100%|██████████| 1/1 [01:32<00:00, 92.10s/it]
  9%|▉         | 467/5198 [13:37:00<125:07:10, 95.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.12s/it][A100%|██████████| 1/1 [01:32<00:00, 92.13s/it]
  9%|▉         | 467/5198 [13:37:00<125:06:55, 95.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.17s/it][A100%|██████████| 1/1 [01:32<00:00, 92.17s/it]
  9%|▉         | 467/5198 [13:37:03<125:08:07, 95.22s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_438

100%|██████████| 1/1 [01:32<00:00, 92.18s/it][A100%|██████████| 1/1 [01:32<00:00, 92.18s/it]
  9%|▉         | 467/5198 [13:37:01<125:08:23, 95.22s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.45s/it][A100%|██████████| 1/1 [01:44<00:00, 104.45s/it]
  9%|▉         | 468/5198 [13:38:44<128:56:10, 98.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 09:03:50,955] [INFO] [logging.py:96:log_dist] [Rank 0] step=460, skipped=0, lr=[1.98668321506377e-05], mom=[(0.9, 0.999)]
steps: 460 loss: 0.6290 iter time (s): 104.441 samples/sec: 1.226

100%|██████████| 1/1 [01:45<00:00, 105.18s/it][A100%|██████████| 1/1 [01:45<00:00, 105.18s/it]
  9%|▉         | 468/5198 [13:38:45<129:03:24, 98.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.30s/it][A100%|██████████| 1/1 [01:45<00:00, 105.30s/it]
  9%|▉         | 468/5198 [13:38:45<129:04:23, 98.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.31s/it][A100%|██████████| 1/1 [01:45<00:00, 105.31s/it]
  9%|▉         | 468/5198 [13:38:46<129:04:37, 98.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.32s/it][A100%|██████████| 1/1 [01:45<00:00, 105.32s/it]
  9%|▉         | 468/5198 [13:38:46<129:04:53, 98.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.39s/it][A100%|██████████| 1/1 [01:45<00:00, 105.39s/it]
  9%|▉         | 468/5198 [13:38:46<129:06:25, 98.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.32s/it][A100%|██████████| 1/1 [01:45<00:00, 105.32s/it]
  9%|▉         | 468/5198 [13:38:46<129:05:43, 98.25s/it]
100%|██████████| 1/1 [01:45<00:00, 105.33s/it][A100%|██████████| 1/1 [01:45<00:00, 105.33s/it]
  9%|▉         | 468/5198 [13:38:48<129:05:45, 98.25s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_439

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.90s/it][A100%|██████████| 1/1 [01:31<00:00, 91.90s/it]
  9%|▉         | 469/5198 [13:40:16<126:32:56, 96.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 09:05:22,753] [INFO] [logging.py:96:log_dist] [Rank 0] step=461, skipped=0, lr=[1.9865909320992317e-05], mom=[(0.9, 0.999)]
steps: 461 loss: 0.5822 iter time (s): 90.903 samples/sec: 1.408

100%|██████████| 1/1 [01:31<00:00, 91.77s/it][A100%|██████████| 1/1 [01:31<00:00, 91.77s/it]
  9%|▉         | 469/5198 [13:40:17<126:29:26, 96.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.75s/it][A100%|██████████| 1/1 [01:31<00:00, 91.75s/it]
  9%|▉         | 469/5198 [13:40:17<126:29:37, 96.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.75s/it][A100%|██████████| 1/1 [01:31<00:00, 91.75s/it]
  9%|▉         | 469/5198 [13:40:17<126:29:51, 96.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.69s/it][A100%|██████████| 1/1 [01:31<00:00, 91.69s/it]
  9%|▉         | 469/5198 [13:40:17<126:28:36, 96.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.67s/it][A100%|██████████| 1/1 [01:31<00:00, 91.67s/it]
  9%|▉         | 469/5198 [13:40:18<126:28:58, 96.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.67s/it][A100%|██████████| 1/1 [01:31<00:00, 91.67s/it]
  9%|▉         | 469/5198 [13:40:18<126:28:37, 96.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.69s/it][A100%|██████████| 1/1 [01:31<00:00, 91.69s/it]
  9%|▉         | 469/5198 [13:40:20<126:28:59, 96.29s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_440
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.09s/it][A100%|██████████| 1/1 [01:41<00:00, 101.09s/it]
  9%|▉         | 470/5198 [13:41:58<128:27:00, 97.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 09:07:04,233] [INFO] [logging.py:96:log_dist] [Rank 0] step=462, skipped=0, lr=[1.9864983326439143e-05], mom=[(0.9, 0.999)]
steps: 462 loss: 0.5476 iter time (s): 100.705 samples/sec: 1.271

100%|██████████| 1/1 [01:41<00:00, 101.46s/it][A100%|██████████| 1/1 [01:41<00:00, 101.46s/it]
  9%|▉         | 470/5198 [13:41:58<128:30:06, 97.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.55s/it][A100%|██████████| 1/1 [01:41<00:00, 101.55s/it]
  9%|▉         | 470/5198 [13:41:59<128:32:29, 97.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.50s/it][A100%|██████████| 1/1 [01:41<00:00, 101.50s/it]
  9%|▉         | 470/5198 [13:41:59<128:31:27, 97.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.53s/it][A100%|██████████| 1/1 [01:41<00:00, 101.53s/it]
  9%|▉         | 470/5198 [13:41:59<128:31:14, 97.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.47s/it][A100%|██████████| 1/1 [01:41<00:00, 101.47s/it]
  9%|▉         | 470/5198 [13:41:59<128:30:10, 97.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.46s/it][A100%|██████████| 1/1 [01:41<00:00, 101.46s/it]
  9%|▉         | 470/5198 [13:41:59<128:29:40, 97.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.47s/it][A100%|██████████| 1/1 [01:41<00:00, 101.47s/it]
  9%|▉         | 470/5198 [13:42:01<128:30:02, 97.84s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_441
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.86s/it][A100%|██████████| 1/1 [01:30<00:00, 90.86s/it]
  9%|▉         | 471/5198 [13:43:29<125:45:51, 95.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 09:08:34,995] [INFO] [logging.py:96:log_dist] [Rank 0] step=463, skipped=0, lr=[1.986405416727527e-05], mom=[(0.9, 0.999)]
steps: 463 loss: 0.6073 iter time (s): 89.976 samples/sec: 1.423

100%|██████████| 1/1 [01:30<00:00, 90.73s/it][A100%|██████████| 1/1 [01:30<00:00, 90.73s/it]
  9%|▉         | 471/5198 [13:43:29<125:40:36, 95.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.73s/it][A100%|██████████| 1/1 [01:30<00:00, 90.73s/it]
  9%|▉         | 471/5198 [13:43:29<125:42:20, 95.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.76s/it][A100%|██████████| 1/1 [01:30<00:00, 90.77s/it]
  9%|▉         | 471/5198 [13:43:30<125:42:17, 95.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.80s/it][A100%|██████████| 1/1 [01:30<00:00, 90.80s/it]
  9%|▉         | 471/5198 [13:43:30<125:43:03, 95.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.81s/it][A100%|██████████| 1/1 [01:30<00:00, 90.81s/it]
  9%|▉         | 471/5198 [13:43:30<125:42:25, 95.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.84s/it][A100%|██████████| 1/1 [01:30<00:00, 90.84s/it]
  9%|▉         | 471/5198 [13:43:30<125:42:44, 95.74s/it]
100%|██████████| 1/1 [01:30<00:00, 90.82s/it][A100%|██████████| 1/1 [01:30<00:00, 90.82s/it]
  9%|▉         | 471/5198 [13:43:32<125:42:31, 95.74s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_442

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.84s/it][A100%|██████████| 1/1 [01:27<00:00, 87.84s/it]
  9%|▉         | 472/5198 [13:44:57<122:40:41, 93.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 09:10:02,900] [INFO] [logging.py:96:log_dist] [Rank 0] step=464, skipped=0, lr=[1.9863121843798786e-05], mom=[(0.9, 0.999)]
steps: 464 loss: 0.5724 iter time (s): 87.060 samples/sec: 1.470

100%|██████████| 1/1 [01:27<00:00, 87.95s/it][A100%|██████████| 1/1 [01:27<00:00, 87.95s/it]
  9%|▉         | 472/5198 [13:44:57<122:35:50, 93.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.84s/it][A100%|██████████| 1/1 [01:27<00:00, 87.84s/it]
  9%|▉         | 472/5198 [13:44:57<122:34:38, 93.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.76s/it][A100%|██████████| 1/1 [01:27<00:00, 87.76s/it]
  9%|▉         | 472/5198 [13:44:57<122:32:31, 93.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.78s/it][A100%|██████████| 1/1 [01:27<00:00, 87.78s/it]
  9%|▉         | 472/5198 [13:44:58<122:33:23, 93.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.81s/it][A100%|██████████| 1/1 [01:27<00:00, 87.81s/it]
  9%|▉         | 472/5198 [13:44:58<122:33:42, 93.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.80s/it][A100%|██████████| 1/1 [01:27<00:00, 87.80s/it]
  9%|▉         | 472/5198 [13:44:58<122:33:39, 93.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.82s/it][A100%|██████████| 1/1 [01:27<00:00, 87.82s/it]
  9%|▉         | 472/5198 [13:45:00<122:33:53, 93.36s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_443
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.30s/it][A100%|██████████| 1/1 [01:19<00:00, 79.30s/it]
  9%|▉         | 473/5198 [13:46:16<117:09:21, 89.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 09:11:22,146] [INFO] [logging.py:96:log_dist] [Rank 0] step=465, skipped=0, lr=[1.9862186356308813e-05], mom=[(0.9, 0.999)]
steps: 465 loss: 0.5684 iter time (s): 78.479 samples/sec: 1.631

100%|██████████| 1/1 [01:19<00:00, 79.27s/it][A100%|██████████| 1/1 [01:19<00:00, 79.27s/it]
  9%|▉         | 473/5198 [13:46:16<117:00:53, 89.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.18s/it][A100%|██████████| 1/1 [01:19<00:00, 79.18s/it]
  9%|▉         | 473/5198 [13:46:16<116:57:58, 89.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.32s/it][A100%|██████████| 1/1 [01:19<00:00, 79.32s/it]
  9%|▉         | 473/5198 [13:46:17<116:59:52, 89.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.26s/it][A100%|██████████| 1/1 [01:19<00:00, 79.26s/it]
  9%|▉         | 473/5198 [13:46:17<116:59:01, 89.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.34s/it][A100%|██████████| 1/1 [01:19<00:00, 79.34s/it]
  9%|▉         | 473/5198 [13:46:17<117:01:02, 89.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.33s/it][A100%|██████████| 1/1 [01:19<00:00, 79.33s/it]
  9%|▉         | 473/5198 [13:46:17<117:00:48, 89.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.32s/it][A100%|██████████| 1/1 [01:19<00:00, 79.32s/it]
  9%|▉         | 473/5198 [13:46:19<117:00:40, 89.15s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_444
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.36s/it][A100%|██████████| 1/1 [01:30<00:00, 90.36s/it]
  9%|▉         | 474/5198 [13:47:47<117:37:44, 89.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 09:12:53,023] [INFO] [logging.py:96:log_dist] [Rank 0] step=466, skipped=0, lr=[1.986124770510547e-05], mom=[(0.9, 0.999)]
steps: 466 loss: 0.5860 iter time (s): 90.032 samples/sec: 1.422

100%|██████████| 1/1 [01:30<00:00, 90.97s/it][A100%|██████████| 1/1 [01:30<00:00, 90.97s/it]
  9%|▉         | 474/5198 [13:47:47<117:42:28, 89.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.99s/it][A100%|██████████| 1/1 [01:30<00:00, 90.99s/it]
  9%|▉         | 474/5198 [13:47:47<117:40:58, 89.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.93s/it][A100%|██████████| 1/1 [01:30<00:00, 90.93s/it]
  9%|▉         | 474/5198 [13:47:48<117:40:47, 89.68s/it]
100%|██████████| 1/1 [01:30<00:00, 90.86s/it][A100%|██████████| 1/1 [01:30<00:00, 90.86s/it]
  9%|▉         | 474/5198 [13:47:48<117:38:27, 89.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.87s/it][A100%|██████████| 1/1 [01:30<00:00, 90.87s/it]
  9%|▉         | 474/5198 [13:47:48<117:40:04, 89.67s/it]
100%|██████████| 1/1 [01:30<00:00, 90.90s/it][A100%|██████████| 1/1 [01:30<00:00, 90.90s/it]
  9%|▉         | 474/5198 [13:47:48<117:40:59, 89.68s/it]

  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.87s/it][A100%|██████████| 1/1 [01:30<00:00, 90.87s/it]
  9%|▉         | 474/5198 [13:47:50<117:39:59, 89.67s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_445
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.40s/it][A100%|██████████| 1/1 [01:54<00:00, 114.40s/it]
  9%|▉         | 475/5198 [13:49:41<127:25:12, 97.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 09:14:48,279] [INFO] [logging.py:96:log_dist] [Rank 0] step=467, skipped=0, lr=[1.9860305890489905e-05], mom=[(0.9, 0.999)]
steps: 467 loss: 0.5634 iter time (s): 114.412 samples/sec: 1.119

100%|██████████| 1/1 [01:55<00:00, 115.13s/it][A100%|██████████| 1/1 [01:55<00:00, 115.13s/it]
  9%|▉         | 475/5198 [13:49:42<127:41:47, 97.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.21s/it][A100%|██████████| 1/1 [01:55<00:00, 115.21s/it]
  9%|▉         | 475/5198 [13:49:43<127:42:36, 97.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.20s/it][A100%|██████████| 1/1 [01:55<00:00, 115.20s/it]
  9%|▉         | 475/5198 [13:49:43<127:42:05, 97.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.32s/it][A100%|██████████| 1/1 [01:55<00:00, 115.32s/it]
  9%|▉         | 475/5198 [13:49:43<127:43:24, 97.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.21s/it][A100%|██████████| 1/1 [01:55<00:00, 115.21s/it]
  9%|▉         | 475/5198 [13:49:43<127:42:30, 97.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.23s/it][A100%|██████████| 1/1 [01:55<00:00, 115.23s/it]
  9%|▉         | 475/5198 [13:49:43<127:42:22, 97.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.24s/it][A100%|██████████| 1/1 [01:55<00:00, 115.24s/it]
  9%|▉         | 475/5198 [13:49:45<127:42:25, 97.34s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_446
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.05s/it][A100%|██████████| 1/1 [01:25<00:00, 85.05s/it]
  9%|▉         | 476/5198 [13:51:07<122:44:53, 93.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 09:16:12,708] [INFO] [logging.py:96:log_dist] [Rank 0] step=468, skipped=0, lr=[1.985936091276427e-05], mom=[(0.9, 0.999)]
steps: 468 loss: 0.5677 iter time (s): 83.590 samples/sec: 1.531

100%|██████████| 1/1 [01:24<00:00, 84.46s/it][A100%|██████████| 1/1 [01:24<00:00, 84.46s/it]
  9%|▉         | 476/5198 [13:51:07<122:36:31, 93.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.39s/it][A100%|██████████| 1/1 [01:24<00:00, 84.39s/it]
  9%|▉         | 476/5198 [13:51:07<122:35:33, 93.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.36s/it][A100%|██████████| 1/1 [01:24<00:00, 84.37s/it]
  9%|▉         | 476/5198 [13:51:07<122:34:39, 93.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.39s/it][A100%|██████████| 1/1 [01:24<00:00, 84.39s/it]
  9%|▉         | 476/5198 [13:51:07<122:35:49, 93.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.38s/it][A100%|██████████| 1/1 [01:24<00:00, 84.38s/it]
  9%|▉         | 476/5198 [13:51:08<122:34:56, 93.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.40s/it][A100%|██████████| 1/1 [01:24<00:00, 84.40s/it]
  9%|▉         | 476/5198 [13:51:08<122:35:21, 93.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.40s/it][A100%|██████████| 1/1 [01:24<00:00, 84.40s/it]
  9%|▉         | 476/5198 [13:51:10<122:35:32, 93.46s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_447
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.91s/it][A100%|██████████| 1/1 [01:46<00:00, 106.91s/it]
  9%|▉         | 477/5198 [13:52:54<128:01:54, 97.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 09:18:00,457] [INFO] [logging.py:96:log_dist] [Rank 0] step=469, skipped=0, lr=[1.9858412772231748e-05], mom=[(0.9, 0.999)]
steps: 469 loss: 0.5335 iter time (s): 106.932 samples/sec: 1.197

100%|██████████| 1/1 [01:47<00:00, 107.60s/it][A100%|██████████| 1/1 [01:47<00:00, 107.60s/it]
  9%|▉         | 477/5198 [13:52:55<128:08:32, 97.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.73s/it][A100%|██████████| 1/1 [01:47<00:00, 107.73s/it]
  9%|▉         | 477/5198 [13:52:55<128:11:04, 97.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.77s/it][A100%|██████████| 1/1 [01:47<00:00, 107.77s/it]
  9%|▉         | 477/5198 [13:52:55<128:12:08, 97.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.94s/it][A100%|██████████| 1/1 [01:47<00:00, 107.94s/it]
  9%|▉         | 477/5198 [13:52:55<128:15:16, 97.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.78s/it][A100%|██████████| 1/1 [01:47<00:00, 107.79s/it]
  9%|▉         | 477/5198 [13:52:55<128:11:50, 97.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.85s/it][A100%|██████████| 1/1 [01:47<00:00, 107.85s/it]
  9%|▉         | 477/5198 [13:52:58<128:13:42, 97.78s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_448

100%|██████████| 1/1 [01:47<00:00, 107.87s/it][A100%|██████████| 1/1 [01:47<00:00, 107.87s/it]
  9%|▉         | 477/5198 [13:52:55<128:14:04, 97.79s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.31s/it][A100%|██████████| 1/1 [01:20<00:00, 80.31s/it]
  9%|▉         | 478/5198 [13:54:14<121:14:59, 92.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 09:19:20,145] [INFO] [logging.py:96:log_dist] [Rank 0] step=470, skipped=0, lr=[1.9857461469196517e-05], mom=[(0.9, 0.999)]
steps: 470 loss: 0.5709 iter time (s): 78.763 samples/sec: 1.625

100%|██████████| 1/1 [01:19<00:00, 79.73s/it][A100%|██████████| 1/1 [01:19<00:00, 79.73s/it]
  9%|▉         | 478/5198 [13:54:14<121:02:40, 92.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.64s/it][A100%|██████████| 1/1 [01:19<00:00, 79.64s/it]
  9%|▉         | 478/5198 [13:54:14<121:02:26, 92.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.54s/it][A100%|██████████| 1/1 [01:19<00:00, 79.54s/it]
  9%|▉         | 478/5198 [13:54:15<121:03:08, 92.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.61s/it][A100%|██████████| 1/1 [01:19<00:00, 79.61s/it]
  9%|▉         | 478/5198 [13:54:15<121:02:45, 92.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.58s/it][A100%|██████████| 1/1 [01:19<00:00, 79.58s/it]
  9%|▉         | 478/5198 [13:54:15<121:01:47, 92.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.53s/it][A100%|██████████| 1/1 [01:19<00:00, 79.53s/it]
  9%|▉         | 478/5198 [13:54:15<121:01:47, 92.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.55s/it][A100%|██████████| 1/1 [01:19<00:00, 79.55s/it]
  9%|▉         | 478/5198 [13:54:17<121:02:03, 92.31s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_449
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.65s/it][A100%|██████████| 1/1 [01:39<00:00, 99.66s/it]
  9%|▉         | 479/5198 [13:55:54<124:04:54, 94.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 09:21:00,462] [INFO] [logging.py:96:log_dist] [Rank 0] step=471, skipped=0, lr=[1.9856507003963777e-05], mom=[(0.9, 0.999)]
steps: 471 loss: 0.5591 iter time (s): 99.636 samples/sec: 1.285

100%|██████████| 1/1 [01:40<00:00, 100.46s/it][A100%|██████████| 1/1 [01:40<00:00, 100.46s/it]
  9%|▉         | 479/5198 [13:55:55<124:13:19, 94.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.40s/it][A100%|██████████| 1/1 [01:40<00:00, 100.40s/it]
  9%|▉         | 479/5198 [13:55:55<124:11:44, 94.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.39s/it][A100%|██████████| 1/1 [01:40<00:00, 100.40s/it]
  9%|▉         | 479/5198 [13:55:55<124:12:16, 94.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.38s/it][A100%|██████████| 1/1 [01:40<00:00, 100.38s/it]
  9%|▉         | 479/5198 [13:55:55<124:11:27, 94.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.38s/it][A100%|██████████| 1/1 [01:40<00:00, 100.38s/it]
  9%|▉         | 479/5198 [13:55:55<124:10:54, 94.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.37s/it][A100%|██████████| 1/1 [01:40<00:00, 100.37s/it]
  9%|▉         | 479/5198 [13:55:58<124:10:47, 94.73s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_29

100%|██████████| 1/1 [01:40<00:00, 100.39s/it][A100%|██████████| 1/1 [01:40<00:00, 100.39s/it]
  9%|▉         | 479/5198 [13:55:55<124:11:12, 94.74s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:04<00:00, 124.48s/it][A100%|██████████| 1/1 [02:04<00:00, 124.48s/it]
  9%|▉         | 480/5198 [13:57:59<135:51:31, 103.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 09:23:05,523] [INFO] [logging.py:96:log_dist] [Rank 0] step=472, skipped=0, lr=[1.9855549376839748e-05], mom=[(0.9, 0.999)]
steps: 472 loss: 0.7865 iter time (s): 124.442 samples/sec: 1.029

100%|██████████| 1/1 [02:05<00:00, 125.16s/it][A100%|██████████| 1/1 [02:05<00:00, 125.16s/it]
  9%|▉         | 480/5198 [13:58:00<136:09:03, 103.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:05<00:00, 125.14s/it][A100%|██████████| 1/1 [02:05<00:00, 125.14s/it]
  9%|▉         | 480/5198 [13:58:00<136:07:21, 103.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:05<00:00, 125.12s/it][A100%|██████████| 1/1 [02:05<00:00, 125.12s/it]
  9%|▉         | 480/5198 [13:58:00<136:07:10, 103.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:05<00:00, 125.22s/it][A100%|██████████| 1/1 [02:05<00:00, 125.22s/it]
  9%|▉         | 480/5198 [13:58:00<136:09:01, 103.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:05<00:00, 125.26s/it][A100%|██████████| 1/1 [02:05<00:00, 125.26s/it]
  9%|▉         | 480/5198 [13:58:01<136:09:41, 103.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:05<00:00, 125.21s/it][A100%|██████████| 1/1 [02:05<00:00, 125.21s/it]
  9%|▉         | 480/5198 [13:58:01<136:08:40, 103.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:05<00:00, 125.24s/it][A100%|██████████| 1/1 [02:05<00:00, 125.24s/it]
  9%|▉         | 480/5198 [13:58:03<136:09:06, 103.89s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_450
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.15s/it][A100%|██████████| 1/1 [01:27<00:00, 87.15s/it]
  9%|▉         | 481/5198 [13:59:26<129:24:53, 98.77s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 09:24:32,063] [INFO] [logging.py:96:log_dist] [Rank 0] step=473, skipped=0, lr=[1.9854588588131664e-05], mom=[(0.9, 0.999)]
steps: 473 loss: 0.6122 iter time (s): 85.511 samples/sec: 1.497

100%|██████████| 1/1 [01:26<00:00, 86.36s/it][A100%|██████████| 1/1 [01:26<00:00, 86.36s/it]
  9%|▉         | 481/5198 [13:59:26<129:14:04, 98.63s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.36s/it][A100%|██████████| 1/1 [01:26<00:00, 86.36s/it]
  9%|▉         | 481/5198 [13:59:26<129:12:57, 98.62s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.37s/it][A100%|██████████| 1/1 [01:26<00:00, 86.37s/it]
  9%|▉         | 481/5198 [13:59:27<129:14:21, 98.64s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.51s/it][A100%|██████████| 1/1 [01:26<00:00, 86.51s/it]
  9%|▉         | 481/5198 [13:59:27<129:16:26, 98.66s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.39s/it][A100%|██████████| 1/1 [01:26<00:00, 86.39s/it]
  9%|▉         | 481/5198 [13:59:27<129:14:32, 98.64s/it] 
100%|██████████| 1/1 [01:26<00:00, 86.41s/it][A100%|██████████| 1/1 [01:26<00:00, 86.41s/it]
  9%|▉         | 481/5198 [13:59:27<129:15:43, 98.65s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.39s/it][A100%|██████████| 1/1 [01:26<00:00, 86.39s/it]
  9%|▉         | 481/5198 [13:59:29<129:14:47, 98.64s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_451
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.51s/it][A100%|██████████| 1/1 [01:26<00:00, 86.51s/it]
  9%|▉         | 482/5198 [14:00:53<124:37:57, 95.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 09:25:58,777] [INFO] [logging.py:96:log_dist] [Rank 0] step=474, skipped=0, lr=[1.9853624638147766e-05], mom=[(0.9, 0.999)]
steps: 474 loss: 0.5689 iter time (s): 85.848 samples/sec: 1.491

100%|██████████| 1/1 [01:26<00:00, 86.64s/it][A100%|██████████| 1/1 [01:26<00:00, 86.64s/it]
  9%|▉         | 482/5198 [14:00:53<124:29:21, 95.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.71s/it][A100%|██████████| 1/1 [01:26<00:00, 86.71s/it]
  9%|▉         | 482/5198 [14:00:53<124:31:32, 95.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.55s/it][A100%|██████████| 1/1 [01:26<00:00, 86.55s/it]
  9%|▉         | 482/5198 [14:00:53<124:29:23, 95.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.60s/it][A100%|██████████| 1/1 [01:26<00:00, 86.60s/it]
  9%|▉         | 482/5198 [14:00:53<124:29:01, 95.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.55s/it][A100%|██████████| 1/1 [01:26<00:00, 86.55s/it]
  9%|▉         | 482/5198 [14:00:54<124:28:58, 95.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.60s/it][A100%|██████████| 1/1 [01:26<00:00, 86.60s/it]
  9%|▉         | 482/5198 [14:00:54<124:29:15, 95.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.59s/it][A100%|██████████| 1/1 [01:26<00:00, 86.59s/it]
  9%|▉         | 482/5198 [14:00:56<124:29:11, 95.03s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_452
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.54s/it][A100%|██████████| 1/1 [01:25<00:00, 85.54s/it]
  9%|▉         | 483/5198 [14:02:18<120:53:59, 92.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 09:27:24,468] [INFO] [logging.py:96:log_dist] [Rank 0] step=475, skipped=0, lr=[1.985265752719731e-05], mom=[(0.9, 0.999)]
steps: 475 loss: 0.6533 iter time (s): 84.904 samples/sec: 1.508

100%|██████████| 1/1 [01:25<00:00, 85.66s/it][A100%|██████████| 1/1 [01:25<00:00, 85.66s/it]
  9%|▉         | 483/5198 [14:02:19<120:48:38, 92.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.76s/it][A100%|██████████| 1/1 [01:25<00:00, 85.76s/it]
  9%|▉         | 483/5198 [14:02:19<120:49:31, 92.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.68s/it][A100%|██████████| 1/1 [01:25<00:00, 85.69s/it]
  9%|▉         | 483/5198 [14:02:19<120:47:49, 92.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.71s/it][A100%|██████████| 1/1 [01:25<00:00, 85.71s/it]
  9%|▉         | 483/5198 [14:02:19<120:48:03, 92.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.73s/it][A100%|██████████| 1/1 [01:25<00:00, 85.73s/it]
  9%|▉         | 483/5198 [14:02:19<120:48:26, 92.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.74s/it][A100%|██████████| 1/1 [01:25<00:00, 85.74s/it]
  9%|▉         | 483/5198 [14:02:19<120:48:46, 92.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.74s/it][A100%|██████████| 1/1 [01:25<00:00, 85.74s/it]
  9%|▉         | 483/5198 [14:02:22<120:48:50, 92.24s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_453
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.38s/it][A100%|██████████| 1/1 [01:26<00:00, 86.38s/it]
  9%|▉         | 484/5198 [14:03:45<118:36:13, 90.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 09:28:51,012] [INFO] [logging.py:96:log_dist] [Rank 0] step=476, skipped=0, lr=[1.985168725559058e-05], mom=[(0.9, 0.999)]
steps: 476 loss: 0.5875 iter time (s): 85.701 samples/sec: 1.494

100%|██████████| 1/1 [01:26<00:00, 86.46s/it][A100%|██████████| 1/1 [01:26<00:00, 86.46s/it]
  9%|▉         | 484/5198 [14:03:45<118:30:59, 90.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.47s/it][A100%|██████████| 1/1 [01:26<00:00, 86.47s/it]
  9%|▉         | 484/5198 [14:03:45<118:31:58, 90.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.46s/it][A100%|██████████| 1/1 [01:26<00:00, 86.46s/it]
  9%|▉         | 484/5198 [14:03:46<118:30:39, 90.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.50s/it][A100%|██████████| 1/1 [01:26<00:00, 86.50s/it]
  9%|▉         | 484/5198 [14:03:46<118:31:29, 90.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.44s/it][A100%|██████████| 1/1 [01:26<00:00, 86.44s/it]
  9%|▉         | 484/5198 [14:03:46<118:30:26, 90.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.47s/it][A100%|██████████| 1/1 [01:26<00:00, 86.47s/it]
  9%|▉         | 484/5198 [14:03:46<118:31:20, 90.51s/it]
100%|██████████| 1/1 [01:26<00:00, 86.45s/it][A100%|██████████| 1/1 [01:26<00:00, 86.45s/it]
  9%|▉         | 484/5198 [14:03:48<118:31:00, 90.51s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_454

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 86.00s/it][A100%|██████████| 1/1 [01:25<00:00, 86.00s/it]
  9%|▉         | 485/5198 [14:05:11<116:50:47, 89.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 09:30:17,176] [INFO] [logging.py:96:log_dist] [Rank 0] step=477, skipped=0, lr=[1.985071382363885e-05], mom=[(0.9, 0.999)]
steps: 477 loss: 0.5941 iter time (s): 85.404 samples/sec: 1.499

100%|██████████| 1/1 [01:26<00:00, 86.09s/it][A100%|██████████| 1/1 [01:26<00:00, 86.09s/it]
  9%|▉         | 485/5198 [14:05:11<116:45:41, 89.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.21s/it][A100%|██████████| 1/1 [01:26<00:00, 86.21s/it]
  9%|▉         | 485/5198 [14:05:11<116:49:04, 89.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.18s/it][A100%|██████████| 1/1 [01:26<00:00, 86.18s/it]
  9%|▉         | 485/5198 [14:05:12<116:47:30, 89.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.26s/it][A100%|██████████| 1/1 [01:26<00:00, 86.26s/it]
  9%|▉         | 485/5198 [14:05:12<116:49:50, 89.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.26s/it][A100%|██████████| 1/1 [01:26<00:00, 86.26s/it]
  9%|▉         | 485/5198 [14:05:12<116:49:11, 89.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.21s/it][A100%|██████████| 1/1 [01:26<00:00, 86.21s/it]
  9%|▉         | 485/5198 [14:05:12<116:48:35, 89.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.23s/it][A100%|██████████| 1/1 [01:26<00:00, 86.23s/it]
  9%|▉         | 485/5198 [14:05:14<116:48:42, 89.23s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_455
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.75s/it][A100%|██████████| 1/1 [01:27<00:00, 87.75s/it]
  9%|▉         | 486/5198 [14:06:39<116:17:58, 88.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 09:31:45,148] [INFO] [logging.py:96:log_dist] [Rank 0] step=478, skipped=0, lr=[1.9849737231654426e-05], mom=[(0.9, 0.999)]
steps: 478 loss: 0.5734 iter time (s): 87.139 samples/sec: 1.469

100%|██████████| 1/1 [01:28<00:00, 88.08s/it][A100%|██████████| 1/1 [01:28<00:00, 88.08s/it]
  9%|▉         | 486/5198 [14:06:39<116:18:19, 88.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.92s/it][A100%|██████████| 1/1 [01:27<00:00, 87.92s/it]
  9%|▉         | 486/5198 [14:06:39<116:16:55, 88.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.95s/it][A100%|██████████| 1/1 [01:27<00:00, 87.95s/it]
  9%|▉         | 486/5198 [14:06:40<116:16:30, 88.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.94s/it][A100%|██████████| 1/1 [01:27<00:00, 87.94s/it]
  9%|▉         | 486/5198 [14:06:40<116:17:51, 88.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.93s/it][A100%|██████████| 1/1 [01:27<00:00, 87.93s/it]
  9%|▉         | 486/5198 [14:06:40<116:17:17, 88.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.92s/it][A100%|██████████| 1/1 [01:27<00:00, 87.92s/it]
  9%|▉         | 486/5198 [14:06:40<116:16:30, 88.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.91s/it][A100%|██████████| 1/1 [01:27<00:00, 87.91s/it]
  9%|▉         | 486/5198 [14:06:42<116:16:25, 88.83s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_456
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.33s/it][A100%|██████████| 1/1 [01:40<00:00, 100.33s/it]
  9%|▉         | 487/5198 [14:08:19<120:51:43, 92.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 09:33:26,039] [INFO] [logging.py:96:log_dist] [Rank 0] step=479, skipped=0, lr=[1.9848757479950624e-05], mom=[(0.9, 0.999)]
steps: 479 loss: 0.5759 iter time (s): 100.176 samples/sec: 1.278

100%|██████████| 1/1 [01:40<00:00, 100.91s/it][A100%|██████████| 1/1 [01:40<00:00, 100.91s/it]
  9%|▉         | 487/5198 [14:08:20<121:00:58, 92.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.99s/it][A100%|██████████| 1/1 [01:40<00:00, 100.99s/it]
  9%|▉         | 487/5198 [14:08:20<121:01:49, 92.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.02s/it][A100%|██████████| 1/1 [01:41<00:00, 101.02s/it]
  9%|▉         | 487/5198 [14:08:21<121:02:15, 92.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.96s/it][A100%|██████████| 1/1 [01:40<00:00, 100.96s/it]
  9%|▉         | 487/5198 [14:08:21<121:01:46, 92.49s/it]
100%|██████████| 1/1 [01:40<00:00, 100.93s/it][A100%|██████████| 1/1 [01:40<00:00, 100.93s/it]
  9%|▉         | 487/5198 [14:08:21<121:00:40, 92.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 101.00s/it][A100%|██████████| 1/1 [01:40<00:00, 101.00s/it]
  9%|▉         | 487/5198 [14:08:21<121:01:44, 92.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.00s/it][A100%|██████████| 1/1 [01:41<00:00, 101.00s/it]
  9%|▉         | 487/5198 [14:08:23<121:01:46, 92.49s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_457
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.08s/it][A100%|██████████| 1/1 [01:29<00:00, 89.08s/it]
  9%|▉         | 488/5198 [14:09:49<119:37:56, 91.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 09:34:55,025] [INFO] [logging.py:96:log_dist] [Rank 0] step=480, skipped=0, lr=[1.9847774568841773e-05], mom=[(0.9, 0.999)]
steps: 480 loss: 0.5729 iter time (s): 88.093 samples/sec: 1.453

100%|██████████| 1/1 [01:28<00:00, 88.90s/it][A100%|██████████| 1/1 [01:28<00:00, 88.90s/it]
  9%|▉         | 488/5198 [14:09:49<119:35:35, 91.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.93s/it][A100%|██████████| 1/1 [01:28<00:00, 88.93s/it]
  9%|▉         | 488/5198 [14:09:49<119:36:50, 91.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.82s/it][A100%|██████████| 1/1 [01:28<00:00, 88.82s/it]
  9%|▉         | 488/5198 [14:09:50<119:34:23, 91.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.88s/it][A100%|██████████| 1/1 [01:28<00:00, 88.88s/it]
  9%|▉         | 488/5198 [14:09:50<119:35:22, 91.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.88s/it][A100%|██████████| 1/1 [01:28<00:00, 88.88s/it]
  9%|▉         | 488/5198 [14:09:50<119:34:47, 91.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.88s/it][A100%|██████████| 1/1 [01:28<00:00, 88.88s/it]
  9%|▉         | 488/5198 [14:09:50<119:35:31, 91.41s/it]
100%|██████████| 1/1 [01:28<00:00, 88.87s/it][A100%|██████████| 1/1 [01:28<00:00, 88.87s/it]
  9%|▉         | 488/5198 [14:09:52<119:35:13, 91.40s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_458

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.01s/it][A100%|██████████| 1/1 [01:34<00:00, 94.01s/it]
  9%|▉         | 489/5198 [14:11:23<120:41:18, 92.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 09:36:29,334] [INFO] [logging.py:96:log_dist] [Rank 0] step=481, skipped=0, lr=[1.9846788498643216e-05], mom=[(0.9, 0.999)]
steps: 481 loss: 0.5735 iter time (s): 93.538 samples/sec: 1.368

100%|██████████| 1/1 [01:34<00:00, 94.38s/it][A100%|██████████| 1/1 [01:34<00:00, 94.38s/it]
  9%|▉         | 489/5198 [14:11:24<120:44:15, 92.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.31s/it][A100%|██████████| 1/1 [01:34<00:00, 94.31s/it]
  9%|▉         | 489/5198 [14:11:24<120:43:25, 92.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.39s/it][A100%|██████████| 1/1 [01:34<00:00, 94.39s/it]
  9%|▉         | 489/5198 [14:11:24<120:43:36, 92.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.36s/it][A100%|██████████| 1/1 [01:34<00:00, 94.36s/it]
  9%|▉         | 489/5198 [14:11:24<120:43:29, 92.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.40s/it][A100%|██████████| 1/1 [01:34<00:00, 94.40s/it]
  9%|▉         | 489/5198 [14:11:24<120:44:16, 92.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.35s/it][A100%|██████████| 1/1 [01:34<00:00, 94.35s/it]
  9%|▉         | 489/5198 [14:11:24<120:43:24, 92.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.37s/it][A100%|██████████| 1/1 [01:34<00:00, 94.37s/it]
  9%|▉         | 489/5198 [14:11:26<120:43:38, 92.30s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_459
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.19s/it][A100%|██████████| 1/1 [01:29<00:00, 89.19s/it]
  9%|▉         | 490/5198 [14:12:52<119:33:41, 91.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 09:37:58,656] [INFO] [logging.py:96:log_dist] [Rank 0] step=482, skipped=0, lr=[1.984579926967131e-05], mom=[(0.9, 0.999)]
steps: 482 loss: 0.6035 iter time (s): 88.469 samples/sec: 1.447

100%|██████████| 1/1 [01:29<00:00, 89.17s/it][A100%|██████████| 1/1 [01:29<00:00, 89.17s/it]
  9%|▉         | 490/5198 [14:12:53<119:29:09, 91.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.21s/it][A100%|██████████| 1/1 [01:29<00:00, 89.21s/it]
  9%|▉         | 490/5198 [14:12:53<119:29:33, 91.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.18s/it][A100%|██████████| 1/1 [01:29<00:00, 89.18s/it]
  9%|▉         | 490/5198 [14:12:53<119:28:56, 91.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.23s/it][A100%|██████████| 1/1 [01:29<00:00, 89.23s/it]
  9%|▉         | 490/5198 [14:12:53<119:29:59, 91.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.22s/it][A100%|██████████| 1/1 [01:29<00:00, 89.22s/it]
  9%|▉         | 490/5198 [14:12:53<119:30:16, 91.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.25s/it][A100%|██████████| 1/1 [01:29<00:00, 89.25s/it]
  9%|▉         | 490/5198 [14:12:54<119:30:24, 91.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.24s/it][A100%|██████████| 1/1 [01:29<00:00, 89.24s/it]
  9%|▉         | 490/5198 [14:12:56<119:30:24, 91.38s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_460
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.32s/it][A100%|██████████| 1/1 [01:29<00:00, 89.32s/it]
  9%|▉         | 491/5198 [14:14:22<118:46:44, 90.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 09:39:28,170] [INFO] [logging.py:96:log_dist] [Rank 0] step=483, skipped=0, lr=[1.984480688224342e-05], mom=[(0.9, 0.999)]
steps: 483 loss: 0.5571 iter time (s): 88.734 samples/sec: 1.443

100%|██████████| 1/1 [01:29<00:00, 89.52s/it][A100%|██████████| 1/1 [01:29<00:00, 89.52s/it]
  9%|▉         | 491/5198 [14:14:22<118:44:34, 90.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.57s/it][A100%|██████████| 1/1 [01:29<00:00, 89.57s/it]
  9%|▉         | 491/5198 [14:14:22<118:45:57, 90.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.53s/it][A100%|██████████| 1/1 [01:29<00:00, 89.53s/it]
  9%|▉         | 491/5198 [14:14:23<118:44:36, 90.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.52s/it][A100%|██████████| 1/1 [01:29<00:00, 89.52s/it]
  9%|▉         | 491/5198 [14:14:23<118:44:59, 90.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.53s/it][A100%|██████████| 1/1 [01:29<00:00, 89.53s/it]
  9%|▉         | 491/5198 [14:14:23<118:45:18, 90.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.52s/it][A100%|██████████| 1/1 [01:29<00:00, 89.52s/it]
  9%|▉         | 491/5198 [14:14:23<118:45:13, 90.83s/it]
100%|██████████| 1/1 [01:29<00:00, 89.51s/it][A100%|██████████| 1/1 [01:29<00:00, 89.51s/it]
  9%|▉         | 491/5198 [14:14:25<118:45:04, 90.82s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_461

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.23s/it][A100%|██████████| 1/1 [01:20<00:00, 80.23s/it]
  9%|▉         | 492/5198 [14:15:42<114:40:47, 87.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 09:40:48,322] [INFO] [logging.py:96:log_dist] [Rank 0] step=484, skipped=0, lr=[1.984381133667793e-05], mom=[(0.9, 0.999)]
steps: 484 loss: 0.6133 iter time (s): 79.367 samples/sec: 1.613

100%|██████████| 1/1 [01:20<00:00, 80.11s/it][A100%|██████████| 1/1 [01:20<00:00, 80.11s/it]
  9%|▉         | 492/5198 [14:15:42<114:31:21, 87.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.05s/it][A100%|██████████| 1/1 [01:20<00:00, 80.05s/it]
  9%|▉         | 492/5198 [14:15:42<114:30:56, 87.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.09s/it][A100%|██████████| 1/1 [01:20<00:00, 80.09s/it]
  9%|▉         | 492/5198 [14:15:43<114:30:58, 87.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.08s/it][A100%|██████████| 1/1 [01:20<00:00, 80.08s/it]
  9%|▉         | 492/5198 [14:15:43<114:30:59, 87.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.12s/it][A100%|██████████| 1/1 [01:20<00:00, 80.12s/it]
  9%|▉         | 492/5198 [14:15:43<114:32:04, 87.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.08s/it][A100%|██████████| 1/1 [01:20<00:00, 80.08s/it]
  9%|▉         | 492/5198 [14:15:45<114:31:00, 87.60s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_462
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.10s/it][A100%|██████████| 1/1 [01:20<00:00, 80.10s/it]
  9%|▉         | 492/5198 [14:15:43<114:31:30, 87.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.42s/it][A100%|██████████| 1/1 [01:50<00:00, 110.42s/it]
  9%|▉         | 493/5198 [14:17:33<123:36:43, 94.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 09:42:39,805] [INFO] [logging.py:96:log_dist] [Rank 0] step=485, skipped=0, lr=[1.9842812633294234e-05], mom=[(0.9, 0.999)]
steps: 485 loss: 0.5619 iter time (s): 110.757 samples/sec: 1.156

100%|██████████| 1/1 [01:51<00:00, 111.53s/it][A100%|██████████| 1/1 [01:51<00:00, 111.53s/it]
  9%|▉         | 493/5198 [14:17:34<123:52:54, 94.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.58s/it][A100%|██████████| 1/1 [01:51<00:00, 111.58s/it]
  9%|▉         | 493/5198 [14:17:34<123:53:43, 94.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.58s/it][A100%|██████████| 1/1 [01:51<00:00, 111.58s/it]
  9%|▉         | 493/5198 [14:17:34<123:53:45, 94.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.59s/it][A100%|██████████| 1/1 [01:51<00:00, 111.59s/it]
  9%|▉         | 493/5198 [14:17:35<123:54:03, 94.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.54s/it][A100%|██████████| 1/1 [01:51<00:00, 111.54s/it]
  9%|▉         | 493/5198 [14:17:35<123:53:38, 94.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.54s/it][A100%|██████████| 1/1 [01:51<00:00, 111.54s/it]
  9%|▉         | 493/5198 [14:17:35<123:53:09, 94.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.56s/it][A100%|██████████| 1/1 [01:51<00:00, 111.56s/it]
  9%|▉         | 493/5198 [14:17:37<123:53:21, 94.79s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_463
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.76s/it][A100%|██████████| 1/1 [01:33<00:00, 93.76s/it]
 10%|▉         | 494/5198 [14:19:07<123:21:54, 94.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 09:44:13,301] [INFO] [logging.py:96:log_dist] [Rank 0] step=486, skipped=0, lr=[1.984181077241274e-05], mom=[(0.9, 0.999)]
steps: 486 loss: 0.5691 iter time (s): 92.682 samples/sec: 1.381

100%|██████████| 1/1 [01:33<00:00, 93.52s/it][A100%|██████████| 1/1 [01:33<00:00, 93.52s/it]
 10%|▉         | 494/5198 [14:19:07<123:21:38, 94.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.51s/it][A100%|██████████| 1/1 [01:33<00:00, 93.51s/it]
 10%|▉         | 494/5198 [14:19:08<123:22:08, 94.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.50s/it][A100%|██████████| 1/1 [01:33<00:00, 93.50s/it]
 10%|▉         | 494/5198 [14:19:08<123:22:07, 94.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.45s/it][A100%|██████████| 1/1 [01:33<00:00, 93.45s/it]
 10%|▉         | 494/5198 [14:19:08<123:20:53, 94.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.47s/it][A100%|██████████| 1/1 [01:33<00:00, 93.47s/it]
 10%|▉         | 494/5198 [14:19:08<123:21:10, 94.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.48s/it][A100%|██████████| 1/1 [01:33<00:00, 93.49s/it]
 10%|▉         | 494/5198 [14:19:08<123:21:05, 94.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.49s/it][A100%|██████████| 1/1 [01:33<00:00, 93.49s/it]
 10%|▉         | 494/5198 [14:19:10<123:21:17, 94.40s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_464
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.08s/it][A100%|██████████| 1/1 [01:28<00:00, 88.08s/it]
 10%|▉         | 495/5198 [14:20:35<120:55:13, 92.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 09:45:41,416] [INFO] [logging.py:96:log_dist] [Rank 0] step=487, skipped=0, lr=[1.984080575435488e-05], mom=[(0.9, 0.999)]
steps: 487 loss: 0.5947 iter time (s): 87.303 samples/sec: 1.466

100%|██████████| 1/1 [01:28<00:00, 88.04s/it][A100%|██████████| 1/1 [01:28<00:00, 88.04s/it]
 10%|▉         | 495/5198 [14:20:35<120:50:35, 92.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.08s/it][A100%|██████████| 1/1 [01:28<00:00, 88.08s/it]
 10%|▉         | 495/5198 [14:20:36<120:51:50, 92.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.06s/it][A100%|██████████| 1/1 [01:28<00:00, 88.06s/it]
 10%|▉         | 495/5198 [14:20:36<120:51:15, 92.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.07s/it][A100%|██████████| 1/1 [01:28<00:00, 88.07s/it]
 10%|▉         | 495/5198 [14:20:36<120:50:43, 92.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.06s/it][A100%|██████████| 1/1 [01:28<00:00, 88.06s/it]
 10%|▉         | 495/5198 [14:20:36<120:50:33, 92.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.09s/it][A100%|██████████| 1/1 [01:28<00:00, 88.09s/it]
 10%|▉         | 495/5198 [14:20:36<120:51:23, 92.51s/it]
100%|██████████| 1/1 [01:28<00:00, 88.08s/it][A100%|██████████| 1/1 [01:28<00:00, 88.08s/it]
 10%|▉         | 495/5198 [14:20:39<120:51:15, 92.51s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_30

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:05<00:00, 125.79s/it][A100%|██████████| 1/1 [02:05<00:00, 125.79s/it]
 10%|▉         | 496/5198 [14:22:41<133:58:08, 102.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 09:47:48,099] [INFO] [logging.py:96:log_dist] [Rank 0] step=488, skipped=0, lr=[1.9839797579443077e-05], mom=[(0.9, 0.999)]
steps: 488 loss: 0.8658 iter time (s): 126.200 samples/sec: 1.014

100%|██████████| 1/1 [02:07<00:00, 127.29s/it][A100%|██████████| 1/1 [02:07<00:00, 127.29s/it]
 10%|▉         | 496/5198 [14:22:43<134:27:08, 102.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:07<00:00, 127.18s/it][A100%|██████████| 1/1 [02:07<00:00, 127.18s/it]
 10%|▉         | 496/5198 [14:22:43<134:25:38, 102.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:07<00:00, 127.21s/it][A100%|██████████| 1/1 [02:07<00:00, 127.21s/it]
 10%|▉         | 496/5198 [14:22:43<134:25:43, 102.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:07<00:00, 127.20s/it][A100%|██████████| 1/1 [02:07<00:00, 127.20s/it]
 10%|▉         | 496/5198 [14:22:43<134:25:04, 102.91s/it]
100%|██████████| 1/1 [02:07<00:00, 127.26s/it][A100%|██████████| 1/1 [02:07<00:00, 127.26s/it]
 10%|▉         | 496/5198 [14:22:43<134:26:33, 102.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:07<00:00, 127.17s/it][A100%|██████████| 1/1 [02:07<00:00, 127.17s/it]
 10%|▉         | 496/5198 [14:22:46<134:24:40, 102.91s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_465
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:07<00:00, 127.19s/it][A100%|██████████| 1/1 [02:07<00:00, 127.19s/it]
 10%|▉         | 496/5198 [14:22:43<134:25:15, 102.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:14<00:00, 134.66s/it][A100%|██████████| 1/1 [02:14<00:00, 134.66s/it]
 10%|▉         | 497/5198 [14:24:56<146:35:55, 112.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 09:50:03,436] [INFO] [logging.py:96:log_dist] [Rank 0] step=489, skipped=0, lr=[1.9838786248000787e-05], mom=[(0.9, 0.999)]
steps: 489 loss: 0.5768 iter time (s): 134.064 samples/sec: 0.955

100%|██████████| 1/1 [02:14<00:00, 134.82s/it][A100%|██████████| 1/1 [02:14<00:00, 134.82s/it]
 10%|▉         | 497/5198 [14:24:58<146:54:51, 112.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:14<00:00, 134.83s/it][A100%|██████████| 1/1 [02:14<00:00, 134.83s/it]
 10%|▉         | 497/5198 [14:24:58<146:54:09, 112.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:14<00:00, 134.79s/it][A100%|██████████| 1/1 [02:14<00:00, 134.79s/it]
 10%|▉         | 497/5198 [14:24:58<146:53:11, 112.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:14<00:00, 134.78s/it][A100%|██████████| 1/1 [02:14<00:00, 134.78s/it]
 10%|▉         | 497/5198 [14:24:58<146:52:38, 112.48s/it]
100%|██████████| 1/1 [02:14<00:00, 134.78s/it][A100%|██████████| 1/1 [02:14<00:00, 134.78s/it]
 10%|▉         | 497/5198 [14:24:58<146:53:39, 112.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:14<00:00, 134.82s/it][A100%|██████████| 1/1 [02:14<00:00, 134.82s/it]
 10%|▉         | 497/5198 [14:24:58<146:53:32, 112.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:14<00:00, 134.84s/it][A100%|██████████| 1/1 [02:14<00:00, 134.84s/it]
 10%|▉         | 497/5198 [14:25:01<146:53:43, 112.49s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_466
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.18s/it][A100%|██████████| 1/1 [01:31<00:00, 91.18s/it]
 10%|▉         | 498/5198 [14:26:27<138:23:08, 106.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 09:51:33,652] [INFO] [logging.py:96:log_dist] [Rank 0] step=490, skipped=0, lr=[1.9837771760352463e-05], mom=[(0.9, 0.999)]
steps: 490 loss: 0.5583 iter time (s): 89.422 samples/sec: 1.431

100%|██████████| 1/1 [01:30<00:00, 90.11s/it][A100%|██████████| 1/1 [01:30<00:00, 90.11s/it]
 10%|▉         | 498/5198 [14:26:28<138:07:00, 105.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.18s/it][A100%|██████████| 1/1 [01:30<00:00, 90.18s/it]
 10%|▉         | 498/5198 [14:26:28<138:08:13, 105.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.31s/it][A100%|██████████| 1/1 [01:30<00:00, 90.31s/it]
 10%|▉         | 498/5198 [14:26:28<138:10:23, 105.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.24s/it][A100%|██████████| 1/1 [01:30<00:00, 90.24s/it]
 10%|▉         | 498/5198 [14:26:28<138:08:23, 105.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.25s/it][A100%|██████████| 1/1 [01:30<00:00, 90.25s/it]
 10%|▉         | 498/5198 [14:26:28<138:09:14, 105.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.22s/it][A100%|██████████| 1/1 [01:30<00:00, 90.22s/it]
 10%|▉         | 498/5198 [14:26:29<138:08:34, 105.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.24s/it][A100%|██████████| 1/1 [01:30<00:00, 90.24s/it]
 10%|▉         | 498/5198 [14:26:31<138:09:09, 105.82s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_467
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.16s/it][A100%|██████████| 1/1 [01:53<00:00, 113.16s/it]
 10%|▉         | 499/5198 [14:28:21<141:14:22, 108.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 09:53:27,640] [INFO] [logging.py:96:log_dist] [Rank 0] step=491, skipped=0, lr=[1.983675411682358e-05], mom=[(0.9, 0.999)]
steps: 491 loss: 0.6006 iter time (s): 113.164 samples/sec: 1.131

100%|██████████| 1/1 [01:53<00:00, 113.91s/it][A100%|██████████| 1/1 [01:53<00:00, 113.91s/it]
 10%|▉         | 499/5198 [14:28:22<141:16:15, 108.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.00s/it][A100%|██████████| 1/1 [01:54<00:00, 114.00s/it]
 10%|▉         | 499/5198 [14:28:22<141:19:16, 108.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.92s/it][A100%|██████████| 1/1 [01:53<00:00, 113.92s/it]
 10%|▉         | 499/5198 [14:28:22<141:18:42, 108.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.88s/it][A100%|██████████| 1/1 [01:53<00:00, 113.88s/it]
 10%|▉         | 499/5198 [14:28:22<141:17:00, 108.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.98s/it][A100%|██████████| 1/1 [01:53<00:00, 113.98s/it]
 10%|▉         | 499/5198 [14:28:22<141:18:53, 108.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.94s/it][A100%|██████████| 1/1 [01:53<00:00, 113.94s/it]
 10%|▉         | 499/5198 [14:28:22<141:18:01, 108.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.94s/it][A100%|██████████| 1/1 [01:53<00:00, 113.94s/it]
 10%|▉         | 499/5198 [14:28:25<141:18:19, 108.26s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_468
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.62s/it][A100%|██████████| 1/1 [01:32<00:00, 92.62s/it]
[2024-06-30 09:54:59,983] [INFO] [logging.py:96:log_dist] [Rank 0] step=492, skipped=0, lr=[1.9835733317740626e-05], mom=[(0.9, 0.999)]
steps: 492 loss: 0.5860 iter time (s): 91.559 samples/sec: 1.398

100%|██████████| 1/1 [01:32<00:00, 92.44s/it][A100%|██████████| 1/1 [01:32<00:00, 92.44s/it]

100%|██████████| 1/1 [01:32<00:00, 92.26s/it][A100%|██████████| 1/1 [01:32<00:00, 92.26s/it]

100%|██████████| 1/1 [01:32<00:00, 92.33s/it][A100%|██████████| 1/1 [01:32<00:00, 92.33s/it]

100%|██████████| 1/1 [01:32<00:00, 92.46s/it][A100%|██████████| 1/1 [01:32<00:00, 92.46s/it]

100%|██████████| 1/1 [01:32<00:00, 92.43s/it][A100%|██████████| 1/1 [01:32<00:00, 92.43s/it]

100%|██████████| 1/1 [01:32<00:00, 92.46s/it][A100%|██████████| 1/1 [01:32<00:00, 92.46s/it]

100%|██████████| 1/1 [01:32<00:00, 92.46s/it][A100%|██████████| 1/1 [01:32<00:00, 92.46s/it]
Checkpointing at shard 499
[2024-06-30 09:55:00,874] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step492 is about to be saved!
[2024-06-30 09:55:01,826] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step492/layer_00-model_states.pt...
[2024-06-30 09:55:04,669] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step492/layer_02-model_states.pt...
[2024-06-30 09:55:05,690] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step492/layer_07-model_states.pt...
[2024-06-30 09:55:05,939] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step492/layer_05-model_states.pt...
[2024-06-30 09:55:05,946] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step492/layer_06-model_states.pt...
[2024-06-30 09:55:07,659] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step492/layer_08-model_states.pt...
[2024-06-30 09:55:09,739] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step492/layer_00-model_states.pt.
[2024-06-30 09:55:16,600] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step492/layer_01-model_states.pt...
[2024-06-30 09:55:17,110] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step492/layer_04-model_states.pt...
[2024-06-30 09:55:17,593] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step492/layer_03-model_states.pt...
[2024-06-30 09:58:27,379] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step492/layer_04-model_states.pt.
[2024-06-30 09:58:27,700] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step492/mp_rank_03_model_states.pt...
[2024-06-30 09:58:27,870] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step492/mp_rank_03_model_states.pt.
[2024-06-30 09:58:27,870] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step492 is ready now!
[2024-06-30 09:58:48,982] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step492/layer_06-model_states.pt.
[2024-06-30 09:58:48,993] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step492/layer_05-model_states.pt.
[2024-06-30 09:58:48,994] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step492/layer_08-model_states.pt.
[2024-06-30 09:58:49,009] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step492/layer_02-model_states.pt.
[2024-06-30 09:58:49,031] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step492/mp_rank_05_model_states.pt...
[2024-06-30 09:58:49,040] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step492/mp_rank_04_model_states.pt...
[2024-06-30 09:58:49,041] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step492/layer_07-model_states.pt.
[2024-06-30 09:58:49,046] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step492/layer_03-model_states.pt.
[2024-06-30 09:58:49,058] [INFO] [logging.py:96:log_dist] [Rank 1] Saving model checkpoint: /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step492/mp_rank_01_model_states.pt
[2024-06-30 09:58:49,058] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step492/mp_rank_01_model_states.pt...
[2024-06-30 09:58:49,085] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step492/mp_rank_06_model_states.pt...
[2024-06-30 09:58:49,155] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step492/mp_rank_05_model_states.pt.
[2024-06-30 09:58:49,155] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step492 is ready now!
[2024-06-30 09:58:49,190] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step492/layer_01-model_states.pt.
[2024-06-30 09:58:49,198] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step492/mp_rank_04_model_states.pt.
[2024-06-30 09:58:49,198] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step492 is ready now!
[2024-06-30 09:58:49,263] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step492/mp_rank_06_model_states.pt.
[2024-06-30 09:58:49,264] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step492 is ready now!
[2024-06-30 09:58:49,269] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step492/mp_rank_01_model_states.pt.
[2024-06-30 09:58:49,269] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step492 is ready now!
[2024-06-30 09:58:49,380] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step492/mp_rank_02_model_states.pt...
[2024-06-30 09:58:49,509] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step492/mp_rank_02_model_states.pt.
[2024-06-30 09:58:49,510] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step492 is ready now!
[2024-06-30 09:58:49,550] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step492/layer_09-model_states.pt...
[2024-06-30 09:58:49,776] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step492/mp_rank_00_model_states.pt
[2024-06-30 09:58:49,776] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step492/mp_rank_00_model_states.pt...
[2024-06-30 09:58:50,879] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step492/mp_rank_00_model_states.pt.
[2024-06-30 09:58:50,879] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step492 is ready now!
[2024-06-30 09:58:51,166] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step492/layer_09-model_states.pt.
[2024-06-30 09:58:51,168] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step492/mp_rank_07_model_states.pt...
[2024-06-30 09:58:51,271] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step492/mp_rank_07_model_states.pt.
[2024-06-30 09:58:51,271] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step492 is ready now!
Checkpoint saved using --- 230.39743900299072 seconds ---
 10%|▉         | 500/5198 [14:33:48<225:17:35, 172.64s/it] 10%|▉         | 500/5198 [14:33:47<226:37:00, 173.65s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_469
 10%|▉         | 500/5198 [14:33:45<225:19:06, 172.66s/it] 10%|▉         | 500/5198 [14:33:45<225:28:45, 172.78s/it] 10%|▉         | 500/5198 [14:33:45<225:24:21, 172.72s/it] 10%|▉         | 500/5198 [14:33:45<225:19:57, 172.67s/it] 10%|▉         | 500/5198 [14:33:45<225:21:58, 172.69s/it] 10%|▉         | 500/5198 [14:33:45<225:17:56, 172.64s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.63s/it][A100%|██████████| 1/1 [01:40<00:00, 100.63s/it]
 10%|▉         | 501/5198 [14:35:28<198:08:01, 151.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 10:00:34,693] [INFO] [logging.py:96:log_dist] [Rank 0] step=493, skipped=0, lr=[1.98347093634311e-05], mom=[(0.9, 0.999)]
steps: 493 loss: 0.5656 iter time (s): 103.110 samples/sec: 1.241

100%|██████████| 1/1 [01:43<00:00, 103.43s/it][A100%|██████████| 1/1 [01:43<00:00, 103.43s/it]
 10%|▉         | 501/5198 [14:35:29<198:26:03, 152.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.61s/it][A100%|██████████| 1/1 [01:43<00:00, 103.61s/it]
 10%|▉         | 501/5198 [14:35:29<198:27:06, 152.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.70s/it][A100%|██████████| 1/1 [01:43<00:00, 103.70s/it]
 10%|▉         | 501/5198 [14:35:29<198:27:40, 152.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.81s/it][A100%|██████████| 1/1 [01:43<00:00, 103.81s/it]
 10%|▉         | 501/5198 [14:35:29<198:28:50, 152.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.83s/it][A100%|██████████| 1/1 [01:43<00:00, 103.83s/it]
 10%|▉         | 501/5198 [14:35:30<198:28:47, 152.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.87s/it][A100%|██████████| 1/1 [01:43<00:00, 103.87s/it]
 10%|▉         | 501/5198 [14:35:30<198:28:45, 152.12s/it]
100%|██████████| 1/1 [01:43<00:00, 103.88s/it][A100%|██████████| 1/1 [01:43<00:00, 103.88s/it]
 10%|▉         | 501/5198 [14:35:32<198:28:43, 152.12s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_470

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.72s/it][A100%|██████████| 1/1 [01:31<00:00, 91.72s/it]
 10%|▉         | 502/5198 [14:37:00<174:39:21, 133.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 10:02:06,387] [INFO] [logging.py:96:log_dist] [Rank 0] step=494, skipped=0, lr=[1.983368225422351e-05], mom=[(0.9, 0.999)]
steps: 494 loss: 0.5729 iter time (s): 90.840 samples/sec: 1.409

100%|██████████| 1/1 [01:31<00:00, 91.65s/it][A100%|██████████| 1/1 [01:31<00:00, 91.65s/it]
 10%|▉         | 502/5198 [14:37:01<174:44:43, 133.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.59s/it][A100%|██████████| 1/1 [01:31<00:00, 91.59s/it]
 10%|▉         | 502/5198 [14:37:01<174:43:51, 133.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.66s/it][A100%|██████████| 1/1 [01:31<00:00, 91.66s/it]
 10%|▉         | 502/5198 [14:37:01<174:46:04, 133.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.61s/it][A100%|██████████| 1/1 [01:31<00:00, 91.61s/it]
 10%|▉         | 502/5198 [14:37:01<174:45:40, 133.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.68s/it][A100%|██████████| 1/1 [01:31<00:00, 91.68s/it]
 10%|▉         | 502/5198 [14:37:01<174:47:14, 133.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A

100%|██████████| 1/1 [01:31<00:00, 91.66s/it]100%|██████████| 1/1 [01:31<00:00, 91.65s/it][A[A100%|██████████| 1/1 [01:31<00:00, 91.66s/it]
100%|██████████| 1/1 [01:31<00:00, 91.65s/it]
 10%|▉         | 502/5198 [14:37:01<174:46:41, 133.99s/it] 10%|▉         | 502/5198 [14:37:04<174:46:28, 133.98s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_471

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.63s/it][A100%|██████████| 1/1 [01:35<00:00, 95.63s/it]
 10%|▉         | 503/5198 [14:38:36<159:43:36, 122.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 10:03:42,314] [INFO] [logging.py:96:log_dist] [Rank 0] step=495, skipped=0, lr=[1.9832651990447372e-05], mom=[(0.9, 0.999)]
steps: 495 loss: 0.5720 iter time (s): 95.107 samples/sec: 1.346

100%|██████████| 1/1 [01:35<00:00, 95.96s/it][A100%|██████████| 1/1 [01:35<00:00, 95.96s/it]
 10%|▉         | 503/5198 [14:38:37<159:50:40, 122.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.97s/it][A100%|██████████| 1/1 [01:35<00:00, 95.97s/it]
 10%|▉         | 503/5198 [14:38:37<159:50:08, 122.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.92s/it][A100%|██████████| 1/1 [01:35<00:00, 95.92s/it]
 10%|▉         | 503/5198 [14:38:37<159:50:41, 122.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.88s/it][A100%|██████████| 1/1 [01:35<00:00, 95.89s/it]
 10%|▉         | 503/5198 [14:38:37<159:50:35, 122.56s/it]
100%|██████████| 1/1 [01:35<00:00, 95.98s/it][A100%|██████████| 1/1 [01:35<00:00, 95.98s/it]
 10%|▉         | 503/5198 [14:38:37<159:51:47, 122.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.91s/it][A100%|██████████| 1/1 [01:35<00:00, 95.91s/it]
 10%|▉         | 503/5198 [14:38:39<159:50:32, 122.56s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_472
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.94s/it][A100%|██████████| 1/1 [01:35<00:00, 95.94s/it]
 10%|▉         | 503/5198 [14:38:37<159:51:23, 122.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.09s/it][A100%|██████████| 1/1 [01:49<00:00, 109.09s/it]
 10%|▉         | 504/5198 [14:40:25<154:33:18, 118.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 10:05:32,037] [INFO] [logging.py:96:log_dist] [Rank 0] step=496, skipped=0, lr=[1.9831618572433225e-05], mom=[(0.9, 0.999)]
steps: 496 loss: 0.6011 iter time (s): 108.923 samples/sec: 1.175

100%|██████████| 1/1 [01:49<00:00, 109.65s/it][A100%|██████████| 1/1 [01:49<00:00, 109.65s/it]
 10%|▉         | 504/5198 [14:40:26<154:45:58, 118.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.68s/it][A100%|██████████| 1/1 [01:49<00:00, 109.68s/it]
 10%|▉         | 504/5198 [14:40:26<154:46:12, 118.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.72s/it][A100%|██████████| 1/1 [01:49<00:00, 109.72s/it]
 10%|▉         | 504/5198 [14:40:27<154:47:16, 118.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.70s/it][A100%|██████████| 1/1 [01:49<00:00, 109.71s/it]
 10%|▉         | 504/5198 [14:40:27<154:47:46, 118.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.73s/it][A100%|██████████| 1/1 [01:49<00:00, 109.73s/it]
 10%|▉         | 504/5198 [14:40:27<154:47:34, 118.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.72s/it][A100%|██████████| 1/1 [01:49<00:00, 109.72s/it]
 10%|▉         | 504/5198 [14:40:27<154:47:46, 118.72s/it]
100%|██████████| 1/1 [01:49<00:00, 109.75s/it][A100%|██████████| 1/1 [01:49<00:00, 109.75s/it]
 10%|▉         | 504/5198 [14:40:29<154:48:02, 118.72s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_473

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.46s/it][A100%|██████████| 1/1 [01:38<00:00, 98.46s/it]
 10%|▉         | 505/5198 [14:42:04<146:44:42, 112.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 10:07:10,434] [INFO] [logging.py:96:log_dist] [Rank 0] step=497, skipped=0, lr=[1.9830582000512618e-05], mom=[(0.9, 0.999)]
steps: 497 loss: 0.5631 iter time (s): 97.559 samples/sec: 1.312

100%|██████████| 1/1 [01:38<00:00, 98.40s/it][A100%|██████████| 1/1 [01:38<00:00, 98.40s/it]
 10%|▉         | 505/5198 [14:42:05<146:48:00, 112.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.33s/it][A100%|██████████| 1/1 [01:38<00:00, 98.33s/it]
 10%|▉         | 505/5198 [14:42:05<146:46:37, 112.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.31s/it][A100%|██████████| 1/1 [01:38<00:00, 98.31s/it]
 10%|▉         | 505/5198 [14:42:05<146:46:43, 112.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.38s/it][A100%|██████████| 1/1 [01:38<00:00, 98.38s/it]
 10%|▉         | 505/5198 [14:42:05<146:48:37, 112.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.40s/it][A100%|██████████| 1/1 [01:38<00:00, 98.40s/it]
 10%|▉         | 505/5198 [14:42:05<146:49:05, 112.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.38s/it][A100%|██████████| 1/1 [01:38<00:00, 98.39s/it]
 10%|▉         | 505/5198 [14:42:05<146:48:50, 112.62s/it]
100%|██████████| 1/1 [01:38<00:00, 98.38s/it][A100%|██████████| 1/1 [01:38<00:00, 98.38s/it]
 10%|▉         | 505/5198 [14:42:08<146:48:53, 112.62s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_474
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.16s/it][A100%|██████████| 1/1 [01:31<00:00, 91.16s/it]
 10%|▉         | 506/5198 [14:43:35<138:24:54, 106.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 10:08:41,515] [INFO] [logging.py:96:log_dist] [Rank 0] step=498, skipped=0, lr=[1.9829542275018105e-05], mom=[(0.9, 0.999)]
steps: 498 loss: 0.6138 iter time (s): 90.323 samples/sec: 1.417

100%|██████████| 1/1 [01:31<00:00, 91.18s/it][A100%|██████████| 1/1 [01:31<00:00, 91.18s/it]
 10%|▉         | 506/5198 [14:43:36<138:23:34, 106.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.26s/it][A100%|██████████| 1/1 [01:31<00:00, 91.26s/it]
 10%|▉         | 506/5198 [14:43:36<138:24:23, 106.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.25s/it][A100%|██████████| 1/1 [01:31<00:00, 91.25s/it]
 10%|▉         | 506/5198 [14:43:36<138:24:20, 106.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.09s/it][A100%|██████████| 1/1 [01:31<00:00, 91.09s/it]
 10%|▉         | 506/5198 [14:43:36<138:22:12, 106.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.16s/it][A100%|██████████| 1/1 [01:31<00:00, 91.16s/it]
 10%|▉         | 506/5198 [14:43:36<138:23:30, 106.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.17s/it][A100%|██████████| 1/1 [01:31<00:00, 91.17s/it]
 10%|▉         | 506/5198 [14:43:37<138:23:55, 106.19s/it]
100%|██████████| 1/1 [01:31<00:00, 91.18s/it][A100%|██████████| 1/1 [01:31<00:00, 91.18s/it]
 10%|▉         | 506/5198 [14:43:39<138:24:06, 106.19s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_475

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.67s/it][A100%|██████████| 1/1 [01:25<00:00, 85.67s/it]
 10%|▉         | 507/5198 [14:45:01<130:27:15, 100.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 10:10:07,299] [INFO] [logging.py:96:log_dist] [Rank 0] step=499, skipped=0, lr=[1.9828499396283262e-05], mom=[(0.9, 0.999)]
steps: 499 loss: 0.6193 iter time (s): 84.851 samples/sec: 1.509

100%|██████████| 1/1 [01:25<00:00, 85.63s/it][A100%|██████████| 1/1 [01:25<00:00, 85.63s/it]
 10%|▉         | 507/5198 [14:45:01<130:19:47, 100.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.53s/it][A100%|██████████| 1/1 [01:25<00:00, 85.53s/it]
 10%|▉         | 507/5198 [14:45:01<130:18:14, 100.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.51s/it][A100%|██████████| 1/1 [01:25<00:00, 85.51s/it]
 10%|▉         | 507/5198 [14:45:02<130:17:43, 99.99s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.60s/it][A100%|██████████| 1/1 [01:25<00:00, 85.60s/it]
 10%|▉         | 507/5198 [14:45:02<130:19:13, 100.01s/it]
100%|██████████| 1/1 [01:25<00:00, 85.63s/it][A100%|██████████| 1/1 [01:25<00:00, 85.63s/it]
 10%|▉         | 507/5198 [14:45:02<130:18:51, 100.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.57s/it][A100%|██████████| 1/1 [01:25<00:00, 85.57s/it]
 10%|▉         | 507/5198 [14:45:02<130:18:41, 100.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.58s/it][A100%|██████████| 1/1 [01:25<00:00, 85.58s/it]
 10%|▉         | 507/5198 [14:45:04<130:19:03, 100.01s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_476
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.89s/it][A100%|██████████| 1/1 [01:27<00:00, 87.89s/it]
 10%|▉         | 508/5198 [14:46:29<125:43:35, 96.51s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 10:11:35,425] [INFO] [logging.py:96:log_dist] [Rank 0] step=500, skipped=0, lr=[1.982745336464266e-05], mom=[(0.9, 0.999)]
steps: 500 loss: 0.5762 iter time (s): 87.389 samples/sec: 1.465

100%|██████████| 1/1 [01:28<00:00, 88.16s/it][A100%|██████████| 1/1 [01:28<00:00, 88.16s/it]
 10%|▉         | 508/5198 [14:46:30<125:40:21, 96.47s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.27s/it][A100%|██████████| 1/1 [01:28<00:00, 88.27s/it]
 10%|▉         | 508/5198 [14:46:30<125:41:52, 96.48s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.25s/it][A100%|██████████| 1/1 [01:28<00:00, 88.25s/it]
 10%|▉         | 508/5198 [14:46:30<125:41:06, 96.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.21s/it][A100%|██████████| 1/1 [01:28<00:00, 88.22s/it]
 10%|▉         | 508/5198 [14:46:30<125:41:07, 96.47s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.24s/it][A100%|██████████| 1/1 [01:28<00:00, 88.24s/it]
 10%|▉         | 508/5198 [14:46:30<125:41:23, 96.48s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.26s/it][A100%|██████████| 1/1 [01:28<00:00, 88.26s/it]
 10%|▉         | 508/5198 [14:46:30<125:41:51, 96.48s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.26s/it][A100%|██████████| 1/1 [01:28<00:00, 88.26s/it]
 10%|▉         | 508/5198 [14:46:33<125:41:55, 96.49s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_477
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.99s/it][A100%|██████████| 1/1 [01:28<00:00, 88.99s/it]
 10%|▉         | 509/5198 [14:47:58<122:51:31, 94.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 10:13:04,733] [INFO] [logging.py:96:log_dist] [Rank 0] step=501, skipped=0, lr=[1.9826404180431897e-05], mom=[(0.9, 0.999)]
steps: 501 loss: 0.5776 iter time (s): 88.431 samples/sec: 1.447

100%|██████████| 1/1 [01:29<00:00, 89.33s/it][A100%|██████████| 1/1 [01:29<00:00, 89.33s/it]
 10%|▉         | 509/5198 [14:47:59<122:51:43, 94.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.25s/it][A100%|██████████| 1/1 [01:29<00:00, 89.25s/it]
 10%|▉         | 509/5198 [14:47:59<122:51:04, 94.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.28s/it][A100%|██████████| 1/1 [01:29<00:00, 89.28s/it]
 10%|▉         | 509/5198 [14:47:59<122:51:12, 94.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.27s/it][A100%|██████████| 1/1 [01:29<00:00, 89.27s/it]
 10%|▉         | 509/5198 [14:47:59<122:50:44, 94.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.27s/it][A100%|██████████| 1/1 [01:29<00:00, 89.28s/it]
 10%|▉         | 509/5198 [14:48:00<122:51:06, 94.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.24s/it][A100%|██████████| 1/1 [01:29<00:00, 89.24s/it]
 10%|▉         | 509/5198 [14:48:00<122:50:29, 94.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.25s/it][A100%|██████████| 1/1 [01:29<00:00, 89.25s/it]
 10%|▉         | 509/5198 [14:48:02<122:50:54, 94.32s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_478
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.75s/it][A100%|██████████| 1/1 [01:20<00:00, 80.75s/it]
 10%|▉         | 510/5198 [14:49:19<117:35:37, 90.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 10:14:25,396] [INFO] [logging.py:96:log_dist] [Rank 0] step=502, skipped=0, lr=[1.9825351843987584e-05], mom=[(0.9, 0.999)]
steps: 502 loss: 0.6379 iter time (s): 79.843 samples/sec: 1.603

100%|██████████| 1/1 [01:20<00:00, 80.60s/it][A100%|██████████| 1/1 [01:20<00:00, 80.60s/it]
 10%|▉         | 510/5198 [14:49:20<117:28:31, 90.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.63s/it][A100%|██████████| 1/1 [01:20<00:00, 80.63s/it]
 10%|▉         | 510/5198 [14:49:20<117:28:50, 90.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.60s/it][A100%|██████████| 1/1 [01:20<00:00, 80.60s/it]
 10%|▉         | 510/5198 [14:49:20<117:28:14, 90.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.59s/it][A100%|██████████| 1/1 [01:20<00:00, 80.59s/it]
 10%|▉         | 510/5198 [14:49:20<117:27:43, 90.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.59s/it][A100%|██████████| 1/1 [01:20<00:00, 80.59s/it]
 10%|▉         | 510/5198 [14:49:20<117:27:54, 90.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.61s/it][A100%|██████████| 1/1 [01:20<00:00, 80.61s/it]
 10%|▉         | 510/5198 [14:49:20<117:27:54, 90.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.60s/it][A100%|██████████| 1/1 [01:20<00:00, 80.60s/it]
 10%|▉         | 510/5198 [14:49:22<117:27:55, 90.20s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_479
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:13<00:00, 133.45s/it][A100%|██████████| 1/1 [02:13<00:00, 133.45s/it]
 10%|▉         | 511/5198 [14:51:33<134:29:29, 103.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 10:16:40,491] [INFO] [logging.py:96:log_dist] [Rank 0] step=503, skipped=0, lr=[1.9824296355647327e-05], mom=[(0.9, 0.999)]
steps: 503 loss: 0.5764 iter time (s): 134.331 samples/sec: 0.953

100%|██████████| 1/1 [02:15<00:00, 135.06s/it][A100%|██████████| 1/1 [02:15<00:00, 135.06s/it]
 10%|▉         | 511/5198 [14:51:35<134:58:19, 103.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:15<00:00, 135.12s/it][A100%|██████████| 1/1 [02:15<00:00, 135.12s/it]
 10%|▉         | 511/5198 [14:51:35<134:59:58, 103.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:15<00:00, 135.12s/it][A100%|██████████| 1/1 [02:15<00:00, 135.12s/it]
 10%|▉         | 511/5198 [14:51:35<134:59:04, 103.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:15<00:00, 135.23s/it][A100%|██████████| 1/1 [02:15<00:00, 135.23s/it]
 10%|▉         | 511/5198 [14:51:35<135:02:04, 103.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:15<00:00, 135.24s/it][A100%|██████████| 1/1 [02:15<00:00, 135.24s/it]
 10%|▉         | 511/5198 [14:51:35<135:01:59, 103.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:15<00:00, 135.20s/it][A100%|██████████| 1/1 [02:15<00:00, 135.20s/it]
 10%|▉         | 511/5198 [14:51:35<135:01:00, 103.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:15<00:00, 135.23s/it][A100%|██████████| 1/1 [02:15<00:00, 135.23s/it]
 10%|▉         | 511/5198 [14:51:38<135:01:44, 103.71s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_31
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.42s/it][A100%|██████████| 1/1 [02:00<00:00, 120.42s/it]
 10%|▉         | 512/5198 [14:53:34<141:12:07, 108.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 10:18:40,380] [INFO] [logging.py:96:log_dist] [Rank 0] step=504, skipped=0, lr=[1.9823237715749754e-05], mom=[(0.9, 0.999)]
steps: 504 loss: 0.8073 iter time (s): 119.277 samples/sec: 1.073

100%|██████████| 1/1 [02:00<00:00, 120.45s/it][A100%|██████████| 1/1 [02:00<00:00, 120.45s/it]
 10%|▉         | 512/5198 [14:53:35<141:30:01, 108.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.32s/it][A100%|██████████| 1/1 [02:00<00:00, 120.32s/it]
 10%|▉         | 512/5198 [14:53:35<141:28:20, 108.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.42s/it][A100%|██████████| 1/1 [02:00<00:00, 120.42s/it]
 10%|▉         | 512/5198 [14:53:36<141:31:56, 108.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.46s/it][A100%|██████████| 1/1 [02:00<00:00, 120.46s/it]
 10%|▉         | 512/5198 [14:53:36<141:32:43, 108.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.61s/it][A100%|██████████| 1/1 [02:00<00:00, 120.61s/it]
 10%|▉         | 512/5198 [14:53:36<141:34:20, 108.76s/it]
100%|██████████| 1/1 [02:00<00:00, 120.41s/it][A100%|██████████| 1/1 [02:00<00:00, 120.41s/it]
 10%|▉         | 512/5198 [14:53:38<141:31:25, 108.73s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_480
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.49s/it][A100%|██████████| 1/1 [02:00<00:00, 120.49s/it]
 10%|▉         | 512/5198 [14:53:36<141:32:50, 108.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.13s/it][A100%|██████████| 1/1 [01:36<00:00, 96.14s/it]
 10%|▉         | 513/5198 [14:55:10<136:25:21, 104.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 10:20:16,296] [INFO] [logging.py:96:log_dist] [Rank 0] step=505, skipped=0, lr=[1.9822175924634507e-05], mom=[(0.9, 0.999)]
steps: 505 loss: 0.6296 iter time (s): 94.491 samples/sec: 1.355

100%|██████████| 1/1 [01:35<00:00, 95.41s/it][A100%|██████████| 1/1 [01:35<00:00, 95.41s/it]
 10%|▉         | 513/5198 [14:55:11<136:17:32, 104.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.47s/it][A100%|██████████| 1/1 [01:35<00:00, 95.47s/it]
 10%|▉         | 513/5198 [14:55:11<136:17:16, 104.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.35s/it][A100%|██████████| 1/1 [01:35<00:00, 95.35s/it]
 10%|▉         | 513/5198 [14:55:11<136:16:53, 104.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.23s/it][A100%|██████████| 1/1 [01:35<00:00, 95.23s/it]
 10%|▉         | 513/5198 [14:55:11<136:15:37, 104.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.27s/it][A100%|██████████| 1/1 [01:35<00:00, 95.27s/it]
 10%|▉         | 513/5198 [14:55:11<136:15:31, 104.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.31s/it][A100%|██████████| 1/1 [01:35<00:00, 95.31s/it]
 10%|▉         | 513/5198 [14:55:11<136:16:27, 104.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.36s/it][A100%|██████████| 1/1 [01:35<00:00, 95.36s/it]
 10%|▉         | 513/5198 [14:55:13<136:16:45, 104.72s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_481
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.97s/it][A100%|██████████| 1/1 [01:19<00:00, 79.97s/it]
 10%|▉         | 514/5198 [14:56:30<126:45:54, 97.43s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 10:21:36,034] [INFO] [logging.py:96:log_dist] [Rank 0] step=506, skipped=0, lr=[1.9821110982642234e-05], mom=[(0.9, 0.999)]
steps: 506 loss: 0.5692 iter time (s): 78.862 samples/sec: 1.623

100%|██████████| 1/1 [01:19<00:00, 79.66s/it][A100%|██████████| 1/1 [01:19<00:00, 79.66s/it]
 10%|▉         | 514/5198 [14:56:30<126:28:56, 97.21s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.79s/it][A100%|██████████| 1/1 [01:19<00:00, 79.79s/it]
 10%|▉         | 514/5198 [14:56:30<126:31:53, 97.25s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.67s/it][A100%|██████████| 1/1 [01:19<00:00, 79.67s/it]
 10%|▉         | 514/5198 [14:56:31<126:28:39, 97.21s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.78s/it][A100%|██████████| 1/1 [01:19<00:00, 79.78s/it]
 10%|▉         | 514/5198 [14:56:31<126:30:19, 97.23s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.76s/it][A100%|██████████| 1/1 [01:19<00:00, 79.76s/it]
 10%|▉         | 514/5198 [14:56:31<126:29:50, 97.22s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.72s/it][A100%|██████████| 1/1 [01:19<00:00, 79.72s/it]
 10%|▉         | 514/5198 [14:56:31<126:29:36, 97.22s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.72s/it][A100%|██████████| 1/1 [01:19<00:00, 79.72s/it]
 10%|▉         | 514/5198 [14:56:33<126:29:48, 97.22s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_482
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.92s/it][A100%|██████████| 1/1 [01:28<00:00, 88.92s/it]
 10%|▉         | 515/5198 [14:57:59<123:29:59, 94.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 10:23:05,449] [INFO] [logging.py:96:log_dist] [Rank 0] step=507, skipped=0, lr=[1.9820042890114596e-05], mom=[(0.9, 0.999)]
steps: 507 loss: 0.5590 iter time (s): 88.586 samples/sec: 1.445

100%|██████████| 1/1 [01:29<00:00, 89.51s/it][A100%|██████████| 1/1 [01:29<00:00, 89.51s/it]
 10%|▉         | 515/5198 [14:58:00<123:27:08, 94.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.32s/it][A100%|██████████| 1/1 [01:29<00:00, 89.32s/it]
 10%|▉         | 515/5198 [14:58:00<123:24:49, 94.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.42s/it][A100%|██████████| 1/1 [01:29<00:00, 89.42s/it]
 10%|▉         | 515/5198 [14:58:00<123:24:53, 94.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.34s/it][A100%|██████████| 1/1 [01:29<00:00, 89.34s/it]
 10%|▉         | 515/5198 [14:58:00<123:24:05, 94.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.43s/it][A100%|██████████| 1/1 [01:29<00:00, 89.43s/it]
 10%|▉         | 515/5198 [14:58:00<123:25:58, 94.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.40s/it][A100%|██████████| 1/1 [01:29<00:00, 89.40s/it]
 10%|▉         | 515/5198 [14:58:03<123:25:12, 94.88s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_483

100%|██████████| 1/1 [01:29<00:00, 89.42s/it][A100%|██████████| 1/1 [01:29<00:00, 89.42s/it]
 10%|▉         | 515/5198 [14:58:00<123:25:28, 94.88s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.73s/it][A100%|██████████| 1/1 [01:40<00:00, 100.73s/it]
 10%|▉         | 516/5198 [14:59:40<125:49:48, 96.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 10:24:46,748] [INFO] [logging.py:96:log_dist] [Rank 0] step=508, skipped=0, lr=[1.981897164739426e-05], mom=[(0.9, 0.999)]
steps: 508 loss: 0.5875 iter time (s): 100.429 samples/sec: 1.275

100%|██████████| 1/1 [01:41<00:00, 101.14s/it][A100%|██████████| 1/1 [01:41<00:00, 101.14s/it]
 10%|▉         | 516/5198 [14:59:41<125:51:43, 96.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.19s/it][A100%|██████████| 1/1 [01:41<00:00, 101.19s/it]
 10%|▉         | 516/5198 [14:59:41<125:51:34, 96.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.28s/it][A100%|██████████| 1/1 [01:41<00:00, 101.28s/it]
 10%|▉         | 516/5198 [14:59:41<125:53:33, 96.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.26s/it][A100%|██████████| 1/1 [01:41<00:00, 101.26s/it]
 10%|▉         | 516/5198 [14:59:41<125:52:22, 96.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.21s/it][A100%|██████████| 1/1 [01:41<00:00, 101.21s/it]
 10%|▉         | 516/5198 [14:59:42<125:52:45, 96.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.21s/it][A100%|██████████| 1/1 [01:41<00:00, 101.22s/it]
 10%|▉         | 516/5198 [14:59:44<125:52:07, 96.78s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_484
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.23s/it][A100%|██████████| 1/1 [01:41<00:00, 101.23s/it]
 10%|▉         | 516/5198 [14:59:42<125:52:35, 96.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.13s/it][A100%|██████████| 1/1 [01:20<00:00, 80.13s/it]
 10%|▉         | 517/5198 [15:01:01<119:24:46, 91.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 10:26:06,518] [INFO] [logging.py:96:log_dist] [Rank 0] step=509, skipped=0, lr=[1.981789725482491e-05], mom=[(0.9, 0.999)]
steps: 509 loss: 0.6161 iter time (s): 78.970 samples/sec: 1.621

100%|██████████| 1/1 [01:19<00:00, 79.78s/it][A100%|██████████| 1/1 [01:19<00:00, 79.78s/it]
 10%|▉         | 517/5198 [15:01:01<119:12:50, 91.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.82s/it][A100%|██████████| 1/1 [01:19<00:00, 79.82s/it]
 10%|▉         | 517/5198 [15:01:01<119:13:21, 91.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.70s/it][A100%|██████████| 1/1 [01:19<00:00, 79.70s/it]
 10%|▉         | 517/5198 [15:01:01<119:11:56, 91.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.75s/it][A100%|██████████| 1/1 [01:19<00:00, 79.75s/it]
 10%|▉         | 517/5198 [15:01:01<119:12:15, 91.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.70s/it][A100%|██████████| 1/1 [01:19<00:00, 79.70s/it]
 10%|▉         | 517/5198 [15:01:01<119:11:23, 91.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.69s/it][A100%|██████████| 1/1 [01:19<00:00, 79.69s/it]
 10%|▉         | 517/5198 [15:01:01<119:11:01, 91.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.73s/it][A100%|██████████| 1/1 [01:19<00:00, 79.73s/it]
 10%|▉         | 517/5198 [15:01:04<119:11:33, 91.67s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_485
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.07s/it][A100%|██████████| 1/1 [01:44<00:00, 104.07s/it]
 10%|▉         | 518/5198 [15:02:45<124:13:50, 95.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 10:27:51,465] [INFO] [logging.py:96:log_dist] [Rank 0] step=510, skipped=0, lr=[1.9816819712751234e-05], mom=[(0.9, 0.999)]
steps: 510 loss: 0.5828 iter time (s): 104.182 samples/sec: 1.229

100%|██████████| 1/1 [01:44<00:00, 104.99s/it][A100%|██████████| 1/1 [01:44<00:00, 104.99s/it]
 10%|▉         | 518/5198 [15:02:46<124:22:56, 95.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.98s/it][A100%|██████████| 1/1 [01:44<00:00, 104.98s/it]
 10%|▉         | 518/5198 [15:02:46<124:23:02, 95.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.00s/it][A100%|██████████| 1/1 [01:45<00:00, 105.00s/it]
 10%|▉         | 518/5198 [15:02:46<124:22:40, 95.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.99s/it][A100%|██████████| 1/1 [01:44<00:00, 104.99s/it]
 10%|▉         | 518/5198 [15:02:46<124:22:32, 95.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.00s/it][A100%|██████████| 1/1 [01:45<00:00, 105.00s/it]
 10%|▉         | 518/5198 [15:02:46<124:22:11, 95.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.05s/it][A100%|██████████| 1/1 [01:45<00:00, 105.05s/it]
 10%|▉         | 518/5198 [15:02:46<124:22:56, 95.68s/it]
100%|██████████| 1/1 [01:45<00:00, 105.03s/it][A100%|██████████| 1/1 [01:45<00:00, 105.03s/it]
 10%|▉         | 518/5198 [15:02:49<124:22:49, 95.68s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_486

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.56s/it][A100%|██████████| 1/1 [01:25<00:00, 85.56s/it]
 10%|▉         | 519/5198 [15:04:10<120:21:16, 92.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 10:29:16,589] [INFO] [logging.py:96:log_dist] [Rank 0] step=511, skipped=0, lr=[1.981573902151894e-05], mom=[(0.9, 0.999)]
steps: 511 loss: 0.5957 iter time (s): 84.275 samples/sec: 1.519

100%|██████████| 1/1 [01:25<00:00, 85.04s/it][A100%|██████████| 1/1 [01:25<00:00, 85.05s/it]
 10%|▉         | 519/5198 [15:04:11<120:12:45, 92.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.02s/it][A100%|██████████| 1/1 [01:25<00:00, 85.03s/it]
 10%|▉         | 519/5198 [15:04:11<120:12:25, 92.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.03s/it][A100%|██████████| 1/1 [01:25<00:00, 85.03s/it]
 10%|▉         | 519/5198 [15:04:11<120:12:18, 92.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.06s/it][A100%|██████████| 1/1 [01:25<00:00, 85.06s/it]
 10%|▉         | 519/5198 [15:04:11<120:12:47, 92.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.07s/it][A100%|██████████| 1/1 [01:25<00:00, 85.07s/it]
 10%|▉         | 519/5198 [15:04:11<120:12:55, 92.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.02s/it][A100%|██████████| 1/1 [01:25<00:00, 85.02s/it]
 10%|▉         | 519/5198 [15:04:11<120:12:07, 92.48s/it]
100%|██████████| 1/1 [01:25<00:00, 85.02s/it][A100%|██████████| 1/1 [01:25<00:00, 85.02s/it]
 10%|▉         | 519/5198 [15:04:14<120:12:07, 92.48s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_487

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.27s/it][A100%|██████████| 1/1 [01:29<00:00, 89.27s/it]
 10%|█         | 520/5198 [15:05:40<119:08:13, 91.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 10:30:46,256] [INFO] [logging.py:96:log_dist] [Rank 0] step=512, skipped=0, lr=[1.9814655181474738e-05], mom=[(0.9, 0.999)]
steps: 512 loss: 0.5662 iter time (s): 88.903 samples/sec: 1.440

100%|██████████| 1/1 [01:29<00:00, 89.71s/it][A100%|██████████| 1/1 [01:29<00:00, 89.71s/it]
 10%|█         | 520/5198 [15:05:40<119:06:19, 91.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.70s/it][A100%|██████████| 1/1 [01:29<00:00, 89.70s/it]
 10%|█         | 520/5198 [15:05:41<119:06:08, 91.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.72s/it][A100%|██████████| 1/1 [01:29<00:00, 89.72s/it]
 10%|█         | 520/5198 [15:05:41<119:06:23, 91.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.72s/it][A100%|██████████| 1/1 [01:29<00:00, 89.72s/it]
 10%|█         | 520/5198 [15:05:41<119:06:35, 91.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.70s/it][A100%|██████████| 1/1 [01:29<00:00, 89.70s/it]
 10%|█         | 520/5198 [15:05:41<119:05:43, 91.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.74s/it][A100%|██████████| 1/1 [01:29<00:00, 89.74s/it]
 10%|█         | 520/5198 [15:05:41<119:07:16, 91.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.73s/it][A100%|██████████| 1/1 [01:29<00:00, 89.74s/it]
 10%|█         | 520/5198 [15:05:43<119:06:30, 91.66s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_488
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.84s/it][A100%|██████████| 1/1 [01:26<00:00, 86.84s/it]
 10%|█         | 521/5198 [15:07:07<117:18:18, 90.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 10:32:13,011] [INFO] [logging.py:96:log_dist] [Rank 0] step=513, skipped=0, lr=[1.981356819296635e-05], mom=[(0.9, 0.999)]
steps: 513 loss: 0.5780 iter time (s): 85.926 samples/sec: 1.490

100%|██████████| 1/1 [01:26<00:00, 86.67s/it][A100%|██████████| 1/1 [01:26<00:00, 86.67s/it]
 10%|█         | 521/5198 [15:07:07<117:08:21, 90.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.70s/it][A100%|██████████| 1/1 [01:26<00:00, 86.70s/it]
 10%|█         | 521/5198 [15:07:07<117:09:04, 90.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.75s/it][A100%|██████████| 1/1 [01:26<00:00, 86.75s/it]
 10%|█         | 521/5198 [15:07:08<117:10:22, 90.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.78s/it][A100%|██████████| 1/1 [01:26<00:00, 86.78s/it]
 10%|█         | 521/5198 [15:07:08<117:11:07, 90.20s/it]
100%|██████████| 1/1 [01:26<00:00, 86.71s/it][A100%|██████████| 1/1 [01:26<00:00, 86.71s/it]
 10%|█         | 521/5198 [15:07:08<117:09:57, 90.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.80s/it][A100%|██████████| 1/1 [01:26<00:00, 86.80s/it]
 10%|█         | 521/5198 [15:07:08<117:10:56, 90.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.77s/it][A100%|██████████| 1/1 [01:26<00:00, 86.77s/it]
 10%|█         | 521/5198 [15:07:10<117:10:48, 90.20s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_489
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.03s/it][A100%|██████████| 1/1 [01:43<00:00, 103.03s/it]
 10%|█         | 522/5198 [15:08:50<122:20:38, 94.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 10:33:56,881] [INFO] [logging.py:96:log_dist] [Rank 0] step=514, skipped=0, lr=[1.9812478056342504e-05], mom=[(0.9, 0.999)]
steps: 514 loss: 0.5873 iter time (s): 103.152 samples/sec: 1.241

100%|██████████| 1/1 [01:44<00:00, 104.04s/it][A100%|██████████| 1/1 [01:44<00:00, 104.04s/it]
 10%|█         | 522/5198 [15:08:51<122:31:20, 94.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.94s/it][A100%|██████████| 1/1 [01:43<00:00, 103.94s/it]
 10%|█         | 522/5198 [15:08:51<122:29:40, 94.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.92s/it][A100%|██████████| 1/1 [01:43<00:00, 103.92s/it]
 10%|█         | 522/5198 [15:08:52<122:30:03, 94.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.93s/it][A100%|██████████| 1/1 [01:43<00:00, 103.93s/it]
 10%|█         | 522/5198 [15:08:52<122:30:54, 94.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.01s/it][A100%|██████████| 1/1 [01:44<00:00, 104.01s/it]
 10%|█         | 522/5198 [15:08:52<122:31:54, 94.34s/it]
100%|██████████| 1/1 [01:43<00:00, 103.94s/it][A100%|██████████| 1/1 [01:43<00:00, 103.94s/it]
 10%|█         | 522/5198 [15:08:54<122:30:48, 94.32s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_490
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.96s/it][A100%|██████████| 1/1 [01:43<00:00, 103.96s/it]
 10%|█         | 522/5198 [15:08:52<122:31:20, 94.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.20s/it][A100%|██████████| 1/1 [01:21<00:00, 81.20s/it]
 10%|█         | 523/5198 [15:10:12<117:20:56, 90.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 10:35:17,818] [INFO] [logging.py:96:log_dist] [Rank 0] step=515, skipped=0, lr=[1.9811384771952954e-05], mom=[(0.9, 0.999)]
steps: 515 loss: 0.6199 iter time (s): 80.008 samples/sec: 1.600

100%|██████████| 1/1 [01:20<00:00, 80.74s/it][A100%|██████████| 1/1 [01:20<00:00, 80.74s/it]
 10%|█         | 523/5198 [15:10:12<117:12:21, 90.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.84s/it][A100%|██████████| 1/1 [01:20<00:00, 80.84s/it]
 10%|█         | 523/5198 [15:10:12<117:13:33, 90.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.87s/it][A100%|██████████| 1/1 [01:20<00:00, 80.87s/it]
 10%|█         | 523/5198 [15:10:12<117:14:32, 90.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.76s/it][A100%|██████████| 1/1 [01:20<00:00, 80.76s/it]
 10%|█         | 523/5198 [15:10:13<117:12:25, 90.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.74s/it][A100%|██████████| 1/1 [01:20<00:00, 80.75s/it]
 10%|█         | 523/5198 [15:10:13<117:12:49, 90.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.77s/it][A100%|██████████| 1/1 [01:20<00:00, 80.77s/it]
 10%|█         | 523/5198 [15:10:13<117:13:07, 90.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.80s/it][A100%|██████████| 1/1 [01:20<00:00, 80.80s/it]
 10%|█         | 523/5198 [15:10:15<117:13:13, 90.27s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_491
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.19s/it][A100%|██████████| 1/1 [01:59<00:00, 119.19s/it]
 10%|█         | 524/5198 [15:12:11<128:38:02, 99.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 10:37:18,276] [INFO] [logging.py:96:log_dist] [Rank 0] step=516, skipped=0, lr=[1.9810288340148445e-05], mom=[(0.9, 0.999)]
steps: 516 loss: 0.5804 iter time (s): 119.690 samples/sec: 1.069

100%|██████████| 1/1 [02:00<00:00, 120.53s/it][A100%|██████████| 1/1 [02:00<00:00, 120.53s/it]
 10%|█         | 524/5198 [15:12:12<128:58:47, 99.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.45s/it][A100%|██████████| 1/1 [02:00<00:00, 120.45s/it]
 10%|█         | 524/5198 [15:12:13<128:57:44, 99.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.47s/it][A100%|██████████| 1/1 [02:00<00:00, 120.47s/it]
 10%|█         | 524/5198 [15:12:13<128:58:43, 99.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.51s/it][A100%|██████████| 1/1 [02:00<00:00, 120.51s/it]
 10%|█         | 524/5198 [15:12:13<128:58:08, 99.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.47s/it][A100%|██████████| 1/1 [02:00<00:00, 120.47s/it]
 10%|█         | 524/5198 [15:12:13<128:57:30, 99.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.50s/it][A100%|██████████| 1/1 [02:00<00:00, 120.50s/it]
 10%|█         | 524/5198 [15:12:13<128:58:20, 99.34s/it]
100%|██████████| 1/1 [02:00<00:00, 120.49s/it][A100%|██████████| 1/1 [02:00<00:00, 120.49s/it]
 10%|█         | 524/5198 [15:12:15<128:58:09, 99.33s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_492
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.85s/it][A100%|██████████| 1/1 [01:42<00:00, 102.85s/it]
 10%|█         | 525/5198 [15:13:54<130:09:58, 100.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 10:39:00,890] [INFO] [logging.py:96:log_dist] [Rank 0] step=517, skipped=0, lr=[1.9809188761280738e-05], mom=[(0.9, 0.999)]
steps: 517 loss: 0.5933 iter time (s): 101.782 samples/sec: 1.258

100%|██████████| 1/1 [01:42<00:00, 102.57s/it][A100%|██████████| 1/1 [01:42<00:00, 102.57s/it]
 10%|█         | 525/5198 [15:13:55<130:12:41, 100.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.74s/it][A100%|██████████| 1/1 [01:42<00:00, 102.74s/it]
 10%|█         | 525/5198 [15:13:55<130:15:57, 100.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.56s/it][A100%|██████████| 1/1 [01:42<00:00, 102.56s/it]
 10%|█         | 525/5198 [15:13:56<130:12:33, 100.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.60s/it][A100%|██████████| 1/1 [01:42<00:00, 102.60s/it]
 10%|█         | 525/5198 [15:13:56<130:13:03, 100.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.58s/it][A100%|██████████| 1/1 [01:42<00:00, 102.58s/it]
 10%|█         | 525/5198 [15:13:56<130:12:05, 100.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.58s/it][A100%|██████████| 1/1 [01:42<00:00, 102.58s/it]
 10%|█         | 525/5198 [15:13:56<130:12:33, 100.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.59s/it][A100%|██████████| 1/1 [01:42<00:00, 102.59s/it]
 10%|█         | 525/5198 [15:13:58<130:12:36, 100.31s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_493
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.60s/it][A100%|██████████| 1/1 [01:21<00:00, 81.60s/it]
 10%|█         | 526/5198 [15:15:16<122:57:12, 94.74s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 10:40:22,128] [INFO] [logging.py:96:log_dist] [Rank 0] step=518, skipped=0, lr=[1.9808086035702618e-05], mom=[(0.9, 0.999)]
steps: 518 loss: 0.5668 iter time (s): 80.428 samples/sec: 1.591

100%|██████████| 1/1 [01:21<00:00, 81.25s/it][A100%|██████████| 1/1 [01:21<00:00, 81.25s/it]
 10%|█         | 526/5198 [15:15:16<122:45:53, 94.60s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.13s/it][A100%|██████████| 1/1 [01:21<00:00, 81.13s/it]
 10%|█         | 526/5198 [15:15:16<122:45:24, 94.59s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.14s/it][A100%|██████████| 1/1 [01:21<00:00, 81.14s/it]
 10%|█         | 526/5198 [15:15:17<122:43:20, 94.56s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.14s/it][A100%|██████████| 1/1 [01:21<00:00, 81.14s/it]
 10%|█         | 526/5198 [15:15:17<122:43:41, 94.57s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.21s/it][A100%|██████████| 1/1 [01:21<00:00, 81.21s/it]
 10%|█         | 526/5198 [15:15:17<122:44:29, 94.58s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.18s/it][A
100%|██████████| 1/1 [01:21<00:00, 81.18s/it]
 10%|█         | 526/5198 [15:15:19<122:44:16, 94.58s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_494
100%|██████████| 1/1 [01:21<00:00, 81.19s/it][A100%|██████████| 1/1 [01:21<00:00, 81.19s/it]
 10%|█         | 526/5198 [15:15:17<122:44:27, 94.58s/it] Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.01s/it][A100%|██████████| 1/1 [01:27<00:00, 87.01s/it]
 10%|█         | 527/5198 [15:16:43<120:01:21, 92.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 10:41:49,561] [INFO] [logging.py:96:log_dist] [Rank 0] step=519, skipped=0, lr=[1.9806980163767848e-05], mom=[(0.9, 0.999)]
steps: 519 loss: 0.5757 iter time (s): 86.696 samples/sec: 1.476

100%|██████████| 1/1 [01:27<00:00, 87.41s/it][A100%|██████████| 1/1 [01:27<00:00, 87.41s/it]
 10%|█         | 527/5198 [15:16:44<119:56:38, 92.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.43s/it][A100%|██████████| 1/1 [01:27<00:00, 87.43s/it]
 10%|█         | 527/5198 [15:16:44<119:56:43, 92.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.48s/it][A100%|██████████| 1/1 [01:27<00:00, 87.48s/it]
 10%|█         | 527/5198 [15:16:44<119:56:31, 92.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.52s/it][A100%|██████████| 1/1 [01:27<00:00, 87.52s/it]
 10%|█         | 527/5198 [15:16:44<119:57:38, 92.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.47s/it][A100%|██████████| 1/1 [01:27<00:00, 87.47s/it]
 10%|█         | 527/5198 [15:16:44<119:56:58, 92.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.45s/it][A100%|██████████| 1/1 [01:27<00:00, 87.45s/it]
 10%|█         | 527/5198 [15:16:44<119:56:30, 92.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.47s/it][A100%|██████████| 1/1 [01:27<00:00, 87.47s/it]
 10%|█         | 527/5198 [15:16:47<119:56:57, 92.45s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_32
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.75s/it][A100%|██████████| 1/1 [01:59<00:00, 119.75s/it]
 10%|█         | 528/5198 [15:18:43<130:39:16, 100.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 10:43:50,100] [INFO] [logging.py:96:log_dist] [Rank 0] step=520, skipped=0, lr=[1.9805871145831233e-05], mom=[(0.9, 0.999)]
steps: 520 loss: 0.8139 iter time (s): 120.019 samples/sec: 1.067

100%|██████████| 1/1 [02:00<00:00, 120.82s/it][A100%|██████████| 1/1 [02:00<00:00, 120.82s/it]
 10%|█         | 528/5198 [15:18:45<130:57:56, 100.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.81s/it][A100%|██████████| 1/1 [02:00<00:00, 120.81s/it]
 10%|█         | 528/5198 [15:18:45<130:57:57, 100.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.81s/it][A100%|██████████| 1/1 [02:00<00:00, 120.81s/it]
 10%|█         | 528/5198 [15:18:45<130:57:37, 100.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.83s/it][A100%|██████████| 1/1 [02:00<00:00, 120.83s/it]
 10%|█         | 528/5198 [15:18:45<130:58:43, 100.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.83s/it][A100%|██████████| 1/1 [02:00<00:00, 120.83s/it]
 10%|█         | 528/5198 [15:18:45<130:58:21, 100.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.84s/it][A100%|██████████| 1/1 [02:00<00:00, 120.84s/it]
 10%|█         | 528/5198 [15:18:45<130:58:18, 100.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.84s/it][A100%|██████████| 1/1 [02:00<00:00, 120.84s/it]
 10%|█         | 528/5198 [15:18:48<130:58:36, 100.97s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_495
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.88s/it][A100%|██████████| 1/1 [01:38<00:00, 98.88s/it]
 10%|█         | 529/5198 [15:20:22<130:01:17, 100.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 10:45:28,839] [INFO] [logging.py:96:log_dist] [Rank 0] step=521, skipped=0, lr=[1.980475898224857e-05], mom=[(0.9, 0.999)]
steps: 521 loss: 0.6472 iter time (s): 97.651 samples/sec: 1.311

100%|██████████| 1/1 [01:38<00:00, 98.59s/it][A100%|██████████| 1/1 [01:38<00:00, 98.59s/it]
 10%|█         | 529/5198 [15:20:23<130:01:21, 100.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s]
[A100%|██████████| 1/1 [01:38<00:00, 98.45s/it][A100%|██████████| 1/1 [01:38<00:00, 98.45s/it]
 10%|█         | 529/5198 [15:20:23<129:58:06, 100.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.61s/it][A100%|██████████| 1/1 [01:38<00:00, 98.61s/it]
 10%|█         | 529/5198 [15:20:24<130:01:26, 100.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.47s/it][A100%|██████████| 1/1 [01:38<00:00, 98.47s/it]
 10%|█         | 529/5198 [15:20:24<129:58:53, 100.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.51s/it][A100%|██████████| 1/1 [01:38<00:00, 98.51s/it]
 10%|█         | 529/5198 [15:20:24<129:59:28, 100.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.51s/it][A100%|██████████| 1/1 [01:38<00:00, 98.51s/it]
 10%|█         | 529/5198 [15:20:24<129:59:30, 100.23s/it]
100%|██████████| 1/1 [01:38<00:00, 98.49s/it][A100%|██████████| 1/1 [01:38<00:00, 98.49s/it]
 10%|█         | 529/5198 [15:20:26<129:59:14, 100.23s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_496

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.51s/it][A100%|██████████| 1/1 [01:41<00:00, 101.51s/it]
 10%|█         | 530/5198 [15:22:04<130:33:27, 100.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 10:47:10,736] [INFO] [logging.py:96:log_dist] [Rank 0] step=522, skipped=0, lr=[1.9803643673376667e-05], mom=[(0.9, 0.999)]
steps: 522 loss: 0.5882 iter time (s): 101.021 samples/sec: 1.267

100%|██████████| 1/1 [01:41<00:00, 101.70s/it][A100%|██████████| 1/1 [01:41<00:00, 101.70s/it]
 10%|█         | 530/5198 [15:22:05<130:33:40, 100.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.79s/it][A100%|██████████| 1/1 [01:41<00:00, 101.79s/it]
 10%|█         | 530/5198 [15:22:05<130:33:36, 100.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.66s/it][A100%|██████████| 1/1 [01:41<00:00, 101.66s/it]
 10%|█         | 530/5198 [15:22:05<130:32:48, 100.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.79s/it][A100%|██████████| 1/1 [01:41<00:00, 101.79s/it]
 10%|█         | 530/5198 [15:22:05<130:34:07, 100.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.75s/it][A100%|██████████| 1/1 [01:41<00:00, 101.75s/it]
 10%|█         | 530/5198 [15:22:06<130:33:24, 100.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.77s/it][A100%|██████████| 1/1 [01:41<00:00, 101.77s/it]
 10%|█         | 530/5198 [15:22:06<130:33:55, 100.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.77s/it][A100%|██████████| 1/1 [01:41<00:00, 101.77s/it]
 10%|█         | 530/5198 [15:22:08<130:33:52, 100.69s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_497
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.62s/it][A100%|██████████| 1/1 [01:24<00:00, 84.62s/it]
 10%|█         | 531/5198 [15:23:29<124:21:51, 95.93s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 10:48:35,066] [INFO] [logging.py:96:log_dist] [Rank 0] step=523, skipped=0, lr=[1.9802525219573343e-05], mom=[(0.9, 0.999)]
steps: 523 loss: 0.5950 iter time (s): 83.571 samples/sec: 1.532

100%|██████████| 1/1 [01:24<00:00, 84.29s/it][A100%|██████████| 1/1 [01:24<00:00, 84.29s/it]
 10%|█         | 531/5198 [15:23:29<124:09:30, 95.77s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.31s/it][A100%|██████████| 1/1 [01:24<00:00, 84.31s/it]
 10%|█         | 531/5198 [15:23:29<124:09:56, 95.78s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.28s/it][A100%|██████████| 1/1 [01:24<00:00, 84.28s/it]
 10%|█         | 531/5198 [15:23:30<124:09:31, 95.77s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.43s/it][A100%|██████████| 1/1 [01:24<00:00, 84.43s/it]
 10%|█         | 531/5198 [15:23:30<124:12:13, 95.81s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.50s/it][A100%|██████████| 1/1 [01:24<00:00, 84.50s/it]
 10%|█         | 531/5198 [15:23:30<124:14:09, 95.83s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.52s/it][A100%|██████████| 1/1 [01:24<00:00, 84.52s/it]
 10%|█         | 531/5198 [15:23:32<124:14:59, 95.84s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_498
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.54s/it][A100%|██████████| 1/1 [01:24<00:00, 84.54s/it]
 10%|█         | 531/5198 [15:23:30<124:15:27, 95.85s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.70s/it][A100%|██████████| 1/1 [01:28<00:00, 88.70s/it]
 10%|█         | 532/5198 [15:24:58<121:36:24, 93.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 10:50:04,114] [INFO] [logging.py:96:log_dist] [Rank 0] step=524, skipped=0, lr=[1.9801403621197427e-05], mom=[(0.9, 0.999)]
steps: 524 loss: 0.6247 iter time (s): 88.089 samples/sec: 1.453

100%|██████████| 1/1 [01:29<00:00, 89.10s/it][A100%|██████████| 1/1 [01:29<00:00, 89.10s/it]
 10%|█         | 532/5198 [15:24:58<121:32:22, 93.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.13s/it][A100%|██████████| 1/1 [01:29<00:00, 89.13s/it]
 10%|█         | 532/5198 [15:24:58<121:33:26, 93.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.97s/it][A100%|██████████| 1/1 [01:28<00:00, 88.97s/it]
 10%|█         | 532/5198 [15:24:59<121:33:01, 93.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.12s/it][A100%|██████████| 1/1 [01:29<00:00, 89.12s/it]
 10%|█         | 532/5198 [15:24:59<121:32:58, 93.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.97s/it][A100%|██████████| 1/1 [01:28<00:00, 88.97s/it]
 10%|█         | 532/5198 [15:24:59<121:32:42, 93.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.91s/it][A100%|██████████| 1/1 [01:28<00:00, 88.92s/it]
 10%|█         | 532/5198 [15:24:59<121:32:16, 93.77s/it]
100%|██████████| 1/1 [01:28<00:00, 88.93s/it][A100%|██████████| 1/1 [01:28<00:00, 88.93s/it]
 10%|█         | 532/5198 [15:25:01<121:32:17, 93.77s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_499

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.67s/it][A100%|██████████| 1/1 [01:32<00:00, 92.67s/it]
 10%|█         | 533/5198 [15:26:31<121:12:17, 93.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 10:51:37,081] [INFO] [logging.py:96:log_dist] [Rank 0] step=525, skipped=0, lr=[1.980027887860875e-05], mom=[(0.9, 0.999)]
steps: 525 loss: 0.5842 iter time (s): 92.131 samples/sec: 1.389

100%|██████████| 1/1 [01:33<00:00, 93.03s/it][A100%|██████████| 1/1 [01:33<00:00, 93.03s/it]
 10%|█         | 533/5198 [15:26:31<121:13:47, 93.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.92s/it][A100%|██████████| 1/1 [01:32<00:00, 92.92s/it]
 10%|█         | 533/5198 [15:26:31<121:11:51, 93.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.91s/it][A100%|██████████| 1/1 [01:32<00:00, 92.91s/it]
 10%|█         | 533/5198 [15:26:32<121:11:18, 93.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.94s/it][A100%|██████████| 1/1 [01:32<00:00, 92.94s/it]
 10%|█         | 533/5198 [15:26:32<121:11:58, 93.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.90s/it][A100%|██████████| 1/1 [01:32<00:00, 92.90s/it]
 10%|█         | 533/5198 [15:26:32<121:10:57, 93.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.91s/it][A100%|██████████| 1/1 [01:32<00:00, 92.91s/it]
 10%|█         | 533/5198 [15:26:32<121:10:51, 93.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.93s/it][A100%|██████████| 1/1 [01:32<00:00, 92.93s/it]
 10%|█         | 533/5198 [15:26:34<121:11:20, 93.52s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_500
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.98s/it][A100%|██████████| 1/1 [01:22<00:00, 82.98s/it]
 10%|█         | 534/5198 [15:27:54<117:10:08, 90.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 10:53:00,003] [INFO] [logging.py:96:log_dist] [Rank 0] step=526, skipped=0, lr=[1.979915099216817e-05], mom=[(0.9, 0.999)]
steps: 526 loss: 0.5561 iter time (s): 82.104 samples/sec: 1.559

100%|██████████| 1/1 [01:22<00:00, 82.83s/it][A100%|██████████| 1/1 [01:22<00:00, 82.83s/it]
 10%|█         | 534/5198 [15:27:54<117:02:23, 90.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.89s/it][A100%|██████████| 1/1 [01:22<00:00, 82.90s/it]
 10%|█         | 534/5198 [15:27:54<117:02:32, 90.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.91s/it][A100%|██████████| 1/1 [01:22<00:00, 82.91s/it]
 10%|█         | 534/5198 [15:27:55<117:02:24, 90.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.87s/it][A100%|██████████| 1/1 [01:22<00:00, 82.87s/it]
 10%|█         | 534/5198 [15:27:55<117:01:55, 90.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.88s/it][A100%|██████████| 1/1 [01:22<00:00, 82.88s/it]
 10%|█         | 534/5198 [15:27:55<117:01:35, 90.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.84s/it][A100%|██████████| 1/1 [01:22<00:00, 82.84s/it]
 10%|█         | 534/5198 [15:27:57<117:00:54, 90.32s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_501

100%|██████████| 1/1 [01:22<00:00, 82.87s/it][A100%|██████████| 1/1 [01:22<00:00, 82.87s/it]
 10%|█         | 534/5198 [15:27:55<117:01:16, 90.33s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.97s/it][A100%|██████████| 1/1 [01:51<00:00, 111.97s/it]
 10%|█         | 535/5198 [15:29:46<125:35:30, 96.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 10:54:53,042] [INFO] [logging.py:96:log_dist] [Rank 0] step=527, skipped=0, lr=[1.9798019962237527e-05], mom=[(0.9, 0.999)]
steps: 527 loss: 0.5803 iter time (s): 112.288 samples/sec: 1.140

100%|██████████| 1/1 [01:53<00:00, 113.06s/it][A100%|██████████| 1/1 [01:53<00:00, 113.06s/it]
 10%|█         | 535/5198 [15:29:47<125:50:55, 97.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.10s/it][A100%|██████████| 1/1 [01:53<00:00, 113.10s/it]
 10%|█         | 535/5198 [15:29:47<125:51:53, 97.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.08s/it][A100%|██████████| 1/1 [01:53<00:00, 113.08s/it]
 10%|█         | 535/5198 [15:29:48<125:51:10, 97.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.11s/it][A100%|██████████| 1/1 [01:53<00:00, 113.12s/it]
 10%|█         | 535/5198 [15:29:48<125:51:44, 97.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.10s/it][A100%|██████████| 1/1 [01:53<00:00, 113.10s/it]
 10%|█         | 535/5198 [15:29:48<125:51:11, 97.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.12s/it][A100%|██████████| 1/1 [01:53<00:00, 113.12s/it]
 10%|█         | 535/5198 [15:29:48<125:51:19, 97.16s/it]
100%|██████████| 1/1 [01:53<00:00, 113.12s/it][A100%|██████████| 1/1 [01:53<00:00, 113.12s/it]
 10%|█         | 535/5198 [15:29:50<125:51:16, 97.16s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_502

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:17<00:00, 137.33s/it][A100%|██████████| 1/1 [02:17<00:00, 137.33s/it]
 10%|█         | 536/5198 [15:32:04<141:18:36, 109.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 10:57:11,198] [INFO] [logging.py:96:log_dist] [Rank 0] step=528, skipped=0, lr=[1.979688578917969e-05], mom=[(0.9, 0.999)]
steps: 528 loss: 0.5752 iter time (s): 137.316 samples/sec: 0.932

100%|██████████| 1/1 [02:18<00:00, 138.17s/it][A100%|██████████| 1/1 [02:18<00:00, 138.17s/it]
 10%|█         | 536/5198 [15:32:05<141:45:39, 109.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:18<00:00, 138.12s/it][A100%|██████████| 1/1 [02:18<00:00, 138.12s/it]
 10%|█         | 536/5198 [15:32:05<141:45:09, 109.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:18<00:00, 138.07s/it][A100%|██████████| 1/1 [02:18<00:00, 138.07s/it]
 10%|█         | 536/5198 [15:32:06<141:43:27, 109.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:18<00:00, 138.08s/it][A100%|██████████| 1/1 [02:18<00:00, 138.08s/it]
 10%|█         | 536/5198 [15:32:06<141:43:55, 109.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:18<00:00, 138.06s/it][A100%|██████████| 1/1 [02:18<00:00, 138.06s/it]
 10%|█         | 536/5198 [15:32:08<141:42:59, 109.43s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_503

100%|██████████| 1/1 [02:18<00:00, 138.12s/it][A100%|██████████| 1/1 [02:18<00:00, 138.12s/it]
 10%|█         | 536/5198 [15:32:06<141:44:24, 109.45s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:18<00:00, 138.08s/it][A100%|██████████| 1/1 [02:18<00:00, 138.08s/it]
 10%|█         | 536/5198 [15:32:06<141:43:30, 109.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.11s/it][A100%|██████████| 1/1 [01:30<00:00, 90.11s/it]
 10%|█         | 537/5198 [15:33:34<133:57:55, 103.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 10:58:40,188] [INFO] [logging.py:96:log_dist] [Rank 0] step=529, skipped=0, lr=[1.9795748473358537e-05], mom=[(0.9, 0.999)]
steps: 529 loss: 0.5885 iter time (s): 88.237 samples/sec: 1.451

100%|██████████| 1/1 [01:28<00:00, 88.97s/it][A100%|██████████| 1/1 [01:28<00:00, 88.97s/it]
 10%|█         | 537/5198 [15:33:34<133:46:18, 103.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.95s/it][A100%|██████████| 1/1 [01:28<00:00, 88.95s/it]
 10%|█         | 537/5198 [15:33:34<133:45:41, 103.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.11s/it][A100%|██████████| 1/1 [01:29<00:00, 89.11s/it]
 10%|█         | 537/5198 [15:33:35<133:48:05, 103.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.08s/it][A100%|██████████| 1/1 [01:29<00:00, 89.08s/it]
 10%|█         | 537/5198 [15:33:35<133:47:46, 103.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.02s/it][A100%|██████████| 1/1 [01:29<00:00, 89.02s/it]
 10%|█         | 537/5198 [15:33:35<133:46:33, 103.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.06s/it][A100%|██████████| 1/1 [01:29<00:00, 89.06s/it]
 10%|█         | 537/5198 [15:33:35<133:46:49, 103.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.09s/it][A100%|██████████| 1/1 [01:29<00:00, 89.09s/it]
 10%|█         | 537/5198 [15:33:37<133:47:18, 103.33s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_504
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.27s/it][A100%|██████████| 1/1 [01:43<00:00, 103.27s/it]
 10%|█         | 538/5198 [15:35:17<133:55:34, 103.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 11:00:24,017] [INFO] [logging.py:96:log_dist] [Rank 0] step=530, skipped=0, lr=[1.9794608015138936e-05], mom=[(0.9, 0.999)]
steps: 530 loss: 0.5723 iter time (s): 102.972 samples/sec: 1.243

100%|██████████| 1/1 [01:43<00:00, 103.81s/it][A100%|██████████| 1/1 [01:43<00:00, 103.82s/it]
 10%|█         | 538/5198 [15:35:18<133:56:16, 103.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.90s/it][A100%|██████████| 1/1 [01:43<00:00, 103.91s/it]
 10%|█         | 538/5198 [15:35:18<133:58:13, 103.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.81s/it][A100%|██████████| 1/1 [01:43<00:00, 103.81s/it]
 10%|█         | 538/5198 [15:35:19<133:57:31, 103.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.84s/it][A100%|██████████| 1/1 [01:43<00:00, 103.84s/it]
 10%|█         | 538/5198 [15:35:19<133:57:49, 103.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.85s/it][A100%|██████████| 1/1 [01:43<00:00, 103.85s/it]
 10%|█         | 538/5198 [15:35:19<133:57:16, 103.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.84s/it][A100%|██████████| 1/1 [01:43<00:00, 103.84s/it]
 10%|█         | 538/5198 [15:35:19<133:57:19, 103.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.84s/it][A100%|██████████| 1/1 [01:43<00:00, 103.84s/it]
 10%|█         | 538/5198 [15:35:21<133:57:26, 103.49s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_505
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.66s/it][A100%|██████████| 1/1 [01:38<00:00, 98.66s/it]
 10%|█         | 539/5198 [15:36:56<132:05:09, 102.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 11:02:02,693] [INFO] [logging.py:96:log_dist] [Rank 0] step=531, skipped=0, lr=[1.9793464414886774e-05], mom=[(0.9, 0.999)]
steps: 531 loss: 0.6328 iter time (s): 97.800 samples/sec: 1.309

100%|██████████| 1/1 [01:38<00:00, 98.60s/it][A100%|██████████| 1/1 [01:38<00:00, 98.60s/it]
 10%|█         | 539/5198 [15:36:57<132:01:22, 102.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.48s/it][A100%|██████████| 1/1 [01:38<00:00, 98.48s/it]
 10%|█         | 539/5198 [15:36:57<132:00:02, 102.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.54s/it][A100%|██████████| 1/1 [01:38<00:00, 98.54s/it]
 10%|█         | 539/5198 [15:36:57<132:00:40, 102.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.58s/it][A100%|██████████| 1/1 [01:38<00:00, 98.58s/it]
 10%|█         | 539/5198 [15:36:57<132:01:53, 102.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.60s/it][A100%|██████████| 1/1 [01:38<00:00, 98.60s/it]
 10%|█         | 539/5198 [15:36:58<132:01:57, 102.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.60s/it][A100%|██████████| 1/1 [01:38<00:00, 98.60s/it]
 10%|█         | 539/5198 [15:36:58<132:01:59, 102.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.61s/it][A100%|██████████| 1/1 [01:38<00:00, 98.61s/it]
 10%|█         | 539/5198 [15:37:00<132:02:20, 102.03s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_506
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.06s/it][A100%|██████████| 1/1 [01:40<00:00, 100.06s/it]
 10%|█         | 540/5198 [15:38:36<131:19:57, 101.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 11:03:42,915] [INFO] [logging.py:96:log_dist] [Rank 0] step=532, skipped=0, lr=[1.9792317672968954e-05], mom=[(0.9, 0.999)]
steps: 532 loss: 0.5799 iter time (s): 99.408 samples/sec: 1.288

100%|██████████| 1/1 [01:40<00:00, 100.24s/it][A100%|██████████| 1/1 [01:40<00:00, 100.24s/it]
 10%|█         | 540/5198 [15:38:37<131:17:36, 101.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.34s/it][A100%|██████████| 1/1 [01:40<00:00, 100.34s/it]
 10%|█         | 540/5198 [15:38:37<131:21:05, 101.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.29s/it][A100%|██████████| 1/1 [01:40<00:00, 100.29s/it]
 10%|█         | 540/5198 [15:38:38<131:19:16, 101.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.24s/it][A100%|██████████| 1/1 [01:40<00:00, 100.24s/it]
 10%|█         | 540/5198 [15:38:38<131:18:58, 101.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.22s/it][A100%|██████████| 1/1 [01:40<00:00, 100.23s/it]
 10%|█         | 540/5198 [15:38:38<131:18:35, 101.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.22s/it][A100%|██████████| 1/1 [01:40<00:00, 100.22s/it]
 10%|█         | 540/5198 [15:38:38<131:18:35, 101.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.22s/it][A100%|██████████| 1/1 [01:40<00:00, 100.22s/it]
 10%|█         | 540/5198 [15:38:40<131:18:42, 101.49s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_507
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.35s/it][A100%|██████████| 1/1 [01:30<00:00, 90.35s/it]
 10%|█         | 541/5198 [15:40:07<127:01:49, 98.20s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 11:05:13,049] [INFO] [logging.py:96:log_dist] [Rank 0] step=533, skipped=0, lr=[1.9791167789753372e-05], mom=[(0.9, 0.999)]
steps: 533 loss: 0.5493 iter time (s): 89.315 samples/sec: 1.433

100%|██████████| 1/1 [01:29<00:00, 89.96s/it][A100%|██████████| 1/1 [01:29<00:00, 89.96s/it]
 10%|█         | 541/5198 [15:40:07<126:50:37, 98.05s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.10s/it][A100%|██████████| 1/1 [01:30<00:00, 90.10s/it]
 10%|█         | 541/5198 [15:40:07<126:51:29, 98.07s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.09s/it][A100%|██████████| 1/1 [01:30<00:00, 90.09s/it]
 10%|█         | 541/5198 [15:40:08<126:52:19, 98.08s/it] 
100%|██████████| 1/1 [01:30<00:00, 90.02s/it][A100%|██████████| 1/1 [01:30<00:00, 90.02s/it]
 10%|█         | 541/5198 [15:40:08<126:50:16, 98.05s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.07s/it][A100%|██████████| 1/1 [01:30<00:00, 90.07s/it]
 10%|█         | 541/5198 [15:40:08<126:51:17, 98.06s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.06s/it][A100%|██████████| 1/1 [01:30<00:00, 90.06s/it]
 10%|█         | 541/5198 [15:40:08<126:51:01, 98.06s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.08s/it][A100%|██████████| 1/1 [01:30<00:00, 90.08s/it]
 10%|█         | 541/5198 [15:40:10<126:51:28, 98.06s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_508
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:15<00:00, 135.79s/it][A100%|██████████| 1/1 [02:15<00:00, 135.79s/it]
 10%|█         | 542/5198 [15:42:23<141:38:06, 109.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 11:07:30,282] [INFO] [logging.py:96:log_dist] [Rank 0] step=534, skipped=0, lr=[1.9790014765608948e-05], mom=[(0.9, 0.999)]
steps: 534 loss: 0.6117 iter time (s): 136.460 samples/sec: 0.938

100%|██████████| 1/1 [02:17<00:00, 137.28s/it][A100%|██████████| 1/1 [02:17<00:00, 137.28s/it]
 10%|█         | 542/5198 [15:42:24<142:02:24, 109.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:17<00:00, 137.36s/it][A100%|██████████| 1/1 [02:17<00:00, 137.36s/it]
 10%|█         | 542/5198 [15:42:25<142:04:49, 109.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:17<00:00, 137.22s/it][A100%|██████████| 1/1 [02:17<00:00, 137.22s/it]
 10%|█         | 542/5198 [15:42:25<142:02:03, 109.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:17<00:00, 137.31s/it][A100%|██████████| 1/1 [02:17<00:00, 137.31s/it]
 10%|█         | 542/5198 [15:42:25<142:02:45, 109.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:17<00:00, 137.24s/it][A100%|██████████| 1/1 [02:17<00:00, 137.24s/it]
 10%|█         | 542/5198 [15:42:25<142:01:54, 109.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:17<00:00, 137.27s/it][A100%|██████████| 1/1 [02:17<00:00, 137.27s/it]
 10%|█         | 542/5198 [15:42:25<142:02:21, 109.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:17<00:00, 137.24s/it][A100%|██████████| 1/1 [02:17<00:00, 137.24s/it]
 10%|█         | 542/5198 [15:42:27<142:02:08, 109.82s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_509
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.19s/it][A100%|██████████| 1/1 [01:21<00:00, 81.19s/it]
 10%|█         | 543/5198 [15:43:44<130:41:02, 101.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 11:08:50,049] [INFO] [logging.py:96:log_dist] [Rank 0] step=535, skipped=0, lr=[1.978885860090559e-05], mom=[(0.9, 0.999)]
steps: 535 loss: 0.5717 iter time (s): 79.092 samples/sec: 1.618

100%|██████████| 1/1 [01:19<00:00, 79.87s/it][A100%|██████████| 1/1 [01:19<00:00, 79.87s/it]
 10%|█         | 543/5198 [15:43:44<130:23:56, 100.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.82s/it][A100%|██████████| 1/1 [01:19<00:00, 79.82s/it]
 10%|█         | 543/5198 [15:43:44<130:24:13, 100.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.91s/it][A100%|██████████| 1/1 [01:19<00:00, 79.91s/it]
 10%|█         | 543/5198 [15:43:45<130:24:18, 100.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.84s/it][A100%|██████████| 1/1 [01:19<00:00, 79.84s/it]
 10%|█         | 543/5198 [15:43:45<130:23:07, 100.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.86s/it][A100%|██████████| 1/1 [01:19<00:00, 79.86s/it]
 10%|█         | 543/5198 [15:43:45<130:23:06, 100.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.87s/it][A100%|██████████| 1/1 [01:19<00:00, 79.87s/it]
 10%|█         | 543/5198 [15:43:45<130:23:31, 100.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.88s/it][A100%|██████████| 1/1 [01:19<00:00, 79.88s/it]
 10%|█         | 543/5198 [15:43:47<130:23:39, 100.84s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_33
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.87s/it][A100%|██████████| 1/1 [01:58<00:00, 118.87s/it]
 10%|█         | 544/5198 [15:45:43<137:38:35, 106.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 11:10:50,005] [INFO] [logging.py:96:log_dist] [Rank 0] step=536, skipped=0, lr=[1.9787699296014235e-05], mom=[(0.9, 0.999)]
steps: 536 loss: 0.7604 iter time (s): 119.334 samples/sec: 1.073

100%|██████████| 1/1 [02:00<00:00, 120.34s/it][A100%|██████████| 1/1 [02:00<00:00, 120.34s/it]
 10%|█         | 544/5198 [15:45:45<137:56:13, 106.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.39s/it][A100%|██████████| 1/1 [02:00<00:00, 120.39s/it]
 10%|█         | 544/5198 [15:45:45<137:57:38, 106.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.32s/it][A100%|██████████| 1/1 [02:00<00:00, 120.32s/it]
 10%|█         | 544/5198 [15:45:45<137:55:57, 106.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.34s/it][A100%|██████████| 1/1 [02:00<00:00, 120.34s/it]
 10%|█         | 544/5198 [15:45:45<137:55:32, 106.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.38s/it][A100%|██████████| 1/1 [02:00<00:00, 120.39s/it]
 10%|█         | 544/5198 [15:45:45<137:56:35, 106.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.34s/it][A100%|██████████| 1/1 [02:00<00:00, 120.34s/it]
 10%|█         | 544/5198 [15:45:48<137:55:54, 106.69s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_510

100%|██████████| 1/1 [02:00<00:00, 120.37s/it][A100%|██████████| 1/1 [02:00<00:00, 120.37s/it]
 10%|█         | 544/5198 [15:45:45<137:56:23, 106.70s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.98s/it][A100%|██████████| 1/1 [01:41<00:00, 101.98s/it]
 10%|█         | 545/5198 [15:47:25<135:58:24, 105.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 11:12:31,854] [INFO] [logging.py:96:log_dist] [Rank 0] step=537, skipped=0, lr=[1.9786536851306807e-05], mom=[(0.9, 0.999)]
steps: 537 loss: 0.6039 iter time (s): 100.549 samples/sec: 1.273

100%|██████████| 1/1 [01:41<00:00, 101.32s/it][A100%|██████████| 1/1 [01:41<00:00, 101.33s/it]
 10%|█         | 545/5198 [15:47:26<135:49:42, 105.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.25s/it][A100%|██████████| 1/1 [01:41<00:00, 101.25s/it]
 10%|█         | 545/5198 [15:47:26<135:49:01, 105.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.31s/it][A100%|██████████| 1/1 [01:41<00:00, 101.31s/it]
 10%|█         | 545/5198 [15:47:26<135:49:06, 105.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.38s/it][A100%|██████████| 1/1 [01:41<00:00, 101.38s/it]
 10%|█         | 545/5198 [15:47:27<135:50:20, 105.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.33s/it][A100%|██████████| 1/1 [01:41<00:00, 101.33s/it]
 10%|█         | 545/5198 [15:47:27<135:50:07, 105.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.45s/it][A100%|██████████| 1/1 [01:41<00:00, 101.45s/it]
 10%|█         | 545/5198 [15:47:27<135:52:39, 105.13s/it]
100%|██████████| 1/1 [01:41<00:00, 101.45s/it][A100%|██████████| 1/1 [01:41<00:00, 101.45s/it]
 10%|█         | 545/5198 [15:47:29<135:52:28, 105.13s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_511

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.98s/it][A100%|██████████| 1/1 [01:22<00:00, 82.98s/it]
 11%|█         | 546/5198 [15:48:49<127:25:09, 98.60s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 11:13:54,677] [INFO] [logging.py:96:log_dist] [Rank 0] step=538, skipped=0, lr=[1.978537126715625e-05], mom=[(0.9, 0.999)]
steps: 538 loss: 0.5984 iter time (s): 81.899 samples/sec: 1.563

100%|██████████| 1/1 [01:22<00:00, 82.85s/it][A100%|██████████| 1/1 [01:22<00:00, 82.85s/it]
 11%|█         | 546/5198 [15:48:49<127:10:53, 98.42s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.79s/it][A100%|██████████| 1/1 [01:22<00:00, 82.79s/it]
 11%|█         | 546/5198 [15:48:49<127:09:01, 98.40s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.85s/it][A100%|██████████| 1/1 [01:22<00:00, 82.85s/it]
 11%|█         | 546/5198 [15:48:49<127:10:28, 98.42s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.84s/it][A100%|██████████| 1/1 [01:22<00:00, 82.84s/it]
 11%|█         | 546/5198 [15:48:49<127:11:08, 98.42s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.82s/it][A100%|██████████| 1/1 [01:22<00:00, 82.83s/it]
 11%|█         | 546/5198 [15:48:50<127:10:33, 98.42s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.71s/it][A100%|██████████| 1/1 [01:22<00:00, 82.71s/it]
 11%|█         | 546/5198 [15:48:50<127:09:39, 98.40s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.72s/it][A100%|██████████| 1/1 [01:22<00:00, 82.72s/it]
 11%|█         | 546/5198 [15:48:52<127:09:46, 98.41s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_512
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.21s/it][A100%|██████████| 1/1 [01:39<00:00, 99.21s/it]
 11%|█         | 547/5198 [15:50:28<127:40:58, 98.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 11:15:34,523] [INFO] [logging.py:96:log_dist] [Rank 0] step=539, skipped=0, lr=[1.978420254393652e-05], mom=[(0.9, 0.999)]
steps: 539 loss: 0.6194 iter time (s): 99.022 samples/sec: 1.293

100%|██████████| 1/1 [01:39<00:00, 99.81s/it][A100%|██████████| 1/1 [01:39<00:00, 99.81s/it]
 11%|█         | 547/5198 [15:50:29<127:41:40, 98.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.89s/it][A100%|██████████| 1/1 [01:39<00:00, 99.89s/it]
 11%|█         | 547/5198 [15:50:29<127:42:23, 98.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.82s/it][A100%|██████████| 1/1 [01:39<00:00, 99.82s/it]
 11%|█         | 547/5198 [15:50:29<127:41:36, 98.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.81s/it][A100%|██████████| 1/1 [01:39<00:00, 99.81s/it]
 11%|█         | 547/5198 [15:50:29<127:41:59, 98.84s/it]
100%|██████████| 1/1 [01:39<00:00, 99.78s/it][A100%|██████████| 1/1 [01:39<00:00, 99.78s/it]
 11%|█         | 547/5198 [15:50:29<127:40:53, 98.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.80s/it][A100%|██████████| 1/1 [01:39<00:00, 99.80s/it]
 11%|█         | 547/5198 [15:50:29<127:40:31, 98.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.80s/it][A100%|██████████| 1/1 [01:39<00:00, 99.80s/it]
 11%|█         | 547/5198 [15:50:32<127:40:37, 98.83s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_513
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.61s/it][A100%|██████████| 1/1 [01:18<00:00, 78.61s/it]
 11%|█         | 548/5198 [15:51:47<119:55:56, 92.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 11:16:52,846] [INFO] [logging.py:96:log_dist] [Rank 0] step=540, skipped=0, lr=[1.9783030682022566e-05], mom=[(0.9, 0.999)]
steps: 540 loss: 0.6296 iter time (s): 77.539 samples/sec: 1.651

100%|██████████| 1/1 [01:18<00:00, 78.28s/it][A100%|██████████| 1/1 [01:18<00:00, 78.28s/it]
 11%|█         | 548/5198 [15:51:47<119:42:09, 92.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.29s/it][A100%|██████████| 1/1 [01:18<00:00, 78.29s/it]
 11%|█         | 548/5198 [15:51:47<119:43:03, 92.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.33s/it][A100%|██████████| 1/1 [01:18<00:00, 78.33s/it]
 11%|█         | 548/5198 [15:51:47<119:43:19, 92.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.27s/it][A100%|██████████| 1/1 [01:18<00:00, 78.27s/it]
 11%|█         | 548/5198 [15:51:48<119:42:15, 92.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.37s/it][A100%|██████████| 1/1 [01:18<00:00, 78.37s/it]
 11%|█         | 548/5198 [15:51:48<119:43:46, 92.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.33s/it][A100%|██████████| 1/1 [01:18<00:00, 78.33s/it]
 11%|█         | 548/5198 [15:51:48<119:42:38, 92.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.34s/it][A100%|██████████| 1/1 [01:18<00:00, 78.34s/it]
 11%|█         | 548/5198 [15:51:50<119:42:54, 92.68s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_514
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.72s/it][A100%|██████████| 1/1 [01:35<00:00, 95.72s/it]
 11%|█         | 549/5198 [15:53:23<121:05:14, 93.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 11:18:29,259] [INFO] [logging.py:96:log_dist] [Rank 0] step=541, skipped=0, lr=[1.9781855681790346e-05], mom=[(0.9, 0.999)]
steps: 541 loss: 0.5637 iter time (s): 95.603 samples/sec: 1.339

100%|██████████| 1/1 [01:36<00:00, 96.41s/it][A100%|██████████| 1/1 [01:36<00:00, 96.41s/it]
 11%|█         | 549/5198 [15:53:23<121:07:47, 93.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.37s/it][A100%|██████████| 1/1 [01:36<00:00, 96.37s/it]
 11%|█         | 549/5198 [15:53:23<121:07:29, 93.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.44s/it][A100%|██████████| 1/1 [01:36<00:00, 96.44s/it]
 11%|█         | 549/5198 [15:53:24<121:09:09, 93.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.47s/it][A100%|██████████| 1/1 [01:36<00:00, 96.47s/it]
 11%|█         | 549/5198 [15:53:24<121:09:05, 93.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.38s/it][A100%|██████████| 1/1 [01:36<00:00, 96.38s/it]
 11%|█         | 549/5198 [15:53:24<121:08:04, 93.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.38s/it][A100%|██████████| 1/1 [01:36<00:00, 96.38s/it]
 11%|█         | 549/5198 [15:53:26<121:07:29, 93.79s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_515

100%|██████████| 1/1 [01:36<00:00, 96.41s/it][A100%|██████████| 1/1 [01:36<00:00, 96.41s/it]
 11%|█         | 549/5198 [15:53:24<121:07:55, 93.80s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.33s/it][A100%|██████████| 1/1 [01:35<00:00, 95.33s/it]
 11%|█         | 550/5198 [15:54:58<121:45:32, 94.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 11:20:04,778] [INFO] [logging.py:96:log_dist] [Rank 0] step=542, skipped=0, lr=[1.9780677543616837e-05], mom=[(0.9, 0.999)]
steps: 542 loss: 0.6186 iter time (s): 94.732 samples/sec: 1.351

100%|██████████| 1/1 [01:35<00:00, 95.54s/it][A100%|██████████| 1/1 [01:35<00:00, 95.54s/it]
 11%|█         | 550/5198 [15:54:59<121:46:49, 94.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.76s/it][A100%|██████████| 1/1 [01:35<00:00, 95.76s/it]
 11%|█         | 550/5198 [15:54:59<121:51:49, 94.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.59s/it][A100%|██████████| 1/1 [01:35<00:00, 95.59s/it]
 11%|█         | 550/5198 [15:55:00<121:49:00, 94.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.68s/it][A100%|██████████| 1/1 [01:35<00:00, 95.68s/it]
 11%|█         | 550/5198 [15:55:00<121:50:55, 94.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.75s/it][A100%|██████████| 1/1 [01:35<00:00, 95.75s/it]
 11%|█         | 550/5198 [15:55:00<121:51:50, 94.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.74s/it][A100%|██████████| 1/1 [01:35<00:00, 95.74s/it]
 11%|█         | 550/5198 [15:55:00<121:51:38, 94.38s/it]
100%|██████████| 1/1 [01:35<00:00, 95.75s/it][A100%|██████████| 1/1 [01:35<00:00, 95.75s/it]
 11%|█         | 550/5198 [15:55:02<121:51:35, 94.38s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_516

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.18s/it][A100%|██████████| 1/1 [01:23<00:00, 83.18s/it]
 11%|█         | 551/5198 [15:56:22<117:29:33, 91.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 11:21:27,700] [INFO] [logging.py:96:log_dist] [Rank 0] step=543, skipped=0, lr=[1.9779496267880012e-05], mom=[(0.9, 0.999)]
steps: 543 loss: 0.6027 iter time (s): 81.893 samples/sec: 1.563

100%|██████████| 1/1 [01:22<00:00, 82.89s/it][A100%|██████████| 1/1 [01:22<00:00, 82.89s/it]
 11%|█         | 551/5198 [15:56:22<117:19:43, 90.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.63s/it][A100%|██████████| 1/1 [01:22<00:00, 82.63s/it]
 11%|█         | 551/5198 [15:56:22<117:17:47, 90.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.72s/it][A100%|██████████| 1/1 [01:22<00:00, 82.73s/it]
 11%|█         | 551/5198 [15:56:22<117:17:39, 90.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.69s/it][A100%|██████████| 1/1 [01:22<00:00, 82.69s/it]
 11%|█         | 551/5198 [15:56:22<117:17:58, 90.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.67s/it][A100%|██████████| 1/1 [01:22<00:00, 82.67s/it]
 11%|█         | 551/5198 [15:56:23<117:18:09, 90.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.64s/it][A100%|██████████| 1/1 [01:22<00:00, 82.64s/it]
 11%|█         | 551/5198 [15:56:25<117:17:22, 90.86s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_517
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.66s/it][A100%|██████████| 1/1 [01:22<00:00, 82.66s/it]
 11%|█         | 551/5198 [15:56:23<117:17:51, 90.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:16<00:00, 136.30s/it][A100%|██████████| 1/1 [02:16<00:00, 136.30s/it]
 11%|█         | 552/5198 [15:58:38<135:03:31, 104.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 11:23:45,726] [INFO] [logging.py:96:log_dist] [Rank 0] step=544, skipped=0, lr=[1.9778311854958855e-05], mom=[(0.9, 0.999)]
steps: 544 loss: 0.6044 iter time (s): 137.297 samples/sec: 0.932

100%|██████████| 1/1 [02:18<00:00, 138.02s/it][A100%|██████████| 1/1 [02:18<00:00, 138.02s/it]
 11%|█         | 552/5198 [15:58:40<135:33:15, 105.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:18<00:00, 138.01s/it][A100%|██████████| 1/1 [02:18<00:00, 138.01s/it]
 11%|█         | 552/5198 [15:58:40<135:31:34, 105.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:18<00:00, 138.07s/it][A100%|██████████| 1/1 [02:18<00:00, 138.07s/it]
 11%|█         | 552/5198 [15:58:40<135:32:52, 105.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:17<00:00, 137.97s/it][A100%|██████████| 1/1 [02:17<00:00, 137.97s/it]
 11%|█         | 552/5198 [15:58:40<135:30:50, 105.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:18<00:00, 138.01s/it][A100%|██████████| 1/1 [02:18<00:00, 138.01s/it]
 11%|█         | 552/5198 [15:58:41<135:31:42, 105.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:18<00:00, 138.02s/it][A100%|██████████| 1/1 [02:18<00:00, 138.02s/it]
 11%|█         | 552/5198 [15:58:43<135:31:26, 105.01s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_518

100%|██████████| 1/1 [02:18<00:00, 138.01s/it][A100%|██████████| 1/1 [02:18<00:00, 138.01s/it]
 11%|█         | 552/5198 [15:58:41<135:31:33, 105.01s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.69s/it][A100%|██████████| 1/1 [01:35<00:00, 95.69s/it]
 11%|█         | 553/5198 [16:00:14<131:37:05, 102.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 11:25:20,338] [INFO] [logging.py:96:log_dist] [Rank 0] step=545, skipped=0, lr=[1.9777124305233354e-05], mom=[(0.9, 0.999)]
steps: 545 loss: 0.5973 iter time (s): 93.862 samples/sec: 1.364

100%|██████████| 1/1 [01:34<00:00, 94.58s/it][A100%|██████████| 1/1 [01:34<00:00, 94.58s/it]
 11%|█         | 553/5198 [16:00:14<131:28:53, 101.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.62s/it][A100%|██████████| 1/1 [01:34<00:00, 94.62s/it]
 11%|█         | 553/5198 [16:00:15<131:28:46, 101.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.60s/it][A100%|██████████| 1/1 [01:34<00:00, 94.60s/it]
 11%|█         | 553/5198 [16:00:15<131:27:36, 101.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.64s/it][A100%|██████████| 1/1 [01:34<00:00, 94.64s/it]
 11%|█         | 553/5198 [16:00:15<131:30:01, 101.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.59s/it][A100%|██████████| 1/1 [01:34<00:00, 94.59s/it]
 11%|█         | 553/5198 [16:00:15<131:27:59, 101.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.60s/it][A100%|██████████| 1/1 [01:34<00:00, 94.60s/it]
 11%|█         | 553/5198 [16:00:15<131:28:05, 101.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.64s/it][A100%|██████████| 1/1 [01:34<00:00, 94.64s/it]
 11%|█         | 553/5198 [16:00:17<131:28:54, 101.90s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_519
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.40s/it][A100%|██████████| 1/1 [01:23<00:00, 83.40s/it]
 11%|█         | 554/5198 [16:01:38<124:27:25, 96.48s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 11:26:43,624] [INFO] [logging.py:96:log_dist] [Rank 0] step=546, skipped=0, lr=[1.97759336190845e-05], mom=[(0.9, 0.999)]
steps: 546 loss: 0.5599 iter time (s): 82.493 samples/sec: 1.552

100%|██████████| 1/1 [01:23<00:00, 83.36s/it][A100%|██████████| 1/1 [01:23<00:00, 83.36s/it]
 11%|█         | 554/5198 [16:01:38<124:16:52, 96.34s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.28s/it][A100%|██████████| 1/1 [01:23<00:00, 83.28s/it]
 11%|█         | 554/5198 [16:01:38<124:14:58, 96.32s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.16s/it][A100%|██████████| 1/1 [01:23<00:00, 83.16s/it]
 11%|█         | 554/5198 [16:01:38<124:13:04, 96.29s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.37s/it][A100%|██████████| 1/1 [01:23<00:00, 83.37s/it]
 11%|█         | 554/5198 [16:01:38<124:16:16, 96.33s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.30s/it][A100%|██████████| 1/1 [01:23<00:00, 83.30s/it]
 11%|█         | 554/5198 [16:01:38<124:14:47, 96.32s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.33s/it][A100%|██████████| 1/1 [01:23<00:00, 83.33s/it]
 11%|█         | 554/5198 [16:01:38<124:15:28, 96.32s/it] 
100%|██████████| 1/1 [01:23<00:00, 83.29s/it][A
100%|██████████| 1/1 [01:23<00:00, 83.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A 11%|█         | 554/5198 [16:01:41<124:15:22, 96.32s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_520
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.12s/it][A100%|██████████| 1/1 [01:29<00:00, 89.12s/it]
 11%|█         | 555/5198 [16:03:07<121:39:57, 94.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 11:28:13,072] [INFO] [logging.py:96:log_dist] [Rank 0] step=547, skipped=0, lr=[1.97747397968943e-05], mom=[(0.9, 0.999)]
steps: 547 loss: 0.5478 iter time (s): 88.640 samples/sec: 1.444

100%|██████████| 1/1 [01:29<00:00, 89.40s/it][A100%|██████████| 1/1 [01:29<00:00, 89.40s/it]
 11%|█         | 555/5198 [16:03:07<121:34:18, 94.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.46s/it][A100%|██████████| 1/1 [01:29<00:00, 89.46s/it]
 11%|█         | 555/5198 [16:03:07<121:34:16, 94.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.49s/it][A100%|██████████| 1/1 [01:29<00:00, 89.49s/it]
 11%|█         | 555/5198 [16:03:08<121:33:41, 94.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.42s/it][A100%|██████████| 1/1 [01:29<00:00, 89.42s/it]
 11%|█         | 555/5198 [16:03:08<121:34:11, 94.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.46s/it][A100%|██████████| 1/1 [01:29<00:00, 89.46s/it]
 11%|█         | 555/5198 [16:03:08<121:34:18, 94.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.41s/it][A100%|██████████| 1/1 [01:29<00:00, 89.41s/it]
 11%|█         | 555/5198 [16:03:08<121:33:34, 94.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.42s/it][A100%|██████████| 1/1 [01:29<00:00, 89.42s/it]
 11%|█         | 555/5198 [16:03:10<121:33:41, 94.25s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_521
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.01s/it][A100%|██████████| 1/1 [01:32<00:00, 92.01s/it]
 11%|█         | 556/5198 [16:04:39<120:47:56, 93.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 11:29:45,319] [INFO] [logging.py:96:log_dist] [Rank 0] step=548, skipped=0, lr=[1.9773542839045763e-05], mom=[(0.9, 0.999)]
steps: 548 loss: 0.5894 iter time (s): 91.459 samples/sec: 1.400

100%|██████████| 1/1 [01:32<00:00, 92.21s/it][A100%|██████████| 1/1 [01:32<00:00, 92.21s/it]
 11%|█         | 556/5198 [16:04:39<120:45:25, 93.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.23s/it][A100%|██████████| 1/1 [01:32<00:00, 92.24s/it]
 11%|█         | 556/5198 [16:04:40<120:45:52, 93.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.25s/it][A100%|██████████| 1/1 [01:32<00:00, 92.25s/it]
 11%|█         | 556/5198 [16:04:40<120:45:48, 93.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.27s/it][A100%|██████████| 1/1 [01:32<00:00, 92.28s/it]
 11%|█         | 556/5198 [16:04:40<120:46:41, 93.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.24s/it][A100%|██████████| 1/1 [01:32<00:00, 92.24s/it]
 11%|█         | 556/5198 [16:04:40<120:46:06, 93.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.32s/it][A100%|██████████| 1/1 [01:32<00:00, 92.32s/it]
 11%|█         | 556/5198 [16:04:40<120:47:12, 93.67s/it]
100%|██████████| 1/1 [01:32<00:00, 92.30s/it][A100%|██████████| 1/1 [01:32<00:00, 92.30s/it]
 11%|█         | 556/5198 [16:04:42<120:47:01, 93.67s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_522

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.70s/it][A100%|██████████| 1/1 [01:36<00:00, 96.71s/it]
 11%|█         | 557/5198 [16:06:16<122:00:04, 94.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 11:31:22,343] [INFO] [logging.py:96:log_dist] [Rank 0] step=549, skipped=0, lr=[1.97723427459229e-05], mom=[(0.9, 0.999)]
steps: 549 loss: 0.5491 iter time (s): 96.176 samples/sec: 1.331

100%|██████████| 1/1 [01:36<00:00, 96.97s/it][A100%|██████████| 1/1 [01:36<00:00, 96.97s/it]
 11%|█         | 557/5198 [16:06:16<122:01:03, 94.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.02s/it][A100%|██████████| 1/1 [01:37<00:00, 97.02s/it]
 11%|█         | 557/5198 [16:06:17<122:02:30, 94.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.05s/it][A100%|██████████| 1/1 [01:37<00:00, 97.05s/it]
 11%|█         | 557/5198 [16:06:17<122:03:10, 94.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.94s/it][A100%|██████████| 1/1 [01:36<00:00, 96.94s/it]
 11%|█         | 557/5198 [16:06:17<122:01:20, 94.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.94s/it][A100%|██████████| 1/1 [01:36<00:00, 96.94s/it]
 11%|█         | 557/5198 [16:06:17<122:00:46, 94.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.92s/it][A100%|██████████| 1/1 [01:36<00:00, 96.92s/it]
 11%|█         | 557/5198 [16:06:19<122:01:08, 94.65s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_523

100%|██████████| 1/1 [01:36<00:00, 96.93s/it][A100%|██████████| 1/1 [01:36<00:00, 96.93s/it]
 11%|█         | 557/5198 [16:06:17<122:01:23, 94.65s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.32s/it][A100%|██████████| 1/1 [01:46<00:00, 106.32s/it]
 11%|█         | 558/5198 [16:08:02<126:33:02, 98.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 11:33:09,074] [INFO] [logging.py:96:log_dist] [Rank 0] step=550, skipped=0, lr=[1.977113951791073e-05], mom=[(0.9, 0.999)]
steps: 550 loss: 0.5589 iter time (s): 105.975 samples/sec: 1.208

100%|██████████| 1/1 [01:47<00:00, 107.11s/it][A100%|██████████| 1/1 [01:47<00:00, 107.11s/it]
 11%|█         | 558/5198 [16:08:04<126:48:40, 98.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.99s/it][A100%|██████████| 1/1 [01:46<00:00, 106.99s/it]
 11%|█         | 558/5198 [16:08:04<126:46:59, 98.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.91s/it][A100%|██████████| 1/1 [01:46<00:00, 106.91s/it]
 11%|█         | 558/5198 [16:08:04<126:45:42, 98.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.05s/it][A100%|██████████| 1/1 [01:47<00:00, 107.05s/it]
 11%|█         | 558/5198 [16:08:04<126:47:37, 98.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.99s/it][A100%|██████████| 1/1 [01:46<00:00, 106.99s/it]
 11%|█         | 558/5198 [16:08:06<126:45:56, 98.35s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_524
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.13s/it][A100%|██████████| 1/1 [01:47<00:00, 107.13s/it]
 11%|█         | 558/5198 [16:08:04<126:49:08, 98.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.14s/it][A100%|██████████| 1/1 [01:47<00:00, 107.14s/it]
 11%|█         | 558/5198 [16:08:04<126:49:34, 98.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.68s/it][A100%|██████████| 1/1 [01:29<00:00, 89.68s/it]
 11%|█         | 559/5198 [16:09:32<123:18:09, 95.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 11:34:38,423] [INFO] [logging.py:96:log_dist] [Rank 0] step=551, skipped=0, lr=[1.976993315539528e-05], mom=[(0.9, 0.999)]
steps: 551 loss: 0.5871 iter time (s): 88.327 samples/sec: 1.449

100%|██████████| 1/1 [01:28<00:00, 88.99s/it][A100%|██████████| 1/1 [01:28<00:00, 88.99s/it]
 11%|█         | 559/5198 [16:09:33<123:09:22, 95.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.02s/it][A100%|██████████| 1/1 [01:29<00:00, 89.02s/it]
 11%|█         | 559/5198 [16:09:33<123:08:48, 95.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.11s/it][A100%|██████████| 1/1 [01:29<00:00, 89.11s/it]
 11%|█         | 559/5198 [16:09:33<123:09:59, 95.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.02s/it][A100%|██████████| 1/1 [01:29<00:00, 89.02s/it]
 11%|█         | 559/5198 [16:09:33<123:09:16, 95.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.93s/it][A100%|██████████| 1/1 [01:28<00:00, 88.93s/it]
 11%|█         | 559/5198 [16:09:33<123:08:08, 95.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.08s/it][A100%|██████████| 1/1 [01:29<00:00, 89.08s/it]
 11%|█         | 559/5198 [16:09:35<123:09:19, 95.57s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_34

100%|██████████| 1/1 [01:28<00:00, 88.93s/it][A100%|██████████| 1/1 [01:28<00:00, 88.93s/it]
 11%|█         | 559/5198 [16:09:33<123:08:25, 95.56s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:02<00:00, 122.11s/it][A100%|██████████| 1/1 [02:02<00:00, 122.11s/it]
 11%|█         | 560/5198 [16:11:34<133:31:36, 103.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 11:36:41,370] [INFO] [logging.py:96:log_dist] [Rank 0] step=552, skipped=0, lr=[1.976872365876358e-05], mom=[(0.9, 0.999)]
steps: 552 loss: 0.8109 iter time (s): 122.488 samples/sec: 1.045

100%|██████████| 1/1 [02:03<00:00, 123.30s/it][A100%|██████████| 1/1 [02:03<00:00, 123.30s/it]
 11%|█         | 560/5198 [16:11:36<133:50:59, 103.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.25s/it][A100%|██████████| 1/1 [02:03<00:00, 123.25s/it]
 11%|█         | 560/5198 [16:11:36<133:49:22, 103.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.25s/it][A100%|██████████| 1/1 [02:03<00:00, 123.25s/it]
 11%|█         | 560/5198 [16:11:36<133:50:24, 103.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.29s/it][A100%|██████████| 1/1 [02:03<00:00, 123.29s/it]
 11%|█         | 560/5198 [16:11:36<133:50:36, 103.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.31s/it][A100%|██████████| 1/1 [02:03<00:00, 123.31s/it]
 11%|█         | 560/5198 [16:11:36<133:50:21, 103.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.26s/it][A100%|██████████| 1/1 [02:03<00:00, 123.26s/it]
 11%|█         | 560/5198 [16:11:39<133:50:00, 103.88s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_525

100%|██████████| 1/1 [02:03<00:00, 123.26s/it][A100%|██████████| 1/1 [02:03<00:00, 123.26s/it]
 11%|█         | 560/5198 [16:11:37<133:49:20, 103.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.42s/it][A100%|██████████| 1/1 [01:38<00:00, 98.42s/it]
 11%|█         | 561/5198 [16:13:13<131:31:51, 102.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 11:38:19,471] [INFO] [logging.py:96:log_dist] [Rank 0] step=553, skipped=0, lr=[1.9767511028403668e-05], mom=[(0.9, 0.999)]
steps: 553 loss: 0.5564 iter time (s): 97.044 samples/sec: 1.319

100%|██████████| 1/1 [01:37<00:00, 97.73s/it][A100%|██████████| 1/1 [01:37<00:00, 97.73s/it]
 11%|█         | 561/5198 [16:13:14<131:26:33, 102.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.87s/it][A100%|██████████| 1/1 [01:37<00:00, 97.87s/it]
 11%|█         | 561/5198 [16:13:14<131:28:33, 102.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.80s/it][A100%|██████████| 1/1 [01:37<00:00, 97.81s/it]
 11%|█         | 561/5198 [16:13:14<131:27:57, 102.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.73s/it][A100%|██████████| 1/1 [01:37<00:00, 97.73s/it]
 11%|█         | 561/5198 [16:13:14<131:26:13, 102.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.79s/it][A100%|██████████| 1/1 [01:37<00:00, 97.79s/it]
 11%|█         | 561/5198 [16:13:14<131:27:31, 102.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.77s/it][A100%|██████████| 1/1 [01:37<00:00, 97.78s/it]
 11%|█         | 561/5198 [16:13:14<131:26:23, 102.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.79s/it][A100%|██████████| 1/1 [01:37<00:00, 97.79s/it]
 11%|█         | 561/5198 [16:13:17<131:27:11, 102.06s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_526
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.25s/it][A100%|██████████| 1/1 [01:38<00:00, 98.25s/it]
 11%|█         | 562/5198 [16:14:51<130:04:23, 101.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 11:39:57,954] [INFO] [logging.py:96:log_dist] [Rank 0] step=554, skipped=0, lr=[1.9766295264704586e-05], mom=[(0.9, 0.999)]
steps: 554 loss: 0.6267 iter time (s): 97.714 samples/sec: 1.310

100%|██████████| 1/1 [01:38<00:00, 98.46s/it][A100%|██████████| 1/1 [01:38<00:00, 98.46s/it]
 11%|█         | 562/5198 [16:14:52<130:01:53, 100.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.53s/it][A100%|██████████| 1/1 [01:38<00:00, 98.53s/it]
 11%|█         | 562/5198 [16:14:52<130:04:59, 101.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.50s/it][A100%|██████████| 1/1 [01:38<00:00, 98.50s/it]
 11%|█         | 562/5198 [16:14:53<130:03:48, 101.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.53s/it][A100%|██████████| 1/1 [01:38<00:00, 98.53s/it]
 11%|█         | 562/5198 [16:14:53<130:03:21, 100.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.51s/it][A100%|██████████| 1/1 [01:38<00:00, 98.51s/it]
 11%|█         | 562/5198 [16:14:53<130:03:44, 101.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.57s/it][A100%|██████████| 1/1 [01:38<00:00, 98.57s/it]
 11%|█         | 562/5198 [16:14:55<130:04:47, 101.01s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_527
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.60s/it][A100%|██████████| 1/1 [01:38<00:00, 98.60s/it]
 11%|█         | 562/5198 [16:14:53<130:05:02, 101.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.58s/it][A100%|██████████| 1/1 [01:53<00:00, 113.58s/it]
 11%|█         | 563/5198 [16:16:45<134:58:24, 104.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 11:41:52,157] [INFO] [logging.py:96:log_dist] [Rank 0] step=555, skipped=0, lr=[1.9765076368056377e-05], mom=[(0.9, 0.999)]
steps: 555 loss: 0.6662 iter time (s): 113.342 samples/sec: 1.129

100%|██████████| 1/1 [01:54<00:00, 114.18s/it][A100%|██████████| 1/1 [01:54<00:00, 114.18s/it]
 11%|█         | 563/5198 [16:16:46<135:06:32, 104.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.15s/it][A100%|██████████| 1/1 [01:54<00:00, 114.15s/it]
 11%|█         | 563/5198 [16:16:46<135:08:01, 104.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.23s/it][A100%|██████████| 1/1 [01:54<00:00, 114.24s/it]
 11%|█         | 563/5198 [16:16:47<135:08:44, 104.97s/it]
100%|██████████| 1/1 [01:54<00:00, 114.29s/it][A100%|██████████| 1/1 [01:54<00:00, 114.29s/it]
 11%|█         | 563/5198 [16:16:47<135:10:24, 104.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.27s/it][A100%|██████████| 1/1 [01:54<00:00, 114.27s/it]
 11%|█         | 563/5198 [16:16:47<135:09:54, 104.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.24s/it][A100%|██████████| 1/1 [01:54<00:00, 114.24s/it]
 11%|█         | 563/5198 [16:16:49<135:09:50, 104.98s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_528

100%|██████████| 1/1 [01:54<00:00, 114.22s/it][A100%|██████████| 1/1 [01:54<00:00, 114.22s/it]
 11%|█         | 563/5198 [16:16:47<135:09:33, 104.98s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.75s/it][A100%|██████████| 1/1 [01:28<00:00, 88.75s/it]
 11%|█         | 564/5198 [16:18:14<128:47:34, 100.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 11:43:20,281] [INFO] [logging.py:96:log_dist] [Rank 0] step=556, skipped=0, lr=[1.9763854338850096e-05], mom=[(0.9, 0.999)]
steps: 556 loss: 0.5614 iter time (s): 87.550 samples/sec: 1.462

100%|██████████| 1/1 [01:28<00:00, 88.52s/it][A100%|██████████| 1/1 [01:28<00:00, 88.52s/it]
 11%|█         | 564/5198 [16:18:15<128:44:37, 100.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.38s/it][A100%|██████████| 1/1 [01:28<00:00, 88.38s/it]
 11%|█         | 564/5198 [16:18:15<128:42:17, 99.99s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.36s/it][A100%|██████████| 1/1 [01:28<00:00, 88.36s/it]
 11%|█         | 564/5198 [16:18:15<128:43:38, 100.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.44s/it][A100%|██████████| 1/1 [01:28<00:00, 88.44s/it]
 11%|█         | 564/5198 [16:18:15<128:44:18, 100.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.39s/it][A100%|██████████| 1/1 [01:28<00:00, 88.39s/it]
 11%|█         | 564/5198 [16:18:15<128:43:51, 100.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.40s/it][A100%|██████████| 1/1 [01:28<00:00, 88.40s/it]
 11%|█         | 564/5198 [16:18:18<128:43:57, 100.01s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_529

100%|██████████| 1/1 [01:28<00:00, 88.40s/it][A100%|██████████| 1/1 [01:28<00:00, 88.40s/it]
 11%|█         | 564/5198 [16:18:16<128:43:49, 100.01s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.27s/it][A100%|██████████| 1/1 [01:47<00:00, 107.27s/it]
 11%|█         | 565/5198 [16:20:02<131:43:49, 102.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 11:45:08,360] [INFO] [logging.py:96:log_dist] [Rank 0] step=557, skipped=0, lr=[1.9762629177477806e-05], mom=[(0.9, 0.999)]
steps: 557 loss: 0.5900 iter time (s): 106.895 samples/sec: 1.197

100%|██████████| 1/1 [01:47<00:00, 107.68s/it][A100%|██████████| 1/1 [01:47<00:00, 107.68s/it]
 11%|█         | 565/5198 [16:20:02<131:40:48, 102.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.81s/it][A100%|██████████| 1/1 [01:47<00:00, 107.81s/it]
 11%|█         | 565/5198 [16:20:03<131:42:11, 102.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.71s/it][A100%|██████████| 1/1 [01:47<00:00, 107.71s/it]
 11%|█         | 565/5198 [16:20:03<131:40:48, 102.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.80s/it][A100%|██████████| 1/1 [01:47<00:00, 107.80s/it]
 11%|█         | 565/5198 [16:20:03<131:43:10, 102.35s/it]
100%|██████████| 1/1 [01:47<00:00, 107.74s/it][A100%|██████████| 1/1 [01:47<00:00, 107.74s/it]
 11%|█         | 565/5198 [16:20:03<131:41:30, 102.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.86s/it][A100%|██████████| 1/1 [01:47<00:00, 107.86s/it]
 11%|█         | 565/5198 [16:20:03<131:44:18, 102.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.68s/it][A100%|██████████| 1/1 [01:48<00:00, 108.68s/it]
 11%|█         | 565/5198 [16:20:06<132:03:20, 102.61s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_530
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.86s/it][A100%|██████████| 1/1 [01:48<00:00, 108.86s/it]
 11%|█         | 566/5198 [16:21:51<134:24:52, 104.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 11:46:57,706] [INFO] [logging.py:96:log_dist] [Rank 0] step=558, skipped=0, lr=[1.976140088433256e-05], mom=[(0.9, 0.999)]
steps: 558 loss: 0.5653 iter time (s): 107.860 samples/sec: 1.187

100%|██████████| 1/1 [01:49<00:00, 109.69s/it][A100%|██████████| 1/1 [01:49<00:00, 109.69s/it]
 11%|█         | 566/5198 [16:21:52<134:29:55, 104.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.62s/it][A100%|██████████| 1/1 [01:49<00:00, 109.62s/it]
 11%|█         | 566/5198 [16:21:52<134:29:27, 104.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.69s/it][A100%|██████████| 1/1 [01:49<00:00, 109.69s/it]
 11%|█         | 566/5198 [16:21:53<134:30:04, 104.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.57s/it][A100%|██████████| 1/1 [01:49<00:00, 109.57s/it]
 11%|█         | 566/5198 [16:21:53<134:29:00, 104.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.63s/it][A100%|██████████| 1/1 [01:49<00:00, 109.63s/it]
 11%|█         | 566/5198 [16:21:53<134:29:09, 104.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.50s/it][A100%|██████████| 1/1 [01:49<00:00, 109.50s/it]
 11%|█         | 566/5198 [16:21:53<134:28:17, 104.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.76s/it][A100%|██████████| 1/1 [01:48<00:00, 108.76s/it]
 11%|█         | 566/5198 [16:21:55<134:24:08, 104.46s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_531
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.95s/it][A100%|██████████| 1/1 [01:28<00:00, 88.95s/it]
 11%|█         | 567/5198 [16:23:21<128:39:58, 100.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 11:48:27,051] [INFO] [logging.py:96:log_dist] [Rank 0] step=559, skipped=0, lr=[1.976016945980843e-05], mom=[(0.9, 0.999)]
steps: 559 loss: 0.6112 iter time (s): 88.134 samples/sec: 1.452

100%|██████████| 1/1 [01:29<00:00, 89.03s/it][A100%|██████████| 1/1 [01:29<00:00, 89.03s/it]
 11%|█         | 567/5198 [16:23:21<128:29:36, 99.89s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.98s/it][A100%|██████████| 1/1 [01:28<00:00, 88.98s/it]
 11%|█         | 567/5198 [16:23:21<128:27:59, 99.87s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.93s/it][A100%|██████████| 1/1 [01:28<00:00, 88.93s/it]
 11%|█         | 567/5198 [16:23:22<128:27:15, 99.86s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.95s/it][A100%|██████████| 1/1 [01:28<00:00, 88.95s/it]
 11%|█         | 567/5198 [16:23:22<128:26:57, 99.85s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.95s/it][A100%|██████████| 1/1 [01:28<00:00, 88.95s/it]
 11%|█         | 567/5198 [16:23:22<128:27:14, 99.86s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.94s/it][A100%|██████████| 1/1 [01:28<00:00, 88.94s/it]
 11%|█         | 567/5198 [16:23:22<128:26:14, 99.84s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.90s/it][A100%|██████████| 1/1 [01:28<00:00, 88.90s/it]
 11%|█         | 567/5198 [16:23:24<128:22:22, 99.79s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_532
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.76s/it][A100%|██████████| 1/1 [01:31<00:00, 91.76s/it]
 11%|█         | 568/5198 [16:24:53<125:32:38, 97.62s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 11:49:59,168] [INFO] [logging.py:96:log_dist] [Rank 0] step=560, skipped=0, lr=[1.9758934904300483e-05], mom=[(0.9, 0.999)]
steps: 560 loss: 0.5782 iter time (s): 91.345 samples/sec: 1.401

100%|██████████| 1/1 [01:32<00:00, 92.09s/it][A100%|██████████| 1/1 [01:32<00:00, 92.09s/it]
 11%|█         | 568/5198 [16:24:53<125:27:38, 97.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.09s/it][A100%|██████████| 1/1 [01:32<00:00, 92.09s/it]
 11%|█         | 568/5198 [16:24:53<125:26:32, 97.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.13s/it][A100%|██████████| 1/1 [01:32<00:00, 92.13s/it]
 11%|█         | 568/5198 [16:24:54<125:27:02, 97.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.11s/it][A100%|██████████| 1/1 [01:32<00:00, 92.11s/it]
 11%|█         | 568/5198 [16:24:54<125:26:11, 97.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.09s/it][A100%|██████████| 1/1 [01:32<00:00, 92.09s/it]
 11%|█         | 568/5198 [16:24:54<125:25:56, 97.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.11s/it][A100%|██████████| 1/1 [01:32<00:00, 92.11s/it]
 11%|█         | 568/5198 [16:24:54<125:25:49, 97.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.13s/it][A100%|██████████| 1/1 [01:32<00:00, 92.13s/it]
 11%|█         | 568/5198 [16:24:56<125:23:31, 97.50s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_533
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.03s/it][A100%|██████████| 1/1 [01:33<00:00, 93.03s/it]
 11%|█         | 569/5198 [16:26:26<123:48:48, 96.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 11:51:32,381] [INFO] [logging.py:96:log_dist] [Rank 0] step=561, skipped=0, lr=[1.9757697218204802e-05], mom=[(0.9, 0.999)]
steps: 561 loss: 0.5853 iter time (s): 92.419 samples/sec: 1.385

100%|██████████| 1/1 [01:33<00:00, 93.18s/it][A100%|██████████| 1/1 [01:33<00:00, 93.18s/it]
 11%|█         | 569/5198 [16:26:26<123:45:01, 96.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.22s/it][A100%|██████████| 1/1 [01:33<00:00, 93.22s/it]
 11%|█         | 569/5198 [16:26:27<123:45:27, 96.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.14s/it][A100%|██████████| 1/1 [01:33<00:00, 93.14s/it]
 11%|█         | 569/5198 [16:26:27<123:43:53, 96.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.29s/it][A100%|██████████| 1/1 [01:33<00:00, 93.29s/it]
 11%|█         | 569/5198 [16:26:27<123:46:38, 96.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.27s/it][A100%|██████████| 1/1 [01:33<00:00, 93.27s/it]
 11%|█         | 569/5198 [16:26:27<123:46:00, 96.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.22s/it][A100%|██████████| 1/1 [01:33<00:00, 93.22s/it]
 11%|█         | 569/5198 [16:26:27<123:44:45, 96.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.22s/it][A100%|██████████| 1/1 [01:33<00:00, 93.22s/it]
 11%|█         | 569/5198 [16:26:29<123:43:06, 96.22s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_534
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.58s/it][A100%|██████████| 1/1 [01:21<00:00, 81.58s/it]
 11%|█         | 570/5198 [16:27:48<118:10:46, 91.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 11:52:53,853] [INFO] [logging.py:96:log_dist] [Rank 0] step=562, skipped=0, lr=[1.9756456401918464e-05], mom=[(0.9, 0.999)]
steps: 562 loss: 0.5834 iter time (s): 80.658 samples/sec: 1.587

100%|██████████| 1/1 [01:21<00:00, 81.45s/it][A100%|██████████| 1/1 [01:21<00:00, 81.45s/it]
 11%|█         | 570/5198 [16:27:48<118:01:24, 91.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.43s/it][A100%|██████████| 1/1 [01:21<00:00, 81.43s/it]
 11%|█         | 570/5198 [16:27:48<118:01:06, 91.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.46s/it][A100%|██████████| 1/1 [01:21<00:00, 81.46s/it]
 11%|█         | 570/5198 [16:27:48<118:00:52, 91.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.40s/it][A100%|██████████| 1/1 [01:21<00:00, 81.40s/it]
 11%|█         | 570/5198 [16:27:49<118:00:45, 91.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.45s/it][A100%|██████████| 1/1 [01:21<00:00, 81.45s/it]
 11%|█         | 570/5198 [16:27:49<118:02:23, 91.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.42s/it][A100%|██████████| 1/1 [01:21<00:00, 81.42s/it]
 11%|█         | 570/5198 [16:27:49<118:00:32, 91.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.40s/it][A100%|██████████| 1/1 [01:21<00:00, 81.40s/it]
 11%|█         | 570/5198 [16:27:51<117:58:54, 91.77s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_535
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.02s/it][A100%|██████████| 1/1 [01:21<00:00, 81.02s/it]
 11%|█         | 571/5198 [16:29:09<114:02:09, 88.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 11:54:15,100] [INFO] [logging.py:96:log_dist] [Rank 0] step=563, skipped=0, lr=[1.9755212455839552e-05], mom=[(0.9, 0.999)]
steps: 563 loss: 0.6015 iter time (s): 80.491 samples/sec: 1.590

100%|██████████| 1/1 [01:21<00:00, 81.31s/it][A100%|██████████| 1/1 [01:21<00:00, 81.31s/it]
 11%|█         | 571/5198 [16:29:09<113:57:23, 88.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.45s/it][A100%|██████████| 1/1 [01:21<00:00, 81.45s/it]
 11%|█         | 571/5198 [16:29:10<114:00:15, 88.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.36s/it][A100%|██████████| 1/1 [01:21<00:00, 81.36s/it]
 11%|█         | 571/5198 [16:29:10<113:57:56, 88.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.31s/it][A100%|██████████| 1/1 [01:21<00:00, 81.31s/it]
 11%|█         | 571/5198 [16:29:10<113:57:46, 88.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.35s/it][A100%|██████████| 1/1 [01:21<00:00, 81.35s/it]
 11%|█         | 571/5198 [16:29:10<113:57:37, 88.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.36s/it][A100%|██████████| 1/1 [01:21<00:00, 81.36s/it]
 11%|█         | 571/5198 [16:29:10<113:57:44, 88.67s/it]
100%|██████████| 1/1 [01:21<00:00, 81.35s/it][A100%|██████████| 1/1 [01:21<00:00, 81.35s/it]
 11%|█         | 571/5198 [16:29:12<113:56:22, 88.65s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_536
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.59s/it][A100%|██████████| 1/1 [01:40<00:00, 100.59s/it]
 11%|█         | 572/5198 [16:30:50<118:38:59, 92.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 11:55:56,418] [INFO] [logging.py:96:log_dist] [Rank 0] step=564, skipped=0, lr=[1.9753965380367157e-05], mom=[(0.9, 0.999)]
steps: 564 loss: 0.5897 iter time (s): 100.455 samples/sec: 1.274

100%|██████████| 1/1 [01:41<00:00, 101.24s/it][A100%|██████████| 1/1 [01:41<00:00, 101.24s/it]
 11%|█         | 572/5198 [16:30:51<118:47:03, 92.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.12s/it][A100%|██████████| 1/1 [01:41<00:00, 101.12s/it]
 11%|█         | 572/5198 [16:30:51<118:46:12, 92.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.26s/it][A100%|██████████| 1/1 [01:41<00:00, 101.26s/it]
 11%|█         | 572/5198 [16:30:51<118:47:55, 92.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.22s/it][A100%|██████████| 1/1 [01:41<00:00, 101.22s/it]
 11%|█         | 572/5198 [16:30:51<118:46:42, 92.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.28s/it][A100%|██████████| 1/1 [01:41<00:00, 101.28s/it]
 11%|█         | 572/5198 [16:30:51<118:48:08, 92.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.25s/it][A100%|██████████| 1/1 [01:41<00:00, 101.25s/it]
 11%|█         | 572/5198 [16:30:51<118:47:27, 92.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.26s/it][A100%|██████████| 1/1 [01:41<00:00, 101.26s/it]
 11%|█         | 572/5198 [16:30:54<118:46:41, 92.43s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_537
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.01s/it][A100%|██████████| 1/1 [01:35<00:00, 95.01s/it]
 11%|█         | 573/5198 [16:32:25<119:43:53, 93.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 11:57:31,404] [INFO] [logging.py:96:log_dist] [Rank 0] step=565, skipped=0, lr=[1.9752715175901373e-05], mom=[(0.9, 0.999)]
steps: 565 loss: 0.6443 iter time (s): 94.175 samples/sec: 1.359

100%|██████████| 1/1 [01:34<00:00, 94.95s/it][A100%|██████████| 1/1 [01:34<00:00, 94.95s/it]
 11%|█         | 573/5198 [16:32:25<119:43:56, 93.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.89s/it][A100%|██████████| 1/1 [01:34<00:00, 94.89s/it]
 11%|█         | 573/5198 [16:32:26<119:41:50, 93.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.92s/it][A100%|██████████| 1/1 [01:34<00:00, 94.92s/it]
 11%|█         | 573/5198 [16:32:26<119:43:53, 93.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.98s/it][A100%|██████████| 1/1 [01:34<00:00, 94.98s/it]
 11%|█         | 573/5198 [16:32:26<119:44:08, 93.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.95s/it][A100%|██████████| 1/1 [01:34<00:00, 94.95s/it]
 11%|█         | 573/5198 [16:32:26<119:44:24, 93.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.96s/it][A100%|██████████| 1/1 [01:34<00:00, 94.96s/it]
 11%|█         | 573/5198 [16:32:26<119:44:10, 93.20s/it]
100%|██████████| 1/1 [01:34<00:00, 94.96s/it][A100%|██████████| 1/1 [01:34<00:00, 94.96s/it]
 11%|█         | 573/5198 [16:32:28<119:43:36, 93.19s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_538

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.04s/it][A100%|██████████| 1/1 [01:41<00:00, 101.04s/it]
 11%|█         | 574/5198 [16:34:06<122:48:50, 95.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 11:59:12,452] [INFO] [logging.py:96:log_dist] [Rank 0] step=566, skipped=0, lr=[1.975146184284329e-05], mom=[(0.9, 0.999)]
steps: 566 loss: 0.5675 iter time (s): 100.259 samples/sec: 1.277

100%|██████████| 1/1 [01:41<00:00, 101.10s/it][A100%|██████████| 1/1 [01:41<00:00, 101.10s/it]
 11%|█         | 574/5198 [16:34:07<122:45:25, 95.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.24s/it][A100%|██████████| 1/1 [01:41<00:00, 101.24s/it]
 11%|█         | 574/5198 [16:34:07<122:47:07, 95.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.10s/it][A100%|██████████| 1/1 [01:41<00:00, 101.10s/it]
 11%|█         | 574/5198 [16:34:07<122:45:14, 95.57s/it]
100%|██████████| 1/1 [01:40<00:00, 100.97s/it][A100%|██████████| 1/1 [01:40<00:00, 100.97s/it]
 11%|█         | 574/5198 [16:34:07<122:42:37, 95.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.05s/it][A100%|██████████| 1/1 [01:41<00:00, 101.05s/it]
 11%|█         | 574/5198 [16:34:07<122:44:16, 95.56s/it]
100%|██████████| 1/1 [01:41<00:00, 101.12s/it][A100%|██████████| 1/1 [01:41<00:00, 101.12s/it]
 11%|█         | 574/5198 [16:34:07<122:45:49, 95.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.05s/it][A100%|██████████| 1/1 [01:41<00:00, 101.05s/it]
 11%|█         | 574/5198 [16:34:10<122:43:54, 95.55s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_539

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.99s/it][A100%|██████████| 1/1 [01:27<00:00, 87.99s/it]
 11%|█         | 575/5198 [16:35:35<119:56:58, 93.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 12:00:40,780] [INFO] [logging.py:96:log_dist] [Rank 0] step=567, skipped=0, lr=[1.9750205381595017e-05], mom=[(0.9, 0.999)]
steps: 567 loss: 0.6116 iter time (s): 87.533 samples/sec: 1.462

100%|██████████| 1/1 [01:28<00:00, 88.29s/it][A100%|██████████| 1/1 [01:28<00:00, 88.29s/it]
 11%|█         | 575/5198 [16:35:35<119:55:48, 93.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.23s/it][A100%|██████████| 1/1 [01:28<00:00, 88.23s/it]
 11%|█         | 575/5198 [16:35:35<119:55:38, 93.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.26s/it][A100%|██████████| 1/1 [01:28<00:00, 88.26s/it]
 11%|█         | 575/5198 [16:35:35<119:54:51, 93.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.40s/it][A100%|██████████| 1/1 [01:28<00:00, 88.41s/it]
 11%|█         | 575/5198 [16:35:36<119:56:22, 93.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.33s/it][A100%|██████████| 1/1 [01:28<00:00, 88.33s/it]
 11%|█         | 575/5198 [16:35:36<119:56:51, 93.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.37s/it][A100%|██████████| 1/1 [01:28<00:00, 88.37s/it]
 11%|█         | 575/5198 [16:35:38<119:56:29, 93.40s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_35

100%|██████████| 1/1 [01:28<00:00, 88.38s/it][A100%|██████████| 1/1 [01:28<00:00, 88.38s/it]
 11%|█         | 575/5198 [16:35:36<119:57:01, 93.41s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.90s/it][A100%|██████████| 1/1 [01:53<00:00, 113.90s/it]
 11%|█         | 576/5198 [16:37:29<127:52:22, 99.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 12:02:35,295] [INFO] [logging.py:96:log_dist] [Rank 0] step=568, skipped=0, lr=[1.974894579255965e-05], mom=[(0.9, 0.999)]
steps: 568 loss: 0.7901 iter time (s): 113.944 samples/sec: 1.123

100%|██████████| 1/1 [01:54<00:00, 114.98s/it][A100%|██████████| 1/1 [01:54<00:00, 114.98s/it]
 11%|█         | 576/5198 [16:37:30<128:13:23, 99.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.91s/it][A100%|██████████| 1/1 [01:54<00:00, 114.91s/it]
 11%|█         | 576/5198 [16:37:30<128:11:39, 99.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.99s/it][A100%|██████████| 1/1 [01:54<00:00, 114.99s/it]
 11%|█         | 576/5198 [16:37:30<128:12:49, 99.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.84s/it][A100%|██████████| 1/1 [01:54<00:00, 114.84s/it]
 11%|█         | 576/5198 [16:37:31<128:10:44, 99.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.93s/it][A100%|██████████| 1/1 [01:54<00:00, 114.93s/it]
 11%|█         | 576/5198 [16:37:30<128:12:36, 99.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.90s/it][A100%|██████████| 1/1 [01:54<00:00, 114.90s/it]
 11%|█         | 576/5198 [16:37:31<128:12:22, 99.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.92s/it][A100%|██████████| 1/1 [01:54<00:00, 114.92s/it]
 11%|█         | 576/5198 [16:37:33<128:12:30, 99.86s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_540
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.31s/it][A100%|██████████| 1/1 [01:20<00:00, 80.31s/it]
 11%|█         | 577/5198 [16:38:49<120:27:55, 93.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 12:03:55,010] [INFO] [logging.py:96:log_dist] [Rank 0] step=569, skipped=0, lr=[1.9747683076141307e-05], mom=[(0.9, 0.999)]
steps: 569 loss: 0.6101 iter time (s): 78.462 samples/sec: 1.631

100%|██████████| 1/1 [01:19<00:00, 79.35s/it][A100%|██████████| 1/1 [01:19<00:00, 79.35s/it]
 11%|█         | 577/5198 [16:38:49<120:17:49, 93.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.44s/it][A100%|██████████| 1/1 [01:19<00:00, 79.44s/it]
 11%|█         | 577/5198 [16:38:49<120:18:43, 93.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.40s/it][A100%|██████████| 1/1 [01:19<00:00, 79.40s/it]
 11%|█         | 577/5198 [16:38:50<120:18:35, 93.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.49s/it][A100%|██████████| 1/1 [01:19<00:00, 79.49s/it]
 11%|█         | 577/5198 [16:38:50<120:19:03, 93.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.44s/it][A100%|██████████| 1/1 [01:19<00:00, 79.44s/it]
 11%|█         | 577/5198 [16:38:50<120:19:05, 93.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.54s/it][A100%|██████████| 1/1 [01:19<00:00, 79.54s/it]
 11%|█         | 577/5198 [16:38:50<120:21:31, 93.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.47s/it][A100%|██████████| 1/1 [01:19<00:00, 79.47s/it]
 11%|█         | 577/5198 [16:38:52<120:19:52, 93.74s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_541
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.62s/it][A100%|██████████| 1/1 [01:30<00:00, 90.62s/it]
 11%|█         | 578/5198 [16:40:20<119:15:57, 92.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 12:05:26,141] [INFO] [logging.py:96:log_dist] [Rank 0] step=570, skipped=0, lr=[1.974641723274509e-05], mom=[(0.9, 0.999)]
steps: 570 loss: 0.5731 iter time (s): 90.111 samples/sec: 1.420

100%|██████████| 1/1 [01:31<00:00, 91.22s/it][A100%|██████████| 1/1 [01:31<00:00, 91.22s/it]
 11%|█         | 578/5198 [16:40:20<119:18:48, 92.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.32s/it][A100%|██████████| 1/1 [01:31<00:00, 91.32s/it]
 11%|█         | 578/5198 [16:40:21<119:21:52, 93.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.28s/it][A100%|██████████| 1/1 [01:31<00:00, 91.28s/it]
 11%|█         | 578/5198 [16:40:21<119:20:45, 93.00s/it]
100%|██████████| 1/1 [01:31<00:00, 91.06s/it][A100%|██████████| 1/1 [01:31<00:00, 91.06s/it]
 11%|█         | 578/5198 [16:40:21<119:17:38, 92.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.22s/it][A100%|██████████| 1/1 [01:31<00:00, 91.22s/it]
 11%|█         | 578/5198 [16:40:21<119:19:35, 92.98s/it]
100%|██████████| 1/1 [01:31<00:00, 91.29s/it][A100%|██████████| 1/1 [01:31<00:00, 91.29s/it]
 11%|█         | 578/5198 [16:40:21<119:21:09, 93.00s/it]
100%|██████████| 1/1 [01:31<00:00, 91.18s/it][A
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [01:31<00:00, 91.18s/it]
[A 11%|█         | 578/5198 [16:40:24<119:19:08, 92.98s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_542

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.99s/it][A100%|██████████| 1/1 [01:43<00:00, 103.99s/it]
 11%|█         | 579/5198 [16:42:04<123:35:44, 96.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 12:07:10,732] [INFO] [logging.py:96:log_dist] [Rank 0] step=571, skipped=0, lr=[1.974514826277711e-05], mom=[(0.9, 0.999)]
steps: 571 loss: 0.5638 iter time (s): 103.516 samples/sec: 1.237

100%|██████████| 1/1 [01:44<00:00, 104.36s/it][A100%|██████████| 1/1 [01:44<00:00, 104.36s/it]
 11%|█         | 579/5198 [16:42:05<123:40:30, 96.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.31s/it][A100%|██████████| 1/1 [01:44<00:00, 104.31s/it]
 11%|█         | 579/5198 [16:42:05<123:41:28, 96.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.24s/it][A100%|██████████| 1/1 [01:44<00:00, 104.24s/it]
 11%|█         | 579/5198 [16:42:05<123:39:13, 96.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.31s/it][A100%|██████████| 1/1 [01:44<00:00, 104.31s/it]
 11%|█         | 579/5198 [16:42:05<123:38:26, 96.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.26s/it][A100%|██████████| 1/1 [01:44<00:00, 104.26s/it]
 11%|█         | 579/5198 [16:42:06<123:39:49, 96.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.32s/it][A100%|██████████| 1/1 [01:44<00:00, 104.32s/it]
 11%|█         | 579/5198 [16:42:06<123:39:59, 96.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.32s/it][A100%|██████████| 1/1 [01:44<00:00, 104.32s/it]
 11%|█         | 579/5198 [16:42:08<123:39:49, 96.38s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_543
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.08s/it][A100%|██████████| 1/1 [01:26<00:00, 86.08s/it]
 11%|█         | 580/5198 [16:43:30<119:42:02, 93.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 12:08:36,525] [INFO] [logging.py:96:log_dist] [Rank 0] step=572, skipped=0, lr=[1.9743876166644496e-05], mom=[(0.9, 0.999)]
steps: 572 loss: 0.5743 iter time (s): 84.980 samples/sec: 1.506

100%|██████████| 1/1 [01:25<00:00, 85.82s/it][A100%|██████████| 1/1 [01:25<00:00, 85.82s/it]
 11%|█         | 580/5198 [16:43:31<119:34:57, 93.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.81s/it][A100%|██████████| 1/1 [01:25<00:00, 85.81s/it]
 11%|█         | 580/5198 [16:43:31<119:35:24, 93.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.81s/it][A100%|██████████| 1/1 [01:25<00:00, 85.81s/it]
 11%|█         | 580/5198 [16:43:31<119:33:57, 93.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.93s/it][A100%|██████████| 1/1 [01:25<00:00, 85.93s/it]
 11%|█         | 580/5198 [16:43:31<119:36:01, 93.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.86s/it][A100%|██████████| 1/1 [01:25<00:00, 85.86s/it]
 11%|█         | 580/5198 [16:43:31<119:35:26, 93.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.85s/it][A100%|██████████| 1/1 [01:25<00:00, 85.86s/it]
 11%|█         | 580/5198 [16:43:31<119:35:27, 93.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.87s/it][A100%|██████████| 1/1 [01:25<00:00, 85.87s/it]
 11%|█         | 580/5198 [16:43:34<119:35:33, 93.23s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_544
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.87s/it][A100%|██████████| 1/1 [01:25<00:00, 85.87s/it]
 11%|█         | 581/5198 [16:44:56<116:52:45, 91.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 12:10:02,550] [INFO] [logging.py:96:log_dist] [Rank 0] step=573, skipped=0, lr=[1.9742600944755358e-05], mom=[(0.9, 0.999)]
steps: 573 loss: 0.5755 iter time (s): 85.135 samples/sec: 1.503

100%|██████████| 1/1 [01:25<00:00, 85.97s/it][A100%|██████████| 1/1 [01:25<00:00, 85.97s/it]
 11%|█         | 581/5198 [16:44:57<116:46:18, 91.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.87s/it][A100%|██████████| 1/1 [01:25<00:00, 85.87s/it]
 11%|█         | 581/5198 [16:44:57<116:44:12, 91.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.05s/it][A100%|██████████| 1/1 [01:26<00:00, 86.05s/it]
 11%|█         | 581/5198 [16:44:57<116:47:15, 91.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.94s/it][A100%|██████████| 1/1 [01:25<00:00, 85.95s/it]
 11%|█         | 581/5198 [16:44:57<116:46:20, 91.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.96s/it][A100%|██████████| 1/1 [01:25<00:00, 85.96s/it]
 11%|█         | 581/5198 [16:44:57<116:46:15, 91.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.97s/it][A100%|██████████| 1/1 [01:25<00:00, 85.97s/it]
 11%|█         | 581/5198 [16:44:57<116:46:28, 91.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.96s/it][A100%|██████████| 1/1 [01:25<00:00, 85.96s/it]
 11%|█         | 581/5198 [16:45:00<116:46:17, 91.05s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_545
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.61s/it][A100%|██████████| 1/1 [01:28<00:00, 88.61s/it]
 11%|█         | 582/5198 [16:46:25<115:58:31, 90.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 12:11:31,502] [INFO] [logging.py:96:log_dist] [Rank 0] step=574, skipped=0, lr=[1.9741322597518824e-05], mom=[(0.9, 0.999)]
steps: 574 loss: 0.6133 iter time (s): 88.161 samples/sec: 1.452

100%|██████████| 1/1 [01:29<00:00, 89.01s/it][A100%|██████████| 1/1 [01:29<00:00, 89.01s/it]
 11%|█         | 582/5198 [16:46:26<115:57:53, 90.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.04s/it][A100%|██████████| 1/1 [01:29<00:00, 89.04s/it]
 11%|█         | 582/5198 [16:46:26<115:57:14, 90.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.00s/it][A100%|██████████| 1/1 [01:29<00:00, 89.00s/it]
 11%|█         | 582/5198 [16:46:26<115:58:22, 90.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.97s/it][A100%|██████████| 1/1 [01:28<00:00, 88.97s/it]
 11%|█         | 582/5198 [16:46:26<115:56:59, 90.43s/it]
100%|██████████| 1/1 [01:29<00:00, 89.02s/it][A100%|██████████| 1/1 [01:29<00:00, 89.02s/it]
 11%|█         | 582/5198 [16:46:26<115:58:09, 90.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.01s/it][A100%|██████████| 1/1 [01:29<00:00, 89.01s/it]
 11%|█         | 582/5198 [16:46:26<115:58:01, 90.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.01s/it][A100%|██████████| 1/1 [01:29<00:00, 89.01s/it]
 11%|█         | 582/5198 [16:46:29<115:57:57, 90.44s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_546
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.73s/it][A100%|██████████| 1/1 [01:37<00:00, 97.73s/it]
 11%|█         | 583/5198 [16:48:03<118:49:02, 92.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 12:13:09,689] [INFO] [logging.py:96:log_dist] [Rank 0] step=575, skipped=0, lr=[1.9740041125345016e-05], mom=[(0.9, 0.999)]
steps: 575 loss: 0.5462 iter time (s): 97.288 samples/sec: 1.316

100%|██████████| 1/1 [01:38<00:00, 98.26s/it][A100%|██████████| 1/1 [01:38<00:00, 98.27s/it]
 11%|█         | 583/5198 [16:48:04<118:57:13, 92.79s/it]
100%|██████████| 1/1 [01:38<00:00, 98.15s/it][A100%|██████████| 1/1 [01:38<00:00, 98.15s/it]
 11%|█         | 583/5198 [16:48:04<118:54:07, 92.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.18s/it][A100%|██████████| 1/1 [01:38<00:00, 98.18s/it]
 11%|█         | 583/5198 [16:48:04<118:55:34, 92.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.12s/it][A100%|██████████| 1/1 [01:38<00:00, 98.12s/it]
 11%|█         | 583/5198 [16:48:04<118:53:54, 92.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.25s/it][A100%|██████████| 1/1 [01:38<00:00, 98.25s/it]
 11%|█         | 583/5198 [16:48:05<118:56:03, 92.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.44s/it][A100%|██████████| 1/1 [01:38<00:00, 98.44s/it]
 11%|█         | 583/5198 [16:48:07<119:01:14, 92.84s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_547
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.70s/it][A100%|██████████| 1/1 [01:38<00:00, 98.70s/it]
 11%|█         | 583/5198 [16:48:05<119:07:18, 92.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.95s/it][A100%|██████████| 1/1 [01:33<00:00, 93.95s/it]
 11%|█         | 584/5198 [16:49:37<119:21:57, 93.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 12:14:43,714] [INFO] [logging.py:96:log_dist] [Rank 0] step=576, skipped=0, lr=[1.973875652864506e-05], mom=[(0.9, 0.999)]
steps: 576 loss: 0.5895 iter time (s): 92.850 samples/sec: 1.379

100%|██████████| 1/1 [01:33<00:00, 93.88s/it][A100%|██████████| 1/1 [01:33<00:00, 93.88s/it]
 11%|█         | 584/5198 [16:49:38<119:21:11, 93.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.93s/it][A100%|██████████| 1/1 [01:33<00:00, 93.93s/it]
 11%|█         | 584/5198 [16:49:38<119:20:01, 93.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.86s/it][A100%|██████████| 1/1 [01:33<00:00, 93.86s/it]
 11%|█         | 584/5198 [16:49:38<119:19:28, 93.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.94s/it][A100%|██████████| 1/1 [01:33<00:00, 93.94s/it]
 11%|█         | 584/5198 [16:49:38<119:20:04, 93.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.86s/it][A100%|██████████| 1/1 [01:33<00:00, 93.86s/it]
 11%|█         | 584/5198 [16:49:38<119:19:43, 93.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.34s/it][A100%|██████████| 1/1 [01:33<00:00, 93.34s/it]
 11%|█         | 584/5198 [16:49:39<119:15:39, 93.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.60s/it][A100%|██████████| 1/1 [01:33<00:00, 93.60s/it]
 11%|█         | 584/5198 [16:49:41<119:17:34, 93.08s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_548
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.16s/it][A100%|██████████| 1/1 [01:29<00:00, 89.16s/it]
 11%|█▏        | 585/5198 [16:51:07<117:52:18, 91.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 12:16:12,847] [INFO] [logging.py:96:log_dist] [Rank 0] step=577, skipped=0, lr=[1.9737468807831098e-05], mom=[(0.9, 0.999)]
steps: 577 loss: 0.6176 iter time (s): 88.379 samples/sec: 1.448

100%|██████████| 1/1 [01:29<00:00, 89.10s/it][A100%|██████████| 1/1 [01:29<00:00, 89.10s/it]
 11%|█▏        | 585/5198 [16:51:07<117:46:58, 91.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.17s/it][A100%|██████████| 1/1 [01:29<00:00, 89.17s/it]
 11%|█▏        | 585/5198 [16:51:07<117:47:52, 91.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.21s/it][A100%|██████████| 1/1 [01:29<00:00, 89.21s/it]
 11%|█▏        | 585/5198 [16:51:08<117:48:19, 91.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.20s/it][A100%|██████████| 1/1 [01:29<00:00, 89.20s/it]
 11%|█▏        | 585/5198 [16:51:08<117:48:29, 91.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.21s/it][A100%|██████████| 1/1 [01:29<00:00, 89.22s/it]
 11%|█▏        | 585/5198 [16:51:08<117:48:40, 91.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.22s/it][A100%|██████████| 1/1 [01:29<00:00, 89.22s/it]
 11%|█▏        | 585/5198 [16:51:08<117:45:55, 91.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.21s/it][A100%|██████████| 1/1 [01:29<00:00, 89.21s/it]
 11%|█▏        | 585/5198 [16:51:10<117:47:05, 91.92s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_549
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.53s/it][A100%|██████████| 1/1 [01:22<00:00, 82.53s/it]
 11%|█▏        | 586/5198 [16:52:30<114:20:12, 89.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 12:17:35,570] [INFO] [logging.py:96:log_dist] [Rank 0] step=578, skipped=0, lr=[1.9736177963316252e-05], mom=[(0.9, 0.999)]
steps: 578 loss: 0.5453 iter time (s): 81.879 samples/sec: 1.563

100%|██████████| 1/1 [01:22<00:00, 82.67s/it][A100%|██████████| 1/1 [01:22<00:00, 82.67s/it]
 11%|█▏        | 586/5198 [16:52:30<114:12:21, 89.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.65s/it][A100%|██████████| 1/1 [01:22<00:00, 82.65s/it]
 11%|█▏        | 586/5198 [16:52:30<114:12:39, 89.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.69s/it][A100%|██████████| 1/1 [01:22<00:00, 82.69s/it]
 11%|█▏        | 586/5198 [16:52:30<114:13:56, 89.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.68s/it][A100%|██████████| 1/1 [01:22<00:00, 82.68s/it]
 11%|█▏        | 586/5198 [16:52:30<114:13:41, 89.16s/it]
100%|██████████| 1/1 [01:22<00:00, 82.65s/it][A100%|██████████| 1/1 [01:22<00:00, 82.65s/it]
 11%|█▏        | 586/5198 [16:52:30<114:13:09, 89.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.67s/it][A100%|██████████| 1/1 [01:22<00:00, 82.67s/it]
 11%|█▏        | 586/5198 [16:52:33<114:12:22, 89.15s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_550
Training on 128 of 128 sentences.


100%|██████████| 1/1 [01:22<00:00, 82.69s/it][A  0%|          | 0/1 [00:00<?, ?it/s][A100%|██████████| 1/1 [01:22<00:00, 82.69s/it]
 11%|█▏        | 586/5198 [16:52:30<114:12:00, 89.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:17<00:00, 77.74s/it][A100%|██████████| 1/1 [01:17<00:00, 77.74s/it]
 11%|█▏        | 587/5198 [16:53:47<109:58:10, 85.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 12:18:53,391] [INFO] [logging.py:96:log_dist] [Rank 0] step=579, skipped=0, lr=[1.9734883995514658e-05], mom=[(0.9, 0.999)]
steps: 579 loss: 0.6105 iter time (s): 77.025 samples/sec: 1.662

100%|██████████| 1/1 [01:17<00:00, 77.84s/it][A100%|██████████| 1/1 [01:17<00:00, 77.84s/it]
 11%|█▏        | 587/5198 [16:53:48<109:50:33, 85.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:17<00:00, 77.80s/it][A100%|██████████| 1/1 [01:17<00:00, 77.80s/it]
 11%|█▏        | 587/5198 [16:53:48<109:49:45, 85.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:17<00:00, 77.75s/it][A100%|██████████| 1/1 [01:17<00:00, 77.75s/it]
 11%|█▏        | 587/5198 [16:53:48<109:49:25, 85.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:17<00:00, 77.71s/it][A100%|██████████| 1/1 [01:17<00:00, 77.72s/it]
 11%|█▏        | 587/5198 [16:53:48<109:49:07, 85.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:17<00:00, 77.77s/it][A100%|██████████| 1/1 [01:17<00:00, 77.77s/it]
 11%|█▏        | 587/5198 [16:53:48<109:49:27, 85.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:17<00:00, 77.75s/it][A100%|██████████| 1/1 [01:17<00:00, 77.75s/it]
 11%|█▏        | 587/5198 [16:53:48<109:48:11, 85.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:17<00:00, 77.77s/it][A100%|██████████| 1/1 [01:17<00:00, 77.77s/it]
 11%|█▏        | 587/5198 [16:53:50<109:48:49, 85.74s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_551
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.32s/it][A100%|██████████| 1/1 [01:33<00:00, 93.32s/it]
 11%|█▏        | 588/5198 [16:55:21<112:52:02, 88.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 12:20:27,297] [INFO] [logging.py:96:log_dist] [Rank 0] step=580, skipped=0, lr=[1.9733586904841457e-05], mom=[(0.9, 0.999)]
steps: 580 loss: 0.5664 iter time (s): 93.152 samples/sec: 1.374

100%|██████████| 1/1 [01:33<00:00, 93.94s/it][A100%|██████████| 1/1 [01:33<00:00, 93.94s/it]
 11%|█▏        | 588/5198 [16:55:21<112:57:57, 88.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.00s/it][A100%|██████████| 1/1 [01:34<00:00, 94.00s/it]
 11%|█▏        | 588/5198 [16:55:22<112:58:46, 88.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.94s/it][A100%|██████████| 1/1 [01:33<00:00, 93.94s/it]
 11%|█▏        | 588/5198 [16:55:22<112:57:07, 88.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.91s/it][A100%|██████████| 1/1 [01:33<00:00, 93.91s/it]
 11%|█▏        | 588/5198 [16:55:22<112:56:28, 88.20s/it]
100%|██████████| 1/1 [01:33<00:00, 93.98s/it][A100%|██████████| 1/1 [01:33<00:00, 93.98s/it]
 11%|█▏        | 588/5198 [16:55:22<112:57:45, 88.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.94s/it][A100%|██████████| 1/1 [01:33<00:00, 93.94s/it]
 11%|█▏        | 588/5198 [16:55:22<112:56:07, 88.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.94s/it][A100%|██████████| 1/1 [01:33<00:00, 93.94s/it]
 11%|█▏        | 588/5198 [16:55:24<112:56:44, 88.20s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_552
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.37s/it][A100%|██████████| 1/1 [01:29<00:00, 89.37s/it]
 11%|█▏        | 589/5198 [16:56:50<113:22:02, 88.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 12:21:56,647] [INFO] [logging.py:96:log_dist] [Rank 0] step=581, skipped=0, lr=[1.9732286691712786e-05], mom=[(0.9, 0.999)]
steps: 581 loss: 0.5518 iter time (s): 88.596 samples/sec: 1.445

100%|██████████| 1/1 [01:29<00:00, 89.34s/it][A100%|██████████| 1/1 [01:29<00:00, 89.34s/it]
 11%|█▏        | 589/5198 [16:56:51<113:22:33, 88.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.32s/it][A100%|██████████| 1/1 [01:29<00:00, 89.32s/it]
 11%|█▏        | 589/5198 [16:56:51<113:22:36, 88.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.38s/it][A100%|██████████| 1/1 [01:29<00:00, 89.38s/it]
 11%|█▏        | 589/5198 [16:56:51<113:22:50, 88.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.37s/it][A100%|██████████| 1/1 [01:29<00:00, 89.37s/it]
 11%|█▏        | 589/5198 [16:56:51<113:22:59, 88.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.49s/it][A100%|██████████| 1/1 [01:29<00:00, 89.49s/it]
 11%|█▏        | 589/5198 [16:56:52<113:25:03, 88.59s/it]
100%|██████████| 1/1 [01:29<00:00, 89.41s/it][A100%|██████████| 1/1 [01:29<00:00, 89.41s/it]
 11%|█▏        | 589/5198 [16:56:54<113:23:12, 88.56s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_553

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.43s/it][A100%|██████████| 1/1 [01:29<00:00, 89.43s/it]
 11%|█▏        | 589/5198 [16:56:52<113:23:17, 88.57s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:06<00:00, 126.35s/it][A100%|██████████| 1/1 [02:06<00:00, 126.35s/it]
 11%|█▏        | 590/5198 [16:58:57<127:56:28, 99.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 12:24:04,259] [INFO] [logging.py:96:log_dist] [Rank 0] step=582, skipped=0, lr=[1.9730983356545785e-05], mom=[(0.9, 0.999)]
steps: 582 loss: 0.6021 iter time (s): 126.751 samples/sec: 1.010

100%|██████████| 1/1 [02:07<00:00, 127.52s/it][A100%|██████████| 1/1 [02:07<00:00, 127.52s/it]
 11%|█▏        | 590/5198 [16:58:58<128:19:12, 100.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:07<00:00, 127.62s/it][A100%|██████████| 1/1 [02:07<00:00, 127.62s/it]
 11%|█▏        | 590/5198 [16:58:59<128:21:20, 100.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:07<00:00, 127.63s/it][A100%|██████████| 1/1 [02:07<00:00, 127.64s/it]
 11%|█▏        | 590/5198 [16:58:59<128:21:54, 100.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:07<00:00, 127.58s/it][A100%|██████████| 1/1 [02:07<00:00, 127.58s/it]
 11%|█▏        | 590/5198 [16:58:59<128:20:45, 100.27s/it]
100%|██████████| 1/1 [02:07<00:00, 127.46s/it][A100%|██████████| 1/1 [02:07<00:00, 127.46s/it]
 11%|█▏        | 590/5198 [16:58:59<128:19:26, 100.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:07<00:00, 127.52s/it][A100%|██████████| 1/1 [02:07<00:00, 127.52s/it]
 11%|█▏        | 590/5198 [16:58:59<128:19:28, 100.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:07<00:00, 127.54s/it][A100%|██████████| 1/1 [02:07<00:00, 127.54s/it]
 11%|█▏        | 590/5198 [16:59:01<128:19:50, 100.26s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_554
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.28s/it][A100%|██████████| 1/1 [01:56<00:00, 116.28s/it]
 11%|█▏        | 591/5198 [17:00:54<134:21:35, 104.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 12:26:00,363] [INFO] [logging.py:96:log_dist] [Rank 0] step=583, skipped=0, lr=[1.9729676899758596e-05], mom=[(0.9, 0.999)]
steps: 583 loss: 0.5862 iter time (s): 115.313 samples/sec: 1.110

100%|██████████| 1/1 [01:56<00:00, 116.14s/it][A100%|██████████| 1/1 [01:56<00:00, 116.14s/it]
 11%|█▏        | 591/5198 [17:00:54<134:23:50, 105.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.13s/it][A100%|██████████| 1/1 [01:56<00:00, 116.13s/it]
 11%|█▏        | 591/5198 [17:00:55<134:25:15, 105.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.09s/it][A100%|██████████| 1/1 [01:56<00:00, 116.09s/it]
 11%|█▏        | 591/5198 [17:00:55<134:24:37, 105.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.18s/it][A100%|██████████| 1/1 [01:56<00:00, 116.18s/it]
 11%|█▏        | 591/5198 [17:00:55<134:25:53, 105.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.17s/it][A100%|██████████| 1/1 [01:56<00:00, 116.17s/it]
 11%|█▏        | 591/5198 [17:00:55<134:24:34, 105.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.29s/it][A100%|██████████| 1/1 [01:56<00:00, 116.29s/it]
 11%|█▏        | 591/5198 [17:00:55<134:27:27, 105.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:56<00:00, 116.25s/it][A100%|██████████| 1/1 [01:56<00:00, 116.25s/it]
 11%|█▏        | 591/5198 [17:00:58<134:26:41, 105.06s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_36
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.83s/it][A100%|██████████| 1/1 [01:59<00:00, 119.83s/it]
 11%|█▏        | 592/5198 [17:02:54<140:07:19, 109.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 12:28:00,629] [INFO] [logging.py:96:log_dist] [Rank 0] step=584, skipped=0, lr=[1.9728367321770367e-05], mom=[(0.9, 0.999)]
steps: 584 loss: 0.7713 iter time (s): 119.609 samples/sec: 1.070

100%|██████████| 1/1 [02:00<00:00, 120.72s/it][A100%|██████████| 1/1 [02:00<00:00, 120.72s/it]
 11%|█▏        | 592/5198 [17:02:55<140:23:57, 109.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.67s/it][A100%|██████████| 1/1 [02:00<00:00, 120.67s/it]
 11%|█▏        | 592/5198 [17:02:55<140:23:51, 109.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.72s/it][A100%|██████████| 1/1 [02:00<00:00, 120.72s/it]
 11%|█▏        | 592/5198 [17:02:56<140:24:21, 109.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.67s/it][A100%|██████████| 1/1 [02:00<00:00, 120.67s/it]
 11%|█▏        | 592/5198 [17:02:56<140:24:04, 109.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.70s/it][A100%|██████████| 1/1 [02:00<00:00, 120.70s/it]
 11%|█▏        | 592/5198 [17:02:56<140:24:12, 109.74s/it]
100%|██████████| 1/1 [02:00<00:00, 120.66s/it][A100%|██████████| 1/1 [02:00<00:00, 120.66s/it]
 11%|█▏        | 592/5198 [17:02:56<140:24:53, 109.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.64s/it][A100%|██████████| 1/1 [02:00<00:00, 120.64s/it]
 11%|█▏        | 592/5198 [17:02:58<140:23:57, 109.73s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_555
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.72s/it][A100%|██████████| 1/1 [01:26<00:00, 86.72s/it]
 11%|█▏        | 593/5198 [17:04:21<131:26:30, 102.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 12:29:26,861] [INFO] [logging.py:96:log_dist] [Rank 0] step=585, skipped=0, lr=[1.9727054623001234e-05], mom=[(0.9, 0.999)]
steps: 585 loss: 0.5666 iter time (s): 84.909 samples/sec: 1.508

100%|██████████| 1/1 [01:25<00:00, 85.82s/it][A100%|██████████| 1/1 [01:25<00:00, 85.82s/it]
 11%|█▏        | 593/5198 [17:04:21<131:11:40, 102.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.79s/it][A100%|██████████| 1/1 [01:25<00:00, 85.79s/it]
 11%|█▏        | 593/5198 [17:04:21<131:11:19, 102.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.72s/it][A100%|██████████| 1/1 [01:25<00:00, 85.72s/it]
 11%|█▏        | 593/5198 [17:04:22<131:09:45, 102.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.76s/it][A100%|██████████| 1/1 [01:25<00:00, 85.76s/it]
 11%|█▏        | 593/5198 [17:04:22<131:10:22, 102.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.69s/it][A100%|██████████| 1/1 [01:25<00:00, 85.69s/it]
 11%|█▏        | 593/5198 [17:04:22<131:09:23, 102.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.76s/it][A100%|██████████| 1/1 [01:25<00:00, 85.76s/it]
 11%|█▏        | 593/5198 [17:04:22<131:10:30, 102.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.76s/it][A100%|██████████| 1/1 [01:25<00:00, 85.76s/it]
 11%|█▏        | 593/5198 [17:04:24<131:10:16, 102.54s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_556
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.07s/it][A100%|██████████| 1/1 [01:49<00:00, 109.07s/it]
 11%|█▏        | 594/5198 [17:06:10<133:55:23, 104.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 12:31:16,899] [INFO] [logging.py:96:log_dist] [Rank 0] step=586, skipped=0, lr=[1.9725738803872353e-05], mom=[(0.9, 0.999)]
steps: 586 loss: 0.5674 iter time (s): 109.171 samples/sec: 1.172

100%|██████████| 1/1 [01:50<00:00, 110.03s/it][A100%|██████████| 1/1 [01:50<00:00, 110.03s/it]
 11%|█▏        | 594/5198 [17:06:11<134:02:02, 104.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.91s/it][A100%|██████████| 1/1 [01:49<00:00, 109.91s/it]
 11%|█▏        | 594/5198 [17:06:11<133:59:09, 104.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.96s/it][A100%|██████████| 1/1 [01:49<00:00, 109.96s/it]
 11%|█▏        | 594/5198 [17:06:11<133:59:05, 104.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.92s/it][A100%|██████████| 1/1 [01:49<00:00, 109.92s/it]
 11%|█▏        | 594/5198 [17:06:12<133:58:40, 104.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.00s/it][A100%|██████████| 1/1 [01:50<00:00, 110.00s/it]
 11%|█▏        | 594/5198 [17:06:12<133:59:50, 104.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 110.00s/it][A100%|██████████| 1/1 [01:49<00:00, 110.00s/it]
 11%|█▏        | 594/5198 [17:06:12<134:00:26, 104.78s/it]
100%|██████████| 1/1 [01:49<00:00, 109.98s/it][A100%|██████████| 1/1 [01:49<00:00, 109.98s/it]
 11%|█▏        | 594/5198 [17:06:14<133:59:54, 104.78s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_557
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.29s/it][A100%|██████████| 1/1 [01:21<00:00, 81.29s/it]
 11%|█▏        | 595/5198 [17:07:32<124:59:28, 97.76s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 12:32:37,600] [INFO] [logging.py:96:log_dist] [Rank 0] step=587, skipped=0, lr=[1.9724419864805866e-05], mom=[(0.9, 0.999)]
steps: 587 loss: 0.6081 iter time (s): 79.888 samples/sec: 1.602

100%|██████████| 1/1 [01:20<00:00, 80.65s/it][A100%|██████████| 1/1 [01:20<00:00, 80.65s/it]
 11%|█▏        | 595/5198 [17:07:32<124:44:32, 97.56s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.75s/it][A100%|██████████| 1/1 [01:20<00:00, 80.75s/it]
 11%|█▏        | 595/5198 [17:07:32<124:44:52, 97.57s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.67s/it][A100%|██████████| 1/1 [01:20<00:00, 80.67s/it]
 11%|█▏        | 595/5198 [17:07:32<124:42:53, 97.54s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.76s/it][A100%|██████████| 1/1 [01:20<00:00, 80.76s/it]
 11%|█▏        | 595/5198 [17:07:32<124:44:47, 97.56s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.67s/it][A100%|██████████| 1/1 [01:20<00:00, 80.67s/it]
 11%|█▏        | 595/5198 [17:07:32<124:43:32, 97.55s/it] 
100%|██████████| 1/1 [01:20<00:00, 80.63s/it][A100%|██████████| 1/1 [01:20<00:00, 80.63s/it]
 11%|█▏        | 595/5198 [17:07:32<124:42:53, 97.54s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.65s/it][A100%|██████████| 1/1 [01:20<00:00, 80.65s/it]
 11%|█▏        | 595/5198 [17:07:35<124:42:54, 97.54s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_558
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.46s/it][A100%|██████████| 1/1 [01:29<00:00, 89.46s/it]
 11%|█▏        | 596/5198 [17:09:01<121:53:09, 95.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 12:34:07,609] [INFO] [logging.py:96:log_dist] [Rank 0] step=588, skipped=0, lr=[1.9723097806224922e-05], mom=[(0.9, 0.999)]
steps: 588 loss: 0.5572 iter time (s): 89.246 samples/sec: 1.434

100%|██████████| 1/1 [01:29<00:00, 89.96s/it][A100%|██████████| 1/1 [01:29<00:00, 89.96s/it]
 11%|█▏        | 596/5198 [17:09:02<121:48:21, 95.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.96s/it][A100%|██████████| 1/1 [01:29<00:00, 89.96s/it]
 11%|█▏        | 596/5198 [17:09:02<121:48:36, 95.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.04s/it][A100%|██████████| 1/1 [01:30<00:00, 90.04s/it]
 11%|█▏        | 596/5198 [17:09:02<121:48:51, 95.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.93s/it][A100%|██████████| 1/1 [01:29<00:00, 89.93s/it]
 11%|█▏        | 596/5198 [17:09:02<121:47:39, 95.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.98s/it][A100%|██████████| 1/1 [01:29<00:00, 89.98s/it]
 11%|█▏        | 596/5198 [17:09:02<121:47:57, 95.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.99s/it][A100%|██████████| 1/1 [01:29<00:00, 89.99s/it]
 11%|█▏        | 596/5198 [17:09:02<121:47:42, 95.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.99s/it][A100%|██████████| 1/1 [01:29<00:00, 89.99s/it]
 11%|█▏        | 596/5198 [17:09:05<121:47:40, 95.28s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_559
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.91s/it][A100%|██████████| 1/1 [01:36<00:00, 96.91s/it]
 11%|█▏        | 597/5198 [17:10:39<122:33:59, 95.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 12:35:44,921] [INFO] [logging.py:96:log_dist] [Rank 0] step=589, skipped=0, lr=[1.9721772628553675e-05], mom=[(0.9, 0.999)]
steps: 589 loss: 0.6068 iter time (s): 96.562 samples/sec: 1.326

100%|██████████| 1/1 [01:37<00:00, 97.32s/it][A100%|██████████| 1/1 [01:37<00:00, 97.32s/it]
 11%|█▏        | 597/5198 [17:10:39<122:33:42, 95.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.26s/it][A100%|██████████| 1/1 [01:37<00:00, 97.26s/it]
 11%|█▏        | 597/5198 [17:10:39<122:32:31, 95.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.25s/it][A100%|██████████| 1/1 [01:37<00:00, 97.25s/it]
 11%|█▏        | 597/5198 [17:10:39<122:32:38, 95.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.30s/it][A100%|██████████| 1/1 [01:37<00:00, 97.30s/it]
 11%|█▏        | 597/5198 [17:10:40<122:32:52, 95.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.27s/it][A100%|██████████| 1/1 [01:37<00:00, 97.27s/it]
 11%|█▏        | 597/5198 [17:10:40<122:32:13, 95.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.28s/it][A100%|██████████| 1/1 [01:37<00:00, 97.28s/it]
 11%|█▏        | 597/5198 [17:10:42<122:32:23, 95.88s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_560

100%|██████████| 1/1 [01:37<00:00, 97.30s/it][A100%|██████████| 1/1 [01:37<00:00, 97.30s/it]
 11%|█▏        | 597/5198 [17:10:40<122:32:49, 95.89s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.25s/it][A100%|██████████| 1/1 [02:03<00:00, 123.25s/it]
 12%|█▏        | 598/5198 [17:12:42<133:05:38, 104.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 12:37:49,161] [INFO] [logging.py:96:log_dist] [Rank 0] step=590, skipped=0, lr=[1.9720444332217268e-05], mom=[(0.9, 0.999)]
steps: 590 loss: 0.5728 iter time (s): 123.514 samples/sec: 1.036

100%|██████████| 1/1 [02:04<00:00, 124.20s/it][A100%|██████████| 1/1 [02:04<00:00, 124.20s/it]
 12%|█▏        | 598/5198 [17:12:43<133:23:15, 104.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:04<00:00, 124.28s/it][A100%|██████████| 1/1 [02:04<00:00, 124.28s/it]
 12%|█▏        | 598/5198 [17:12:43<133:24:13, 104.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:04<00:00, 124.38s/it][A100%|██████████| 1/1 [02:04<00:00, 124.38s/it]
 12%|█▏        | 598/5198 [17:12:44<133:26:59, 104.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:04<00:00, 124.38s/it][A100%|██████████| 1/1 [02:04<00:00, 124.38s/it]
 12%|█▏        | 598/5198 [17:12:44<133:26:47, 104.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:04<00:00, 124.38s/it][A100%|██████████| 1/1 [02:04<00:00, 124.38s/it]
 12%|█▏        | 598/5198 [17:12:44<133:26:14, 104.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:04<00:00, 124.36s/it][A100%|██████████| 1/1 [02:04<00:00, 124.36s/it]
 12%|█▏        | 598/5198 [17:12:44<133:26:11, 104.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:04<00:00, 124.37s/it][A100%|██████████| 1/1 [02:04<00:00, 124.37s/it]
 12%|█▏        | 598/5198 [17:12:46<133:26:07, 104.43s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_561
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.22s/it][A100%|██████████| 1/1 [01:36<00:00, 96.22s/it]
 12%|█▏        | 599/5198 [17:14:19<130:08:49, 101.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 12:39:24,893] [INFO] [logging.py:96:log_dist] [Rank 0] step=591, skipped=0, lr=[1.9719112917641853e-05], mom=[(0.9, 0.999)]
steps: 591 loss: 0.5822 iter time (s): 94.872 samples/sec: 1.349

100%|██████████| 1/1 [01:35<00:00, 95.75s/it][A100%|██████████| 1/1 [01:35<00:00, 95.75s/it]
 12%|█▏        | 599/5198 [17:14:19<130:03:06, 101.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.73s/it][A100%|██████████| 1/1 [01:35<00:00, 95.73s/it]
 12%|█▏        | 599/5198 [17:14:19<130:03:09, 101.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.65s/it][A100%|██████████| 1/1 [01:35<00:00, 95.65s/it]
 12%|█▏        | 599/5198 [17:14:20<130:03:18, 101.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.63s/it][A100%|██████████| 1/1 [01:35<00:00, 95.63s/it]
 12%|█▏        | 599/5198 [17:14:20<130:02:45, 101.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.62s/it][A100%|██████████| 1/1 [01:35<00:00, 95.62s/it]
 12%|█▏        | 599/5198 [17:14:20<130:02:10, 101.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.64s/it][A100%|██████████| 1/1 [01:35<00:00, 95.64s/it]
 12%|█▏        | 599/5198 [17:14:22<130:02:23, 101.79s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_562

100%|██████████| 1/1 [01:35<00:00, 95.65s/it][A100%|██████████| 1/1 [01:35<00:00, 95.65s/it]
 12%|█▏        | 599/5198 [17:14:20<130:02:40, 101.80s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.58s/it][A100%|██████████| 1/1 [01:32<00:00, 92.58s/it]
[2024-06-30 12:40:57,658] [INFO] [logging.py:96:log_dist] [Rank 0] step=592, skipped=0, lr=[1.9717778385254585e-05], mom=[(0.9, 0.999)]
steps: 592 loss: 0.6129 iter time (s): 91.996 samples/sec: 1.391

100%|██████████| 1/1 [01:32<00:00, 92.81s/it][A100%|██████████| 1/1 [01:32<00:00, 92.81s/it]

100%|██████████| 1/1 [01:32<00:00, 92.79s/it][A100%|██████████| 1/1 [01:32<00:00, 92.79s/it]

100%|██████████| 1/1 [01:32<00:00, 92.72s/it][A100%|██████████| 1/1 [01:32<00:00, 92.72s/it]

100%|██████████| 1/1 [01:32<00:00, 92.82s/it][A100%|██████████| 1/1 [01:32<00:00, 92.82s/it]

100%|██████████| 1/1 [01:32<00:00, 92.81s/it][A100%|██████████| 1/1 [01:32<00:00, 92.81s/it]

100%|██████████| 1/1 [01:32<00:00, 92.82s/it][A100%|██████████| 1/1 [01:32<00:00, 92.82s/it]

100%|██████████| 1/1 [01:32<00:00, 92.85s/it][A100%|██████████| 1/1 [01:32<00:00, 92.85s/it]
Checkpointing at shard 599
[2024-06-30 12:40:58,504] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step592 is about to be saved!
[2024-06-30 12:40:59,554] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step592/layer_00-model_states.pt...
[2024-06-30 12:41:02,387] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step592/layer_02-model_states.pt...
[2024-06-30 12:41:03,786] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step592/layer_07-model_states.pt...
[2024-06-30 12:41:04,007] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step592/layer_05-model_states.pt...
[2024-06-30 12:41:04,013] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step592/layer_06-model_states.pt...
[2024-06-30 12:41:07,713] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step592/layer_00-model_states.pt.
[2024-06-30 12:41:07,825] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step592/layer_08-model_states.pt...
[2024-06-30 12:41:14,131] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step592/layer_01-model_states.pt...
[2024-06-30 12:41:14,867] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step592/layer_04-model_states.pt...
[2024-06-30 12:41:15,466] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step592/layer_03-model_states.pt...
[2024-06-30 12:44:19,504] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step592/layer_02-model_states.pt.
[2024-06-30 12:44:19,549] [INFO] [logging.py:96:log_dist] [Rank 1] Saving model checkpoint: /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step592/mp_rank_01_model_states.pt
[2024-06-30 12:44:19,549] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step592/mp_rank_01_model_states.pt...
[2024-06-30 12:44:19,677] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step592/mp_rank_01_model_states.pt.
[2024-06-30 12:44:19,677] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step592 is ready now!
[2024-06-30 12:44:34,809] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step592/layer_05-model_states.pt.
[2024-06-30 12:44:34,815] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step592/layer_06-model_states.pt.
[2024-06-30 12:44:34,856] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step592/mp_rank_05_model_states.pt...
[2024-06-30 12:44:34,857] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step592/mp_rank_04_model_states.pt...
[2024-06-30 12:44:35,079] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step592/mp_rank_05_model_states.pt.
[2024-06-30 12:44:35,079] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step592 is ready now!
[2024-06-30 12:44:35,186] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step592/mp_rank_04_model_states.pt.
[2024-06-30 12:44:35,187] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step592 is ready now!
[2024-06-30 12:44:37,895] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step592/layer_03-model_states.pt.
[2024-06-30 12:44:38,343] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step592/mp_rank_02_model_states.pt...
[2024-06-30 12:44:38,510] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step592/mp_rank_02_model_states.pt.
[2024-06-30 12:44:38,510] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step592 is ready now!
[2024-06-30 12:44:38,690] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step592/layer_04-model_states.pt.
[2024-06-30 12:44:39,066] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step592/mp_rank_03_model_states.pt...
[2024-06-30 12:44:39,612] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step592/mp_rank_03_model_states.pt.
[2024-06-30 12:44:39,612] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step592 is ready now!
[2024-06-30 12:44:40,483] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step592/layer_01-model_states.pt.
[2024-06-30 12:44:40,829] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step592/layer_07-model_states.pt.
[2024-06-30 12:44:40,871] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step592/mp_rank_06_model_states.pt...
[2024-06-30 12:44:40,947] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step592/mp_rank_00_model_states.pt
[2024-06-30 12:44:40,947] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step592/mp_rank_00_model_states.pt...
[2024-06-30 12:44:40,955] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step592/mp_rank_06_model_states.pt.
[2024-06-30 12:44:40,955] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step592 is ready now!
[2024-06-30 12:44:41,329] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step592/mp_rank_00_model_states.pt.
[2024-06-30 12:44:41,329] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step592 is ready now!
[2024-06-30 12:44:48,659] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step592/layer_08-model_states.pt.
[2024-06-30 12:44:49,274] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step592/layer_09-model_states.pt...
[2024-06-30 12:44:49,822] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step592/layer_09-model_states.pt.
[2024-06-30 12:44:49,825] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step592/mp_rank_07_model_states.pt...
[2024-06-30 12:44:49,871] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step592/mp_rank_07_model_states.pt.
[2024-06-30 12:44:49,871] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step592 is ready now!
Checkpoint saved using --- 231.36756992340088 seconds ---
 12%|█▏        | 600/5198 [17:19:46<216:27:03, 169.47s/it] 12%|█▏        | 600/5198 [17:19:44<215:15:24, 168.54s/it] 12%|█▏        | 600/5198 [17:19:46<215:14:18, 168.52s/it] 12%|█▏        | 600/5198 [17:19:44<215:16:26, 168.55s/it] 12%|█▏        | 600/5198 [17:19:44<215:24:23, 168.65s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_563
 12%|█▏        | 600/5198 [17:19:44<215:14:28, 168.52s/it] 12%|█▏        | 600/5198 [17:19:44<215:18:40, 168.58s/it] 12%|█▏        | 600/5198 [17:19:44<215:21:52, 168.62s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A

  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.57s/it][A100%|██████████| 1/1 [01:24<00:00, 84.57s/it]
 12%|█▏        | 601/5198 [17:21:11<184:00:09, 144.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 12:46:16,739] [INFO] [logging.py:96:log_dist] [Rank 0] step=593, skipped=0, lr=[1.971644073548361e-05], mom=[(0.9, 0.999)]
steps: 593 loss: 0.5482 iter time (s): 86.536 samples/sec: 1.479

100%|██████████| 1/1 [01:26<00:00, 86.93s/it][A100%|██████████| 1/1 [01:26<00:00, 86.93s/it]
 12%|█▏        | 601/5198 [17:21:11<184:10:31, 144.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.01s/it][A100%|██████████| 1/1 [01:27<00:00, 87.01s/it]
 12%|█▏        | 601/5198 [17:21:11<184:10:40, 144.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.19s/it][A100%|██████████| 1/1 [01:27<00:00, 87.19s/it]
 12%|█▏        | 601/5198 [17:21:11<184:12:32, 144.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.30s/it][A100%|██████████| 1/1 [01:27<00:00, 87.30s/it]
 12%|█▏        | 601/5198 [17:21:12<184:13:37, 144.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.33s/it][A100%|██████████| 1/1 [01:27<00:00, 87.33s/it]
 12%|█▏        | 601/5198 [17:21:12<184:13:25, 144.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.39s/it][A100%|██████████| 1/1 [01:27<00:00, 87.39s/it]
 12%|█▏        | 601/5198 [17:21:14<184:14:04, 144.28s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_564
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.40s/it][A100%|██████████| 1/1 [01:27<00:00, 87.40s/it]
 12%|█▏        | 601/5198 [17:21:12<184:14:22, 144.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.06s/it][A100%|██████████| 1/1 [01:27<00:00, 87.06s/it]
 12%|█▏        | 602/5198 [17:22:38<162:14:21, 127.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 12:47:44,102] [INFO] [logging.py:96:log_dist] [Rank 0] step=594, skipped=0, lr=[1.9715099968758085e-05], mom=[(0.9, 0.999)]
steps: 594 loss: 0.5940 iter time (s): 86.494 samples/sec: 1.480

100%|██████████| 1/1 [01:27<00:00, 87.61s/it][A100%|██████████| 1/1 [01:27<00:00, 87.61s/it]
 12%|█▏        | 602/5198 [17:22:39<162:27:07, 127.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.60s/it][A100%|██████████| 1/1 [01:27<00:00, 87.60s/it]
 12%|█▏        | 602/5198 [17:22:39<162:27:04, 127.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.51s/it][A100%|██████████| 1/1 [01:27<00:00, 87.51s/it]
 12%|█▏        | 602/5198 [17:22:39<162:26:25, 127.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.45s/it][A100%|██████████| 1/1 [01:27<00:00, 87.45s/it]
 12%|█▏        | 602/5198 [17:22:39<162:25:38, 127.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.49s/it][A100%|██████████| 1/1 [01:27<00:00, 87.49s/it]
 12%|█▏        | 602/5198 [17:22:39<162:26:27, 127.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.50s/it][A100%|██████████| 1/1 [01:27<00:00, 87.50s/it]
 12%|█▏        | 602/5198 [17:22:41<162:27:07, 127.25s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_565
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.50s/it][A100%|██████████| 1/1 [01:27<00:00, 87.50s/it]
 12%|█▏        | 602/5198 [17:22:39<162:27:19, 127.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.22s/it][A100%|██████████| 1/1 [01:27<00:00, 87.22s/it]
 12%|█▏        | 603/5198 [17:24:05<147:02:04, 115.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 12:49:11,268] [INFO] [logging.py:96:log_dist] [Rank 0] step=595, skipped=0, lr=[1.9713756085508156e-05], mom=[(0.9, 0.999)]
steps: 595 loss: 0.5742 iter time (s): 86.154 samples/sec: 1.486

100%|██████████| 1/1 [01:26<00:00, 86.92s/it][A100%|██████████| 1/1 [01:26<00:00, 86.92s/it]
 12%|█▏        | 603/5198 [17:24:05<146:58:45, 115.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.89s/it][A100%|██████████| 1/1 [01:26<00:00, 86.89s/it]
 12%|█▏        | 603/5198 [17:24:06<146:58:06, 115.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.99s/it][A100%|██████████| 1/1 [01:26<00:00, 86.99s/it]
 12%|█▏        | 603/5198 [17:24:06<146:59:45, 115.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.95s/it][A100%|██████████| 1/1 [01:26<00:00, 86.95s/it]
 12%|█▏        | 603/5198 [17:24:06<146:58:28, 115.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.96s/it][A100%|██████████| 1/1 [01:26<00:00, 86.96s/it]
 12%|█▏        | 603/5198 [17:24:06<146:59:02, 115.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.93s/it][A100%|██████████| 1/1 [01:26<00:00, 86.93s/it]
 12%|█▏        | 603/5198 [17:24:06<146:59:00, 115.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.95s/it][A100%|██████████| 1/1 [01:26<00:00, 86.95s/it]
 12%|█▏        | 603/5198 [17:24:08<146:59:23, 115.16s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_566
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.44s/it][A100%|██████████| 1/1 [01:33<00:00, 93.44s/it]
 12%|█▏        | 604/5198 [17:25:39<138:45:20, 108.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 12:50:45,432] [INFO] [logging.py:96:log_dist] [Rank 0] step=596, skipped=0, lr=[1.9712409086164978e-05], mom=[(0.9, 0.999)]
steps: 596 loss: 0.5815 iter time (s): 93.357 samples/sec: 1.371

100%|██████████| 1/1 [01:34<00:00, 94.08s/it][A100%|██████████| 1/1 [01:34<00:00, 94.08s/it]
 12%|█▏        | 604/5198 [17:25:40<138:53:11, 108.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.11s/it][A100%|██████████| 1/1 [01:34<00:00, 94.11s/it]
 12%|█▏        | 604/5198 [17:25:40<138:53:19, 108.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.10s/it][A100%|██████████| 1/1 [01:34<00:00, 94.10s/it]
 12%|█▏        | 604/5198 [17:25:40<138:54:15, 108.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.16s/it][A100%|██████████| 1/1 [01:34<00:00, 94.17s/it]
 12%|█▏        | 604/5198 [17:25:40<138:54:44, 108.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.16s/it][A100%|██████████| 1/1 [01:34<00:00, 94.16s/it]
 12%|█▏        | 604/5198 [17:25:40<138:54:57, 108.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.14s/it][A100%|██████████| 1/1 [01:34<00:00, 94.14s/it]
 12%|█▏        | 604/5198 [17:25:43<138:54:44, 108.86s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_567

100%|██████████| 1/1 [01:34<00:00, 94.15s/it][A100%|██████████| 1/1 [01:34<00:00, 94.15s/it]
 12%|█▏        | 604/5198 [17:25:40<138:54:52, 108.86s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.48s/it][A100%|██████████| 1/1 [01:28<00:00, 88.48s/it]
 12%|█▏        | 605/5198 [17:27:08<131:06:26, 102.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 12:52:14,107] [INFO] [logging.py:96:log_dist] [Rank 0] step=597, skipped=0, lr=[1.9711058971160696e-05], mom=[(0.9, 0.999)]
steps: 597 loss: 0.5908 iter time (s): 87.893 samples/sec: 1.456

100%|██████████| 1/1 [01:28<00:00, 88.68s/it][A100%|██████████| 1/1 [01:28<00:00, 88.68s/it]
 12%|█▏        | 605/5198 [17:27:08<131:08:54, 102.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.71s/it][A100%|██████████| 1/1 [01:28<00:00, 88.71s/it]
 12%|█▏        | 605/5198 [17:27:08<131:09:35, 102.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.73s/it][A100%|██████████| 1/1 [01:28<00:00, 88.73s/it]
 12%|█▏        | 605/5198 [17:27:09<131:10:34, 102.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.71s/it][A100%|██████████| 1/1 [01:28<00:00, 88.71s/it]
 12%|█▏        | 605/5198 [17:27:09<131:10:30, 102.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.69s/it][A100%|██████████| 1/1 [01:28<00:00, 88.69s/it]
 12%|█▏        | 605/5198 [17:27:09<131:10:16, 102.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.75s/it][A100%|██████████| 1/1 [01:28<00:00, 88.75s/it]
 12%|█▏        | 605/5198 [17:27:09<131:11:20, 102.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.79s/it][A100%|██████████| 1/1 [01:28<00:00, 88.79s/it]
 12%|█▏        | 605/5198 [17:27:11<131:12:12, 102.84s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_568
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.17s/it][A100%|██████████| 1/1 [01:42<00:00, 102.17s/it]
 12%|█▏        | 606/5198 [17:28:50<130:55:54, 102.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 12:53:56,851] [INFO] [logging.py:96:log_dist] [Rank 0] step=598, skipped=0, lr=[1.9709705740928466e-05], mom=[(0.9, 0.999)]
steps: 598 loss: 0.5775 iter time (s): 101.941 samples/sec: 1.256

100%|██████████| 1/1 [01:42<00:00, 102.86s/it][A100%|██████████| 1/1 [01:42<00:00, 102.86s/it]
 12%|█▏        | 606/5198 [17:28:51<131:08:55, 102.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.83s/it][A100%|██████████| 1/1 [01:42<00:00, 102.83s/it]
 12%|█▏        | 606/5198 [17:28:51<131:08:40, 102.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.83s/it][A100%|██████████| 1/1 [01:42<00:00, 102.83s/it]
 12%|█▏        | 606/5198 [17:28:52<131:09:27, 102.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.83s/it][A100%|██████████| 1/1 [01:42<00:00, 102.83s/it]
 12%|█▏        | 606/5198 [17:28:52<131:09:24, 102.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.85s/it][A100%|██████████| 1/1 [01:42<00:00, 102.85s/it]
 12%|█▏        | 606/5198 [17:28:52<131:10:03, 102.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.80s/it][A100%|██████████| 1/1 [01:42<00:00, 102.80s/it]
 12%|█▏        | 606/5198 [17:28:52<131:09:04, 102.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.78s/it][A100%|██████████| 1/1 [01:42<00:00, 102.78s/it]
 12%|█▏        | 606/5198 [17:28:54<131:09:18, 102.82s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_569
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.80s/it][A100%|██████████| 1/1 [01:25<00:00, 85.80s/it]
 12%|█▏        | 607/5198 [17:30:16<124:32:48, 97.66s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 12:55:22,458] [INFO] [logging.py:96:log_dist] [Rank 0] step=599, skipped=0, lr=[1.9708349395902437e-05], mom=[(0.9, 0.999)]
steps: 599 loss: 0.6161 iter time (s): 84.661 samples/sec: 1.512

100%|██████████| 1/1 [01:25<00:00, 85.41s/it][A100%|██████████| 1/1 [01:25<00:00, 85.41s/it]
 12%|█▏        | 607/5198 [17:30:17<124:27:57, 97.60s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.48s/it][A100%|██████████| 1/1 [01:25<00:00, 85.48s/it]
 12%|█▏        | 607/5198 [17:30:17<124:29:21, 97.62s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.44s/it][A100%|██████████| 1/1 [01:25<00:00, 85.44s/it]
 12%|█▏        | 607/5198 [17:30:17<124:29:04, 97.61s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.52s/it][A100%|██████████| 1/1 [01:25<00:00, 85.52s/it]
 12%|█▏        | 607/5198 [17:30:17<124:30:47, 97.64s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.47s/it][A100%|██████████| 1/1 [01:25<00:00, 85.47s/it]
 12%|█▏        | 607/5198 [17:30:17<124:30:04, 97.63s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.50s/it][A100%|██████████| 1/1 [01:25<00:00, 85.50s/it]
 12%|█▏        | 607/5198 [17:30:17<124:29:55, 97.62s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.50s/it][A100%|██████████| 1/1 [01:25<00:00, 85.50s/it]
 12%|█▏        | 607/5198 [17:30:20<124:30:06, 97.63s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_37
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.03s/it][A100%|██████████| 1/1 [01:53<00:00, 113.03s/it]
 12%|█▏        | 608/5198 [17:32:10<130:28:05, 102.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 12:57:16,188] [INFO] [logging.py:96:log_dist] [Rank 0] step=600, skipped=0, lr=[1.9706989936517756e-05], mom=[(0.9, 0.999)]
steps: 600 loss: 0.7905 iter time (s): 113.133 samples/sec: 1.131

100%|██████████| 1/1 [01:54<00:00, 114.27s/it][A100%|██████████| 1/1 [01:54<00:00, 114.27s/it]
 12%|█▏        | 608/5198 [17:32:11<130:49:12, 102.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.14s/it][A100%|██████████| 1/1 [01:54<00:00, 114.14s/it]
 12%|█▏        | 608/5198 [17:32:11<130:48:08, 102.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.29s/it][A100%|██████████| 1/1 [01:54<00:00, 114.29s/it]
 12%|█▏        | 608/5198 [17:32:11<130:50:34, 102.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.47s/it][A100%|██████████| 1/1 [01:54<00:00, 114.47s/it]
 12%|█▏        | 608/5198 [17:32:11<130:54:43, 102.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.26s/it][A100%|██████████| 1/1 [01:54<00:00, 114.26s/it]
 12%|█▏        | 608/5198 [17:32:12<130:50:21, 102.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.25s/it][A100%|██████████| 1/1 [01:54<00:00, 114.25s/it]
 12%|█▏        | 608/5198 [17:32:12<130:50:06, 102.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.25s/it][A100%|██████████| 1/1 [01:54<00:00, 114.25s/it]
 12%|█▏        | 608/5198 [17:32:14<130:50:05, 102.62s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_570
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.26s/it][A100%|██████████| 1/1 [01:49<00:00, 109.26s/it]
 12%|█▏        | 609/5198 [17:33:59<133:10:18, 104.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 12:59:05,790] [INFO] [logging.py:96:log_dist] [Rank 0] step=601, skipped=0, lr=[1.9705627363210574e-05], mom=[(0.9, 0.999)]
steps: 601 loss: 0.6064 iter time (s): 108.246 samples/sec: 1.182

100%|██████████| 1/1 [01:49<00:00, 109.26s/it][A100%|██████████| 1/1 [01:49<00:00, 109.26s/it]
 12%|█▏        | 609/5198 [17:34:00<133:20:25, 104.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.11s/it][A100%|██████████| 1/1 [01:49<00:00, 109.11s/it]
 12%|█▏        | 609/5198 [17:34:00<133:20:45, 104.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.17s/it][A100%|██████████| 1/1 [01:49<00:00, 109.17s/it]
 12%|█▏        | 609/5198 [17:34:01<133:19:21, 104.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.22s/it][A100%|██████████| 1/1 [01:49<00:00, 109.22s/it]
 12%|█▏        | 609/5198 [17:34:01<133:18:50, 104.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.15s/it][A100%|██████████| 1/1 [01:49<00:00, 109.15s/it]
 12%|█▏        | 609/5198 [17:34:01<133:18:35, 104.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.16s/it][A100%|██████████| 1/1 [01:49<00:00, 109.16s/it]
 12%|█▏        | 609/5198 [17:34:03<133:18:36, 104.58s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_571
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.19s/it][A100%|██████████| 1/1 [01:49<00:00, 109.19s/it]
 12%|█▏        | 609/5198 [17:34:01<133:19:21, 104.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.01s/it][A100%|██████████| 1/1 [01:45<00:00, 105.01s/it]
 12%|█▏        | 610/5198 [17:35:44<133:24:17, 104.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 13:00:50,777] [INFO] [logging.py:96:log_dist] [Rank 0] step=602, skipped=0, lr=[1.970426167641804e-05], mom=[(0.9, 0.999)]
steps: 602 loss: 0.5540 iter time (s): 104.057 samples/sec: 1.230

100%|██████████| 1/1 [01:44<00:00, 104.80s/it][A100%|██████████| 1/1 [01:44<00:00, 104.80s/it]
 12%|█▏        | 610/5198 [17:35:45<133:23:43, 104.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.78s/it][A100%|██████████| 1/1 [01:44<00:00, 104.78s/it]
 12%|█▏        | 610/5198 [17:35:45<133:23:07, 104.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.81s/it][A100%|██████████| 1/1 [01:44<00:00, 104.81s/it]
 12%|█▏        | 610/5198 [17:35:45<133:22:54, 104.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.85s/it][A100%|██████████| 1/1 [01:44<00:00, 104.85s/it]
 12%|█▏        | 610/5198 [17:35:46<133:23:11, 104.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.92s/it][A100%|██████████| 1/1 [01:44<00:00, 104.92s/it]
 12%|█▏        | 610/5198 [17:35:46<133:25:04, 104.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.88s/it][A100%|██████████| 1/1 [01:44<00:00, 104.88s/it]
 12%|█▏        | 610/5198 [17:35:48<133:23:56, 104.67s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_572

100%|██████████| 1/1 [01:44<00:00, 104.87s/it][A100%|██████████| 1/1 [01:44<00:00, 104.87s/it]
 12%|█▏        | 610/5198 [17:35:46<133:24:10, 104.68s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.45s/it][A100%|██████████| 1/1 [01:24<00:00, 84.45s/it]
 12%|█▏        | 611/5198 [17:37:09<125:43:45, 98.68s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 13:02:14,971] [INFO] [logging.py:96:log_dist] [Rank 0] step=603, skipped=0, lr=[1.970289287657829e-05], mom=[(0.9, 0.999)]
steps: 603 loss: 0.5679 iter time (s): 83.363 samples/sec: 1.535

100%|██████████| 1/1 [01:24<00:00, 84.14s/it][A100%|██████████| 1/1 [01:24<00:00, 84.14s/it]
 12%|█▏        | 611/5198 [17:37:09<125:31:13, 98.51s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.16s/it][A100%|██████████| 1/1 [01:24<00:00, 84.16s/it]
 12%|█▏        | 611/5198 [17:37:09<125:31:19, 98.51s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.17s/it][A100%|██████████| 1/1 [01:24<00:00, 84.17s/it]
 12%|█▏        | 611/5198 [17:37:10<125:31:23, 98.51s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.06s/it][A100%|██████████| 1/1 [01:24<00:00, 84.06s/it]
 12%|█▏        | 611/5198 [17:37:10<125:30:28, 98.50s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.13s/it][A100%|██████████| 1/1 [01:24<00:00, 84.13s/it]
 12%|█▏        | 611/5198 [17:37:10<125:30:36, 98.50s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.10s/it][A100%|██████████| 1/1 [01:24<00:00, 84.10s/it]
 12%|█▏        | 611/5198 [17:37:10<125:30:36, 98.50s/it] 
100%|██████████| 1/1 [01:24<00:00, 84.10s/it][A100%|██████████| 1/1 [01:24<00:00, 84.10s/it]
 12%|█▏        | 611/5198 [17:37:12<125:30:34, 98.50s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_573

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.55s/it][A100%|██████████| 1/1 [01:18<00:00, 78.55s/it]
 12%|█▏        | 612/5198 [17:38:28<118:05:22, 92.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 13:03:33,523] [INFO] [logging.py:96:log_dist] [Rank 0] step=604, skipped=0, lr=[1.970152096413048e-05], mom=[(0.9, 0.999)]
steps: 604 loss: 0.5623 iter time (s): 77.806 samples/sec: 1.645

100%|██████████| 1/1 [01:18<00:00, 78.55s/it][A100%|██████████| 1/1 [01:18<00:00, 78.55s/it]
 12%|█▏        | 612/5198 [17:38:28<117:51:57, 92.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.47s/it][A100%|██████████| 1/1 [01:18<00:00, 78.47s/it]
 12%|█▏        | 612/5198 [17:38:28<117:50:17, 92.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.51s/it][A100%|██████████| 1/1 [01:18<00:00, 78.51s/it]
 12%|█▏        | 612/5198 [17:38:28<117:51:12, 92.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.60s/it][A100%|██████████| 1/1 [01:18<00:00, 78.60s/it]
 12%|█▏        | 612/5198 [17:38:28<117:52:41, 92.53s/it]
100%|██████████| 1/1 [01:18<00:00, 78.56s/it][A100%|██████████| 1/1 [01:18<00:00, 78.56s/it]
 12%|█▏        | 612/5198 [17:38:28<117:51:44, 92.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.54s/it][A100%|██████████| 1/1 [01:18<00:00, 78.54s/it]
 12%|█▏        | 612/5198 [17:38:28<117:51:27, 92.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.56s/it][A100%|██████████| 1/1 [01:18<00:00, 78.56s/it]
 12%|█▏        | 612/5198 [17:38:31<117:51:49, 92.52s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_574
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.74s/it][A100%|██████████| 1/1 [01:34<00:00, 94.75s/it]
 12%|█▏        | 613/5198 [17:40:02<118:54:04, 93.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 13:05:08,824] [INFO] [logging.py:96:log_dist] [Rank 0] step=605, skipped=0, lr=[1.9700145939514747e-05], mom=[(0.9, 0.999)]
steps: 605 loss: 0.5919 iter time (s): 94.530 samples/sec: 1.354

100%|██████████| 1/1 [01:35<00:00, 95.48s/it][A100%|██████████| 1/1 [01:35<00:00, 95.48s/it]
 12%|█▏        | 613/5198 [17:40:03<118:58:19, 93.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.47s/it][A100%|██████████| 1/1 [01:35<00:00, 95.47s/it]
 12%|█▏        | 613/5198 [17:40:03<118:56:55, 93.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.46s/it][A100%|██████████| 1/1 [01:35<00:00, 95.46s/it]
 12%|█▏        | 613/5198 [17:40:04<118:57:26, 93.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.39s/it][A100%|██████████| 1/1 [01:35<00:00, 95.39s/it]
 12%|█▏        | 613/5198 [17:40:04<118:56:54, 93.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.49s/it][A100%|██████████| 1/1 [01:35<00:00, 95.49s/it]
 12%|█▏        | 613/5198 [17:40:04<118:58:25, 93.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.91s/it][A100%|██████████| 1/1 [01:35<00:00, 95.91s/it]
 12%|█▏        | 613/5198 [17:40:04<119:07:54, 93.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.34s/it][A100%|██████████| 1/1 [01:36<00:00, 96.34s/it]
 12%|█▏        | 613/5198 [17:40:07<119:17:58, 93.67s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_575
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.64s/it][A100%|██████████| 1/1 [01:24<00:00, 84.64s/it]
 12%|█▏        | 614/5198 [17:41:27<115:36:39, 90.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 13:06:33,348] [INFO] [logging.py:96:log_dist] [Rank 0] step=606, skipped=0, lr=[1.9698767803172238e-05], mom=[(0.9, 0.999)]
steps: 606 loss: 0.5650 iter time (s): 82.760 samples/sec: 1.547

100%|██████████| 1/1 [01:24<00:00, 84.35s/it][A100%|██████████| 1/1 [01:24<00:00, 84.35s/it]
 12%|█▏        | 614/5198 [17:41:27<115:29:47, 90.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.41s/it][A100%|██████████| 1/1 [01:24<00:00, 84.41s/it]
 12%|█▏        | 614/5198 [17:41:28<115:29:34, 90.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.42s/it][A100%|██████████| 1/1 [01:24<00:00, 84.42s/it]
 12%|█▏        | 614/5198 [17:41:28<115:30:12, 90.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.47s/it][A100%|██████████| 1/1 [01:24<00:00, 84.47s/it]
 12%|█▏        | 614/5198 [17:41:28<115:31:00, 90.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.40s/it][A100%|██████████| 1/1 [01:24<00:00, 84.40s/it]
 12%|█▏        | 614/5198 [17:41:28<115:30:36, 90.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.99s/it][A100%|██████████| 1/1 [01:23<00:00, 84.00s/it]
 12%|█▏        | 614/5198 [17:41:28<115:27:47, 90.68s/it]
100%|██████████| 1/1 [01:23<00:00, 83.55s/it][A100%|██████████| 1/1 [01:23<00:00, 83.55s/it]
 12%|█▏        | 614/5198 [17:41:30<115:24:40, 90.64s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_576

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:15<00:00, 135.61s/it][A100%|██████████| 1/1 [02:15<00:00, 135.61s/it]
 12%|█▏        | 615/5198 [17:43:43<132:48:03, 104.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 13:08:50,724] [INFO] [logging.py:96:log_dist] [Rank 0] step=607, skipped=0, lr=[1.9697386555545092e-05], mom=[(0.9, 0.999)]
steps: 607 loss: 0.6009 iter time (s): 136.528 samples/sec: 0.938

100%|██████████| 1/1 [02:17<00:00, 137.33s/it][A100%|██████████| 1/1 [02:17<00:00, 137.33s/it]
 12%|█▏        | 615/5198 [17:43:45<133:16:58, 104.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:17<00:00, 137.31s/it][A100%|██████████| 1/1 [02:17<00:00, 137.31s/it]
 12%|█▏        | 615/5198 [17:43:45<133:16:16, 104.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:17<00:00, 137.31s/it][A100%|██████████| 1/1 [02:17<00:00, 137.31s/it]
 12%|█▏        | 615/5198 [17:43:45<133:16:47, 104.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:17<00:00, 137.30s/it][A100%|██████████| 1/1 [02:17<00:00, 137.30s/it]
 12%|█▏        | 615/5198 [17:43:45<133:17:08, 104.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:17<00:00, 137.27s/it][A100%|██████████| 1/1 [02:17<00:00, 137.27s/it]
 12%|█▏        | 615/5198 [17:43:46<133:14:00, 104.66s/it]
100%|██████████| 1/1 [02:17<00:00, 137.33s/it][A100%|██████████| 1/1 [02:17<00:00, 137.33s/it]
 12%|█▏        | 615/5198 [17:43:46<133:17:33, 104.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:17<00:00, 137.28s/it][A100%|██████████| 1/1 [02:17<00:00, 137.28s/it]
 12%|█▏        | 615/5198 [17:43:48<133:12:06, 104.63s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_577
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.86s/it][A100%|██████████| 1/1 [01:26<00:00, 86.86s/it]
 12%|█▏        | 616/5198 [17:45:10<126:12:28, 99.16s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 13:10:16,396] [INFO] [logging.py:96:log_dist] [Rank 0] step=608, skipped=0, lr=[1.9696002197076443e-05], mom=[(0.9, 0.999)]
steps: 608 loss: 0.5504 iter time (s): 84.916 samples/sec: 1.507

100%|██████████| 1/1 [01:25<00:00, 85.67s/it][A100%|██████████| 1/1 [01:25<00:00, 85.67s/it]
 12%|█▏        | 616/5198 [17:45:11<125:59:33, 98.99s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.62s/it][A100%|██████████| 1/1 [01:25<00:00, 85.62s/it]
 12%|█▏        | 616/5198 [17:45:11<125:58:00, 98.97s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.65s/it][A100%|██████████| 1/1 [01:25<00:00, 85.65s/it]
 12%|█▏        | 616/5198 [17:45:11<125:59:03, 98.98s/it] 
100%|██████████| 1/1 [01:25<00:00, 85.56s/it][A100%|██████████| 1/1 [01:25<00:00, 85.56s/it]
 12%|█▏        | 616/5198 [17:45:11<125:57:04, 98.96s/it] 

  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.64s/it][A100%|██████████| 1/1 [01:25<00:00, 85.64s/it]
 12%|█▏        | 616/5198 [17:45:11<125:59:14, 98.99s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.69s/it][A100%|██████████| 1/1 [01:25<00:00, 85.69s/it]
 12%|█▏        | 616/5198 [17:45:11<125:57:51, 98.97s/it] 
100%|██████████| 1/1 [01:25<00:00, 85.67s/it][A100%|██████████| 1/1 [01:25<00:00, 85.67s/it]
 12%|█▏        | 616/5198 [17:45:13<125:56:07, 98.95s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_578

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.49s/it][A100%|██████████| 1/1 [01:44<00:00, 104.49s/it]
 12%|█▏        | 617/5198 [17:46:55<128:17:43, 100.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 13:12:01,683] [INFO] [logging.py:96:log_dist] [Rank 0] step=609, skipped=0, lr=[1.9694614728210435e-05], mom=[(0.9, 0.999)]
steps: 609 loss: 0.5848 iter time (s): 104.521 samples/sec: 1.225

100%|██████████| 1/1 [01:45<00:00, 105.26s/it][A100%|██████████| 1/1 [01:45<00:00, 105.26s/it]
 12%|█▏        | 617/5198 [17:46:56<128:21:50, 100.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.46s/it][A100%|██████████| 1/1 [01:45<00:00, 105.46s/it]
 12%|█▏        | 617/5198 [17:46:56<128:25:13, 100.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.30s/it][A100%|██████████| 1/1 [01:45<00:00, 105.30s/it]
 12%|█▏        | 617/5198 [17:46:56<128:22:23, 100.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.37s/it][A100%|██████████| 1/1 [01:45<00:00, 105.37s/it]
 12%|█▏        | 617/5198 [17:46:56<128:22:33, 100.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.29s/it][A100%|██████████| 1/1 [01:45<00:00, 105.29s/it]
 12%|█▏        | 617/5198 [17:46:56<128:22:12, 100.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.30s/it][A100%|██████████| 1/1 [01:45<00:00, 105.30s/it]
 12%|█▏        | 617/5198 [17:46:59<128:20:13, 100.85s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_579

100%|██████████| 1/1 [01:45<00:00, 105.30s/it][A100%|██████████| 1/1 [01:45<00:00, 105.30s/it]
 12%|█▏        | 617/5198 [17:46:57<128:21:29, 100.87s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.72s/it][A100%|██████████| 1/1 [01:35<00:00, 95.72s/it]
 12%|█▏        | 618/5198 [17:48:31<126:22:36, 99.34s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 13:13:37,263] [INFO] [logging.py:96:log_dist] [Rank 0] step=610, skipped=0, lr=[1.96932241493922e-05], mom=[(0.9, 0.999)]
steps: 610 loss: 0.5315 iter time (s): 94.799 samples/sec: 1.350

100%|██████████| 1/1 [01:35<00:00, 95.64s/it][A100%|██████████| 1/1 [01:35<00:00, 95.64s/it]
 12%|█▏        | 618/5198 [17:48:31<126:20:28, 99.31s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.53s/it][A100%|██████████| 1/1 [01:35<00:00, 95.53s/it]
 12%|█▏        | 618/5198 [17:48:32<126:20:25, 99.31s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.65s/it][A100%|██████████| 1/1 [01:35<00:00, 95.65s/it]
 12%|█▏        | 618/5198 [17:48:32<126:21:10, 99.32s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.68s/it][A100%|██████████| 1/1 [01:35<00:00, 95.68s/it]
 12%|█▏        | 618/5198 [17:48:32<126:21:55, 99.33s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.63s/it][A100%|██████████| 1/1 [01:35<00:00, 95.63s/it]
 12%|█▏        | 618/5198 [17:48:32<126:20:24, 99.31s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.60s/it][A100%|██████████| 1/1 [01:35<00:00, 95.60s/it]
 12%|█▏        | 618/5198 [17:48:32<126:19:16, 99.29s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.63s/it][A100%|██████████| 1/1 [01:35<00:00, 95.63s/it]
 12%|█▏        | 618/5198 [17:48:34<126:19:00, 99.29s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_580
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.46s/it][A100%|██████████| 1/1 [01:20<00:00, 80.46s/it]
 12%|█▏        | 619/5198 [17:49:52<119:14:24, 93.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 13:14:57,558] [INFO] [logging.py:96:log_dist] [Rank 0] step=611, skipped=0, lr=[1.9691830461067862e-05], mom=[(0.9, 0.999)]
steps: 611 loss: 0.5589 iter time (s): 79.461 samples/sec: 1.611

100%|██████████| 1/1 [01:20<00:00, 80.22s/it][A100%|██████████| 1/1 [01:20<00:00, 80.22s/it]
 12%|█▏        | 619/5198 [17:49:52<119:02:11, 93.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.22s/it][A100%|██████████| 1/1 [01:20<00:00, 80.22s/it]
 12%|█▏        | 619/5198 [17:49:52<119:02:12, 93.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.23s/it][A100%|██████████| 1/1 [01:20<00:00, 80.23s/it]
 12%|█▏        | 619/5198 [17:49:52<119:02:36, 93.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.19s/it][A100%|██████████| 1/1 [01:20<00:00, 80.19s/it]
 12%|█▏        | 619/5198 [17:49:52<119:02:23, 93.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.21s/it][A100%|██████████| 1/1 [01:20<00:00, 80.22s/it]
 12%|█▏        | 619/5198 [17:49:52<119:01:51, 93.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.30s/it][A100%|██████████| 1/1 [01:20<00:00, 80.30s/it]
 12%|█▏        | 619/5198 [17:49:52<119:02:54, 93.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.32s/it][A100%|██████████| 1/1 [01:20<00:00, 80.32s/it]
 12%|█▏        | 619/5198 [17:49:55<119:03:10, 93.60s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_581
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.13s/it][A100%|██████████| 1/1 [01:19<00:00, 79.13s/it]
 12%|█▏        | 620/5198 [17:51:11<113:45:23, 89.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 13:16:16,988] [INFO] [logging.py:96:log_dist] [Rank 0] step=612, skipped=0, lr=[1.9690433663684562e-05], mom=[(0.9, 0.999)]
steps: 612 loss: 0.6063 iter time (s): 78.569 samples/sec: 1.629

100%|██████████| 1/1 [01:19<00:00, 79.42s/it][A100%|██████████| 1/1 [01:19<00:00, 79.42s/it]
 12%|█▏        | 620/5198 [17:51:11<113:36:40, 89.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.43s/it][A100%|██████████| 1/1 [01:19<00:00, 79.43s/it]
 12%|█▏        | 620/5198 [17:51:11<113:36:55, 89.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.39s/it][A100%|██████████| 1/1 [01:19<00:00, 79.39s/it]
 12%|█▏        | 620/5198 [17:51:12<113:36:15, 89.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.40s/it][A100%|██████████| 1/1 [01:19<00:00, 79.40s/it]
 12%|█▏        | 620/5198 [17:51:12<113:36:13, 89.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.46s/it][A100%|██████████| 1/1 [01:19<00:00, 79.46s/it]
 12%|█▏        | 620/5198 [17:51:12<113:37:15, 89.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.39s/it][A100%|██████████| 1/1 [01:19<00:00, 79.39s/it]
 12%|█▏        | 620/5198 [17:51:12<113:36:22, 89.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:19<00:00, 79.36s/it][A100%|██████████| 1/1 [01:19<00:00, 79.36s/it]
 12%|█▏        | 620/5198 [17:51:14<113:35:53, 89.33s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_582
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.38s/it][A100%|██████████| 1/1 [01:18<00:00, 78.38s/it]
 12%|█▏        | 621/5198 [17:52:30<109:34:45, 86.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 13:17:35,554] [INFO] [logging.py:96:log_dist] [Rank 0] step=613, skipped=0, lr=[1.968903375769042e-05], mom=[(0.9, 0.999)]
steps: 613 loss: 0.5731 iter time (s): 77.769 samples/sec: 1.646

100%|██████████| 1/1 [01:18<00:00, 78.54s/it][A100%|██████████| 1/1 [01:18<00:00, 78.54s/it]
 12%|█▏        | 621/5198 [17:52:30<109:28:14, 86.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.50s/it][A100%|██████████| 1/1 [01:18<00:00, 78.50s/it]
 12%|█▏        | 621/5198 [17:52:30<109:27:34, 86.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.58s/it][A100%|██████████| 1/1 [01:18<00:00, 78.58s/it]
 12%|█▏        | 621/5198 [17:52:30<109:28:47, 86.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.54s/it][A100%|██████████| 1/1 [01:18<00:00, 78.54s/it]
 12%|█▏        | 621/5198 [17:52:30<109:27:56, 86.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.51s/it][A100%|██████████| 1/1 [01:18<00:00, 78.51s/it]
 12%|█▏        | 621/5198 [17:52:30<109:27:56, 86.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.50s/it][A100%|██████████| 1/1 [01:18<00:00, 78.50s/it]
 12%|█▏        | 621/5198 [17:52:30<109:27:06, 86.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.51s/it][A100%|██████████| 1/1 [01:18<00:00, 78.51s/it]
 12%|█▏        | 621/5198 [17:52:33<109:26:52, 86.09s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_583
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.96s/it][A100%|██████████| 1/1 [01:20<00:00, 80.96s/it]
 12%|█▏        | 622/5198 [17:53:51<107:38:36, 84.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 13:18:56,777] [INFO] [logging.py:96:log_dist] [Rank 0] step=614, skipped=0, lr=[1.9687630743534567e-05], mom=[(0.9, 0.999)]
steps: 614 loss: 0.5425 iter time (s): 80.473 samples/sec: 1.591

100%|██████████| 1/1 [01:21<00:00, 81.26s/it][A100%|██████████| 1/1 [01:21<00:00, 81.26s/it]
 12%|█▏        | 622/5198 [17:53:51<107:36:04, 84.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.18s/it][A100%|██████████| 1/1 [01:21<00:00, 81.18s/it]
 12%|█▏        | 622/5198 [17:53:51<107:34:00, 84.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.10s/it][A100%|██████████| 1/1 [01:21<00:00, 81.11s/it]
 12%|█▏        | 622/5198 [17:53:51<107:33:02, 84.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.20s/it][A100%|██████████| 1/1 [01:21<00:00, 81.20s/it]
 12%|█▏        | 622/5198 [17:53:51<107:34:38, 84.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.22s/it][A100%|██████████| 1/1 [01:21<00:00, 81.22s/it]
 12%|█▏        | 622/5198 [17:53:52<107:35:01, 84.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.21s/it][A100%|██████████| 1/1 [01:21<00:00, 81.21s/it]
 12%|█▏        | 622/5198 [17:53:52<107:34:17, 84.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.20s/it][A100%|██████████| 1/1 [01:21<00:00, 81.20s/it]
 12%|█▏        | 622/5198 [17:53:54<107:33:54, 84.62s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_584
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.26s/it][A100%|██████████| 1/1 [01:26<00:00, 86.26s/it]
 12%|█▏        | 623/5198 [17:55:17<108:17:51, 85.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 13:20:23,394] [INFO] [logging.py:96:log_dist] [Rank 0] step=615, skipped=0, lr=[1.968622462166712e-05], mom=[(0.9, 0.999)]
steps: 615 loss: 0.6225 iter time (s): 85.879 samples/sec: 1.490

100%|██████████| 1/1 [01:26<00:00, 86.56s/it][A100%|██████████| 1/1 [01:26<00:00, 86.56s/it]
 12%|█▏        | 623/5198 [17:55:17<108:18:37, 85.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.62s/it][A100%|██████████| 1/1 [01:26<00:00, 86.62s/it]
 12%|█▏        | 623/5198 [17:55:18<108:18:26, 85.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.69s/it][A100%|██████████| 1/1 [01:26<00:00, 86.69s/it]
 12%|█▏        | 623/5198 [17:55:18<108:19:33, 85.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.65s/it][A100%|██████████| 1/1 [01:26<00:00, 86.65s/it]
 12%|█▏        | 623/5198 [17:55:18<108:19:28, 85.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.63s/it][A100%|██████████| 1/1 [01:26<00:00, 86.63s/it]
 12%|█▏        | 623/5198 [17:55:18<108:19:27, 85.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.66s/it][A100%|██████████| 1/1 [01:26<00:00, 86.66s/it]
 12%|█▏        | 623/5198 [17:55:18<108:19:35, 85.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.66s/it][A100%|██████████| 1/1 [01:26<00:00, 86.66s/it]
 12%|█▏        | 623/5198 [17:55:20<108:19:20, 85.24s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_38
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:14<00:00, 134.20s/it][A100%|██████████| 1/1 [02:14<00:00, 134.20s/it]
 12%|█▏        | 624/5198 [17:57:32<126:59:22, 99.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 13:22:38,698] [INFO] [logging.py:96:log_dist] [Rank 0] step=616, skipped=0, lr=[1.9684815392539197e-05], mom=[(0.9, 0.999)]
steps: 616 loss: 0.7901 iter time (s): 134.846 samples/sec: 0.949

100%|██████████| 1/1 [02:15<00:00, 135.96s/it][A100%|██████████| 1/1 [02:15<00:00, 135.96s/it]
 12%|█▏        | 624/5198 [17:57:33<127:37:46, 100.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:16<00:00, 136.12s/it][A100%|██████████| 1/1 [02:16<00:00, 136.12s/it]
 12%|█▏        | 624/5198 [17:57:34<127:41:18, 100.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:16<00:00, 136.02s/it][A100%|██████████| 1/1 [02:16<00:00, 136.02s/it]
 12%|█▏        | 624/5198 [17:57:34<127:39:44, 100.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:16<00:00, 136.00s/it][A100%|██████████| 1/1 [02:16<00:00, 136.00s/it]
 12%|█▏        | 624/5198 [17:57:34<127:39:11, 100.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:16<00:00, 136.09s/it][A100%|██████████| 1/1 [02:16<00:00, 136.09s/it]
 12%|█▏        | 624/5198 [17:57:34<127:41:14, 100.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:15<00:00, 135.99s/it][A100%|██████████| 1/1 [02:15<00:00, 135.99s/it]
 12%|█▏        | 624/5198 [17:57:34<127:39:02, 100.47s/it]
100%|██████████| 1/1 [02:15<00:00, 135.98s/it][A100%|██████████| 1/1 [02:15<00:00, 135.98s/it]
 12%|█▏        | 624/5198 [17:57:36<127:38:38, 100.46s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_585
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.55s/it][A100%|██████████| 1/1 [01:30<00:00, 90.55s/it]
 12%|█▏        | 625/5198 [17:59:02<123:26:35, 97.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 13:24:08,463] [INFO] [logging.py:96:log_dist] [Rank 0] step=617, skipped=0, lr=[1.968340305660292e-05], mom=[(0.9, 0.999)]
steps: 617 loss: 0.5970 iter time (s): 88.353 samples/sec: 1.449

100%|██████████| 1/1 [01:29<00:00, 89.10s/it][A100%|██████████| 1/1 [01:29<00:00, 89.10s/it]
 12%|█▏        | 625/5198 [17:59:03<123:16:47, 97.05s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.02s/it][A100%|██████████| 1/1 [01:29<00:00, 89.02s/it]
 12%|█▏        | 625/5198 [17:59:03<123:17:21, 97.06s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.12s/it][A100%|██████████| 1/1 [01:29<00:00, 89.12s/it]
 12%|█▏        | 625/5198 [17:59:03<123:18:39, 97.07s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.02s/it][A100%|██████████| 1/1 [01:29<00:00, 89.02s/it]
 12%|█▏        | 625/5198 [17:59:03<123:17:18, 97.06s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.11s/it][A100%|██████████| 1/1 [01:29<00:00, 89.11s/it]
 12%|█▏        | 625/5198 [17:59:03<123:17:49, 97.06s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.49s/it][A100%|██████████| 1/1 [01:29<00:00, 89.49s/it]
 12%|█▏        | 625/5198 [17:59:04<123:26:34, 97.18s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.96s/it][A100%|██████████| 1/1 [01:29<00:00, 89.96s/it]
 12%|█▏        | 625/5198 [17:59:06<123:36:59, 97.31s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_586
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.38s/it][A100%|██████████| 1/1 [01:33<00:00, 93.38s/it]
 12%|█▏        | 626/5198 [18:00:36<122:05:18, 96.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 13:25:42,272] [INFO] [logging.py:96:log_dist] [Rank 0] step=618, skipped=0, lr=[1.9681987614311394e-05], mom=[(0.9, 0.999)]
steps: 618 loss: 0.6115 iter time (s): 92.124 samples/sec: 1.389

100%|██████████| 1/1 [01:33<00:00, 93.81s/it][A100%|██████████| 1/1 [01:33<00:00, 93.81s/it]
 12%|█▏        | 626/5198 [18:00:36<122:01:21, 96.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.73s/it][A100%|██████████| 1/1 [01:33<00:00, 93.73s/it]
 12%|█▏        | 626/5198 [18:00:36<121:59:48, 96.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.66s/it][A100%|██████████| 1/1 [01:33<00:00, 93.66s/it]
 12%|█▏        | 626/5198 [18:00:37<121:59:39, 96.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.73s/it][A100%|██████████| 1/1 [01:33<00:00, 93.73s/it]
 12%|█▏        | 626/5198 [18:00:37<121:59:43, 96.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.71s/it][A100%|██████████| 1/1 [01:33<00:00, 93.71s/it]
 12%|█▏        | 626/5198 [18:00:37<121:59:58, 96.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.34s/it][A100%|██████████| 1/1 [01:33<00:00, 93.34s/it]
 12%|█▏        | 626/5198 [18:00:37<121:57:38, 96.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.89s/it][A100%|██████████| 1/1 [01:32<00:00, 92.90s/it]
 12%|█▏        | 626/5198 [18:00:39<121:54:30, 95.99s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_587
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.36s/it][A100%|██████████| 1/1 [01:30<00:00, 90.36s/it]
 12%|█▏        | 627/5198 [18:02:07<119:56:55, 94.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 13:27:12,384] [INFO] [logging.py:96:log_dist] [Rank 0] step=619, skipped=0, lr=[1.9680569066118732e-05], mom=[(0.9, 0.999)]
steps: 619 loss: 0.5660 iter time (s): 89.338 samples/sec: 1.433

100%|██████████| 1/1 [01:30<00:00, 90.12s/it][A100%|██████████| 1/1 [01:30<00:00, 90.12s/it]
 12%|█▏        | 627/5198 [18:02:07<119:43:45, 94.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.16s/it][A100%|██████████| 1/1 [01:30<00:00, 90.16s/it]
 12%|█▏        | 627/5198 [18:02:07<119:43:27, 94.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.19s/it][A100%|██████████| 1/1 [01:30<00:00, 90.19s/it]
 12%|█▏        | 627/5198 [18:02:07<119:44:03, 94.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.18s/it][A100%|██████████| 1/1 [01:30<00:00, 90.18s/it]
 12%|█▏        | 627/5198 [18:02:07<119:43:51, 94.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.16s/it][A100%|██████████| 1/1 [01:30<00:00, 90.16s/it]
 12%|█▏        | 627/5198 [18:02:07<119:43:36, 94.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.12s/it][A100%|██████████| 1/1 [01:30<00:00, 90.12s/it]
 12%|█▏        | 627/5198 [18:02:07<119:41:11, 94.26s/it]
100%|██████████| 1/1 [01:30<00:00, 90.12s/it][A100%|██████████| 1/1 [01:30<00:00, 90.12s/it]
 12%|█▏        | 627/5198 [18:02:09<119:38:50, 94.23s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_588

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.38s/it][A100%|██████████| 1/1 [01:38<00:00, 98.38s/it]
 12%|█▏        | 628/5198 [18:03:45<121:28:14, 95.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 13:28:51,574] [INFO] [logging.py:96:log_dist] [Rank 0] step=620, skipped=0, lr=[1.9679147412480035e-05], mom=[(0.9, 0.999)]
steps: 620 loss: 0.5962 iter time (s): 98.400 samples/sec: 1.301

100%|██████████| 1/1 [01:39<00:00, 99.21s/it][A100%|██████████| 1/1 [01:39<00:00, 99.21s/it]
 12%|█▏        | 628/5198 [18:03:46<121:34:42, 95.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.23s/it][A100%|██████████| 1/1 [01:39<00:00, 99.23s/it]
 12%|█▏        | 628/5198 [18:03:46<121:35:01, 95.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.18s/it][A100%|██████████| 1/1 [01:39<00:00, 99.19s/it]
 12%|█▏        | 628/5198 [18:03:46<121:34:27, 95.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.20s/it][A100%|██████████| 1/1 [01:39<00:00, 99.20s/it]
 12%|█▏        | 628/5198 [18:03:46<121:34:22, 95.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.28s/it][A100%|██████████| 1/1 [01:39<00:00, 99.28s/it]
 12%|█▏        | 628/5198 [18:03:46<121:36:20, 95.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.25s/it][A100%|██████████| 1/1 [01:39<00:00, 99.25s/it]
 12%|█▏        | 628/5198 [18:03:46<121:33:44, 95.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.25s/it][A100%|██████████| 1/1 [01:39<00:00, 99.25s/it]
 12%|█▏        | 628/5198 [18:03:49<121:32:09, 95.74s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_589
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.43s/it][A100%|██████████| 1/1 [01:43<00:00, 103.43s/it]
 12%|█▏        | 629/5198 [18:05:29<124:28:12, 98.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 13:30:35,366] [INFO] [logging.py:96:log_dist] [Rank 0] step=621, skipped=0, lr=[1.9677722653851413e-05], mom=[(0.9, 0.999)]
steps: 621 loss: 0.5528 iter time (s): 102.938 samples/sec: 1.243

100%|██████████| 1/1 [01:43<00:00, 103.73s/it][A100%|██████████| 1/1 [01:43<00:00, 103.73s/it]
 12%|█▏        | 629/5198 [18:05:30<124:35:23, 98.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.90s/it][A100%|██████████| 1/1 [01:43<00:00, 103.90s/it]
 12%|█▏        | 629/5198 [18:05:30<124:38:55, 98.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.88s/it][A100%|██████████| 1/1 [01:43<00:00, 103.88s/it]
 12%|█▏        | 629/5198 [18:05:30<124:38:27, 98.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.75s/it][A100%|██████████| 1/1 [01:43<00:00, 103.75s/it]
 12%|█▏        | 629/5198 [18:05:30<124:36:37, 98.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.84s/it][A100%|██████████| 1/1 [01:43<00:00, 103.84s/it]
 12%|█▏        | 629/5198 [18:05:30<124:37:20, 98.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.82s/it][A100%|██████████| 1/1 [01:43<00:00, 103.82s/it]
 12%|█▏        | 629/5198 [18:05:30<124:36:31, 98.18s/it]
100%|██████████| 1/1 [01:43<00:00, 103.82s/it][A100%|██████████| 1/1 [01:43<00:00, 103.82s/it]
 12%|█▏        | 629/5198 [18:05:33<124:35:15, 98.16s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_590
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.36s/it][A100%|██████████| 1/1 [01:32<00:00, 92.36s/it]
 12%|█▏        | 630/5198 [18:07:01<122:21:36, 96.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 13:32:07,630] [INFO] [logging.py:96:log_dist] [Rank 0] step=622, skipped=0, lr=[1.967629479068996e-05], mom=[(0.9, 0.999)]
steps: 622 loss: 0.5537 iter time (s): 91.372 samples/sec: 1.401

100%|██████████| 1/1 [01:32<00:00, 92.03s/it][A100%|██████████| 1/1 [01:32<00:00, 92.03s/it]
 12%|█▏        | 630/5198 [18:07:02<122:16:21, 96.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.19s/it][A100%|██████████| 1/1 [01:32<00:00, 92.19s/it]
 12%|█▏        | 630/5198 [18:07:02<122:17:22, 96.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.09s/it][A100%|██████████| 1/1 [01:32<00:00, 92.09s/it]
 12%|█▏        | 630/5198 [18:07:02<122:17:19, 96.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.17s/it][A100%|██████████| 1/1 [01:32<00:00, 92.17s/it]
 12%|█▏        | 630/5198 [18:07:02<122:17:54, 96.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.18s/it][A100%|██████████| 1/1 [01:32<00:00, 92.18s/it]
 12%|█▏        | 630/5198 [18:07:02<122:18:31, 96.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.13s/it][A100%|██████████| 1/1 [01:32<00:00, 92.13s/it]
 12%|█▏        | 630/5198 [18:07:02<122:17:04, 96.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.16s/it][A100%|██████████| 1/1 [01:32<00:00, 92.16s/it]
 12%|█▏        | 630/5198 [18:07:05<122:16:41, 96.37s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_591
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.84s/it][A100%|██████████| 1/1 [01:49<00:00, 109.84s/it]
 12%|█▏        | 631/5198 [18:08:51<127:32:06, 100.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 13:33:58,214] [INFO] [logging.py:96:log_dist] [Rank 0] step=623, skipped=0, lr=[1.9674863823453768e-05], mom=[(0.9, 0.999)]
steps: 623 loss: 0.5948 iter time (s): 109.782 samples/sec: 1.166

100%|██████████| 1/1 [01:50<00:00, 110.71s/it][A100%|██████████| 1/1 [01:50<00:00, 110.71s/it]
 12%|█▏        | 631/5198 [18:08:52<127:42:40, 100.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.71s/it][A100%|██████████| 1/1 [01:50<00:00, 110.71s/it]
 12%|█▏        | 631/5198 [18:08:53<127:43:20, 100.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.69s/it][A100%|██████████| 1/1 [01:50<00:00, 110.69s/it]
 12%|█▏        | 631/5198 [18:08:53<127:42:47, 100.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.68s/it][A
100%|██████████| 1/1 [01:50<00:00, 110.68s/it]
 12%|█▏        | 631/5198 [18:08:53<127:42:56, 100.67s/it]100%|██████████| 1/1 [01:50<00:00, 110.62s/it][A100%|██████████| 1/1 [01:50<00:00, 110.62s/it]
 12%|█▏        | 631/5198 [18:08:53<127:41:58, 100.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.65s/it][A100%|██████████| 1/1 [01:50<00:00, 110.65s/it]
 12%|█▏        | 631/5198 [18:08:53<127:41:44, 100.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.64s/it][A100%|██████████| 1/1 [01:50<00:00, 110.64s/it]
 12%|█▏        | 631/5198 [18:08:55<127:41:17, 100.65s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_592
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.64s/it][A100%|██████████| 1/1 [01:26<00:00, 86.65s/it]
 12%|█▏        | 632/5198 [18:10:18<122:21:12, 96.47s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 13:35:24,527] [INFO] [logging.py:96:log_dist] [Rank 0] step=624, skipped=0, lr=[1.9673429752601926e-05], mom=[(0.9, 0.999)]
steps: 624 loss: 0.5830 iter time (s): 85.457 samples/sec: 1.498

100%|██████████| 1/1 [01:26<00:00, 86.22s/it][A100%|██████████| 1/1 [01:26<00:00, 86.22s/it]
 12%|█▏        | 632/5198 [18:10:19<122:11:12, 96.34s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.25s/it][A100%|██████████| 1/1 [01:26<00:00, 86.25s/it]
 12%|█▏        | 632/5198 [18:10:19<122:12:29, 96.35s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.18s/it][A100%|██████████| 1/1 [01:26<00:00, 86.18s/it]
 12%|█▏        | 632/5198 [18:10:19<122:10:28, 96.33s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.19s/it][A100%|██████████| 1/1 [01:26<00:00, 86.19s/it]
 12%|█▏        | 632/5198 [18:10:19<122:10:50, 96.33s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.22s/it][A100%|██████████| 1/1 [01:26<00:00, 86.22s/it]
 12%|█▏        | 632/5198 [18:10:19<122:10:52, 96.33s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.22s/it][A100%|██████████| 1/1 [01:26<00:00, 86.22s/it]
 12%|█▏        | 632/5198 [18:10:19<122:10:35, 96.33s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.22s/it][A100%|██████████| 1/1 [01:26<00:00, 86.22s/it]
 12%|█▏        | 632/5198 [18:10:22<122:10:10, 96.32s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_593
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.58s/it][A100%|██████████| 1/1 [01:48<00:00, 108.58s/it]
 12%|█▏        | 633/5198 [18:12:07<127:03:23, 100.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 13:37:14,096] [INFO] [logging.py:96:log_dist] [Rank 0] step=625, skipped=0, lr=[1.967199257859452e-05], mom=[(0.9, 0.999)]
steps: 625 loss: 0.5832 iter time (s): 108.799 samples/sec: 1.176

100%|██████████| 1/1 [01:49<00:00, 109.50s/it][A100%|██████████| 1/1 [01:49<00:00, 109.50s/it]
 12%|█▏        | 633/5198 [18:12:08<127:10:21, 100.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.57s/it][A100%|██████████| 1/1 [01:49<00:00, 109.57s/it]
 12%|█▏        | 633/5198 [18:12:08<127:12:43, 100.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.54s/it][A100%|██████████| 1/1 [01:49<00:00, 109.54s/it]
 12%|█▏        | 633/5198 [18:12:09<127:10:33, 100.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.55s/it][A100%|██████████| 1/1 [01:49<00:00, 109.55s/it]
 12%|█▏        | 633/5198 [18:12:09<127:11:19, 100.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.61s/it][A100%|██████████| 1/1 [01:49<00:00, 109.61s/it]
 12%|█▏        | 633/5198 [18:12:09<127:12:27, 100.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.61s/it][A100%|██████████| 1/1 [01:49<00:00, 109.61s/it]
 12%|█▏        | 633/5198 [18:12:09<127:12:22, 100.32s/it]
100%|██████████| 1/1 [01:49<00:00, 109.60s/it][A100%|██████████| 1/1 [01:49<00:00, 109.60s/it]
 12%|█▏        | 633/5198 [18:12:11<127:11:50, 100.31s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_594
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.16s/it][A100%|██████████| 1/1 [01:26<00:00, 86.16s/it]
 12%|█▏        | 634/5198 [18:13:34<121:46:47, 96.06s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 13:38:39,821] [INFO] [logging.py:96:log_dist] [Rank 0] step=626, skipped=0, lr=[1.967055230189264e-05], mom=[(0.9, 0.999)]
steps: 626 loss: 0.5917 iter time (s): 84.916 samples/sec: 1.507

100%|██████████| 1/1 [01:25<00:00, 85.76s/it][A100%|██████████| 1/1 [01:25<00:00, 85.76s/it]
 12%|█▏        | 634/5198 [18:13:34<121:37:21, 95.93s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.68s/it][A100%|██████████| 1/1 [01:25<00:00, 85.68s/it]
 12%|█▏        | 634/5198 [18:13:34<121:37:06, 95.93s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.76s/it][A100%|██████████| 1/1 [01:25<00:00, 85.76s/it]
 12%|█▏        | 634/5198 [18:13:34<121:37:24, 95.93s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.69s/it][A100%|██████████| 1/1 [01:25<00:00, 85.69s/it]
 12%|█▏        | 634/5198 [18:13:34<121:36:31, 95.92s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.70s/it][A100%|██████████| 1/1 [01:25<00:00, 85.70s/it]
 12%|█▏        | 634/5198 [18:13:35<121:37:22, 95.93s/it] 
100%|██████████| 1/1 [01:25<00:00, 85.75s/it][A100%|██████████| 1/1 [01:25<00:00, 85.75s/it]
 12%|█▏        | 634/5198 [18:13:35<121:38:37, 95.95s/it] 
100%|██████████| 1/1 [01:25<00:00, 85.71s/it][A100%|██████████| 1/1 [01:25<00:00, 85.71s/it]
 12%|█▏        | 634/5198 [18:13:37<121:37:05, 95.93s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_595

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.72s/it][A100%|██████████| 1/1 [01:36<00:00, 96.72s/it]
 12%|█▏        | 635/5198 [18:15:11<122:05:48, 96.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 13:40:17,112] [INFO] [logging.py:96:log_dist] [Rank 0] step=627, skipped=0, lr=[1.9669108922958348e-05], mom=[(0.9, 0.999)]
steps: 627 loss: 0.5839 iter time (s): 96.492 samples/sec: 1.327

100%|██████████| 1/1 [01:37<00:00, 97.24s/it][A100%|██████████| 1/1 [01:37<00:00, 97.24s/it]
 12%|█▏        | 635/5198 [18:15:11<122:05:56, 96.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.28s/it][A100%|██████████| 1/1 [01:37<00:00, 97.28s/it]
 12%|█▏        | 635/5198 [18:15:11<122:06:35, 96.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.24s/it][A100%|██████████| 1/1 [01:37<00:00, 97.24s/it]
 12%|█▏        | 635/5198 [18:15:12<122:05:58, 96.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.28s/it][A100%|██████████| 1/1 [01:37<00:00, 97.28s/it]
 12%|█▏        | 635/5198 [18:15:12<122:06:03, 96.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.18s/it][A100%|██████████| 1/1 [01:37<00:00, 97.18s/it]
 12%|█▏        | 635/5198 [18:15:12<122:05:11, 96.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.26s/it][A100%|██████████| 1/1 [01:37<00:00, 97.26s/it]
 12%|█▏        | 635/5198 [18:15:12<122:06:14, 96.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.27s/it][A100%|██████████| 1/1 [01:37<00:00, 97.27s/it]
 12%|█▏        | 635/5198 [18:15:14<122:06:09, 96.33s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_596
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.50s/it][A100%|██████████| 1/1 [01:24<00:00, 84.50s/it]
 12%|█▏        | 636/5198 [18:16:35<117:41:02, 92.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 13:41:41,546] [INFO] [logging.py:96:log_dist] [Rank 0] step=628, skipped=0, lr=[1.9667662442254724e-05], mom=[(0.9, 0.999)]
steps: 628 loss: 0.5609 iter time (s): 83.653 samples/sec: 1.530

100%|██████████| 1/1 [01:24<00:00, 84.52s/it][A100%|██████████| 1/1 [01:24<00:00, 84.52s/it]
 12%|█▏        | 636/5198 [18:16:36<117:35:16, 92.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.42s/it][A100%|██████████| 1/1 [01:24<00:00, 84.42s/it]
 12%|█▏        | 636/5198 [18:16:36<117:33:24, 92.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.48s/it][A100%|██████████| 1/1 [01:24<00:00, 84.48s/it]
 12%|█▏        | 636/5198 [18:16:36<117:34:08, 92.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.53s/it][A100%|██████████| 1/1 [01:24<00:00, 84.53s/it]
 12%|█▏        | 636/5198 [18:16:36<117:35:22, 92.79s/it]
100%|██████████| 1/1 [01:24<00:00, 84.49s/it][A100%|██████████| 1/1 [01:24<00:00, 84.49s/it]
 12%|█▏        | 636/5198 [18:16:36<117:34:02, 92.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.48s/it][A100%|██████████| 1/1 [01:24<00:00, 84.48s/it]
 12%|█▏        | 636/5198 [18:16:36<117:34:30, 92.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.49s/it][A100%|██████████| 1/1 [01:24<00:00, 84.49s/it]
 12%|█▏        | 636/5198 [18:16:39<117:34:37, 92.78s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_597
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.50s/it][A100%|██████████| 1/1 [01:32<00:00, 92.50s/it]
 12%|█▏        | 637/5198 [18:18:08<117:37:05, 92.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 13:43:14,529] [INFO] [logging.py:96:log_dist] [Rank 0] step=629, skipped=0, lr=[1.9666212860245836e-05], mom=[(0.9, 0.999)]
steps: 629 loss: 0.6120 iter time (s): 92.137 samples/sec: 1.389

100%|██████████| 1/1 [01:32<00:00, 92.90s/it][A100%|██████████| 1/1 [01:32<00:00, 92.90s/it]
 12%|█▏        | 637/5198 [18:18:09<117:36:27, 92.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.94s/it][A100%|██████████| 1/1 [01:32<00:00, 92.94s/it]
 12%|█▏        | 637/5198 [18:18:09<117:36:02, 92.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.00s/it][A100%|██████████| 1/1 [01:33<00:00, 93.00s/it]
 12%|█▏        | 637/5198 [18:18:09<117:38:00, 92.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.90s/it][A100%|██████████| 1/1 [01:32<00:00, 92.90s/it]
 12%|█▏        | 637/5198 [18:18:09<117:36:30, 92.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.01s/it][A100%|██████████| 1/1 [01:33<00:00, 93.01s/it]
 12%|█▏        | 637/5198 [18:18:09<117:38:04, 92.85s/it]
100%|██████████| 1/1 [01:32<00:00, 92.94s/it][A100%|██████████| 1/1 [01:32<00:00, 92.94s/it]
 12%|█▏        | 637/5198 [18:18:09<117:36:50, 92.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.94s/it][A100%|██████████| 1/1 [01:32<00:00, 92.94s/it]
 12%|█▏        | 637/5198 [18:18:12<117:36:44, 92.83s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_598
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.75s/it][A100%|██████████| 1/1 [01:25<00:00, 85.75s/it]
 12%|█▏        | 638/5198 [18:19:34<114:57:54, 90.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 13:44:40,141] [INFO] [logging.py:96:log_dist] [Rank 0] step=630, skipped=0, lr=[1.9664760177396745e-05], mom=[(0.9, 0.999)]
steps: 630 loss: 0.5437 iter time (s): 84.804 samples/sec: 1.509

100%|██████████| 1/1 [01:25<00:00, 85.52s/it][A100%|██████████| 1/1 [01:25<00:00, 85.52s/it]
 12%|█▏        | 638/5198 [18:19:34<114:48:33, 90.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.54s/it][A100%|██████████| 1/1 [01:25<00:00, 85.54s/it]
 12%|█▏        | 638/5198 [18:19:34<114:48:39, 90.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.45s/it][A100%|██████████| 1/1 [01:25<00:00, 85.45s/it]
 12%|█▏        | 638/5198 [18:19:35<114:48:01, 90.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.55s/it][A100%|██████████| 1/1 [01:25<00:00, 85.55s/it]
 12%|█▏        | 638/5198 [18:19:35<114:49:16, 90.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.48s/it][A100%|██████████| 1/1 [01:25<00:00, 85.48s/it]
 12%|█▏        | 638/5198 [18:19:35<114:48:46, 90.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.52s/it][A100%|██████████| 1/1 [01:25<00:00, 85.52s/it]
 12%|█▏        | 638/5198 [18:19:35<114:48:46, 90.64s/it]
100%|██████████| 1/1 [01:25<00:00, 85.52s/it][A100%|██████████| 1/1 [01:25<00:00, 85.52s/it]
 12%|█▏        | 638/5198 [18:19:37<114:48:33, 90.64s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_599

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.68s/it][A100%|██████████| 1/1 [01:29<00:00, 89.68s/it]
 12%|█▏        | 639/5198 [18:21:04<114:36:07, 90.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 13:46:10,283] [INFO] [logging.py:96:log_dist] [Rank 0] step=631, skipped=0, lr=[1.9663304394173507e-05], mom=[(0.9, 0.999)]
steps: 631 loss: 0.5775 iter time (s): 89.423 samples/sec: 1.431

100%|██████████| 1/1 [01:30<00:00, 90.19s/it][A100%|██████████| 1/1 [01:30<00:00, 90.19s/it]
 12%|█▏        | 639/5198 [18:21:04<114:36:59, 90.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.34s/it][A100%|██████████| 1/1 [01:30<00:00, 90.34s/it]
 12%|█▏        | 639/5198 [18:21:05<114:40:26, 90.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.25s/it][A100%|██████████| 1/1 [01:30<00:00, 90.25s/it]
 12%|█▏        | 639/5198 [18:21:05<114:38:04, 90.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.21s/it][A100%|██████████| 1/1 [01:30<00:00, 90.21s/it]
 12%|█▏        | 639/5198 [18:21:05<114:37:52, 90.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.22s/it][A100%|██████████| 1/1 [01:30<00:00, 90.22s/it]
 12%|█▏        | 639/5198 [18:21:05<114:37:51, 90.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.35s/it][A100%|██████████| 1/1 [01:30<00:00, 90.35s/it]
 12%|█▏        | 639/5198 [18:21:08<114:40:40, 90.56s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_39
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.41s/it][A100%|██████████| 1/1 [01:30<00:00, 90.41s/it]
 12%|█▏        | 639/5198 [18:21:05<114:42:11, 90.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.40s/it][A100%|██████████| 1/1 [02:00<00:00, 120.40s/it]
 12%|█▏        | 640/5198 [18:23:05<126:00:07, 99.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 13:48:11,372] [INFO] [logging.py:96:log_dist] [Rank 0] step=632, skipped=0, lr=[1.9661845511043168e-05], mom=[(0.9, 0.999)]
steps: 632 loss: 0.7778 iter time (s): 120.415 samples/sec: 1.063

100%|██████████| 1/1 [02:01<00:00, 121.32s/it][A100%|██████████| 1/1 [02:01<00:00, 121.32s/it]
 12%|█▏        | 640/5198 [18:23:06<126:20:20, 99.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:01<00:00, 121.48s/it][A100%|██████████| 1/1 [02:01<00:00, 121.48s/it]
 12%|█▏        | 640/5198 [18:23:06<126:21:36, 99.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:01<00:00, 121.37s/it][A100%|██████████| 1/1 [02:01<00:00, 121.37s/it]
 12%|█▏        | 640/5198 [18:23:06<126:19:47, 99.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:01<00:00, 121.40s/it][A100%|██████████| 1/1 [02:01<00:00, 121.41s/it]
 12%|█▏        | 640/5198 [18:23:07<126:20:37, 99.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:01<00:00, 121.48s/it][A100%|██████████| 1/1 [02:01<00:00, 121.48s/it]
 12%|█▏        | 640/5198 [18:23:06<126:22:10, 99.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:01<00:00, 121.28s/it][A100%|██████████| 1/1 [02:01<00:00, 121.28s/it]
 12%|█▏        | 640/5198 [18:23:09<126:19:31, 99.77s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_600

100%|██████████| 1/1 [02:01<00:00, 121.23s/it][A100%|██████████| 1/1 [02:01<00:00, 121.23s/it]
 12%|█▏        | 640/5198 [18:23:07<126:19:25, 99.77s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.71s/it][A100%|██████████| 1/1 [01:24<00:00, 84.71s/it]
 12%|█▏        | 641/5198 [18:24:30<120:27:35, 95.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 13:49:35,618] [INFO] [logging.py:96:log_dist] [Rank 0] step=633, skipped=0, lr=[1.9660383528473782e-05], mom=[(0.9, 0.999)]
steps: 633 loss: 0.5494 iter time (s): 83.123 samples/sec: 1.540

100%|██████████| 1/1 [01:23<00:00, 83.96s/it][A100%|██████████| 1/1 [01:23<00:00, 83.96s/it]
 12%|█▏        | 641/5198 [18:24:30<120:18:26, 95.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.83s/it][A100%|██████████| 1/1 [01:23<00:00, 83.83s/it]
 12%|█▏        | 641/5198 [18:24:30<120:16:11, 95.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.95s/it][A100%|██████████| 1/1 [01:23<00:00, 83.95s/it]
 12%|█▏        | 641/5198 [18:24:30<120:17:41, 95.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.88s/it][A100%|██████████| 1/1 [01:23<00:00, 83.88s/it]
 12%|█▏        | 641/5198 [18:24:30<120:17:37, 95.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.90s/it][A100%|██████████| 1/1 [01:23<00:00, 83.90s/it]
 12%|█▏        | 641/5198 [18:24:30<120:16:59, 95.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.90s/it][A100%|██████████| 1/1 [01:23<00:00, 83.90s/it]
 12%|█▏        | 641/5198 [18:24:30<120:16:09, 95.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.91s/it][A100%|██████████| 1/1 [01:23<00:00, 83.91s/it]
 12%|█▏        | 641/5198 [18:24:33<120:16:33, 95.02s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_601
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.29s/it][A100%|██████████| 1/1 [01:40<00:00, 100.29s/it]
 12%|█▏        | 642/5198 [18:26:10<122:26:41, 96.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 13:51:16,584] [INFO] [logging.py:96:log_dist] [Rank 0] step=634, skipped=0, lr=[1.965891844693439e-05], mom=[(0.9, 0.999)]
steps: 634 loss: 0.6356 iter time (s): 100.161 samples/sec: 1.278

100%|██████████| 1/1 [01:40<00:00, 100.95s/it][A100%|██████████| 1/1 [01:40<00:00, 100.95s/it]
 12%|█▏        | 642/5198 [18:26:11<122:31:38, 96.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.98s/it][A100%|██████████| 1/1 [01:40<00:00, 100.98s/it]
 12%|█▏        | 642/5198 [18:26:11<122:30:45, 96.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.94s/it][A100%|██████████| 1/1 [01:40<00:00, 100.94s/it]
 12%|█▏        | 642/5198 [18:26:11<122:30:57, 96.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.87s/it][A100%|██████████| 1/1 [01:40<00:00, 100.87s/it]
 12%|█▏        | 642/5198 [18:26:11<122:29:11, 96.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.89s/it][A100%|██████████| 1/1 [01:40<00:00, 100.89s/it]
 12%|█▏        | 642/5198 [18:26:11<122:29:13, 96.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.93s/it][A100%|██████████| 1/1 [01:40<00:00, 100.93s/it]
 12%|█▏        | 642/5198 [18:26:11<122:29:25, 96.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.92s/it][A100%|██████████| 1/1 [01:40<00:00, 100.92s/it]
 12%|█▏        | 642/5198 [18:26:14<122:29:42, 96.79s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_602
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.34s/it][A100%|██████████| 1/1 [01:53<00:00, 113.34s/it]
 12%|█▏        | 643/5198 [18:28:04<128:47:56, 101.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 13:53:10,495] [INFO] [logging.py:96:log_dist] [Rank 0] step=635, skipped=0, lr=[1.9657450266895016e-05], mom=[(0.9, 0.999)]
steps: 635 loss: 0.5907 iter time (s): 113.142 samples/sec: 1.131

100%|██████████| 1/1 [01:53<00:00, 113.81s/it][A100%|██████████| 1/1 [01:53<00:00, 113.81s/it]
 12%|█▏        | 643/5198 [18:28:05<128:57:15, 101.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.84s/it][A100%|██████████| 1/1 [01:53<00:00, 113.84s/it]
 12%|█▏        | 643/5198 [18:28:05<128:57:23, 101.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.85s/it][A100%|██████████| 1/1 [01:53<00:00, 113.85s/it]
 12%|█▏        | 643/5198 [18:28:05<128:57:45, 101.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.90s/it][A100%|██████████| 1/1 [01:53<00:00, 113.90s/it]
 12%|█▏        | 643/5198 [18:28:05<128:57:32, 101.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.91s/it][A100%|██████████| 1/1 [01:53<00:00, 113.91s/it]
 12%|█▏        | 643/5198 [18:28:05<128:57:43, 101.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.89s/it][A100%|██████████| 1/1 [01:53<00:00, 113.89s/it]
 12%|█▏        | 643/5198 [18:28:05<128:57:30, 101.92s/it]
100%|██████████| 1/1 [01:53<00:00, 113.88s/it][A100%|██████████| 1/1 [01:53<00:00, 113.89s/it]
 12%|█▏        | 643/5198 [18:28:08<128:57:32, 101.92s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_603

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.44s/it][A100%|██████████| 1/1 [01:48<00:00, 108.44s/it]
 12%|█▏        | 644/5198 [18:29:52<131:20:53, 103.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 13:54:58,934] [INFO] [logging.py:96:log_dist] [Rank 0] step=636, skipped=0, lr=[1.96559789888267e-05], mom=[(0.9, 0.999)]
steps: 636 loss: 0.5532 iter time (s): 107.683 samples/sec: 1.189

100%|██████████| 1/1 [01:48<00:00, 108.45s/it][A100%|██████████| 1/1 [01:48<00:00, 108.45s/it]
 12%|█▏        | 644/5198 [18:29:53<131:24:23, 103.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.44s/it][A100%|██████████| 1/1 [01:48<00:00, 108.44s/it]
 12%|█▏        | 644/5198 [18:29:53<131:24:16, 103.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.50s/it][A100%|██████████| 1/1 [01:48<00:00, 108.50s/it]
 12%|█▏        | 644/5198 [18:29:54<131:25:57, 103.90s/it]
100%|██████████| 1/1 [01:48<00:00, 108.41s/it][A
100%|██████████| 1/1 [01:48<00:00, 108.41s/it]  0%|          | 0/1 [00:00<?, ?it/s]
[A 12%|█▏        | 644/5198 [18:29:54<131:23:44, 103.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.45s/it][A100%|██████████| 1/1 [01:48<00:00, 108.45s/it]
 12%|█▏        | 644/5198 [18:29:54<131:24:51, 103.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.45s/it][A100%|██████████| 1/1 [01:48<00:00, 108.45s/it]
 12%|█▏        | 644/5198 [18:29:56<131:24:37, 103.88s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_604
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.46s/it][A100%|██████████| 1/1 [01:48<00:00, 108.46s/it]
 12%|█▏        | 644/5198 [18:29:54<131:24:48, 103.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.68s/it][A100%|██████████| 1/1 [01:37<00:00, 97.68s/it]
 12%|█▏        | 645/5198 [18:31:30<129:03:13, 102.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 13:56:36,536] [INFO] [logging.py:96:log_dist] [Rank 0] step=637, skipped=0, lr=[1.9654504613201456e-05], mom=[(0.9, 0.999)]
steps: 637 loss: 0.5698 iter time (s): 96.831 samples/sec: 1.322

100%|██████████| 1/1 [01:37<00:00, 97.59s/it][A100%|██████████| 1/1 [01:37<00:00, 97.59s/it]
 12%|█▏        | 645/5198 [18:31:31<128:59:44, 102.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.78s/it][A100%|██████████| 1/1 [01:37<00:00, 97.78s/it]
 12%|█▏        | 645/5198 [18:31:31<129:04:05, 102.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.61s/it][A100%|██████████| 1/1 [01:37<00:00, 97.62s/it]
 12%|█▏        | 645/5198 [18:31:31<129:01:26, 102.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.70s/it][A100%|██████████| 1/1 [01:37<00:00, 97.70s/it]
 12%|█▏        | 645/5198 [18:31:31<129:02:33, 102.03s/it]
100%|██████████| 1/1 [01:37<00:00, 97.79s/it][A100%|██████████| 1/1 [01:37<00:00, 97.79s/it]
 12%|█▏        | 645/5198 [18:31:31<129:03:47, 102.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.70s/it][A100%|██████████| 1/1 [01:37<00:00, 97.70s/it]
 12%|█▏        | 645/5198 [18:31:31<129:02:27, 102.03s/it]
100%|██████████| 1/1 [01:37<00:00, 97.71s/it][A100%|██████████| 1/1 [01:37<00:00, 97.71s/it]
 12%|█▏        | 645/5198 [18:31:34<129:02:36, 102.03s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_605
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.90s/it][A100%|██████████| 1/1 [01:31<00:00, 91.90s/it]
 12%|█▏        | 646/5198 [18:33:02<125:14:27, 99.05s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 13:58:08,439] [INFO] [logging.py:96:log_dist] [Rank 0] step=638, skipped=0, lr=[1.9653027140492307e-05], mom=[(0.9, 0.999)]
steps: 638 loss: 0.5660 iter time (s): 91.020 samples/sec: 1.406

100%|██████████| 1/1 [01:31<00:00, 91.93s/it][A100%|██████████| 1/1 [01:31<00:00, 91.93s/it]
 12%|█▏        | 646/5198 [18:33:03<125:09:13, 98.98s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.78s/it][A100%|██████████| 1/1 [01:31<00:00, 91.78s/it]
 12%|█▏        | 646/5198 [18:33:03<125:08:52, 98.97s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.89s/it][A100%|██████████| 1/1 [01:31<00:00, 91.89s/it]
 12%|█▏        | 646/5198 [18:33:03<125:09:30, 98.98s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.76s/it][A100%|██████████| 1/1 [01:31<00:00, 91.76s/it]
 12%|█▏        | 646/5198 [18:33:03<125:08:08, 98.96s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.85s/it][A100%|██████████| 1/1 [01:31<00:00, 91.85s/it]
 12%|█▏        | 646/5198 [18:33:03<125:09:19, 98.98s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.13s/it][A100%|██████████| 1/1 [01:32<00:00, 92.13s/it]
 12%|█▏        | 646/5198 [18:33:04<125:15:43, 99.06s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.33s/it][A100%|██████████| 1/1 [01:32<00:00, 92.34s/it]
 12%|█▏        | 646/5198 [18:33:06<125:20:18, 99.13s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_606
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.26s/it][A100%|██████████| 1/1 [01:43<00:00, 103.26s/it]
 12%|█▏        | 647/5198 [18:34:46<126:53:14, 100.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 13:59:52,127] [INFO] [logging.py:96:log_dist] [Rank 0] step=639, skipped=0, lr=[1.9651546571173262e-05], mom=[(0.9, 0.999)]
steps: 639 loss: 0.6288 iter time (s): 102.365 samples/sec: 1.250

100%|██████████| 1/1 [01:43<00:00, 103.71s/it][A100%|██████████| 1/1 [01:43<00:00, 103.71s/it]
 12%|█▏        | 647/5198 [18:34:46<126:55:26, 100.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.65s/it][A100%|██████████| 1/1 [01:43<00:00, 103.65s/it]
 12%|█▏        | 647/5198 [18:34:46<126:53:49, 100.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.73s/it][A100%|██████████| 1/1 [01:43<00:00, 103.73s/it]
 12%|█▏        | 647/5198 [18:34:47<126:56:18, 100.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.72s/it][A100%|██████████| 1/1 [01:43<00:00, 103.72s/it]
 12%|█▏        | 647/5198 [18:34:47<126:54:59, 100.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.67s/it][A100%|██████████| 1/1 [01:43<00:00, 103.67s/it]
 12%|█▏        | 647/5198 [18:34:47<126:54:34, 100.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.39s/it][A100%|██████████| 1/1 [01:43<00:00, 103.39s/it]
 12%|█▏        | 647/5198 [18:34:47<126:52:53, 100.37s/it]
100%|██████████| 1/1 [01:43<00:00, 103.20s/it][A100%|██████████| 1/1 [01:43<00:00, 103.20s/it]
 12%|█▏        | 647/5198 [18:34:49<126:51:40, 100.35s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_607

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.98s/it][A100%|██████████| 1/1 [01:26<00:00, 86.98s/it]
 12%|█▏        | 648/5198 [18:36:13<121:54:34, 96.46s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 14:01:19,045] [INFO] [logging.py:96:log_dist] [Rank 0] step=640, skipped=0, lr=[1.9650062905719316e-05], mom=[(0.9, 0.999)]
steps: 640 loss: 0.5918 iter time (s): 86.069 samples/sec: 1.487

100%|██████████| 1/1 [01:26<00:00, 86.88s/it][A100%|██████████| 1/1 [01:26<00:00, 86.88s/it]
 12%|█▏        | 648/5198 [18:36:13<121:46:24, 96.35s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.91s/it][A100%|██████████| 1/1 [01:26<00:00, 86.91s/it]
 12%|█▏        | 648/5198 [18:36:13<121:46:01, 96.34s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.82s/it][A100%|██████████| 1/1 [01:26<00:00, 86.82s/it]
 12%|█▏        | 648/5198 [18:36:14<121:45:40, 96.34s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.89s/it][A100%|██████████| 1/1 [01:26<00:00, 86.89s/it]
 12%|█▏        | 648/5198 [18:36:14<121:45:59, 96.34s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.93s/it][A100%|██████████| 1/1 [01:26<00:00, 86.93s/it]
 12%|█▏        | 648/5198 [18:36:14<121:47:11, 96.36s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.88s/it][A100%|██████████| 1/1 [01:26<00:00, 86.89s/it]
 12%|█▏        | 648/5198 [18:36:14<121:44:43, 96.33s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.89s/it][A100%|██████████| 1/1 [01:26<00:00, 86.89s/it]
 12%|█▏        | 648/5198 [18:36:16<121:43:55, 96.32s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_608
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.82s/it][A100%|██████████| 1/1 [01:31<00:00, 91.82s/it]
 12%|█▏        | 649/5198 [18:37:45<120:12:02, 95.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 14:02:51,242] [INFO] [logging.py:96:log_dist] [Rank 0] step=641, skipped=0, lr=[1.9648576144606476e-05], mom=[(0.9, 0.999)]
steps: 641 loss: 0.5483 iter time (s): 91.371 samples/sec: 1.401

100%|██████████| 1/1 [01:32<00:00, 92.16s/it][A100%|██████████| 1/1 [01:32<00:00, 92.16s/it]
 12%|█▏        | 649/5198 [18:37:45<120:09:57, 95.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.19s/it][A100%|██████████| 1/1 [01:32<00:00, 92.19s/it]
 12%|█▏        | 649/5198 [18:37:45<120:10:13, 95.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.16s/it][A100%|██████████| 1/1 [01:32<00:00, 92.16s/it]
 12%|█▏        | 649/5198 [18:37:46<120:09:18, 95.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.12s/it][A100%|██████████| 1/1 [01:32<00:00, 92.12s/it]
 12%|█▏        | 649/5198 [18:37:46<120:09:16, 95.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.16s/it][A100%|██████████| 1/1 [01:32<00:00, 92.16s/it]
 12%|█▏        | 649/5198 [18:37:46<120:09:31, 95.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.14s/it][A100%|██████████| 1/1 [01:32<00:00, 92.14s/it]
 12%|█▏        | 649/5198 [18:37:46<120:08:10, 95.07s/it]
100%|██████████| 1/1 [01:32<00:00, 92.14s/it][A100%|██████████| 1/1 [01:32<00:00, 92.14s/it]
 12%|█▏        | 649/5198 [18:37:48<120:07:27, 95.06s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_609

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.02s/it][A100%|██████████| 1/1 [01:27<00:00, 87.02s/it]
 13%|█▎        | 650/5198 [18:39:12<117:12:05, 92.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 14:04:18,386] [INFO] [logging.py:96:log_dist] [Rank 0] step=642, skipped=0, lr=[1.9647086288311728e-05], mom=[(0.9, 0.999)]
steps: 642 loss: 0.6053 iter time (s): 86.368 samples/sec: 1.482

100%|██████████| 1/1 [01:27<00:00, 87.12s/it][A100%|██████████| 1/1 [01:27<00:00, 87.12s/it]
 13%|█▎        | 650/5198 [18:39:13<117:07:07, 92.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.12s/it][A100%|██████████| 1/1 [01:27<00:00, 87.12s/it]
 13%|█▎        | 650/5198 [18:39:13<117:07:28, 92.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.12s/it][A100%|██████████| 1/1 [01:27<00:00, 87.12s/it]
 13%|█▎        | 650/5198 [18:39:13<117:06:44, 92.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.25s/it][A100%|██████████| 1/1 [01:27<00:00, 87.25s/it]
 13%|█▎        | 650/5198 [18:39:13<117:09:44, 92.74s/it]
100%|██████████| 1/1 [01:27<00:00, 87.22s/it][A100%|██████████| 1/1 [01:27<00:00, 87.22s/it]
 13%|█▎        | 650/5198 [18:39:13<117:09:10, 92.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.21s/it][A100%|██████████| 1/1 [01:27<00:00, 87.21s/it]
 13%|█▎        | 650/5198 [18:39:13<117:07:59, 92.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.22s/it][A100%|██████████| 1/1 [01:27<00:00, 87.22s/it]
 13%|█▎        | 650/5198 [18:39:16<117:07:36, 92.71s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_610
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.67s/it][A100%|██████████| 1/1 [01:23<00:00, 83.67s/it]
 13%|█▎        | 651/5198 [18:40:36<113:48:07, 90.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 14:05:42,156] [INFO] [logging.py:96:log_dist] [Rank 0] step=643, skipped=0, lr=[1.9645593337313054e-05], mom=[(0.9, 0.999)]
steps: 643 loss: 0.5652 iter time (s): 82.916 samples/sec: 1.544

100%|██████████| 1/1 [01:23<00:00, 83.75s/it][A100%|██████████| 1/1 [01:23<00:00, 83.75s/it]
 13%|█▎        | 651/5198 [18:40:36<113:42:10, 90.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.74s/it][A100%|██████████| 1/1 [01:23<00:00, 83.74s/it]
 13%|█▎        | 651/5198 [18:40:36<113:42:15, 90.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.77s/it][A100%|██████████| 1/1 [01:23<00:00, 83.77s/it]
 13%|█▎        | 651/5198 [18:40:37<113:42:23, 90.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.70s/it][A100%|██████████| 1/1 [01:23<00:00, 83.70s/it]
 13%|█▎        | 651/5198 [18:40:37<113:42:50, 90.03s/it]
100%|██████████| 1/1 [01:23<00:00, 83.70s/it][A100%|██████████| 1/1 [01:23<00:00, 83.70s/it]
 13%|█▎        | 651/5198 [18:40:37<113:42:30, 90.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.70s/it][A100%|██████████| 1/1 [01:23<00:00, 83.70s/it]
 13%|█▎        | 651/5198 [18:40:39<113:41:20, 90.01s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_611
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.72s/it][A100%|██████████| 1/1 [01:23<00:00, 83.72s/it]
 13%|█▎        | 651/5198 [18:40:37<113:42:02, 90.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.72s/it][A100%|██████████| 1/1 [01:51<00:00, 111.72s/it]
 13%|█▎        | 652/5198 [18:42:28<122:03:11, 96.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 14:07:34,893] [INFO] [logging.py:96:log_dist] [Rank 0] step=644, skipped=0, lr=[1.964409729208943e-05], mom=[(0.9, 0.999)]
steps: 644 loss: 0.5394 iter time (s): 111.942 samples/sec: 1.143

100%|██████████| 1/1 [01:52<00:00, 112.81s/it][A100%|██████████| 1/1 [01:52<00:00, 112.81s/it]
 13%|█▎        | 652/5198 [18:42:29<122:18:55, 96.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.81s/it][A100%|██████████| 1/1 [01:52<00:00, 112.81s/it]
 13%|█▎        | 652/5198 [18:42:29<122:19:05, 96.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.80s/it][A100%|██████████| 1/1 [01:52<00:00, 112.80s/it]
 13%|█▎        | 652/5198 [18:42:30<122:18:54, 96.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.71s/it][A100%|██████████| 1/1 [01:52<00:00, 112.71s/it]
 13%|█▎        | 652/5198 [18:42:30<122:17:05, 96.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.76s/it][A100%|██████████| 1/1 [01:52<00:00, 112.76s/it]
 13%|█▎        | 652/5198 [18:42:30<122:17:56, 96.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.73s/it][A100%|██████████| 1/1 [01:52<00:00, 112.73s/it]
 13%|█▎        | 652/5198 [18:42:30<122:16:51, 96.83s/it]
100%|██████████| 1/1 [01:52<00:00, 112.75s/it][A100%|██████████| 1/1 [01:52<00:00, 112.75s/it]
 13%|█▎        | 652/5198 [18:42:32<122:16:43, 96.83s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_612

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.08s/it][A100%|██████████| 1/1 [01:22<00:00, 82.08s/it]
 13%|█▎        | 653/5198 [18:43:50<116:33:32, 92.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 14:08:56,273] [INFO] [logging.py:96:log_dist] [Rank 0] step=645, skipped=0, lr=[1.9642598153120828e-05], mom=[(0.9, 0.999)]
steps: 645 loss: 0.5614 iter time (s): 80.625 samples/sec: 1.588

100%|██████████| 1/1 [01:21<00:00, 81.37s/it][A100%|██████████| 1/1 [01:21<00:00, 81.38s/it]
 13%|█▎        | 653/5198 [18:43:50<116:25:33, 92.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.45s/it][A100%|██████████| 1/1 [01:21<00:00, 81.45s/it]
 13%|█▎        | 653/5198 [18:43:51<116:27:26, 92.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.41s/it][A100%|██████████| 1/1 [01:21<00:00, 81.41s/it]
 13%|█▎        | 653/5198 [18:43:51<116:26:27, 92.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.42s/it][A100%|██████████| 1/1 [01:21<00:00, 81.42s/it]
 13%|█▎        | 653/5198 [18:43:51<116:25:15, 92.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.40s/it][A100%|██████████| 1/1 [01:21<00:00, 81.40s/it]
 13%|█▎        | 653/5198 [18:43:51<116:25:24, 92.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.40s/it][A100%|██████████| 1/1 [01:21<00:00, 81.40s/it]
 13%|█▎        | 653/5198 [18:43:51<116:24:43, 92.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.43s/it][A100%|██████████| 1/1 [01:21<00:00, 81.43s/it]
 13%|█▎        | 653/5198 [18:43:53<116:25:05, 92.21s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_613
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.64s/it][A100%|██████████| 1/1 [01:21<00:00, 81.64s/it]
 13%|█▎        | 654/5198 [18:45:12<112:32:41, 89.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 14:10:18,060] [INFO] [logging.py:96:log_dist] [Rank 0] step=646, skipped=0, lr=[1.9641095920888203e-05], mom=[(0.9, 0.999)]
steps: 646 loss: 0.6076 iter time (s): 80.929 samples/sec: 1.582

100%|██████████| 1/1 [01:21<00:00, 81.83s/it][A100%|██████████| 1/1 [01:21<00:00, 81.83s/it]
 13%|█▎        | 654/5198 [18:45:12<112:28:28, 89.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.81s/it][A100%|██████████| 1/1 [01:21<00:00, 81.81s/it]
 13%|█▎        | 654/5198 [18:45:12<112:29:04, 89.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.75s/it][A100%|██████████| 1/1 [01:21<00:00, 81.75s/it]
 13%|█▎        | 654/5198 [18:45:13<112:26:56, 89.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.71s/it][A100%|██████████| 1/1 [01:21<00:00, 81.71s/it]
 13%|█▎        | 654/5198 [18:45:13<112:25:15, 89.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.73s/it][A100%|██████████| 1/1 [01:21<00:00, 81.73s/it]
 13%|█▎        | 654/5198 [18:45:13<112:25:46, 89.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.76s/it][A100%|██████████| 1/1 [01:21<00:00, 81.76s/it]
 13%|█▎        | 654/5198 [18:45:13<112:26:01, 89.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.77s/it][A100%|██████████| 1/1 [01:21<00:00, 81.77s/it]
 13%|█▎        | 654/5198 [18:45:15<112:26:27, 89.08s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_614
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.97s/it][A100%|██████████| 1/1 [01:26<00:00, 86.97s/it]
 13%|█▎        | 655/5198 [18:46:39<111:44:19, 88.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 14:11:45,308] [INFO] [logging.py:96:log_dist] [Rank 0] step=647, skipped=0, lr=[1.9639590595873516e-05], mom=[(0.9, 0.999)]
steps: 647 loss: 0.6088 iter time (s): 86.399 samples/sec: 1.481

100%|██████████| 1/1 [01:27<00:00, 87.10s/it][A100%|██████████| 1/1 [01:27<00:00, 87.10s/it]
 13%|█▎        | 655/5198 [18:46:39<111:41:36, 88.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.13s/it][A100%|██████████| 1/1 [01:27<00:00, 87.13s/it]
 13%|█▎        | 655/5198 [18:46:40<111:42:43, 88.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.16s/it][A100%|██████████| 1/1 [01:27<00:00, 87.16s/it]
 13%|█▎        | 655/5198 [18:46:40<111:41:56, 88.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.28s/it][A100%|██████████| 1/1 [01:27<00:00, 87.28s/it]
 13%|█▎        | 655/5198 [18:46:40<111:43:18, 88.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.25s/it][A100%|██████████| 1/1 [01:27<00:00, 87.25s/it]
 13%|█▎        | 655/5198 [18:46:40<111:42:57, 88.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.23s/it][A100%|██████████| 1/1 [01:27<00:00, 87.23s/it]
 13%|█▎        | 655/5198 [18:46:40<111:42:47, 88.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.22s/it][A100%|██████████| 1/1 [01:27<00:00, 87.22s/it]
 13%|█▎        | 655/5198 [18:46:42<111:42:43, 88.52s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_40
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:01<00:00, 121.42s/it][A100%|██████████| 1/1 [02:01<00:00, 121.42s/it]
 13%|█▎        | 656/5198 [18:48:41<124:12:19, 98.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 14:13:47,525] [INFO] [logging.py:96:log_dist] [Rank 0] step=648, skipped=0, lr=[1.9638082178559704e-05], mom=[(0.9, 0.999)]
steps: 648 loss: 0.7860 iter time (s): 121.698 samples/sec: 1.052

100%|██████████| 1/1 [02:02<00:00, 122.72s/it][A100%|██████████| 1/1 [02:02<00:00, 122.73s/it]
 13%|█▎        | 656/5198 [18:48:42<124:37:22, 98.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:02<00:00, 122.60s/it][A100%|██████████| 1/1 [02:02<00:00, 122.60s/it]
 13%|█▎        | 656/5198 [18:48:42<124:35:24, 98.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:02<00:00, 122.65s/it][A100%|██████████| 1/1 [02:02<00:00, 122.65s/it]
 13%|█▎        | 656/5198 [18:48:43<124:35:57, 98.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:02<00:00, 122.59s/it][A100%|██████████| 1/1 [02:02<00:00, 122.59s/it]
 13%|█▎        | 656/5198 [18:48:43<124:35:29, 98.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:02<00:00, 122.59s/it][A100%|██████████| 1/1 [02:02<00:00, 122.59s/it]
 13%|█▎        | 656/5198 [18:48:43<124:35:09, 98.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:02<00:00, 122.61s/it][A100%|██████████| 1/1 [02:02<00:00, 122.62s/it]
 13%|█▎        | 656/5198 [18:48:43<124:35:39, 98.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:02<00:00, 122.61s/it][A100%|██████████| 1/1 [02:02<00:00, 122.61s/it]
 13%|█▎        | 656/5198 [18:48:45<124:35:30, 98.75s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_615
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.10s/it][A100%|██████████| 1/1 [01:26<00:00, 86.10s/it]
 13%|█▎        | 657/5198 [18:50:07<119:34:11, 94.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 14:15:13,040] [INFO] [logging.py:96:log_dist] [Rank 0] step=649, skipped=0, lr=[1.9636570669430706e-05], mom=[(0.9, 0.999)]
steps: 649 loss: 0.5740 iter time (s): 84.303 samples/sec: 1.518

100%|██████████| 1/1 [01:25<00:00, 85.03s/it][A100%|██████████| 1/1 [01:25<00:00, 85.03s/it]
 13%|█▎        | 657/5198 [18:50:07<119:23:54, 94.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.07s/it][A100%|██████████| 1/1 [01:25<00:00, 85.07s/it]
 13%|█▎        | 657/5198 [18:50:07<119:23:24, 94.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.05s/it][A100%|██████████| 1/1 [01:25<00:00, 85.05s/it]
 13%|█▎        | 657/5198 [18:50:08<119:23:23, 94.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.06s/it][A100%|██████████| 1/1 [01:25<00:00, 85.06s/it]
 13%|█▎        | 657/5198 [18:50:08<119:23:09, 94.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.08s/it][A100%|██████████| 1/1 [01:25<00:00, 85.08s/it]
 13%|█▎        | 657/5198 [18:50:08<119:23:35, 94.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.08s/it][A100%|██████████| 1/1 [01:25<00:00, 85.08s/it]
 13%|█▎        | 657/5198 [18:50:08<119:23:40, 94.65s/it]
100%|██████████| 1/1 [01:25<00:00, 85.07s/it][A100%|██████████| 1/1 [01:25<00:00, 85.07s/it]
 13%|█▎        | 657/5198 [18:50:10<119:23:18, 94.65s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_616
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.55s/it][A100%|██████████| 1/1 [01:34<00:00, 94.55s/it]
 13%|█▎        | 658/5198 [18:51:42<119:30:37, 94.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 14:16:48,013] [INFO] [logging.py:96:log_dist] [Rank 0] step=650, skipped=0, lr=[1.963505606897146e-05], mom=[(0.9, 0.999)]
steps: 650 loss: 0.6348 iter time (s): 94.192 samples/sec: 1.359

100%|██████████| 1/1 [01:35<00:00, 95.03s/it][A100%|██████████| 1/1 [01:35<00:00, 95.03s/it]
 13%|█▎        | 658/5198 [18:51:42<119:31:01, 94.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.01s/it][A100%|██████████| 1/1 [01:35<00:00, 95.02s/it]
 13%|█▎        | 658/5198 [18:51:42<119:30:20, 94.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.08s/it][A100%|██████████| 1/1 [01:35<00:00, 95.08s/it]
 13%|█▎        | 658/5198 [18:51:43<119:31:53, 94.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.04s/it][A100%|██████████| 1/1 [01:35<00:00, 95.05s/it]
 13%|█▎        | 658/5198 [18:51:43<119:30:47, 94.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.03s/it][A100%|██████████| 1/1 [01:35<00:00, 95.03s/it]
 13%|█▎        | 658/5198 [18:51:43<119:30:42, 94.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.05s/it][A100%|██████████| 1/1 [01:35<00:00, 95.05s/it]
 13%|█▎        | 658/5198 [18:51:43<119:31:11, 94.77s/it]
100%|██████████| 1/1 [01:35<00:00, 95.05s/it][A100%|██████████| 1/1 [01:35<00:00, 95.05s/it]
 13%|█▎        | 658/5198 [18:51:45<119:31:03, 94.77s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_617

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.87s/it][A100%|██████████| 1/1 [01:29<00:00, 89.87s/it]
 13%|█▎        | 659/5198 [18:53:12<117:41:19, 93.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 14:18:17,927] [INFO] [logging.py:96:log_dist] [Rank 0] step=651, skipped=0, lr=[1.963353837766788e-05], mom=[(0.9, 0.999)]
steps: 651 loss: 0.5757 iter time (s): 89.047 samples/sec: 1.437

100%|██████████| 1/1 [01:29<00:00, 89.78s/it][A100%|██████████| 1/1 [01:29<00:00, 89.78s/it]
 13%|█▎        | 659/5198 [18:53:12<117:36:23, 93.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.85s/it][A100%|██████████| 1/1 [01:29<00:00, 89.85s/it]
 13%|█▎        | 659/5198 [18:53:12<117:37:38, 93.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.82s/it][A100%|██████████| 1/1 [01:29<00:00, 89.82s/it]
 13%|█▎        | 659/5198 [18:53:13<117:37:51, 93.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.85s/it][A100%|██████████| 1/1 [01:29<00:00, 89.85s/it]
 13%|█▎        | 659/5198 [18:53:13<117:37:50, 93.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.86s/it][A100%|██████████| 1/1 [01:29<00:00, 89.86s/it]
 13%|█▎        | 659/5198 [18:53:13<117:37:51, 93.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.81s/it][A100%|██████████| 1/1 [01:29<00:00, 89.81s/it]
 13%|█▎        | 659/5198 [18:53:15<117:37:00, 93.29s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_618

100%|██████████| 1/1 [01:29<00:00, 89.82s/it][A100%|██████████| 1/1 [01:29<00:00, 89.82s/it]
 13%|█▎        | 659/5198 [18:53:13<117:37:18, 93.29s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.81s/it][A100%|██████████| 1/1 [01:22<00:00, 82.81s/it]
 13%|█▎        | 660/5198 [18:54:35<113:45:41, 90.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 14:19:40,734] [INFO] [logging.py:96:log_dist] [Rank 0] step=652, skipped=0, lr=[1.963201759600688e-05], mom=[(0.9, 0.999)]
steps: 652 loss: 0.6304 iter time (s): 82.037 samples/sec: 1.560

100%|██████████| 1/1 [01:22<00:00, 82.82s/it][A100%|██████████| 1/1 [01:22<00:00, 82.82s/it]
 13%|█▎        | 660/5198 [18:54:35<113:37:52, 90.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.81s/it][A100%|██████████| 1/1 [01:22<00:00, 82.81s/it]
 13%|█▎        | 660/5198 [18:54:35<113:38:23, 90.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.78s/it][A100%|██████████| 1/1 [01:22<00:00, 82.78s/it]
 13%|█▎        | 660/5198 [18:54:35<113:37:50, 90.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.81s/it][A100%|██████████| 1/1 [01:22<00:00, 82.81s/it]
 13%|█▎        | 660/5198 [18:54:35<113:38:34, 90.15s/it]
100%|██████████| 1/1 [01:22<00:00, 82.78s/it][A100%|██████████| 1/1 [01:22<00:00, 82.79s/it]
 13%|█▎        | 660/5198 [18:54:36<113:37:58, 90.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.82s/it][A100%|██████████| 1/1 [01:22<00:00, 82.82s/it]
 13%|█▎        | 660/5198 [18:54:36<113:38:23, 90.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.84s/it][A100%|██████████| 1/1 [01:22<00:00, 82.84s/it]
 13%|█▎        | 660/5198 [18:54:38<113:38:36, 90.15s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_619
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.88s/it][A100%|██████████| 1/1 [01:44<00:00, 104.88s/it]
 13%|█▎        | 661/5198 [18:56:20<119:18:50, 94.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 14:21:26,391] [INFO] [logging.py:96:log_dist] [Rank 0] step=653, skipped=0, lr=[1.963049372447637e-05], mom=[(0.9, 0.999)]
steps: 653 loss: 0.5660 iter time (s): 104.850 samples/sec: 1.221

100%|██████████| 1/1 [01:45<00:00, 105.65s/it][A100%|██████████| 1/1 [01:45<00:00, 105.65s/it]
 13%|█▎        | 661/5198 [18:56:21<119:28:19, 94.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.58s/it][A100%|██████████| 1/1 [01:45<00:00, 105.58s/it]
 13%|█▎        | 661/5198 [18:56:21<119:27:00, 94.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.65s/it][A100%|██████████| 1/1 [01:45<00:00, 105.65s/it]
 13%|█▎        | 661/5198 [18:56:21<119:28:15, 94.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.69s/it][A100%|██████████| 1/1 [01:45<00:00, 105.69s/it]
 13%|█▎        | 661/5198 [18:56:21<119:29:39, 94.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.72s/it][A100%|██████████| 1/1 [01:45<00:00, 105.72s/it]
 13%|█▎        | 661/5198 [18:56:21<119:30:02, 94.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.67s/it][A100%|██████████| 1/1 [01:45<00:00, 105.67s/it]
 13%|█▎        | 661/5198 [18:56:21<119:29:00, 94.81s/it]
100%|██████████| 1/1 [01:45<00:00, 105.66s/it][A100%|██████████| 1/1 [01:45<00:00, 105.66s/it]

 13%|█▎        | 661/5198 [18:56:24<119:28:59, 94.81s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_620
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.38s/it][A100%|██████████| 1/1 [01:54<00:00, 114.38s/it]
 13%|█▎        | 662/5198 [18:58:14<126:48:26, 100.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 14:23:21,151] [INFO] [logging.py:96:log_dist] [Rank 0] step=654, skipped=0, lr=[1.9628966763565235e-05], mom=[(0.9, 0.999)]
steps: 654 loss: 0.5787 iter time (s): 113.945 samples/sec: 1.123

100%|██████████| 1/1 [01:54<00:00, 114.79s/it][A100%|██████████| 1/1 [01:54<00:00, 114.79s/it]
 13%|█▎        | 662/5198 [18:58:15<127:00:31, 100.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.89s/it][A100%|██████████| 1/1 [01:54<00:00, 114.89s/it]
 13%|█▎        | 662/5198 [18:58:16<127:01:43, 100.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.83s/it][A100%|██████████| 1/1 [01:54<00:00, 114.83s/it]
 13%|█▎        | 662/5198 [18:58:16<127:01:19, 100.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.75s/it][A100%|██████████| 1/1 [01:54<00:00, 114.75s/it]
 13%|█▎        | 662/5198 [18:58:16<127:00:26, 100.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.75s/it][A100%|██████████| 1/1 [01:54<00:00, 114.75s/it]
 13%|█▎        | 662/5198 [18:58:16<127:00:40, 100.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.79s/it][A100%|██████████| 1/1 [01:54<00:00, 114.79s/it]
 13%|█▎        | 662/5198 [18:58:16<127:00:52, 100.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.81s/it][A100%|██████████| 1/1 [01:54<00:00, 114.81s/it]
 13%|█▎        | 662/5198 [18:58:18<127:01:10, 100.81s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_621
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.60s/it][A100%|██████████| 1/1 [01:18<00:00, 78.60s/it]
 13%|█▎        | 663/5198 [18:59:33<118:32:24, 94.10s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 14:24:38,997] [INFO] [logging.py:96:log_dist] [Rank 0] step=655, skipped=0, lr=[1.962743671376337e-05], mom=[(0.9, 0.999)]
steps: 655 loss: 0.5721 iter time (s): 76.978 samples/sec: 1.663

100%|██████████| 1/1 [01:17<00:00, 77.77s/it][A100%|██████████| 1/1 [01:17<00:00, 77.77s/it]
 13%|█▎        | 663/5198 [18:59:33<118:16:42, 93.89s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:17<00:00, 77.64s/it][A100%|██████████| 1/1 [01:17<00:00, 77.65s/it]
 13%|█▎        | 663/5198 [18:59:33<118:14:49, 93.87s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:17<00:00, 77.70s/it][A100%|██████████| 1/1 [01:17<00:00, 77.70s/it]
 13%|█▎        | 663/5198 [18:59:34<118:15:51, 93.88s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:17<00:00, 77.71s/it][A100%|██████████| 1/1 [01:17<00:00, 77.71s/it]
 13%|█▎        | 663/5198 [18:59:34<118:15:33, 93.88s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:17<00:00, 77.76s/it][A100%|██████████| 1/1 [01:17<00:00, 77.76s/it]
 13%|█▎        | 663/5198 [18:59:34<118:16:31, 93.89s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:17<00:00, 77.73s/it][A100%|██████████| 1/1 [01:17<00:00, 77.73s/it]
 13%|█▎        | 663/5198 [18:59:34<118:16:13, 93.89s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:17<00:00, 77.72s/it][A100%|██████████| 1/1 [01:17<00:00, 77.72s/it]
 13%|█▎        | 663/5198 [18:59:36<118:16:09, 93.89s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_622
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.07s/it][A100%|██████████| 1/1 [01:48<00:00, 108.07s/it]
 13%|█▎        | 664/5198 [19:01:21<123:50:57, 98.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 14:26:28,056] [INFO] [logging.py:96:log_dist] [Rank 0] step=656, skipped=0, lr=[1.9625903575561652e-05], mom=[(0.9, 0.999)]
steps: 656 loss: 0.5627 iter time (s): 108.304 samples/sec: 1.182

100%|██████████| 1/1 [01:49<00:00, 109.04s/it][A100%|██████████| 1/1 [01:49<00:00, 109.04s/it]
 13%|█▎        | 664/5198 [19:01:22<123:58:51, 98.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.19s/it][A100%|██████████| 1/1 [01:49<00:00, 109.19s/it]
 13%|█▎        | 664/5198 [19:01:22<124:00:44, 98.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.05s/it][A100%|██████████| 1/1 [01:49<00:00, 109.05s/it]
 13%|█▎        | 664/5198 [19:01:23<123:58:30, 98.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.09s/it][A100%|██████████| 1/1 [01:49<00:00, 109.09s/it]
 13%|█▎        | 664/5198 [19:01:23<123:59:47, 98.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.13s/it][A100%|██████████| 1/1 [01:49<00:00, 109.13s/it]
 13%|█▎        | 664/5198 [19:01:23<124:00:03, 98.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.09s/it][A100%|██████████| 1/1 [01:49<00:00, 109.09s/it]
 13%|█▎        | 664/5198 [19:01:23<123:59:29, 98.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.10s/it][A100%|██████████| 1/1 [01:49<00:00, 109.10s/it]
 13%|█▎        | 664/5198 [19:01:25<123:59:40, 98.45s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_623
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:32<00:00, 152.60s/it][A100%|██████████| 1/1 [02:32<00:00, 152.60s/it]
 13%|█▎        | 665/5198 [19:03:54<144:23:14, 114.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 14:29:02,034] [INFO] [logging.py:96:log_dist] [Rank 0] step=657, skipped=0, lr=[1.9624367349451948e-05], mom=[(0.9, 0.999)]
steps: 657 loss: 0.5495 iter time (s): 153.170 samples/sec: 0.836

100%|██████████| 1/1 [02:33<00:00, 153.97s/it][A100%|██████████| 1/1 [02:33<00:00, 153.97s/it]
 13%|█▎        | 665/5198 [19:03:56<144:56:02, 115.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:33<00:00, 153.89s/it][A100%|██████████| 1/1 [02:33<00:00, 153.90s/it]
 13%|█▎        | 665/5198 [19:03:56<144:55:36, 115.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:34<00:00, 154.01s/it][A100%|██████████| 1/1 [02:34<00:00, 154.01s/it]
 13%|█▎        | 665/5198 [19:03:57<144:56:39, 115.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:33<00:00, 153.98s/it][A100%|██████████| 1/1 [02:33<00:00, 153.98s/it]
 13%|█▎        | 665/5198 [19:03:57<144:56:52, 115.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:33<00:00, 153.97s/it][A100%|██████████| 1/1 [02:33<00:00, 153.97s/it]
 13%|█▎        | 665/5198 [19:03:57<144:56:46, 115.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:33<00:00, 153.96s/it][A100%|██████████| 1/1 [02:33<00:00, 153.96s/it]
 13%|█▎        | 665/5198 [19:03:57<144:56:07, 115.10s/it]
100%|██████████| 1/1 [02:33<00:00, 153.94s/it][A100%|██████████| 1/1 [02:33<00:00, 153.94s/it]
 13%|█▎        | 665/5198 [19:03:59<144:55:50, 115.10s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_624
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.82s/it][A100%|██████████| 1/1 [01:23<00:00, 83.82s/it]
 13%|█▎        | 666/5198 [19:05:18<132:44:47, 105.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 14:30:24,061] [INFO] [logging.py:96:log_dist] [Rank 0] step=658, skipped=0, lr=[1.962282803592712e-05], mom=[(0.9, 0.999)]
steps: 658 loss: 0.5834 iter time (s): 81.259 samples/sec: 1.575

100%|██████████| 1/1 [01:21<00:00, 81.97s/it][A100%|██████████| 1/1 [01:21<00:00, 81.97s/it]
 13%|█▎        | 666/5198 [19:05:18<132:23:26, 105.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.05s/it][A100%|██████████| 1/1 [01:22<00:00, 82.05s/it]
 13%|█▎        | 666/5198 [19:05:18<132:25:07, 105.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.02s/it][A100%|██████████| 1/1 [01:22<00:00, 82.02s/it]
 13%|█▎        | 666/5198 [19:05:19<132:25:10, 105.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.99s/it][A100%|██████████| 1/1 [01:21<00:00, 81.99s/it]
 13%|█▎        | 666/5198 [19:05:19<132:24:28, 105.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.01s/it][A100%|██████████| 1/1 [01:22<00:00, 82.01s/it]
 13%|█▎        | 666/5198 [19:05:19<132:24:50, 105.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.03s/it][A100%|██████████| 1/1 [01:22<00:00, 82.03s/it]
 13%|█▎        | 666/5198 [19:05:19<132:24:52, 105.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.04s/it][A100%|██████████| 1/1 [01:22<00:00, 82.04s/it]
 13%|█▎        | 666/5198 [19:05:21<132:24:59, 105.19s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_625
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.52s/it][A100%|██████████| 1/1 [01:49<00:00, 109.52s/it]
 13%|█▎        | 667/5198 [19:07:08<134:19:15, 106.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 14:32:14,497] [INFO] [logging.py:96:log_dist] [Rank 0] step=659, skipped=0, lr=[1.9621285635481014e-05], mom=[(0.9, 0.999)]
steps: 659 loss: 0.5738 iter time (s): 109.641 samples/sec: 1.167

100%|██████████| 1/1 [01:50<00:00, 110.56s/it][A100%|██████████| 1/1 [01:50<00:00, 110.57s/it]
 13%|█▎        | 667/5198 [19:07:09<134:24:19, 106.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.50s/it][A100%|██████████| 1/1 [01:50<00:00, 110.50s/it]
 13%|█▎        | 667/5198 [19:07:09<134:23:49, 106.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.45s/it][A100%|██████████| 1/1 [01:50<00:00, 110.45s/it]
 13%|█▎        | 667/5198 [19:07:09<134:22:52, 106.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.42s/it][A100%|██████████| 1/1 [01:50<00:00, 110.42s/it]
 13%|█▎        | 667/5198 [19:07:09<134:21:44, 106.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.44s/it][A100%|██████████| 1/1 [01:50<00:00, 110.44s/it]
 13%|█▎        | 667/5198 [19:07:09<134:22:20, 106.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.44s/it][A100%|██████████| 1/1 [01:50<00:00, 110.45s/it]
 13%|█▎        | 667/5198 [19:07:09<134:22:29, 106.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.44s/it][A100%|██████████| 1/1 [01:50<00:00, 110.44s/it]
 13%|█▎        | 667/5198 [19:07:12<134:22:30, 106.76s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_626
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.00s/it][A100%|██████████| 1/1 [01:25<00:00, 85.00s/it]
 13%|█▎        | 668/5198 [19:08:33<126:11:20, 100.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 14:33:39,103] [INFO] [logging.py:96:log_dist] [Rank 0] step=660, skipped=0, lr=[1.961974014860848e-05], mom=[(0.9, 0.999)]
steps: 660 loss: 0.6098 iter time (s): 83.797 samples/sec: 1.527

100%|██████████| 1/1 [01:24<00:00, 84.49s/it][A100%|██████████| 1/1 [01:24<00:00, 84.49s/it]
 13%|█▎        | 668/5198 [19:08:33<125:57:42, 100.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.55s/it][A100%|██████████| 1/1 [01:24<00:00, 84.55s/it]
 13%|█▎        | 668/5198 [19:08:33<125:58:35, 100.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.57s/it][A100%|██████████| 1/1 [01:24<00:00, 84.58s/it]
 13%|█▎        | 668/5198 [19:08:34<125:58:37, 100.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.63s/it][A100%|██████████| 1/1 [01:24<00:00, 84.63s/it]
 13%|█▎        | 668/5198 [19:08:34<125:59:04, 100.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.59s/it][A100%|██████████| 1/1 [01:24<00:00, 84.59s/it]
 13%|█▎        | 668/5198 [19:08:34<125:58:37, 100.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.58s/it][A100%|██████████| 1/1 [01:24<00:00, 84.58s/it]
 13%|█▎        | 668/5198 [19:08:36<125:58:18, 100.11s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_627
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.60s/it][A100%|██████████| 1/1 [01:24<00:00, 84.60s/it]
 13%|█▎        | 668/5198 [19:08:34<125:58:50, 100.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.79s/it][A100%|██████████| 1/1 [01:37<00:00, 97.79s/it]
 13%|█▎        | 669/5198 [19:10:11<125:16:26, 99.58s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 14:35:17,385] [INFO] [logging.py:96:log_dist] [Rank 0] step=661, skipped=0, lr=[1.9618191575805334e-05], mom=[(0.9, 0.999)]
steps: 661 loss: 0.5653 iter time (s): 97.511 samples/sec: 1.313

100%|██████████| 1/1 [01:38<00:00, 98.36s/it][A100%|██████████| 1/1 [01:38<00:00, 98.36s/it]
 13%|█▎        | 669/5198 [19:10:12<125:16:52, 99.58s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.26s/it][A100%|██████████| 1/1 [01:38<00:00, 98.26s/it]
 13%|█▎        | 669/5198 [19:10:12<125:15:17, 99.56s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.28s/it][A100%|██████████| 1/1 [01:38<00:00, 98.28s/it]
 13%|█▎        | 669/5198 [19:10:12<125:15:41, 99.57s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.24s/it][A100%|██████████| 1/1 [01:38<00:00, 98.24s/it]
 13%|█▎        | 669/5198 [19:10:12<125:14:53, 99.56s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.28s/it][A100%|██████████| 1/1 [01:38<00:00, 98.28s/it]
 13%|█▎        | 669/5198 [19:10:12<125:15:29, 99.56s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.28s/it][A100%|██████████| 1/1 [01:38<00:00, 98.28s/it]
 13%|█▎        | 669/5198 [19:10:12<125:15:40, 99.57s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.30s/it][A100%|██████████| 1/1 [01:38<00:00, 98.30s/it]
 13%|█▎        | 669/5198 [19:10:14<125:15:44, 99.57s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_628
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.81s/it][A100%|██████████| 1/1 [01:39<00:00, 99.81s/it]
 13%|█▎        | 670/5198 [19:11:51<125:23:23, 99.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 14:36:57,374] [INFO] [logging.py:96:log_dist] [Rank 0] step=662, skipped=0, lr=[1.9616639917568404e-05], mom=[(0.9, 0.999)]
steps: 662 loss: 0.6084 iter time (s): 99.213 samples/sec: 1.290

100%|██████████| 1/1 [01:40<00:00, 100.03s/it][A100%|██████████| 1/1 [01:40<00:00, 100.03s/it]
 13%|█▎        | 670/5198 [19:11:52<125:25:27, 99.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.98s/it][A100%|██████████| 1/1 [01:39<00:00, 99.98s/it]
 13%|█▎        | 670/5198 [19:11:52<125:23:13, 99.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.04s/it][A100%|██████████| 1/1 [01:40<00:00, 100.04s/it]
 13%|█▎        | 670/5198 [19:11:52<125:25:00, 99.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.05s/it][A100%|██████████| 1/1 [01:40<00:00, 100.05s/it]
 13%|█▎        | 670/5198 [19:11:52<125:24:31, 99.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.01s/it][A100%|██████████| 1/1 [01:40<00:00, 100.01s/it]
 13%|█▎        | 670/5198 [19:11:52<125:24:00, 99.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.00s/it][A100%|██████████| 1/1 [01:40<00:00, 100.00s/it]
 13%|█▎        | 670/5198 [19:11:52<125:24:03, 99.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.01s/it][A100%|██████████| 1/1 [01:40<00:00, 100.01s/it]
 13%|█▎        | 670/5198 [19:11:55<125:24:14, 99.70s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_629
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.73s/it][A100%|██████████| 1/1 [01:25<00:00, 85.73s/it]
 13%|█▎        | 671/5198 [19:13:17<120:11:35, 95.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 14:38:23,002] [INFO] [logging.py:96:log_dist] [Rank 0] step=663, skipped=0, lr=[1.9615085174395502e-05], mom=[(0.9, 0.999)]
steps: 663 loss: 0.5977 iter time (s): 84.794 samples/sec: 1.510

100%|██████████| 1/1 [01:25<00:00, 85.60s/it][A100%|██████████| 1/1 [01:25<00:00, 85.60s/it]
 13%|█▎        | 671/5198 [19:13:17<120:04:21, 95.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.66s/it][A100%|██████████| 1/1 [01:25<00:00, 85.66s/it]
 13%|█▎        | 671/5198 [19:13:17<120:04:11, 95.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.67s/it][A100%|██████████| 1/1 [01:25<00:00, 85.67s/it]
 13%|█▎        | 671/5198 [19:13:18<120:05:42, 95.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.63s/it][A100%|██████████| 1/1 [01:25<00:00, 85.63s/it]
 13%|█▎        | 671/5198 [19:13:18<120:04:28, 95.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.67s/it][A100%|██████████| 1/1 [01:25<00:00, 85.67s/it]
 13%|█▎        | 671/5198 [19:13:18<120:04:57, 95.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.66s/it][A100%|██████████| 1/1 [01:25<00:00, 85.66s/it]
 13%|█▎        | 671/5198 [19:13:18<120:04:41, 95.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.65s/it][A100%|██████████| 1/1 [01:25<00:00, 85.65s/it]
 13%|█▎        | 671/5198 [19:13:20<120:04:42, 95.49s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_41
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.52s/it][A100%|██████████| 1/1 [01:52<00:00, 112.52s/it]
 13%|█▎        | 672/5198 [19:15:10<126:37:36, 100.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 14:40:16,170] [INFO] [logging.py:96:log_dist] [Rank 0] step=664, skipped=0, lr=[1.9613527346785424e-05], mom=[(0.9, 0.999)]
steps: 664 loss: 0.7122 iter time (s): 112.546 samples/sec: 1.137

100%|██████████| 1/1 [01:53<00:00, 113.61s/it][A100%|██████████| 1/1 [01:53<00:00, 113.61s/it]
 13%|█▎        | 672/5198 [19:15:11<126:53:11, 100.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.69s/it][A100%|██████████| 1/1 [01:53<00:00, 113.69s/it]
 13%|█▎        | 672/5198 [19:15:11<126:54:53, 100.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.79s/it][A100%|██████████| 1/1 [01:53<00:00, 113.79s/it]
 13%|█▎        | 672/5198 [19:15:12<126:58:06, 100.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.71s/it][A100%|██████████| 1/1 [01:53<00:00, 113.71s/it]
 13%|█▎        | 672/5198 [19:15:12<126:55:32, 100.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.77s/it][A100%|██████████| 1/1 [01:53<00:00, 113.77s/it]
 13%|█▎        | 672/5198 [19:15:12<126:57:03, 100.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.73s/it][A100%|██████████| 1/1 [01:53<00:00, 113.73s/it]
 13%|█▎        | 672/5198 [19:15:14<126:56:00, 100.96s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_630

100%|██████████| 1/1 [01:53<00:00, 113.83s/it][A100%|██████████| 1/1 [01:53<00:00, 113.83s/it]
 13%|█▎        | 672/5198 [19:15:12<126:58:11, 100.99s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:09<00:00, 129.04s/it][A100%|██████████| 1/1 [02:09<00:00, 129.04s/it]
 13%|█▎        | 673/5198 [19:17:19<137:23:54, 109.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 14:42:25,863] [INFO] [logging.py:96:log_dist] [Rank 0] step=665, skipped=0, lr=[1.9611966435237965e-05], mom=[(0.9, 0.999)]
steps: 665 loss: 0.5615 iter time (s): 128.269 samples/sec: 0.998

100%|██████████| 1/1 [02:09<00:00, 129.16s/it][A100%|██████████| 1/1 [02:09<00:00, 129.16s/it]
 13%|█▎        | 673/5198 [19:17:20<137:31:02, 109.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:09<00:00, 129.05s/it][A100%|██████████| 1/1 [02:09<00:00, 129.05s/it]
 13%|█▎        | 673/5198 [19:17:20<137:29:13, 109.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:08<00:00, 128.93s/it][A100%|██████████| 1/1 [02:08<00:00, 128.93s/it]
 13%|█▎        | 673/5198 [19:17:20<137:28:43, 109.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:09<00:00, 129.12s/it][A100%|██████████| 1/1 [02:09<00:00, 129.12s/it]
 13%|█▎        | 673/5198 [19:17:21<137:32:58, 109.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:09<00:00, 129.16s/it][A100%|██████████| 1/1 [02:09<00:00, 129.16s/it]
 13%|█▎        | 673/5198 [19:17:21<137:32:09, 109.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:09<00:00, 129.18s/it][A100%|██████████| 1/1 [02:09<00:00, 129.18s/it]
 13%|█▎        | 673/5198 [19:17:21<137:33:35, 109.44s/it]
100%|██████████| 1/1 [02:09<00:00, 129.17s/it][A100%|██████████| 1/1 [02:09<00:00, 129.17s/it]
 13%|█▎        | 673/5198 [19:17:23<137:32:40, 109.43s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_631

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.11s/it][A100%|██████████| 1/1 [01:51<00:00, 111.11s/it]
 13%|█▎        | 674/5198 [19:19:11<138:25:49, 110.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 14:44:17,284] [INFO] [logging.py:96:log_dist] [Rank 0] step=666, skipped=0, lr=[1.9610402440253906e-05], mom=[(0.9, 0.999)]
steps: 666 loss: 0.5307 iter time (s): 110.526 samples/sec: 1.158

100%|██████████| 1/1 [01:51<00:00, 111.47s/it][A100%|██████████| 1/1 [01:51<00:00, 111.47s/it]
 13%|█▎        | 674/5198 [19:19:12<138:16:13, 110.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.55s/it][A100%|██████████| 1/1 [01:51<00:00, 111.56s/it]
 13%|█▎        | 674/5198 [19:19:12<138:16:48, 110.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.47s/it][A100%|██████████| 1/1 [01:51<00:00, 111.47s/it]
 13%|█▎        | 674/5198 [19:19:12<138:14:37, 110.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.22s/it][A100%|██████████| 1/1 [01:51<00:00, 111.22s/it]
 13%|█▎        | 674/5198 [19:19:12<138:12:16, 109.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.30s/it][A100%|██████████| 1/1 [01:51<00:00, 111.30s/it]
 13%|█▎        | 674/5198 [19:19:12<138:13:37, 110.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.32s/it][A100%|██████████| 1/1 [01:51<00:00, 111.32s/it]
 13%|█▎        | 674/5198 [19:19:14<138:13:45, 110.00s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_632
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.36s/it][A100%|██████████| 1/1 [01:51<00:00, 111.37s/it]
 13%|█▎        | 674/5198 [19:19:12<138:14:38, 110.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.78s/it][A100%|██████████| 1/1 [01:40<00:00, 100.79s/it]
 13%|█▎        | 675/5198 [19:20:52<134:58:05, 107.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 14:45:58,670] [INFO] [logging.py:96:log_dist] [Rank 0] step=667, skipped=0, lr=[1.9608835362335003e-05], mom=[(0.9, 0.999)]
steps: 667 loss: 0.6331 iter time (s): 100.562 samples/sec: 1.273

100%|██████████| 1/1 [01:41<00:00, 101.29s/it][A100%|██████████| 1/1 [01:41<00:00, 101.29s/it]
 13%|█▎        | 675/5198 [19:20:53<134:57:37, 107.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.28s/it][A100%|██████████| 1/1 [01:41<00:00, 101.28s/it]
 13%|█▎        | 675/5198 [19:20:53<134:57:06, 107.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.40s/it][A100%|██████████| 1/1 [01:41<00:00, 101.40s/it]
 13%|█▎        | 675/5198 [19:20:53<134:58:18, 107.43s/it]
100%|██████████| 1/1 [01:41<00:00, 101.32s/it][A100%|██████████| 1/1 [01:41<00:00, 101.32s/it]
 13%|█▎        | 675/5198 [19:20:53<134:55:52, 107.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.42s/it][A100%|██████████| 1/1 [01:41<00:00, 101.42s/it]
 13%|█▎        | 675/5198 [19:20:54<134:57:07, 107.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.41s/it][A100%|██████████| 1/1 [01:41<00:00, 101.41s/it]
 13%|█▎        | 675/5198 [19:20:56<134:57:49, 107.42s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_633

100%|██████████| 1/1 [01:41<00:00, 101.39s/it][A100%|██████████| 1/1 [01:41<00:00, 101.39s/it]
 13%|█▎        | 675/5198 [19:20:54<134:58:04, 107.43s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.25s/it][A100%|██████████| 1/1 [01:25<00:00, 85.25s/it]
 13%|█▎        | 676/5198 [19:22:18<126:40:11, 100.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 14:47:23,707] [INFO] [logging.py:96:log_dist] [Rank 0] step=668, skipped=0, lr=[1.9607265201984024e-05], mom=[(0.9, 0.999)]
steps: 668 loss: 0.5741 iter time (s): 84.188 samples/sec: 1.520

100%|██████████| 1/1 [01:25<00:00, 85.00s/it][A100%|██████████| 1/1 [01:25<00:00, 85.00s/it]
 13%|█▎        | 676/5198 [19:22:18<126:29:11, 100.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.05s/it][A100%|██████████| 1/1 [01:25<00:00, 85.05s/it]
 13%|█▎        | 676/5198 [19:22:18<126:29:58, 100.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.90s/it][A100%|██████████| 1/1 [01:24<00:00, 84.90s/it]
 13%|█▎        | 676/5198 [19:22:18<126:27:25, 100.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.04s/it][A100%|██████████| 1/1 [01:25<00:00, 85.04s/it]
 13%|█▎        | 676/5198 [19:22:18<126:28:42, 100.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.06s/it][A100%|██████████| 1/1 [01:25<00:00, 85.06s/it]
 13%|█▎        | 676/5198 [19:22:19<126:30:10, 100.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 85.00s/it][A100%|██████████| 1/1 [01:24<00:00, 85.00s/it]
 13%|█▎        | 676/5198 [19:22:21<126:29:10, 100.70s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_634

100%|██████████| 1/1 [01:24<00:00, 85.00s/it][A100%|██████████| 1/1 [01:24<00:00, 85.00s/it]
 13%|█▎        | 676/5198 [19:22:19<126:29:20, 100.70s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:17<00:00, 77.38s/it][A100%|██████████| 1/1 [01:17<00:00, 77.38s/it]
 13%|█▎        | 677/5198 [19:23:35<117:53:50, 93.88s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 14:48:41,154] [INFO] [logging.py:96:log_dist] [Rank 0] step=669, skipped=0, lr=[1.9605691959704714e-05], mom=[(0.9, 0.999)]
steps: 669 loss: 0.5944 iter time (s): 76.630 samples/sec: 1.670

100%|██████████| 1/1 [01:17<00:00, 77.40s/it][A100%|██████████| 1/1 [01:17<00:00, 77.41s/it]
 13%|█▎        | 677/5198 [19:23:35<117:41:18, 93.71s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:17<00:00, 77.38s/it][A100%|██████████| 1/1 [01:17<00:00, 77.38s/it]
 13%|█▎        | 677/5198 [19:23:35<117:41:10, 93.71s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:17<00:00, 77.40s/it][A100%|██████████| 1/1 [01:17<00:00, 77.40s/it]
 13%|█▎        | 677/5198 [19:23:36<117:39:59, 93.70s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:17<00:00, 77.35s/it][A100%|██████████| 1/1 [01:17<00:00, 77.35s/it]
 13%|█▎        | 677/5198 [19:23:36<117:39:31, 93.69s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:17<00:00, 77.33s/it][A100%|██████████| 1/1 [01:17<00:00, 77.33s/it]
 13%|█▎        | 677/5198 [19:23:36<117:40:12, 93.70s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:17<00:00, 77.36s/it][A100%|██████████| 1/1 [01:17<00:00, 77.36s/it]
 13%|█▎        | 677/5198 [19:23:36<117:40:13, 93.70s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:17<00:00, 77.38s/it][A100%|██████████| 1/1 [01:17<00:00, 77.38s/it]
 13%|█▎        | 677/5198 [19:23:38<117:40:39, 93.70s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_635
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.62s/it][A100%|██████████| 1/1 [01:26<00:00, 86.62s/it]
 13%|█▎        | 678/5198 [19:25:02<115:13:27, 91.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 14:50:08,254] [INFO] [logging.py:96:log_dist] [Rank 0] step=670, skipped=0, lr=[1.960411563600181e-05], mom=[(0.9, 0.999)]
steps: 670 loss: 0.5792 iter time (s): 86.338 samples/sec: 1.483

100%|██████████| 1/1 [01:27<00:00, 87.09s/it][A100%|██████████| 1/1 [01:27<00:00, 87.09s/it]
 13%|█▎        | 678/5198 [19:25:02<115:10:18, 91.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.12s/it][A100%|██████████| 1/1 [01:27<00:00, 87.12s/it]
 13%|█▎        | 678/5198 [19:25:03<115:10:57, 91.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.10s/it][A100%|██████████| 1/1 [01:27<00:00, 87.10s/it]
 13%|█▎        | 678/5198 [19:25:03<115:09:39, 91.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.18s/it][A100%|██████████| 1/1 [01:27<00:00, 87.18s/it]
 13%|█▎        | 678/5198 [19:25:03<115:10:56, 91.74s/it]
100%|██████████| 1/1 [01:27<00:00, 87.10s/it][A100%|██████████| 1/1 [01:27<00:00, 87.10s/it]
 13%|█▎        | 678/5198 [19:25:03<115:09:46, 91.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.12s/it][A100%|██████████| 1/1 [01:27<00:00, 87.12s/it]
 13%|█▎        | 678/5198 [19:25:03<115:10:03, 91.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.11s/it][A100%|██████████| 1/1 [01:27<00:00, 87.11s/it]
 13%|█▎        | 678/5198 [19:25:05<115:10:08, 91.73s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_636
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.34s/it][A100%|██████████| 1/1 [01:44<00:00, 104.34s/it]
 13%|█▎        | 679/5198 [19:26:47<119:59:36, 95.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 14:51:53,211] [INFO] [logging.py:96:log_dist] [Rank 0] step=671, skipped=0, lr=[1.9602536231381025e-05], mom=[(0.9, 0.999)]
steps: 671 loss: 0.5527 iter time (s): 104.184 samples/sec: 1.229

100%|██████████| 1/1 [01:44<00:00, 104.95s/it][A100%|██████████| 1/1 [01:44<00:00, 104.95s/it]
 13%|█▎        | 679/5198 [19:26:47<120:07:47, 95.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.96s/it][A100%|██████████| 1/1 [01:44<00:00, 104.96s/it]
 13%|█▎        | 679/5198 [19:26:47<120:08:23, 95.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.02s/it][A100%|██████████| 1/1 [01:45<00:00, 105.02s/it]
 13%|█▎        | 679/5198 [19:26:48<120:08:53, 95.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.93s/it][A100%|██████████| 1/1 [01:44<00:00, 104.93s/it]
 13%|█▎        | 679/5198 [19:26:48<120:07:40, 95.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.99s/it][A100%|██████████| 1/1 [01:44<00:00, 104.99s/it]
 13%|█▎        | 679/5198 [19:26:48<120:08:12, 95.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.99s/it][A100%|██████████| 1/1 [01:44<00:00, 104.99s/it]
 13%|█▎        | 679/5198 [19:26:48<120:08:21, 95.71s/it]
100%|██████████| 1/1 [01:44<00:00, 104.98s/it][A100%|██████████| 1/1 [01:44<00:00, 104.98s/it]
 13%|█▎        | 679/5198 [19:26:50<120:08:10, 95.70s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_637

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.46s/it][A100%|██████████| 1/1 [01:25<00:00, 85.46s/it]
 13%|█▎        | 680/5198 [19:28:12<116:15:35, 92.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 14:53:18,421] [INFO] [logging.py:96:log_dist] [Rank 0] step=672, skipped=0, lr=[1.9600953746349084e-05], mom=[(0.9, 0.999)]
steps: 672 loss: 0.6411 iter time (s): 84.409 samples/sec: 1.516

100%|██████████| 1/1 [01:25<00:00, 85.31s/it][A100%|██████████| 1/1 [01:25<00:00, 85.31s/it]
 13%|█▎        | 680/5198 [19:28:13<116:11:43, 92.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.22s/it][A100%|██████████| 1/1 [01:25<00:00, 85.22s/it]
 13%|█▎        | 680/5198 [19:28:13<116:10:08, 92.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.23s/it][A100%|██████████| 1/1 [01:25<00:00, 85.23s/it]
 13%|█▎        | 680/5198 [19:28:13<116:10:42, 92.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.31s/it][A100%|██████████| 1/1 [01:25<00:00, 85.31s/it]
 13%|█▎        | 680/5198 [19:28:13<116:11:28, 92.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.25s/it][A100%|██████████| 1/1 [01:25<00:00, 85.25s/it]
 13%|█▎        | 680/5198 [19:28:13<116:10:36, 92.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.27s/it][A100%|██████████| 1/1 [01:25<00:00, 85.27s/it]
 13%|█▎        | 680/5198 [19:28:16<116:10:52, 92.57s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_638

100%|██████████| 1/1 [01:25<00:00, 85.27s/it][A100%|██████████| 1/1 [01:25<00:00, 85.27s/it]
 13%|█▎        | 680/5198 [19:28:13<116:11:06, 92.58s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.88s/it][A100%|██████████| 1/1 [01:52<00:00, 112.89s/it]
 13%|█▎        | 681/5198 [19:30:05<123:54:29, 98.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 14:55:11,904] [INFO] [logging.py:96:log_dist] [Rank 0] step=673, skipped=0, lr=[1.959936818141368e-05], mom=[(0.9, 0.999)]
steps: 673 loss: 0.5979 iter time (s): 112.621 samples/sec: 1.137

100%|██████████| 1/1 [01:53<00:00, 113.31s/it][A100%|██████████| 1/1 [01:53<00:00, 113.31s/it]
 13%|█▎        | 681/5198 [19:30:06<123:58:31, 98.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.44s/it][A100%|██████████| 1/1 [01:53<00:00, 113.44s/it]
 13%|█▎        | 681/5198 [19:30:06<124:00:19, 98.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.42s/it][A100%|██████████| 1/1 [01:53<00:00, 113.42s/it]
 13%|█▎        | 681/5198 [19:30:07<124:00:07, 98.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.40s/it][A100%|██████████| 1/1 [01:53<00:00, 113.40s/it]
 13%|█▎        | 681/5198 [19:30:07<124:00:20, 98.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.44s/it][A100%|██████████| 1/1 [01:53<00:00, 113.44s/it]
 13%|█▎        | 681/5198 [19:30:07<124:00:36, 98.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.40s/it][A100%|██████████| 1/1 [01:53<00:00, 113.40s/it]
 13%|█▎        | 681/5198 [19:30:07<124:00:01, 98.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.43s/it][A100%|██████████| 1/1 [01:53<00:00, 113.43s/it]
 13%|█▎        | 681/5198 [19:30:09<124:00:22, 98.83s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_639
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.93s/it][A100%|██████████| 1/1 [01:25<00:00, 85.93s/it]
 13%|█▎        | 682/5198 [19:31:31<119:08:02, 94.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 14:56:37,639] [INFO] [logging.py:96:log_dist] [Rank 0] step=674, skipped=0, lr=[1.9597779537083507e-05], mom=[(0.9, 0.999)]
steps: 674 loss: 0.5663 iter time (s): 84.925 samples/sec: 1.507

100%|██████████| 1/1 [01:25<00:00, 85.74s/it][A100%|██████████| 1/1 [01:25<00:00, 85.74s/it]
 13%|█▎        | 682/5198 [19:31:32<119:02:11, 94.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.70s/it][A100%|██████████| 1/1 [01:25<00:00, 85.70s/it]
 13%|█▎        | 682/5198 [19:31:32<119:02:25, 94.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.73s/it][A100%|██████████| 1/1 [01:25<00:00, 85.73s/it]
 13%|█▎        | 682/5198 [19:31:32<119:02:51, 94.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.70s/it][A100%|██████████| 1/1 [01:25<00:00, 85.70s/it]
 13%|█▎        | 682/5198 [19:31:32<119:02:17, 94.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.72s/it][A100%|██████████| 1/1 [01:25<00:00, 85.72s/it]
 13%|█▎        | 682/5198 [19:31:32<119:03:03, 94.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.73s/it][A100%|██████████| 1/1 [01:25<00:00, 85.73s/it]
 13%|█▎        | 682/5198 [19:31:33<119:02:48, 94.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.74s/it][A100%|██████████| 1/1 [01:25<00:00, 85.74s/it]
 13%|█▎        | 682/5198 [19:31:35<119:03:09, 94.90s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_640
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.73s/it][A100%|██████████| 1/1 [01:20<00:00, 80.73s/it]
 13%|█▎        | 683/5198 [19:32:52<113:50:21, 90.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 14:57:58,468] [INFO] [logging.py:96:log_dist] [Rank 0] step=675, skipped=0, lr=[1.9596187813868238e-05], mom=[(0.9, 0.999)]
steps: 675 loss: 0.6080 iter time (s): 80.011 samples/sec: 1.600

100%|██████████| 1/1 [01:20<00:00, 80.93s/it][A100%|██████████| 1/1 [01:20<00:00, 80.93s/it]
 13%|█▎        | 683/5198 [19:32:53<113:45:42, 90.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.90s/it][A100%|██████████| 1/1 [01:20<00:00, 80.90s/it]
 13%|█▎        | 683/5198 [19:32:53<113:45:02, 90.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.87s/it][A100%|██████████| 1/1 [01:20<00:00, 80.87s/it]
 13%|█▎        | 683/5198 [19:32:53<113:44:46, 90.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.91s/it][A100%|██████████| 1/1 [01:20<00:00, 80.91s/it]
 13%|█▎        | 683/5198 [19:32:53<113:45:17, 90.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.88s/it][A100%|██████████| 1/1 [01:20<00:00, 80.88s/it]
 13%|█▎        | 683/5198 [19:32:53<113:45:02, 90.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.87s/it][A100%|██████████| 1/1 [01:20<00:00, 80.87s/it]
 13%|█▎        | 683/5198 [19:32:53<113:44:32, 90.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:20<00:00, 80.86s/it][A100%|██████████| 1/1 [01:20<00:00, 80.86s/it]
 13%|█▎        | 683/5198 [19:32:56<113:44:40, 90.69s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_641
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.96s/it][A100%|██████████| 1/1 [01:50<00:00, 110.96s/it]
 13%|█▎        | 684/5198 [19:34:44<121:29:23, 96.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 14:59:50,468] [INFO] [logging.py:96:log_dist] [Rank 0] step=676, skipped=0, lr=[1.9594593012278537e-05], mom=[(0.9, 0.999)]
steps: 676 loss: 0.5908 iter time (s): 111.145 samples/sec: 1.152

100%|██████████| 1/1 [01:51<00:00, 111.90s/it][A100%|██████████| 1/1 [01:51<00:00, 111.90s/it]
 13%|█▎        | 684/5198 [19:34:45<121:42:38, 97.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.92s/it][A100%|██████████| 1/1 [01:51<00:00, 111.92s/it]
 13%|█▎        | 684/5198 [19:34:45<121:42:43, 97.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.91s/it][A100%|██████████| 1/1 [01:51<00:00, 111.91s/it]
 13%|█▎        | 684/5198 [19:34:45<121:42:21, 97.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.85s/it][A100%|██████████| 1/1 [01:51<00:00, 111.85s/it]
 13%|█▎        | 684/5198 [19:34:45<121:41:05, 97.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.92s/it][A100%|██████████| 1/1 [01:51<00:00, 111.92s/it]
 13%|█▎        | 684/5198 [19:34:45<121:42:45, 97.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.90s/it][A100%|██████████| 1/1 [01:51<00:00, 111.90s/it]
 13%|█▎        | 684/5198 [19:34:48<121:41:50, 97.06s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_642

100%|██████████| 1/1 [01:51<00:00, 111.92s/it][A100%|██████████| 1/1 [01:51<00:00, 111.92s/it]
 13%|█▎        | 684/5198 [19:34:45<121:42:13, 97.06s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.40s/it][A100%|██████████| 1/1 [01:42<00:00, 102.40s/it]
 13%|█▎        | 685/5198 [19:36:26<123:35:04, 98.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 15:01:32,751] [INFO] [logging.py:96:log_dist] [Rank 0] step=677, skipped=0, lr=[1.959299513282606e-05], mom=[(0.9, 0.999)]
steps: 677 loss: 0.6100 iter time (s): 101.526 samples/sec: 1.261

100%|██████████| 1/1 [01:42<00:00, 102.25s/it][A100%|██████████| 1/1 [01:42<00:00, 102.25s/it]
 13%|█▎        | 685/5198 [19:36:27<123:38:10, 98.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.26s/it][A100%|██████████| 1/1 [01:42<00:00, 102.26s/it]
 13%|█▎        | 685/5198 [19:36:27<123:38:32, 98.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.22s/it][A100%|██████████| 1/1 [01:42<00:00, 102.22s/it]
 13%|█▎        | 685/5198 [19:36:27<123:37:14, 98.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.27s/it][A100%|██████████| 1/1 [01:42<00:00, 102.27s/it]
 13%|█▎        | 685/5198 [19:36:27<123:38:43, 98.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.34s/it][A100%|██████████| 1/1 [01:42<00:00, 102.34s/it]
 13%|█▎        | 685/5198 [19:36:28<123:39:10, 98.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.31s/it][A100%|██████████| 1/1 [01:42<00:00, 102.31s/it]
 13%|█▎        | 685/5198 [19:36:28<123:39:05, 98.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.32s/it][A100%|██████████| 1/1 [01:42<00:00, 102.32s/it]
 13%|█▎        | 685/5198 [19:36:30<123:39:02, 98.64s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_643
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:14<00:00, 134.63s/it][A100%|██████████| 1/1 [02:14<00:00, 134.63s/it]
 13%|█▎        | 686/5198 [19:38:41<137:10:16, 109.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 15:03:48,390] [INFO] [logging.py:96:log_dist] [Rank 0] step=678, skipped=0, lr=[1.959139417602344e-05], mom=[(0.9, 0.999)]
steps: 678 loss: 0.5663 iter time (s): 134.842 samples/sec: 0.949

100%|██████████| 1/1 [02:15<00:00, 135.69s/it][A100%|██████████| 1/1 [02:15<00:00, 135.69s/it]
 13%|█▎        | 686/5198 [19:38:43<137:33:01, 109.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:15<00:00, 135.77s/it][A100%|██████████| 1/1 [02:15<00:00, 135.77s/it]
 13%|█▎        | 686/5198 [19:38:43<137:35:01, 109.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:15<00:00, 135.65s/it][A100%|██████████| 1/1 [02:15<00:00, 135.65s/it]
 13%|█▎        | 686/5198 [19:38:43<137:32:20, 109.74s/it]
100%|██████████| 1/1 [02:15<00:00, 135.83s/it][A100%|██████████| 1/1 [02:15<00:00, 135.83s/it]
 13%|█▎        | 686/5198 [19:38:43<137:35:20, 109.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:15<00:00, 135.70s/it][A100%|██████████| 1/1 [02:15<00:00, 135.70s/it]
 13%|█▎        | 686/5198 [19:38:43<137:33:48, 109.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:15<00:00, 135.67s/it][A100%|██████████| 1/1 [02:15<00:00, 135.67s/it]
 13%|█▎        | 686/5198 [19:38:43<137:33:00, 109.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:15<00:00, 135.68s/it][A100%|██████████| 1/1 [02:15<00:00, 135.68s/it]
 13%|█▎        | 686/5198 [19:38:46<137:33:10, 109.75s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_644
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.41s/it][A100%|██████████| 1/1 [02:00<00:00, 120.41s/it]
 13%|█▎        | 687/5198 [19:40:42<141:20:36, 112.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 15:05:48,652] [INFO] [logging.py:96:log_dist] [Rank 0] step=679, skipped=0, lr=[1.9589790142384307e-05], mom=[(0.9, 0.999)]
steps: 679 loss: 0.6127 iter time (s): 119.423 samples/sec: 1.072

100%|██████████| 1/1 [02:00<00:00, 120.25s/it][A100%|██████████| 1/1 [02:00<00:00, 120.25s/it]
 13%|█▎        | 687/5198 [19:40:43<141:28:10, 112.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.19s/it][A100%|██████████| 1/1 [02:00<00:00, 120.19s/it]
 13%|█▎        | 687/5198 [19:40:43<141:28:26, 112.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.22s/it][A100%|██████████| 1/1 [02:00<00:00, 120.23s/it]
 13%|█▎        | 687/5198 [19:40:43<141:29:27, 112.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.27s/it][A100%|██████████| 1/1 [02:00<00:00, 120.27s/it]
 13%|█▎        | 687/5198 [19:40:43<141:28:16, 112.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.23s/it][A100%|██████████| 1/1 [02:00<00:00, 120.23s/it]
 13%|█▎        | 687/5198 [19:40:44<141:28:21, 112.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.26s/it][A100%|██████████| 1/1 [02:00<00:00, 120.26s/it]
 13%|█▎        | 687/5198 [19:40:44<141:28:27, 112.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.26s/it][A100%|██████████| 1/1 [02:00<00:00, 120.26s/it]
 13%|█▎        | 687/5198 [19:40:46<141:28:29, 112.90s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_42
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.87s/it][A100%|██████████| 1/1 [01:58<00:00, 118.87s/it]
 13%|█▎        | 688/5198 [19:42:41<143:38:33, 114.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 15:07:47,336] [INFO] [logging.py:96:log_dist] [Rank 0] step=680, skipped=0, lr=[1.9588183032423273e-05], mom=[(0.9, 0.999)]
steps: 680 loss: 0.7946 iter time (s): 118.099 samples/sec: 1.084

100%|██████████| 1/1 [01:59<00:00, 119.09s/it][A100%|██████████| 1/1 [01:59<00:00, 119.09s/it]
 13%|█▎        | 688/5198 [19:42:42<143:46:06, 114.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.99s/it][A100%|██████████| 1/1 [01:58<00:00, 118.99s/it]
 13%|█▎        | 688/5198 [19:42:42<143:43:59, 114.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.04s/it][A100%|██████████| 1/1 [01:59<00:00, 119.04s/it]
 13%|█▎        | 688/5198 [19:42:42<143:45:48, 114.76s/it]
100%|██████████| 1/1 [01:59<00:00, 119.01s/it][A100%|██████████| 1/1 [01:59<00:00, 119.01s/it]
 13%|█▎        | 688/5198 [19:42:42<143:44:17, 114.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.03s/it][A100%|██████████| 1/1 [01:59<00:00, 119.03s/it]
 13%|█▎        | 688/5198 [19:42:43<143:44:44, 114.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.01s/it][A100%|██████████| 1/1 [01:59<00:00, 119.01s/it]
 13%|█▎        | 688/5198 [19:42:43<143:44:20, 114.74s/it]
100%|██████████| 1/1 [01:58<00:00, 119.00s/it][A100%|██████████| 1/1 [01:58<00:00, 119.00s/it]
 13%|█▎        | 688/5198 [19:42:45<143:44:10, 114.73s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_645

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.43s/it][A100%|██████████| 1/1 [01:46<00:00, 106.43s/it]
 13%|█▎        | 689/5198 [19:44:27<140:36:55, 112.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 15:09:33,954] [INFO] [logging.py:96:log_dist] [Rank 0] step=681, skipped=0, lr=[1.9586572846655943e-05], mom=[(0.9, 0.999)]
steps: 681 loss: 0.6085 iter time (s): 105.464 samples/sec: 1.214

100%|██████████| 1/1 [01:46<00:00, 106.19s/it][A100%|██████████| 1/1 [01:46<00:00, 106.19s/it]
 13%|█▎        | 689/5198 [19:44:28<140:31:21, 112.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.26s/it][A100%|██████████| 1/1 [01:46<00:00, 106.26s/it]
 13%|█▎        | 689/5198 [19:44:28<140:31:21, 112.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.13s/it][A100%|██████████| 1/1 [01:46<00:00, 106.13s/it]
 13%|█▎        | 689/5198 [19:44:29<140:29:38, 112.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.29s/it][A100%|██████████| 1/1 [01:46<00:00, 106.29s/it]
 13%|█▎        | 689/5198 [19:44:29<140:32:01, 112.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.23s/it][A100%|██████████| 1/1 [01:46<00:00, 106.23s/it]
 13%|█▎        | 689/5198 [19:44:29<140:31:01, 112.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.25s/it][A100%|██████████| 1/1 [01:46<00:00, 106.25s/it]
 13%|█▎        | 689/5198 [19:44:29<140:31:20, 112.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:46<00:00, 106.26s/it][A100%|██████████| 1/1 [01:46<00:00, 106.26s/it]
 13%|█▎        | 689/5198 [19:44:31<140:31:21, 112.19s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_646
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.07s/it][A100%|██████████| 1/1 [01:42<00:00, 102.07s/it]
 13%|█▎        | 690/5198 [19:46:09<136:49:01, 109.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 15:11:16,103] [INFO] [logging.py:96:log_dist] [Rank 0] step=682, skipped=0, lr=[1.9584959585598902e-05], mom=[(0.9, 0.999)]
steps: 682 loss: 0.5895 iter time (s): 101.334 samples/sec: 1.263

100%|██████████| 1/1 [01:42<00:00, 102.14s/it][A100%|██████████| 1/1 [01:42<00:00, 102.14s/it]
 13%|█▎        | 690/5198 [19:46:10<136:43:04, 109.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.13s/it][A100%|██████████| 1/1 [01:42<00:00, 102.14s/it]
 13%|█▎        | 690/5198 [19:46:10<136:43:05, 109.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.13s/it][A100%|██████████| 1/1 [01:42<00:00, 102.13s/it]
 13%|█▎        | 690/5198 [19:46:11<136:41:48, 109.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.10s/it][A100%|██████████| 1/1 [01:42<00:00, 102.10s/it]
 13%|█▎        | 690/5198 [19:46:11<136:42:32, 109.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.15s/it][A100%|██████████| 1/1 [01:42<00:00, 102.15s/it]
 13%|█▎        | 690/5198 [19:46:11<136:43:00, 109.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.12s/it][A100%|██████████| 1/1 [01:42<00:00, 102.12s/it]
 13%|█▎        | 690/5198 [19:46:11<136:42:33, 109.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.13s/it][A100%|██████████| 1/1 [01:42<00:00, 102.13s/it]
 13%|█▎        | 690/5198 [19:46:13<136:42:50, 109.18s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_647
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.08s/it][A100%|██████████| 1/1 [01:33<00:00, 93.08s/it]
 13%|█▎        | 691/5198 [19:47:43<130:46:30, 104.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 15:12:49,072] [INFO] [logging.py:96:log_dist] [Rank 0] step=683, skipped=0, lr=[1.9583343249769725e-05], mom=[(0.9, 0.999)]
steps: 683 loss: 0.5936 iter time (s): 92.170 samples/sec: 1.389

100%|██████████| 1/1 [01:32<00:00, 92.96s/it][A100%|██████████| 1/1 [01:32<00:00, 92.96s/it]
 13%|█▎        | 691/5198 [19:47:43<130:36:01, 104.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.02s/it][A100%|██████████| 1/1 [01:33<00:00, 93.02s/it]
 13%|█▎        | 691/5198 [19:47:43<130:37:18, 104.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.03s/it][A100%|██████████| 1/1 [01:33<00:00, 93.03s/it]
 13%|█▎        | 691/5198 [19:47:44<130:36:42, 104.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.00s/it][A100%|██████████| 1/1 [01:33<00:00, 93.00s/it]
 13%|█▎        | 691/5198 [19:47:44<130:36:26, 104.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.01s/it][A100%|██████████| 1/1 [01:33<00:00, 93.01s/it]
 13%|█▎        | 691/5198 [19:47:44<130:37:01, 104.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.04s/it][A100%|██████████| 1/1 [01:33<00:00, 93.04s/it]
 13%|█▎        | 691/5198 [19:47:44<130:37:16, 104.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.02s/it][A100%|██████████| 1/1 [01:33<00:00, 93.02s/it]
 13%|█▎        | 691/5198 [19:47:46<130:37:10, 104.33s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_648
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.37s/it][A100%|██████████| 1/1 [01:23<00:00, 83.37s/it]
 13%|█▎        | 692/5198 [19:49:06<122:53:07, 98.18s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 15:14:11,986] [INFO] [logging.py:96:log_dist] [Rank 0] step=684, skipped=0, lr=[1.958172383968697e-05], mom=[(0.9, 0.999)]
steps: 684 loss: 0.5520 iter time (s): 82.052 samples/sec: 1.560

100%|██████████| 1/1 [01:22<00:00, 82.86s/it][A100%|██████████| 1/1 [01:22<00:00, 82.86s/it]
 13%|█▎        | 692/5198 [19:49:06<122:31:04, 97.88s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.79s/it][A100%|██████████| 1/1 [01:22<00:00, 82.80s/it]
 13%|█▎        | 692/5198 [19:49:06<122:30:34, 97.88s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.85s/it][A100%|██████████| 1/1 [01:22<00:00, 82.85s/it]
 13%|█▎        | 692/5198 [19:49:07<122:31:23, 97.89s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.85s/it][A100%|██████████| 1/1 [01:22<00:00, 82.85s/it]
 13%|█▎        | 692/5198 [19:49:07<122:31:01, 97.88s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.81s/it][A100%|██████████| 1/1 [01:22<00:00, 82.81s/it]
 13%|█▎        | 692/5198 [19:49:07<122:30:30, 97.88s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.80s/it][A100%|██████████| 1/1 [01:22<00:00, 82.80s/it]
 13%|█▎        | 692/5198 [19:49:07<122:30:35, 97.88s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.82s/it][A100%|██████████| 1/1 [01:22<00:00, 82.82s/it]
 13%|█▎        | 692/5198 [19:49:09<122:30:53, 97.88s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_649
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.80s/it][A100%|██████████| 1/1 [01:26<00:00, 86.80s/it]
 13%|█▎        | 693/5198 [19:50:33<118:38:51, 94.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 15:15:39,398] [INFO] [logging.py:96:log_dist] [Rank 0] step=685, skipped=0, lr=[1.9580101355870188e-05], mom=[(0.9, 0.999)]
steps: 685 loss: 0.5867 iter time (s): 86.635 samples/sec: 1.477

100%|██████████| 1/1 [01:27<00:00, 87.42s/it][A100%|██████████| 1/1 [01:27<00:00, 87.42s/it]
 13%|█▎        | 693/5198 [19:50:34<118:33:53, 94.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.41s/it][A100%|██████████| 1/1 [01:27<00:00, 87.42s/it]
 13%|█▎        | 693/5198 [19:50:34<118:33:29, 94.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.39s/it][A100%|██████████| 1/1 [01:27<00:00, 87.39s/it]
 13%|█▎        | 693/5198 [19:50:34<118:33:23, 94.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.46s/it][A100%|██████████| 1/1 [01:27<00:00, 87.46s/it]
 13%|█▎        | 693/5198 [19:50:34<118:34:47, 94.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.46s/it][A100%|██████████| 1/1 [01:27<00:00, 87.46s/it]
 13%|█▎        | 693/5198 [19:50:34<118:34:30, 94.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.44s/it][A100%|██████████| 1/1 [01:27<00:00, 87.44s/it]
 13%|█▎        | 693/5198 [19:50:34<118:33:57, 94.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.43s/it][A100%|██████████| 1/1 [01:27<00:00, 87.43s/it]
 13%|█▎        | 693/5198 [19:50:37<118:33:57, 94.75s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_650
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.42s/it][A100%|██████████| 1/1 [01:32<00:00, 92.42s/it]
 13%|█▎        | 694/5198 [19:52:06<117:46:57, 94.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 15:17:11,682] [INFO] [logging.py:96:log_dist] [Rank 0] step=686, skipped=0, lr=[1.957847579883991e-05], mom=[(0.9, 0.999)]
steps: 686 loss: 0.6257 iter time (s): 91.487 samples/sec: 1.399

100%|██████████| 1/1 [01:32<00:00, 92.23s/it][A100%|██████████| 1/1 [01:32<00:00, 92.23s/it]
 13%|█▎        | 694/5198 [19:52:06<117:36:00, 94.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.25s/it][A100%|██████████| 1/1 [01:32<00:00, 92.25s/it]
 13%|█▎        | 694/5198 [19:52:06<117:35:59, 94.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.25s/it][A100%|██████████| 1/1 [01:32<00:00, 92.25s/it]
 13%|█▎        | 694/5198 [19:52:06<117:36:03, 94.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.22s/it][A100%|██████████| 1/1 [01:32<00:00, 92.22s/it]
 13%|█▎        | 694/5198 [19:52:06<117:36:17, 94.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.25s/it][A100%|██████████| 1/1 [01:32<00:00, 92.26s/it]
 13%|█▎        | 694/5198 [19:52:07<117:36:47, 94.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.26s/it][A100%|██████████| 1/1 [01:32<00:00, 92.26s/it]
 13%|█▎        | 694/5198 [19:52:07<117:36:28, 94.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.27s/it][A100%|██████████| 1/1 [01:32<00:00, 92.27s/it]
 13%|█▎        | 694/5198 [19:52:09<117:36:37, 94.00s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_651
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.45s/it][A100%|██████████| 1/1 [01:37<00:00, 97.45s/it]
 13%|█▎        | 695/5198 [19:53:43<119:03:39, 95.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 15:18:49,936] [INFO] [logging.py:96:log_dist] [Rank 0] step=687, skipped=0, lr=[1.9576847169117654e-05], mom=[(0.9, 0.999)]
steps: 687 loss: 0.5929 iter time (s): 97.468 samples/sec: 1.313

100%|██████████| 1/1 [01:38<00:00, 98.29s/it][A100%|██████████| 1/1 [01:38<00:00, 98.29s/it]
 13%|█▎        | 695/5198 [19:53:44<119:11:11, 95.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.27s/it][A100%|██████████| 1/1 [01:38<00:00, 98.27s/it]
 13%|█▎        | 695/5198 [19:53:44<119:10:55, 95.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.31s/it][A100%|██████████| 1/1 [01:38<00:00, 98.31s/it]
 13%|█▎        | 695/5198 [19:53:45<119:11:40, 95.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.23s/it][A100%|██████████| 1/1 [01:38<00:00, 98.23s/it]
 13%|█▎        | 695/5198 [19:53:45<119:10:07, 95.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.19s/it][A100%|██████████| 1/1 [01:38<00:00, 98.19s/it]
 13%|█▎        | 695/5198 [19:53:45<119:09:33, 95.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.22s/it][A100%|██████████| 1/1 [01:38<00:00, 98.22s/it]
 13%|█▎        | 695/5198 [19:53:47<119:10:04, 95.27s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_652

100%|██████████| 1/1 [01:38<00:00, 98.24s/it][A100%|██████████| 1/1 [01:38<00:00, 98.24s/it]
 13%|█▎        | 695/5198 [19:53:45<119:10:34, 95.28s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.18s/it][A100%|██████████| 1/1 [01:53<00:00, 113.18s/it]
 13%|█▎        | 696/5198 [19:55:37<125:51:07, 100.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 15:20:43,697] [INFO] [logging.py:96:log_dist] [Rank 0] step=688, skipped=0, lr=[1.9575215467225925e-05], mom=[(0.9, 0.999)]
steps: 688 loss: 0.6060 iter time (s): 113.005 samples/sec: 1.133

100%|██████████| 1/1 [01:53<00:00, 113.68s/it][A100%|██████████| 1/1 [01:53<00:00, 113.68s/it]
 13%|█▎        | 696/5198 [19:55:38<126:04:02, 100.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.72s/it][A100%|██████████| 1/1 [01:53<00:00, 113.72s/it]
 13%|█▎        | 696/5198 [19:55:38<126:04:39, 100.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.76s/it][A100%|██████████| 1/1 [01:53<00:00, 113.76s/it]
 13%|█▎        | 696/5198 [19:55:38<126:05:00, 100.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.76s/it][A100%|██████████| 1/1 [01:53<00:00, 113.76s/it]
 13%|█▎        | 696/5198 [19:55:38<126:04:29, 100.82s/it]
100%|██████████| 1/1 [01:53<00:00, 113.83s/it][A100%|██████████| 1/1 [01:53<00:00, 113.83s/it]
 13%|█▎        | 696/5198 [19:55:38<126:07:30, 100.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:53<00:00, 113.75s/it][A100%|██████████| 1/1 [01:53<00:00, 113.75s/it]
 13%|█▎        | 696/5198 [19:55:39<126:04:54, 100.82s/it]
100%|██████████| 1/1 [01:53<00:00, 113.75s/it][A100%|██████████| 1/1 [01:53<00:00, 113.75s/it]
 13%|█▎        | 696/5198 [19:55:41<126:04:38, 100.82s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_653
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:01<00:00, 121.49s/it][A100%|██████████| 1/1 [02:01<00:00, 121.49s/it]
 13%|█▎        | 697/5198 [19:57:38<133:41:38, 106.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 15:22:45,535] [INFO] [logging.py:96:log_dist] [Rank 0] step=689, skipped=0, lr=[1.9573580693688217e-05], mom=[(0.9, 0.999)]
steps: 689 loss: 0.5646 iter time (s): 121.085 samples/sec: 1.057

100%|██████████| 1/1 [02:01<00:00, 121.86s/it][A100%|██████████| 1/1 [02:01<00:00, 121.86s/it]
 13%|█▎        | 697/5198 [19:57:40<133:56:13, 107.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:01<00:00, 121.91s/it][A100%|██████████| 1/1 [02:01<00:00, 121.91s/it]
 13%|█▎        | 697/5198 [19:57:40<133:57:53, 107.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:01<00:00, 121.79s/it][A100%|██████████| 1/1 [02:01<00:00, 121.80s/it]
 13%|█▎        | 697/5198 [19:57:40<133:57:15, 107.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:01<00:00, 121.93s/it][A100%|██████████| 1/1 [02:01<00:00, 121.93s/it]
 13%|█▎        | 697/5198 [19:57:40<133:58:34, 107.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:01<00:00, 121.95s/it][A100%|██████████| 1/1 [02:01<00:00, 121.95s/it]
 13%|█▎        | 697/5198 [19:57:40<133:58:35, 107.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:01<00:00, 121.90s/it][A100%|██████████| 1/1 [02:01<00:00, 121.90s/it]
 13%|█▎        | 697/5198 [19:57:40<133:57:40, 107.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:01<00:00, 121.93s/it][A100%|██████████| 1/1 [02:01<00:00, 121.93s/it]
 13%|█▎        | 697/5198 [19:57:43<133:58:08, 107.15s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_654
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.25s/it][A100%|██████████| 1/1 [01:39<00:00, 99.25s/it]
 13%|█▎        | 698/5198 [19:59:18<130:50:35, 104.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 15:24:24,345] [INFO] [logging.py:96:log_dist] [Rank 0] step=690, skipped=0, lr=[1.9571942849029e-05], mom=[(0.9, 0.999)]
steps: 690 loss: 0.6081 iter time (s): 97.963 samples/sec: 1.307

100%|██████████| 1/1 [01:38<00:00, 98.81s/it][A100%|██████████| 1/1 [01:38<00:00, 98.81s/it]
 13%|█▎        | 698/5198 [19:59:18<130:47:42, 104.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.72s/it][A100%|██████████| 1/1 [01:38<00:00, 98.72s/it]
 13%|█▎        | 698/5198 [19:59:19<130:46:34, 104.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.77s/it][A100%|██████████| 1/1 [01:38<00:00, 98.77s/it]
 13%|█▎        | 698/5198 [19:59:19<130:47:19, 104.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.69s/it][A100%|██████████| 1/1 [01:38<00:00, 98.69s/it]
 13%|█▎        | 698/5198 [19:59:19<130:46:29, 104.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.69s/it][A100%|██████████| 1/1 [01:38<00:00, 98.69s/it]
 13%|█▎        | 698/5198 [19:59:19<130:46:25, 104.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.75s/it][A100%|██████████| 1/1 [01:38<00:00, 98.75s/it]
 13%|█▎        | 698/5198 [19:59:19<130:47:07, 104.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.73s/it][A100%|██████████| 1/1 [01:38<00:00, 98.73s/it]
 13%|█▎        | 698/5198 [19:59:21<130:46:57, 104.63s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_655
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.47s/it][A100%|██████████| 1/1 [01:34<00:00, 94.47s/it]
 13%|█▎        | 699/5198 [20:00:52<127:02:22, 101.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 15:25:58,813] [INFO] [logging.py:96:log_dist] [Rank 0] step=691, skipped=0, lr=[1.957030193377374e-05], mom=[(0.9, 0.999)]
steps: 691 loss: 0.5971 iter time (s): 93.698 samples/sec: 1.366

100%|██████████| 1/1 [01:34<00:00, 94.49s/it][A100%|██████████| 1/1 [01:34<00:00, 94.49s/it]
 13%|█▎        | 699/5198 [20:00:53<126:57:55, 101.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.54s/it][A100%|██████████| 1/1 [01:34<00:00, 94.54s/it]
 13%|█▎        | 699/5198 [20:00:53<126:58:14, 101.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.50s/it][A100%|██████████| 1/1 [01:34<00:00, 94.50s/it]
 13%|█▎        | 699/5198 [20:00:54<126:57:56, 101.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.55s/it][A100%|██████████| 1/1 [01:34<00:00, 94.55s/it]
 13%|█▎        | 699/5198 [20:00:54<126:58:25, 101.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.52s/it][A100%|██████████| 1/1 [01:34<00:00, 94.52s/it]
 13%|█▎        | 699/5198 [20:00:54<126:57:45, 101.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.52s/it][A100%|██████████| 1/1 [01:34<00:00, 94.52s/it]
 13%|█▎        | 699/5198 [20:00:54<126:58:15, 101.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.54s/it][A100%|██████████| 1/1 [01:34<00:00, 94.54s/it]
 13%|█▎        | 699/5198 [20:00:56<126:58:24, 101.60s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_656
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.05s/it][A100%|██████████| 1/1 [01:26<00:00, 86.05s/it]
[2024-06-30 15:27:24,817] [INFO] [logging.py:96:log_dist] [Rank 0] step=692, skipped=0, lr=[1.956865794844888e-05], mom=[(0.9, 0.999)]
steps: 692 loss: 0.5843 iter time (s): 85.158 samples/sec: 1.503

100%|██████████| 1/1 [01:26<00:00, 86.00s/it][A100%|██████████| 1/1 [01:26<00:00, 86.00s/it]

100%|██████████| 1/1 [01:26<00:00, 86.01s/it][A100%|██████████| 1/1 [01:26<00:00, 86.01s/it]

100%|██████████| 1/1 [01:25<00:00, 85.96s/it][A100%|██████████| 1/1 [01:25<00:00, 85.96s/it]

100%|██████████| 1/1 [01:25<00:00, 85.93s/it][A100%|██████████| 1/1 [01:25<00:00, 85.93s/it]

100%|██████████| 1/1 [01:25<00:00, 85.98s/it][A100%|██████████| 1/1 [01:25<00:00, 85.98s/it]

100%|██████████| 1/1 [01:25<00:00, 85.97s/it][A100%|██████████| 1/1 [01:25<00:00, 85.97s/it]

100%|██████████| 1/1 [01:25<00:00, 85.97s/it][A100%|██████████| 1/1 [01:25<00:00, 85.97s/it]
Checkpointing at shard 699
[2024-06-30 15:27:25,620] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step692 is about to be saved!
[2024-06-30 15:27:26,665] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step692/layer_00-model_states.pt...
[2024-06-30 15:27:29,371] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step692/layer_02-model_states.pt...
[2024-06-30 15:27:32,277] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step692/layer_06-model_states.pt...
[2024-06-30 15:27:32,821] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step692/layer_07-model_states.pt...
[2024-06-30 15:27:33,246] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step692/layer_08-model_states.pt...
[2024-06-30 15:27:33,419] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step692/layer_00-model_states.pt.
[2024-06-30 15:27:33,808] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step692/layer_05-model_states.pt...
[2024-06-30 15:27:38,614] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step692/layer_01-model_states.pt...
[2024-06-30 15:27:39,848] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step692/layer_03-model_states.pt...
[2024-06-30 15:27:40,067] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step692/layer_04-model_states.pt...
[2024-06-30 15:30:47,170] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step692/layer_04-model_states.pt.
[2024-06-30 15:30:47,773] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step692/mp_rank_03_model_states.pt...
[2024-06-30 15:30:47,997] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step692/mp_rank_03_model_states.pt.
[2024-06-30 15:30:47,997] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step692 is ready now!
[2024-06-30 15:30:50,553] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step692/layer_02-model_states.pt.
[2024-06-30 15:30:50,588] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step692/layer_03-model_states.pt.
[2024-06-30 15:30:50,592] [INFO] [logging.py:96:log_dist] [Rank 1] Saving model checkpoint: /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step692/mp_rank_01_model_states.pt
[2024-06-30 15:30:50,592] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step692/mp_rank_01_model_states.pt...
[2024-06-30 15:30:50,711] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step692/mp_rank_02_model_states.pt...
[2024-06-30 15:30:50,820] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step692/mp_rank_01_model_states.pt.
[2024-06-30 15:30:50,820] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step692 is ready now!
[2024-06-30 15:30:50,885] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step692/mp_rank_02_model_states.pt.
[2024-06-30 15:30:50,885] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step692 is ready now!
[2024-06-30 15:31:02,012] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step692/layer_01-model_states.pt.
[2024-06-30 15:31:02,431] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step692/mp_rank_00_model_states.pt
[2024-06-30 15:31:02,432] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step692/mp_rank_00_model_states.pt...
[2024-06-30 15:31:03,558] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step692/mp_rank_00_model_states.pt.
[2024-06-30 15:31:03,558] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step692 is ready now!
[2024-06-30 15:31:25,159] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step692/layer_05-model_states.pt.
[2024-06-30 15:31:25,433] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step692/mp_rank_04_model_states.pt...
[2024-06-30 15:31:25,537] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step692/mp_rank_04_model_states.pt.
[2024-06-30 15:31:25,537] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step692 is ready now!
[2024-06-30 15:31:27,887] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step692/layer_07-model_states.pt.
[2024-06-30 15:31:28,173] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step692/mp_rank_06_model_states.pt...
[2024-06-30 15:31:28,254] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step692/mp_rank_06_model_states.pt.
[2024-06-30 15:31:28,254] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step692 is ready now!
[2024-06-30 15:31:28,637] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step692/layer_06-model_states.pt.
[2024-06-30 15:31:28,677] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step692/mp_rank_05_model_states.pt...
[2024-06-30 15:31:28,763] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step692/mp_rank_05_model_states.pt.
[2024-06-30 15:31:28,764] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step692 is ready now!
[2024-06-30 15:31:29,364] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step692/layer_08-model_states.pt.
[2024-06-30 15:31:29,857] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step692/layer_09-model_states.pt...
[2024-06-30 15:31:30,432] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step692/layer_09-model_states.pt.
[2024-06-30 15:31:30,435] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step692/mp_rank_07_model_states.pt...
[2024-06-30 15:31:30,484] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step692/mp_rank_07_model_states.pt.
[2024-06-30 15:31:30,484] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step692 is ready now!
 13%|█▎        | 700/5198 [20:06:26<214:03:52, 171.33s/it] 13%|█▎        | 700/5198 [20:06:24<212:59:28, 170.47s/it] 13%|█▎        | 700/5198 [20:06:24<213:02:53, 170.51s/it]Checkpoint saved using --- 244.86576461791992 seconds ---
 13%|█▎        | 700/5198 [20:06:25<212:55:57, 170.42s/it] 13%|█▎        | 700/5198 [20:06:27<212:52:18, 170.37s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_657
 13%|█▎        | 700/5198 [20:06:25<212:53:51, 170.39s/it] 13%|█▎        | 700/5198 [20:06:25<212:52:38, 170.38s/it] 13%|█▎        | 700/5198 [20:06:25<212:54:33, 170.40s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A

  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.95s/it][A100%|██████████| 1/1 [01:35<00:00, 95.95s/it]
 13%|█▎        | 701/5198 [20:08:02<185:50:30, 148.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 15:33:08,968] [INFO] [logging.py:96:log_dist] [Rank 0] step=693, skipped=0, lr=[1.9567010893581858e-05], mom=[(0.9, 0.999)]
steps: 693 loss: 0.5380 iter time (s): 98.311 samples/sec: 1.302

100%|██████████| 1/1 [01:38<00:00, 98.79s/it][A100%|██████████| 1/1 [01:38<00:00, 98.79s/it]
 13%|█▎        | 701/5198 [20:08:03<186:11:41, 149.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.06s/it][A100%|██████████| 1/1 [01:39<00:00, 99.06s/it]
 13%|█▎        | 701/5198 [20:08:04<186:12:50, 149.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.12s/it][A100%|██████████| 1/1 [01:39<00:00, 99.12s/it]
 13%|█▎        | 701/5198 [20:08:04<186:16:39, 149.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.42s/it][A100%|██████████| 1/1 [01:39<00:00, 99.42s/it]
 13%|█▎        | 701/5198 [20:08:04<186:19:24, 149.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.44s/it][A100%|██████████| 1/1 [01:39<00:00, 99.44s/it]
 13%|█▎        | 701/5198 [20:08:04<186:20:36, 149.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.70s/it][A100%|██████████| 1/1 [01:39<00:00, 99.70s/it]
 13%|█▎        | 701/5198 [20:08:07<186:24:32, 149.23s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_658
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.74s/it][A100%|██████████| 1/1 [01:39<00:00, 99.74s/it]
 13%|█▎        | 701/5198 [20:08:05<186:25:45, 149.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.00s/it][A100%|██████████| 1/1 [01:41<00:00, 101.01s/it]
 14%|█▎        | 702/5198 [20:09:44<167:59:07, 134.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 15:34:50,237] [INFO] [logging.py:96:log_dist] [Rank 0] step=694, skipped=0, lr=[1.956536076970108e-05], mom=[(0.9, 0.999)]
steps: 694 loss: 0.5969 iter time (s): 99.833 samples/sec: 1.282

100%|██████████| 1/1 [01:41<00:00, 101.14s/it][A100%|██████████| 1/1 [01:41<00:00, 101.14s/it]
 14%|█▎        | 702/5198 [20:09:44<168:12:44, 134.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.94s/it][A100%|██████████| 1/1 [01:40<00:00, 100.94s/it]
 14%|█▎        | 702/5198 [20:09:45<168:11:19, 134.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.07s/it][A100%|██████████| 1/1 [01:41<00:00, 101.07s/it]
 14%|█▎        | 702/5198 [20:09:45<168:11:49, 134.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.87s/it][A100%|██████████| 1/1 [01:40<00:00, 100.87s/it]
 14%|█▎        | 702/5198 [20:09:45<168:11:30, 134.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.85s/it][A100%|██████████| 1/1 [01:40<00:00, 100.85s/it]
 14%|█▎        | 702/5198 [20:09:45<168:12:00, 134.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.62s/it][A100%|██████████| 1/1 [01:40<00:00, 100.62s/it]
 14%|█▎        | 702/5198 [20:09:45<168:10:33, 134.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.68s/it][A100%|██████████| 1/1 [01:40<00:00, 100.68s/it]
 14%|█▎        | 702/5198 [20:09:47<168:11:12, 134.67s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_659
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.50s/it][A100%|██████████| 1/1 [01:31<00:00, 91.50s/it]
 14%|█▎        | 703/5198 [20:11:15<151:54:14, 121.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 15:36:21,670] [INFO] [logging.py:96:log_dist] [Rank 0] step=695, skipped=0, lr=[1.9563707577335952e-05], mom=[(0.9, 0.999)]
steps: 695 loss: 0.5857 iter time (s): 90.579 samples/sec: 1.413

100%|██████████| 1/1 [01:31<00:00, 91.38s/it][A100%|██████████| 1/1 [01:31<00:00, 91.38s/it]
 14%|█▎        | 703/5198 [20:11:16<151:57:36, 121.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.43s/it][A100%|██████████| 1/1 [01:31<00:00, 91.43s/it]
 14%|█▎        | 703/5198 [20:11:16<151:57:20, 121.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.46s/it][A100%|██████████| 1/1 [01:31<00:00, 91.46s/it]
 14%|█▎        | 703/5198 [20:11:16<151:58:31, 121.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.38s/it][A100%|██████████| 1/1 [01:31<00:00, 91.38s/it]
 14%|█▎        | 703/5198 [20:11:16<151:56:41, 121.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.46s/it][A100%|██████████| 1/1 [01:31<00:00, 91.46s/it]
 14%|█▎        | 703/5198 [20:11:17<151:58:14, 121.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.42s/it][A100%|██████████| 1/1 [01:31<00:00, 91.42s/it]
 14%|█▎        | 703/5198 [20:11:17<151:56:44, 121.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.41s/it][A100%|██████████| 1/1 [01:31<00:00, 91.41s/it]
 14%|█▎        | 703/5198 [20:11:19<151:56:54, 121.69s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_43
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.19s/it][A100%|██████████| 1/1 [01:58<00:00, 118.19s/it]
 14%|█▎        | 704/5198 [20:13:14<150:38:10, 120.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 15:38:20,462] [INFO] [logging.py:96:log_dist] [Rank 0] step=696, skipped=0, lr=[1.9562051317016863e-05], mom=[(0.9, 0.999)]
steps: 696 loss: 0.7725 iter time (s): 118.208 samples/sec: 1.083

100%|██████████| 1/1 [01:59<00:00, 119.30s/it][A100%|██████████| 1/1 [01:59<00:00, 119.30s/it]
 14%|█▎        | 704/5198 [20:13:15<151:01:46, 120.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.20s/it][A100%|██████████| 1/1 [01:59<00:00, 119.20s/it]
 14%|█▎        | 704/5198 [20:13:15<150:59:26, 120.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.26s/it][A100%|██████████| 1/1 [01:59<00:00, 119.26s/it]
 14%|█▎        | 704/5198 [20:13:16<151:01:34, 120.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.22s/it][A100%|██████████| 1/1 [01:59<00:00, 119.22s/it]
 14%|█▎        | 704/5198 [20:13:16<151:00:26, 120.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.31s/it][A100%|██████████| 1/1 [01:59<00:00, 119.31s/it]
 14%|█▎        | 704/5198 [20:13:16<151:01:15, 120.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.23s/it][A100%|██████████| 1/1 [01:59<00:00, 119.23s/it]
 14%|█▎        | 704/5198 [20:13:18<150:59:37, 120.96s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_660
Training on 128 of 128 sentences.

100%|██████████| 1/1 [01:59<00:00, 119.25s/it][A
100%|██████████| 1/1 [01:59<00:00, 119.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A 14%|█▎        | 704/5198 [20:13:16<150:59:56, 120.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.35s/it][A100%|██████████| 1/1 [01:35<00:00, 95.35s/it]
 14%|█▎        | 705/5198 [20:14:49<141:11:53, 113.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 15:39:55,660] [INFO] [logging.py:96:log_dist] [Rank 0] step=697, skipped=0, lr=[1.9560391989275175e-05], mom=[(0.9, 0.999)]
steps: 697 loss: 0.5692 iter time (s): 93.926 samples/sec: 1.363

100%|██████████| 1/1 [01:34<00:00, 94.70s/it][A100%|██████████| 1/1 [01:34<00:00, 94.70s/it]
 14%|█▎        | 705/5198 [20:14:50<141:09:24, 113.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.79s/it][A100%|██████████| 1/1 [01:34<00:00, 94.79s/it]
 14%|█▎        | 705/5198 [20:14:50<141:09:54, 113.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.67s/it][A100%|██████████| 1/1 [01:34<00:00, 94.67s/it]
 14%|█▎        | 705/5198 [20:14:50<141:08:41, 113.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.68s/it][A100%|██████████| 1/1 [01:34<00:00, 94.68s/it]
 14%|█▎        | 705/5198 [20:14:50<141:08:35, 113.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.71s/it][A100%|██████████| 1/1 [01:34<00:00, 94.71s/it]
 14%|█▎        | 705/5198 [20:14:50<141:08:47, 113.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.69s/it][A100%|██████████| 1/1 [01:34<00:00, 94.69s/it]
 14%|█▎        | 705/5198 [20:14:51<141:07:55, 113.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.72s/it][A100%|██████████| 1/1 [01:34<00:00, 94.72s/it]
 14%|█▎        | 705/5198 [20:14:53<141:08:29, 113.09s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_661
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.41s/it][A100%|██████████| 1/1 [01:27<00:00, 87.41s/it]
 14%|█▎        | 706/5198 [20:16:17<131:35:13, 105.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 15:41:23,001] [INFO] [logging.py:96:log_dist] [Rank 0] step=698, skipped=0, lr=[1.9558729594643247e-05], mom=[(0.9, 0.999)]
steps: 698 loss: 0.5301 iter time (s): 86.526 samples/sec: 1.479

100%|██████████| 1/1 [01:27<00:00, 87.33s/it][A100%|██████████| 1/1 [01:27<00:00, 87.33s/it]
 14%|█▎        | 706/5198 [20:16:17<131:29:00, 105.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.28s/it][A100%|██████████| 1/1 [01:27<00:00, 87.28s/it]
 14%|█▎        | 706/5198 [20:16:17<131:28:16, 105.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.37s/it][A100%|██████████| 1/1 [01:27<00:00, 87.37s/it]
 14%|█▎        | 706/5198 [20:16:18<131:29:15, 105.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.36s/it][A100%|██████████| 1/1 [01:27<00:00, 87.36s/it]
 14%|█▎        | 706/5198 [20:16:18<131:29:00, 105.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.36s/it][A100%|██████████| 1/1 [01:27<00:00, 87.36s/it]
 14%|█▎        | 706/5198 [20:16:18<131:29:10, 105.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.36s/it][A100%|██████████| 1/1 [01:27<00:00, 87.36s/it]
 14%|█▎        | 706/5198 [20:16:18<131:28:35, 105.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.35s/it][A100%|██████████| 1/1 [01:27<00:00, 87.35s/it]
 14%|█▎        | 706/5198 [20:16:20<131:28:41, 105.37s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_662
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.08s/it][A100%|██████████| 1/1 [01:22<00:00, 82.08s/it]
 14%|█▎        | 707/5198 [20:17:39<122:53:23, 98.51s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 15:42:45,155] [INFO] [logging.py:96:log_dist] [Rank 0] step=699, skipped=0, lr=[1.9557064133654417e-05], mom=[(0.9, 0.999)]
steps: 699 loss: 0.5659 iter time (s): 81.319 samples/sec: 1.574

100%|██████████| 1/1 [01:22<00:00, 82.01s/it][A100%|██████████| 1/1 [01:22<00:00, 82.01s/it]
 14%|█▎        | 707/5198 [20:17:39<122:42:59, 98.37s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.06s/it][A100%|██████████| 1/1 [01:22<00:00, 82.06s/it]
 14%|█▎        | 707/5198 [20:17:39<122:43:19, 98.37s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.11s/it][A100%|██████████| 1/1 [01:22<00:00, 82.11s/it]
 14%|█▎        | 707/5198 [20:17:40<122:45:16, 98.40s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.02s/it][A100%|██████████| 1/1 [01:22<00:00, 82.02s/it]
 14%|█▎        | 707/5198 [20:17:40<122:43:05, 98.37s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.10s/it][A100%|██████████| 1/1 [01:22<00:00, 82.10s/it]
 14%|█▎        | 707/5198 [20:17:40<122:44:59, 98.40s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.08s/it][A100%|██████████| 1/1 [01:22<00:00, 82.08s/it]
 14%|█▎        | 707/5198 [20:17:40<122:44:02, 98.38s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.09s/it][A100%|██████████| 1/1 [01:22<00:00, 82.10s/it]
 14%|█▎        | 707/5198 [20:17:42<122:44:25, 98.39s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_663
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.88s/it][A100%|██████████| 1/1 [01:22<00:00, 82.88s/it]
 14%|█▎        | 708/5198 [20:19:02<117:05:56, 93.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 15:44:08,244] [INFO] [logging.py:96:log_dist] [Rank 0] step=700, skipped=0, lr=[1.9555395606842998e-05], mom=[(0.9, 0.999)]
steps: 700 loss: 0.5862 iter time (s): 82.312 samples/sec: 1.555

100%|██████████| 1/1 [01:23<00:00, 83.11s/it][A100%|██████████| 1/1 [01:23<00:00, 83.11s/it]
 14%|█▎        | 708/5198 [20:19:02<116:59:07, 93.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.13s/it][A100%|██████████| 1/1 [01:23<00:00, 83.14s/it]
 14%|█▎        | 708/5198 [20:19:02<116:59:43, 93.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.07s/it][A100%|██████████| 1/1 [01:23<00:00, 83.07s/it]
 14%|█▎        | 708/5198 [20:19:03<116:59:37, 93.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.11s/it][A100%|██████████| 1/1 [01:23<00:00, 83.11s/it]
 14%|█▎        | 708/5198 [20:19:03<116:59:05, 93.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.05s/it][A100%|██████████| 1/1 [01:23<00:00, 83.05s/it]
 14%|█▎        | 708/5198 [20:19:03<116:58:14, 93.78s/it]
100%|██████████| 1/1 [01:23<00:00, 83.07s/it][A100%|██████████| 1/1 [01:23<00:00, 83.07s/it]
 14%|█▎        | 708/5198 [20:19:03<116:59:25, 93.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.06s/it][A100%|██████████| 1/1 [01:23<00:00, 83.06s/it]
 14%|█▎        | 708/5198 [20:19:05<116:58:49, 93.79s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_664
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.78s/it][A100%|██████████| 1/1 [01:36<00:00, 96.79s/it]
 14%|█▎        | 709/5198 [20:20:39<118:14:14, 94.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 15:45:45,697] [INFO] [logging.py:96:log_dist] [Rank 0] step=701, skipped=0, lr=[1.9553724014744304e-05], mom=[(0.9, 0.999)]
steps: 701 loss: 0.6036 iter time (s): 96.699 samples/sec: 1.324

100%|██████████| 1/1 [01:37<00:00, 97.49s/it][A100%|██████████| 1/1 [01:37<00:00, 97.49s/it]
 14%|█▎        | 709/5198 [20:20:40<118:20:33, 94.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.49s/it][A100%|██████████| 1/1 [01:37<00:00, 97.49s/it]
 14%|█▎        | 709/5198 [20:20:40<118:20:57, 94.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.49s/it][A100%|██████████| 1/1 [01:37<00:00, 97.49s/it]
 14%|█▎        | 709/5198 [20:20:40<118:20:54, 94.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.46s/it][A100%|██████████| 1/1 [01:37<00:00, 97.46s/it]
 14%|█▎        | 709/5198 [20:20:40<118:20:00, 94.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.47s/it][A100%|██████████| 1/1 [01:37<00:00, 97.47s/it]
 14%|█▎        | 709/5198 [20:20:41<118:20:22, 94.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.51s/it][A100%|██████████| 1/1 [01:37<00:00, 97.51s/it]
 14%|█▎        | 709/5198 [20:20:41<118:20:31, 94.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.50s/it][A100%|██████████| 1/1 [01:37<00:00, 97.50s/it]
 14%|█▎        | 709/5198 [20:20:43<118:20:31, 94.91s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_665
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:01<00:00, 121.69s/it][A100%|██████████| 1/1 [02:01<00:00, 121.69s/it]
 14%|█▎        | 710/5198 [20:22:41<128:19:37, 102.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 15:47:48,227] [INFO] [logging.py:96:log_dist] [Rank 0] step=702, skipped=0, lr=[1.955204935789462e-05], mom=[(0.9, 0.999)]
steps: 702 loss: 0.6399 iter time (s): 121.717 samples/sec: 1.052

100%|██████████| 1/1 [02:02<00:00, 122.58s/it][A100%|██████████| 1/1 [02:02<00:00, 122.58s/it]
 14%|█▎        | 710/5198 [20:22:42<128:40:12, 103.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:02<00:00, 122.54s/it][A100%|██████████| 1/1 [02:02<00:00, 122.54s/it]
 14%|█▎        | 710/5198 [20:22:43<128:39:36, 103.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:02<00:00, 122.56s/it][A100%|██████████| 1/1 [02:02<00:00, 122.56s/it]
 14%|█▎        | 710/5198 [20:22:43<128:39:56, 103.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:02<00:00, 122.59s/it][A100%|██████████| 1/1 [02:02<00:00, 122.59s/it]
 14%|█▎        | 710/5198 [20:22:43<128:40:03, 103.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:02<00:00, 122.60s/it][A100%|██████████| 1/1 [02:02<00:00, 122.60s/it]
 14%|█▎        | 710/5198 [20:22:43<128:40:22, 103.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:02<00:00, 122.58s/it][A100%|██████████| 1/1 [02:02<00:00, 122.58s/it]
 14%|█▎        | 710/5198 [20:22:43<128:40:10, 103.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:02<00:00, 122.59s/it][A100%|██████████| 1/1 [02:02<00:00, 122.59s/it]
 14%|█▎        | 710/5198 [20:22:45<128:40:18, 103.21s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_666
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.24s/it][A100%|██████████| 1/1 [01:23<00:00, 83.24s/it]
 14%|█▎        | 711/5198 [20:24:05<121:01:00, 97.09s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 15:49:10,604] [INFO] [logging.py:96:log_dist] [Rank 0] step=703, skipped=0, lr=[1.9550371636831217e-05], mom=[(0.9, 0.999)]
steps: 703 loss: 0.5835 iter time (s): 81.499 samples/sec: 1.571

100%|██████████| 1/1 [01:22<00:00, 82.27s/it][A100%|██████████| 1/1 [01:22<00:00, 82.27s/it]
 14%|█▎        | 711/5198 [20:24:05<120:48:54, 96.93s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.26s/it][A100%|██████████| 1/1 [01:22<00:00, 82.26s/it]
 14%|█▎        | 711/5198 [20:24:05<120:48:08, 96.92s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.22s/it][A100%|██████████| 1/1 [01:22<00:00, 82.22s/it]
 14%|█▎        | 711/5198 [20:24:05<120:47:31, 96.91s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.26s/it][A100%|██████████| 1/1 [01:22<00:00, 82.26s/it]
 14%|█▎        | 711/5198 [20:24:05<120:48:38, 96.93s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.27s/it][A100%|██████████| 1/1 [01:22<00:00, 82.27s/it]
 14%|█▎        | 711/5198 [20:24:05<120:48:59, 96.93s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.28s/it][A100%|██████████| 1/1 [01:22<00:00, 82.28s/it]
 14%|█▎        | 711/5198 [20:24:05<120:49:03, 96.93s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.27s/it][A100%|██████████| 1/1 [01:22<00:00, 82.27s/it]
 14%|█▎        | 711/5198 [20:24:08<120:48:54, 96.93s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_667
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.98s/it][A100%|██████████| 1/1 [01:33<00:00, 93.98s/it]
 14%|█▎        | 712/5198 [20:25:39<119:53:00, 96.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 15:50:45,086] [INFO] [logging.py:96:log_dist] [Rank 0] step=704, skipped=0, lr=[1.9548690852092347e-05], mom=[(0.9, 0.999)]
steps: 704 loss: 0.6073 iter time (s): 93.703 samples/sec: 1.366

100%|██████████| 1/1 [01:34<00:00, 94.59s/it][A100%|██████████| 1/1 [01:34<00:00, 94.59s/it]
 14%|█▎        | 712/5198 [20:25:39<119:54:49, 96.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.51s/it][A100%|██████████| 1/1 [01:34<00:00, 94.51s/it]
 14%|█▎        | 712/5198 [20:25:39<119:52:37, 96.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.55s/it][A100%|██████████| 1/1 [01:34<00:00, 94.55s/it]
 14%|█▎        | 712/5198 [20:25:40<119:52:57, 96.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.56s/it][A100%|██████████| 1/1 [01:34<00:00, 94.57s/it]
 14%|█▎        | 712/5198 [20:25:40<119:54:10, 96.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.57s/it][A100%|██████████| 1/1 [01:34<00:00, 94.57s/it]
 14%|█▎        | 712/5198 [20:25:40<119:54:27, 96.23s/it]
100%|██████████| 1/1 [01:34<00:00, 94.53s/it][A100%|██████████| 1/1 [01:34<00:00, 94.53s/it]
 14%|█▎        | 712/5198 [20:25:40<119:53:44, 96.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.53s/it][A100%|██████████| 1/1 [01:34<00:00, 94.53s/it]
 14%|█▎        | 712/5198 [20:25:42<119:53:34, 96.21s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_668
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.13s/it][A100%|██████████| 1/1 [01:28<00:00, 88.13s/it]
 14%|█▎        | 713/5198 [20:27:07<116:53:08, 93.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 15:52:12,734] [INFO] [logging.py:96:log_dist] [Rank 0] step=705, skipped=0, lr=[1.9547007004217252e-05], mom=[(0.9, 0.999)]
steps: 705 loss: 0.5679 iter time (s): 86.812 samples/sec: 1.474

100%|██████████| 1/1 [01:27<00:00, 87.53s/it][A100%|██████████| 1/1 [01:27<00:00, 87.53s/it]
 14%|█▎        | 713/5198 [20:27:07<116:38:16, 93.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.65s/it][A100%|██████████| 1/1 [01:27<00:00, 87.65s/it]
 14%|█▎        | 713/5198 [20:27:07<116:39:36, 93.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.66s/it][A100%|██████████| 1/1 [01:27<00:00, 87.67s/it]
 14%|█▎        | 713/5198 [20:27:07<116:40:00, 93.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.59s/it][A100%|██████████| 1/1 [01:27<00:00, 87.59s/it]
 14%|█▎        | 713/5198 [20:27:07<116:39:10, 93.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.59s/it][A100%|██████████| 1/1 [01:27<00:00, 87.59s/it]
 14%|█▎        | 713/5198 [20:27:08<116:39:26, 93.64s/it]
100%|██████████| 1/1 [01:27<00:00, 87.59s/it][A100%|██████████| 1/1 [01:27<00:00, 87.59s/it]
 14%|█▎        | 713/5198 [20:27:08<116:38:54, 93.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.60s/it][A100%|██████████| 1/1 [01:27<00:00, 87.60s/it]
 14%|█▎        | 713/5198 [20:27:10<116:39:04, 93.63s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_669
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.26s/it][A100%|██████████| 1/1 [01:42<00:00, 102.26s/it]
 14%|█▎        | 714/5198 [20:28:49<120:04:34, 96.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 15:53:55,986] [INFO] [logging.py:96:log_dist] [Rank 0] step=706, skipped=0, lr=[1.9545320093746153e-05], mom=[(0.9, 0.999)]
steps: 706 loss: 0.5609 iter time (s): 102.460 samples/sec: 1.249

100%|██████████| 1/1 [01:43<00:00, 103.30s/it][A100%|██████████| 1/1 [01:43<00:00, 103.30s/it]
 14%|█▎        | 714/5198 [20:28:50<120:14:04, 96.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.34s/it][A100%|██████████| 1/1 [01:43<00:00, 103.34s/it]
 14%|█▎        | 714/5198 [20:28:50<120:15:46, 96.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.29s/it][A100%|██████████| 1/1 [01:43<00:00, 103.29s/it]
 14%|█▎        | 714/5198 [20:28:51<120:15:01, 96.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.32s/it][A100%|██████████| 1/1 [01:43<00:00, 103.32s/it]
 14%|█▎        | 714/5198 [20:28:51<120:14:51, 96.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.32s/it][A100%|██████████| 1/1 [01:43<00:00, 103.32s/it]
 14%|█▎        | 714/5198 [20:28:51<120:15:00, 96.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.34s/it][A100%|██████████| 1/1 [01:43<00:00, 103.34s/it]
 14%|█▎        | 714/5198 [20:28:51<120:15:08, 96.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.32s/it][A100%|██████████| 1/1 [01:43<00:00, 103.32s/it]
 14%|█▎        | 714/5198 [20:28:53<120:14:53, 96.54s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_670
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.05s/it][A100%|██████████| 1/1 [01:35<00:00, 95.05s/it]
 14%|█▍        | 715/5198 [20:30:25<119:36:35, 96.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 15:55:30,990] [INFO] [logging.py:96:log_dist] [Rank 0] step=707, skipped=0, lr=[1.9543630121220246e-05], mom=[(0.9, 0.999)]
steps: 707 loss: 0.5682 iter time (s): 94.135 samples/sec: 1.360

100%|██████████| 1/1 [01:35<00:00, 95.04s/it][A100%|██████████| 1/1 [01:35<00:00, 95.04s/it]
 14%|█▍        | 715/5198 [20:30:25<119:39:15, 96.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.10s/it][A100%|██████████| 1/1 [01:35<00:00, 95.10s/it]
 14%|█▍        | 715/5198 [20:30:25<119:41:45, 96.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.10s/it][A100%|██████████| 1/1 [01:35<00:00, 95.10s/it]
 14%|█▍        | 715/5198 [20:30:26<119:41:16, 96.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.06s/it][A100%|██████████| 1/1 [01:35<00:00, 95.06s/it]
 14%|█▍        | 715/5198 [20:30:26<119:40:07, 96.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.05s/it][A100%|██████████| 1/1 [01:35<00:00, 95.05s/it]
 14%|█▍        | 715/5198 [20:30:26<119:39:59, 96.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.05s/it][A100%|██████████| 1/1 [01:35<00:00, 95.05s/it]
 14%|█▍        | 715/5198 [20:30:28<119:39:56, 96.10s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_671

100%|██████████| 1/1 [01:35<00:00, 95.06s/it][A100%|██████████| 1/1 [01:35<00:00, 95.06s/it]
 14%|█▍        | 715/5198 [20:30:26<119:40:25, 96.10s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:17<00:00, 77.51s/it][A100%|██████████| 1/1 [01:17<00:00, 77.52s/it]
 14%|█▍        | 716/5198 [20:31:42<112:42:27, 90.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 15:56:48,171] [INFO] [logging.py:96:log_dist] [Rank 0] step=708, skipped=0, lr=[1.954193708718172e-05], mom=[(0.9, 0.999)]
steps: 708 loss: 0.5963 iter time (s): 76.262 samples/sec: 1.678

100%|██████████| 1/1 [01:17<00:00, 77.00s/it][A100%|██████████| 1/1 [01:17<00:00, 77.00s/it]
 14%|█▍        | 716/5198 [20:31:42<112:30:11, 90.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:16<00:00, 76.91s/it][A100%|██████████| 1/1 [01:16<00:00, 76.91s/it]
 14%|█▍        | 716/5198 [20:31:42<112:29:47, 90.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:16<00:00, 76.95s/it][A100%|██████████| 1/1 [01:16<00:00, 76.95s/it]
 14%|█▍        | 716/5198 [20:31:43<112:30:21, 90.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:17<00:00, 77.02s/it][A100%|██████████| 1/1 [01:17<00:00, 77.02s/it]
 14%|█▍        | 716/5198 [20:31:43<112:31:10, 90.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:17<00:00, 77.02s/it][A100%|██████████| 1/1 [01:17<00:00, 77.02s/it]
 14%|█▍        | 716/5198 [20:31:43<112:31:07, 90.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:16<00:00, 77.00s/it][A100%|██████████| 1/1 [01:16<00:00, 77.00s/it]
 14%|█▍        | 716/5198 [20:31:43<112:30:49, 90.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:17<00:00, 77.02s/it][A100%|██████████| 1/1 [01:17<00:00, 77.02s/it]
 14%|█▍        | 716/5198 [20:31:45<112:31:05, 90.38s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_672
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.88s/it][A100%|██████████| 1/1 [01:26<00:00, 86.88s/it]
 14%|█▍        | 717/5198 [20:33:09<111:21:31, 89.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 15:58:15,380] [INFO] [logging.py:96:log_dist] [Rank 0] step=709, skipped=0, lr=[1.9540240992173746e-05], mom=[(0.9, 0.999)]
steps: 709 loss: 0.6273 iter time (s): 86.439 samples/sec: 1.481

100%|██████████| 1/1 [01:27<00:00, 87.31s/it][A100%|██████████| 1/1 [01:27<00:00, 87.32s/it]
 14%|█▍        | 717/5198 [20:33:10<111:20:34, 89.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.24s/it][A100%|██████████| 1/1 [01:27<00:00, 87.24s/it]
 14%|█▍        | 717/5198 [20:33:10<111:18:36, 89.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.21s/it][A100%|██████████| 1/1 [01:27<00:00, 87.21s/it]
 14%|█▍        | 717/5198 [20:33:10<111:18:22, 89.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.16s/it][A100%|██████████| 1/1 [01:27<00:00, 87.16s/it]
 14%|█▍        | 717/5198 [20:33:10<111:17:45, 89.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.21s/it][A100%|██████████| 1/1 [01:27<00:00, 87.21s/it]
 14%|█▍        | 717/5198 [20:33:10<111:18:52, 89.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.21s/it][A100%|██████████| 1/1 [01:27<00:00, 87.21s/it]
 14%|█▍        | 717/5198 [20:33:12<111:18:52, 89.43s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_673

100%|██████████| 1/1 [01:27<00:00, 87.24s/it][A100%|██████████| 1/1 [01:27<00:00, 87.24s/it]
 14%|█▍        | 717/5198 [20:33:10<111:19:17, 89.43s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.95s/it][A100%|██████████| 1/1 [01:21<00:00, 81.95s/it]
 14%|█▍        | 718/5198 [20:34:31<108:35:18, 87.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 15:59:37,347] [INFO] [logging.py:96:log_dist] [Rank 0] step=710, skipped=0, lr=[1.953854183674047e-05], mom=[(0.9, 0.999)]
steps: 710 loss: 0.5276 iter time (s): 81.188 samples/sec: 1.577

100%|██████████| 1/1 [01:21<00:00, 81.95s/it][A100%|██████████| 1/1 [01:21<00:00, 81.95s/it]
 14%|█▍        | 718/5198 [20:34:32<108:31:18, 87.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.95s/it][A100%|██████████| 1/1 [01:21<00:00, 81.95s/it]
 14%|█▍        | 718/5198 [20:34:32<108:29:52, 87.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.97s/it][A100%|██████████| 1/1 [01:21<00:00, 81.97s/it]
 14%|█▍        | 718/5198 [20:34:32<108:30:11, 87.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.97s/it][A100%|██████████| 1/1 [01:21<00:00, 81.97s/it]
 14%|█▍        | 718/5198 [20:34:32<108:29:41, 87.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.93s/it][A100%|██████████| 1/1 [01:21<00:00, 81.93s/it]
 14%|█▍        | 718/5198 [20:34:32<108:29:37, 87.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.93s/it][A100%|██████████| 1/1 [01:21<00:00, 81.93s/it]
 14%|█▍        | 718/5198 [20:34:32<108:29:52, 87.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.96s/it][A100%|██████████| 1/1 [01:21<00:00, 81.96s/it]
 14%|█▍        | 718/5198 [20:34:34<108:30:16, 87.19s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_674
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.93s/it][A100%|██████████| 1/1 [01:31<00:00, 91.93s/it]
 14%|█▍        | 719/5198 [20:36:03<110:22:48, 88.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 16:01:09,782] [INFO] [logging.py:96:log_dist] [Rank 0] step=711, skipped=0, lr=[1.9536839621427022e-05], mom=[(0.9, 0.999)]
steps: 711 loss: 0.6076 iter time (s): 91.651 samples/sec: 1.397

100%|██████████| 1/1 [01:32<00:00, 92.38s/it][A100%|██████████| 1/1 [01:32<00:00, 92.38s/it]
 14%|█▍        | 719/5198 [20:36:04<110:25:55, 88.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.58s/it][A100%|██████████| 1/1 [01:32<00:00, 92.58s/it]
 14%|█▍        | 719/5198 [20:36:04<110:29:30, 88.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.56s/it][A100%|██████████| 1/1 [01:32<00:00, 92.56s/it]
 14%|█▍        | 719/5198 [20:36:05<110:29:17, 88.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][A100%|██████████| 1/1 [01:32<00:00, 92.53s/it][A100%|██████████| 1/1 [01:32<00:00, 92.53s/it]
 14%|█▍        | 719/5198 [20:36:05<110:28:13, 88.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.64s/it][A100%|██████████| 1/1 [01:32<00:00, 92.64s/it]
 14%|█▍        | 719/5198 [20:36:05<110:30:26, 88.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.69s/it][A100%|██████████| 1/1 [01:32<00:00, 92.69s/it]
 14%|█▍        | 719/5198 [20:36:05<110:31:52, 88.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.95s/it][A100%|██████████| 1/1 [01:32<00:00, 92.95s/it]
 14%|█▍        | 719/5198 [20:36:07<110:37:53, 88.92s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_44
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:02<00:00, 122.75s/it][A100%|██████████| 1/1 [02:02<00:00, 122.75s/it]
 14%|█▍        | 720/5198 [20:38:06<123:06:27, 98.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 16:03:12,977] [INFO] [logging.py:96:log_dist] [Rank 0] step=712, skipped=0, lr=[1.9535134346779515e-05], mom=[(0.9, 0.999)]
steps: 712 loss: 0.7548 iter time (s): 122.157 samples/sec: 1.048

100%|██████████| 1/1 [02:03<00:00, 123.50s/it][A100%|██████████| 1/1 [02:03<00:00, 123.50s/it]
 14%|█▍        | 720/5198 [20:38:07<123:22:27, 99.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.32s/it][A100%|██████████| 1/1 [02:03<00:00, 123.32s/it]
 14%|█▍        | 720/5198 [20:38:07<123:21:03, 99.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.34s/it][A100%|██████████| 1/1 [02:03<00:00, 123.34s/it]
 14%|█▍        | 720/5198 [20:38:08<123:21:34, 99.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.48s/it][A100%|██████████| 1/1 [02:03<00:00, 123.48s/it]
 14%|█▍        | 720/5198 [20:38:08<123:23:33, 99.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.35s/it][A100%|██████████| 1/1 [02:03<00:00, 123.35s/it]
 14%|█▍        | 720/5198 [20:38:08<123:22:34, 99.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.30s/it][A100%|██████████| 1/1 [02:03<00:00, 123.30s/it]
 14%|█▍        | 720/5198 [20:38:08<123:22:12, 99.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.04s/it][A100%|██████████| 1/1 [02:03<00:00, 123.04s/it]
 14%|█▍        | 720/5198 [20:38:10<123:20:30, 99.16s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_675
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.20s/it][A100%|██████████| 1/1 [01:26<00:00, 86.20s/it]
 14%|█▍        | 721/5198 [20:39:33<118:22:03, 95.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 16:04:38,782] [INFO] [logging.py:96:log_dist] [Rank 0] step=713, skipped=0, lr=[1.9533426013345048e-05], mom=[(0.9, 0.999)]
steps: 713 loss: 0.5771 iter time (s): 84.662 samples/sec: 1.512

100%|██████████| 1/1 [01:25<00:00, 85.56s/it][A100%|██████████| 1/1 [01:25<00:00, 85.56s/it]
 14%|█▍        | 721/5198 [20:39:33<118:16:11, 95.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.52s/it][A100%|██████████| 1/1 [01:25<00:00, 85.52s/it]
 14%|█▍        | 721/5198 [20:39:33<118:14:06, 95.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.47s/it][A100%|██████████| 1/1 [01:25<00:00, 85.47s/it]
 14%|█▍        | 721/5198 [20:39:33<118:13:20, 95.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.46s/it][A100%|██████████| 1/1 [01:25<00:00, 85.46s/it]
 14%|█▍        | 721/5198 [20:39:33<118:14:26, 95.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.43s/it][A100%|██████████| 1/1 [01:25<00:00, 85.43s/it]
 14%|█▍        | 721/5198 [20:39:34<118:13:13, 95.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.45s/it][A100%|██████████| 1/1 [01:25<00:00, 85.45s/it]
 14%|█▍        | 721/5198 [20:39:34<118:13:15, 95.06s/it]
100%|██████████| 1/1 [01:25<00:00, 85.43s/it][A100%|██████████| 1/1 [01:25<00:00, 85.43s/it]
 14%|█▍        | 721/5198 [20:39:36<118:11:41, 95.04s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_676

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.08s/it][A100%|██████████| 1/1 [01:59<00:00, 119.08s/it]
 14%|█▍        | 722/5198 [20:41:32<127:18:36, 102.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 16:06:38,997] [INFO] [logging.py:96:log_dist] [Rank 0] step=714, skipped=0, lr=[1.9531714621671693e-05], mom=[(0.9, 0.999)]
steps: 714 loss: 0.5578 iter time (s): 119.430 samples/sec: 1.072

100%|██████████| 1/1 [02:00<00:00, 120.15s/it][A100%|██████████| 1/1 [02:00<00:00, 120.15s/it]
 14%|█▍        | 722/5198 [20:41:33<127:35:23, 102.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.25s/it][A100%|██████████| 1/1 [02:00<00:00, 120.25s/it]
 14%|█▍        | 722/5198 [20:41:33<127:36:07, 102.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.26s/it][A100%|██████████| 1/1 [02:00<00:00, 120.26s/it]
 14%|█▍        | 722/5198 [20:41:34<127:35:59, 102.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.18s/it][A100%|██████████| 1/1 [02:00<00:00, 120.18s/it]
 14%|█▍        | 722/5198 [20:41:34<127:34:43, 102.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.17s/it][A100%|██████████| 1/1 [02:00<00:00, 120.17s/it]
 14%|█▍        | 722/5198 [20:41:34<127:33:49, 102.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.19s/it][A100%|██████████| 1/1 [02:00<00:00, 120.19s/it]
 14%|█▍        | 722/5198 [20:41:34<127:34:11, 102.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.21s/it][A100%|██████████| 1/1 [02:00<00:00, 120.21s/it]
 14%|█▍        | 722/5198 [20:41:36<127:33:24, 102.59s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_677
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.49s/it][A100%|██████████| 1/1 [01:27<00:00, 87.49s/it]
 14%|█▍        | 723/5198 [20:43:00<121:46:28, 97.96s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 16:08:05,709] [INFO] [logging.py:96:log_dist] [Rank 0] step=715, skipped=0, lr=[1.953000017230851e-05], mom=[(0.9, 0.999)]
steps: 715 loss: 0.5533 iter time (s): 85.932 samples/sec: 1.490

100%|██████████| 1/1 [01:26<00:00, 86.67s/it][A100%|██████████| 1/1 [01:26<00:00, 86.67s/it]
 14%|█▍        | 723/5198 [20:43:00<121:37:02, 97.84s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.58s/it][A100%|██████████| 1/1 [01:26<00:00, 86.58s/it]
 14%|█▍        | 723/5198 [20:43:00<121:35:24, 97.82s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.68s/it][A100%|██████████| 1/1 [01:26<00:00, 86.68s/it]
 14%|█▍        | 723/5198 [20:43:00<121:37:41, 97.85s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.67s/it][A100%|██████████| 1/1 [01:26<00:00, 86.67s/it]
 14%|█▍        | 723/5198 [20:43:00<121:36:00, 97.82s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.72s/it][A100%|██████████| 1/1 [01:26<00:00, 86.72s/it]
 14%|█▍        | 723/5198 [20:43:00<121:37:42, 97.85s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.69s/it][A100%|██████████| 1/1 [01:26<00:00, 86.69s/it]
 14%|█▍        | 723/5198 [20:43:01<121:36:31, 97.83s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.69s/it][A100%|██████████| 1/1 [01:26<00:00, 86.69s/it]
 14%|█▍        | 723/5198 [20:43:03<121:35:59, 97.82s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_678
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.74s/it][A100%|██████████| 1/1 [01:26<00:00, 86.74s/it]
 14%|█▍        | 724/5198 [20:44:26<117:37:30, 94.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 16:09:32,610] [INFO] [logging.py:96:log_dist] [Rank 0] step=716, skipped=0, lr=[1.9528282665805523e-05], mom=[(0.9, 0.999)]
steps: 716 loss: 0.5459 iter time (s): 86.137 samples/sec: 1.486

100%|██████████| 1/1 [01:26<00:00, 86.95s/it][A100%|██████████| 1/1 [01:26<00:00, 86.95s/it]
 14%|█▍        | 724/5198 [20:44:27<117:32:09, 94.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.22s/it][A100%|██████████| 1/1 [01:27<00:00, 87.22s/it]
 14%|█▍        | 724/5198 [20:44:27<117:37:03, 94.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.03s/it][A100%|██████████| 1/1 [01:27<00:00, 87.03s/it]
 14%|█▍        | 724/5198 [20:44:27<117:34:13, 94.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.12s/it][A100%|██████████| 1/1 [01:27<00:00, 87.12s/it]
 14%|█▍        | 724/5198 [20:44:28<117:35:01, 94.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.13s/it][A100%|██████████| 1/1 [01:27<00:00, 87.13s/it]
 14%|█▍        | 724/5198 [20:44:28<117:36:24, 94.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.11s/it][A100%|██████████| 1/1 [01:27<00:00, 87.11s/it]
 14%|█▍        | 724/5198 [20:44:28<117:35:17, 94.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.12s/it][A100%|██████████| 1/1 [01:27<00:00, 87.12s/it]
 14%|█▍        | 724/5198 [20:44:30<117:35:06, 94.61s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_679
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.83s/it][A100%|██████████| 1/1 [01:42<00:00, 102.83s/it]
 14%|█▍        | 725/5198 [20:46:09<120:42:26, 97.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 16:11:16,071] [INFO] [logging.py:96:log_dist] [Rank 0] step=717, skipped=0, lr=[1.9526562102713776e-05], mom=[(0.9, 0.999)]
steps: 717 loss: 0.5622 iter time (s): 102.471 samples/sec: 1.249

100%|██████████| 1/1 [01:43<00:00, 103.37s/it][A100%|██████████| 1/1 [01:43<00:00, 103.37s/it]
 14%|█▍        | 725/5198 [20:46:10<120:47:28, 97.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.16s/it][A100%|██████████| 1/1 [01:43<00:00, 103.16s/it]
 14%|█▍        | 725/5198 [20:46:10<120:46:07, 97.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.26s/it][A100%|██████████| 1/1 [01:43<00:00, 103.26s/it]
 14%|█▍        | 725/5198 [20:46:11<120:46:24, 97.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.11s/it][A100%|██████████| 1/1 [01:43<00:00, 103.11s/it]
 14%|█▍        | 725/5198 [20:46:11<120:44:29, 97.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.24s/it][A100%|██████████| 1/1 [01:43<00:00, 103.24s/it]
 14%|█▍        | 725/5198 [20:46:11<120:46:39, 97.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.22s/it][A100%|██████████| 1/1 [01:43<00:00, 103.22s/it]
 14%|█▍        | 725/5198 [20:46:11<120:46:21, 97.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.21s/it][A100%|██████████| 1/1 [01:43<00:00, 103.21s/it]
 14%|█▍        | 725/5198 [20:46:13<120:45:53, 97.20s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_680
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.87s/it][A100%|██████████| 1/1 [01:25<00:00, 85.87s/it]
 14%|█▍        | 726/5198 [20:47:35<116:31:51, 93.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 16:12:41,579] [INFO] [logging.py:96:log_dist] [Rank 0] step=718, skipped=0, lr=[1.9524838483585245e-05], mom=[(0.9, 0.999)]
steps: 718 loss: 0.5695 iter time (s): 84.764 samples/sec: 1.510

100%|██████████| 1/1 [01:25<00:00, 85.56s/it][A100%|██████████| 1/1 [01:25<00:00, 85.56s/it]
 14%|█▍        | 726/5198 [20:47:36<116:25:27, 93.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.57s/it][A100%|██████████| 1/1 [01:25<00:00, 85.57s/it]
 14%|█▍        | 726/5198 [20:47:36<116:24:45, 93.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.63s/it][A100%|██████████| 1/1 [01:25<00:00, 85.63s/it]
 14%|█▍        | 726/5198 [20:47:36<116:26:10, 93.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.66s/it][A100%|██████████| 1/1 [01:25<00:00, 85.66s/it]
 14%|█▍        | 726/5198 [20:47:36<116:25:35, 93.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.67s/it][A100%|██████████| 1/1 [01:25<00:00, 85.67s/it]
 14%|█▍        | 726/5198 [20:47:37<116:27:18, 93.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.65s/it][A100%|██████████| 1/1 [01:25<00:00, 85.65s/it]
 14%|█▍        | 726/5198 [20:47:37<116:26:43, 93.74s/it]
100%|██████████| 1/1 [01:25<00:00, 85.65s/it][A100%|██████████| 1/1 [01:25<00:00, 85.65s/it]
 14%|█▍        | 726/5198 [20:47:39<116:26:13, 93.73s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_681

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.16s/it][A100%|██████████| 1/1 [01:29<00:00, 89.16s/it]
 14%|█▍        | 727/5198 [20:49:05<114:49:36, 92.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 16:14:11,001] [INFO] [logging.py:96:log_dist] [Rank 0] step=719, skipped=0, lr=[1.9523111808972924e-05], mom=[(0.9, 0.999)]
steps: 719 loss: 0.5559 iter time (s): 88.537 samples/sec: 1.446

100%|██████████| 1/1 [01:29<00:00, 89.47s/it][A100%|██████████| 1/1 [01:29<00:00, 89.47s/it]
 14%|█▍        | 727/5198 [20:49:05<114:49:03, 92.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.48s/it][A100%|██████████| 1/1 [01:29<00:00, 89.48s/it]
 14%|█▍        | 727/5198 [20:49:05<114:48:51, 92.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.41s/it][A100%|██████████| 1/1 [01:29<00:00, 89.41s/it]
 14%|█▍        | 727/5198 [20:49:06<114:48:02, 92.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.40s/it][A100%|██████████| 1/1 [01:29<00:00, 89.40s/it]
 14%|█▍        | 727/5198 [20:49:06<114:47:31, 92.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.34s/it][A100%|██████████| 1/1 [01:29<00:00, 89.34s/it]
 14%|█▍        | 727/5198 [20:49:06<114:47:17, 92.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.34s/it][A100%|██████████| 1/1 [01:29<00:00, 89.34s/it]
 14%|█▍        | 727/5198 [20:49:06<114:46:58, 92.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.35s/it][A100%|██████████| 1/1 [01:29<00:00, 89.35s/it]
 14%|█▍        | 727/5198 [20:49:08<114:46:45, 92.42s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_682
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.06s/it][A100%|██████████| 1/1 [01:40<00:00, 100.06s/it]
 14%|█▍        | 728/5198 [20:50:45<117:41:56, 94.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 16:15:51,566] [INFO] [logging.py:96:log_dist] [Rank 0] step=720, skipped=0, lr=[1.9521382079430765e-05], mom=[(0.9, 0.999)]
steps: 720 loss: 0.5579 iter time (s): 99.743 samples/sec: 1.283

100%|██████████| 1/1 [01:40<00:00, 100.45s/it][A100%|██████████| 1/1 [01:40<00:00, 100.45s/it]
 14%|█▍        | 728/5198 [20:50:46<117:46:34, 94.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.44s/it][A100%|██████████| 1/1 [01:40<00:00, 100.44s/it]
 14%|█▍        | 728/5198 [20:50:46<117:46:12, 94.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.43s/it][A100%|██████████| 1/1 [01:40<00:00, 100.43s/it]
 14%|█▍        | 728/5198 [20:50:46<117:45:33, 94.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.46s/it][A100%|██████████| 1/1 [01:40<00:00, 100.46s/it]
 14%|█▍        | 728/5198 [20:50:46<117:45:33, 94.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.49s/it][A100%|██████████| 1/1 [01:40<00:00, 100.49s/it]
 14%|█▍        | 728/5198 [20:50:46<117:46:05, 94.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.46s/it][A100%|██████████| 1/1 [01:40<00:00, 100.46s/it]
 14%|█▍        | 728/5198 [20:50:46<117:45:16, 94.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.48s/it][A100%|██████████| 1/1 [01:40<00:00, 100.48s/it]
 14%|█▍        | 728/5198 [20:50:49<117:45:31, 94.84s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_683
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.97s/it][A100%|██████████| 1/1 [01:30<00:00, 90.97s/it]
 14%|█▍        | 729/5198 [20:52:16<116:17:49, 93.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 16:17:22,378] [INFO] [logging.py:96:log_dist] [Rank 0] step=721, skipped=0, lr=[1.9519649295513715e-05], mom=[(0.9, 0.999)]
steps: 721 loss: 0.5370 iter time (s): 90.068 samples/sec: 1.421

100%|██████████| 1/1 [01:30<00:00, 90.88s/it][A100%|██████████| 1/1 [01:30<00:00, 90.88s/it]
 14%|█▍        | 729/5198 [20:52:17<116:16:27, 93.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.80s/it][A100%|██████████| 1/1 [01:30<00:00, 90.80s/it]
 14%|█▍        | 729/5198 [20:52:17<116:14:31, 93.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.85s/it][A100%|██████████| 1/1 [01:30<00:00, 90.85s/it]
 14%|█▍        | 729/5198 [20:52:17<116:14:58, 93.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.88s/it][A100%|██████████| 1/1 [01:30<00:00, 90.88s/it]
 14%|█▍        | 729/5198 [20:52:17<116:15:33, 93.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.85s/it][A100%|██████████| 1/1 [01:30<00:00, 90.85s/it]
 14%|█▍        | 729/5198 [20:52:17<116:15:22, 93.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.91s/it][A100%|██████████| 1/1 [01:30<00:00, 90.91s/it]
 14%|█▍        | 729/5198 [20:52:17<116:16:06, 93.66s/it]
100%|██████████| 1/1 [01:30<00:00, 90.88s/it][A100%|██████████| 1/1 [01:30<00:00, 90.88s/it]
 14%|█▍        | 729/5198 [20:52:20<116:15:42, 93.65s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_684
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.26s/it][A100%|██████████| 1/1 [01:38<00:00, 98.26s/it]
 14%|█▍        | 730/5198 [20:53:54<118:01:09, 95.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 16:19:00,946] [INFO] [logging.py:96:log_dist] [Rank 0] step=722, skipped=0, lr=[1.9517913457777686e-05], mom=[(0.9, 0.999)]
steps: 722 loss: 0.5652 iter time (s): 97.747 samples/sec: 1.310

100%|██████████| 1/1 [01:38<00:00, 98.55s/it][A100%|██████████| 1/1 [01:38<00:00, 98.55s/it]
 14%|█▍        | 730/5198 [20:53:55<118:04:17, 95.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.64s/it][A100%|██████████| 1/1 [01:38<00:00, 98.64s/it]
 14%|█▍        | 730/5198 [20:53:55<118:05:05, 95.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.59s/it][A100%|██████████| 1/1 [01:38<00:00, 98.59s/it]
 14%|█▍        | 730/5198 [20:53:56<118:03:58, 95.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.61s/it][A100%|██████████| 1/1 [01:38<00:00, 98.61s/it]
 14%|█▍        | 730/5198 [20:53:56<118:04:52, 95.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.55s/it][A100%|██████████| 1/1 [01:38<00:00, 98.55s/it]
 14%|█▍        | 730/5198 [20:53:56<118:03:20, 95.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.54s/it][A100%|██████████| 1/1 [01:38<00:00, 98.54s/it]
 14%|█▍        | 730/5198 [20:53:56<118:03:49, 95.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.58s/it][A100%|██████████| 1/1 [01:38<00:00, 98.58s/it]
 14%|█▍        | 730/5198 [20:53:58<118:04:12, 95.13s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_685
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.52s/it][A100%|██████████| 1/1 [01:26<00:00, 86.52s/it]
 14%|█▍        | 731/5198 [20:55:21<114:51:27, 92.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 16:20:27,304] [INFO] [logging.py:96:log_dist] [Rank 0] step=723, skipped=0, lr=[1.9516174566779588e-05], mom=[(0.9, 0.999)]
steps: 723 loss: 0.6052 iter time (s): 85.523 samples/sec: 1.497

100%|██████████| 1/1 [01:26<00:00, 86.29s/it][A100%|██████████| 1/1 [01:26<00:00, 86.29s/it]
 14%|█▍        | 731/5198 [20:55:21<114:45:17, 92.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.22s/it][A100%|██████████| 1/1 [01:26<00:00, 86.22s/it]
 14%|█▍        | 731/5198 [20:55:21<114:44:23, 92.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.26s/it][A100%|██████████| 1/1 [01:26<00:00, 86.26s/it]
 14%|█▍        | 731/5198 [20:55:22<114:44:24, 92.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.29s/it][A100%|██████████| 1/1 [01:26<00:00, 86.29s/it]
 14%|█▍        | 731/5198 [20:55:22<114:45:41, 92.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.34s/it][A100%|██████████| 1/1 [01:26<00:00, 86.34s/it]
 14%|█▍        | 731/5198 [20:55:22<114:45:44, 92.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.29s/it][A100%|██████████| 1/1 [01:26<00:00, 86.29s/it]
 14%|█▍        | 731/5198 [20:55:22<114:44:54, 92.48s/it]
100%|██████████| 1/1 [01:26<00:00, 86.26s/it][A100%|██████████| 1/1 [01:26<00:00, 86.26s/it]
 14%|█▍        | 731/5198 [20:55:24<114:44:36, 92.47s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_686

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.64s/it][A100%|██████████| 1/1 [01:39<00:00, 99.64s/it]
 14%|█▍        | 732/5198 [20:57:01<117:30:50, 94.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 16:22:07,408] [INFO] [logging.py:96:log_dist] [Rank 0] step=724, skipped=0, lr=[1.951443262307729e-05], mom=[(0.9, 0.999)]
steps: 724 loss: 0.6143 iter time (s): 99.361 samples/sec: 1.288

100%|██████████| 1/1 [01:40<00:00, 100.10s/it][A100%|██████████| 1/1 [01:40<00:00, 100.10s/it]
 14%|█▍        | 732/5198 [20:57:02<117:34:06, 94.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.17s/it][A100%|██████████| 1/1 [01:40<00:00, 100.17s/it]
 14%|█▍        | 732/5198 [20:57:02<117:34:55, 94.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.19s/it][A100%|██████████| 1/1 [01:40<00:00, 100.19s/it]
 14%|█▍        | 732/5198 [20:57:02<117:35:22, 94.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.08s/it][A100%|██████████| 1/1 [01:40<00:00, 100.08s/it]
 14%|█▍        | 732/5198 [20:57:02<117:33:47, 94.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.10s/it][A100%|██████████| 1/1 [01:40<00:00, 100.10s/it]
 14%|█▍        | 732/5198 [20:57:02<117:34:25, 94.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.12s/it][A100%|██████████| 1/1 [01:40<00:00, 100.12s/it]
 14%|█▍        | 732/5198 [20:57:02<117:34:07, 94.77s/it]
100%|██████████| 1/1 [01:40<00:00, 100.12s/it][A100%|██████████| 1/1 [01:40<00:00, 100.12s/it]
 14%|█▍        | 732/5198 [20:57:04<117:33:53, 94.77s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_687

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:02<00:00, 122.86s/it][A100%|██████████| 1/1 [02:02<00:00, 122.86s/it]
 14%|█▍        | 733/5198 [20:59:04<127:59:43, 103.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 16:24:11,000] [INFO] [logging.py:96:log_dist] [Rank 0] step=725, skipped=0, lr=[1.9512687627229657e-05], mom=[(0.9, 0.999)]
steps: 725 loss: 0.5746 iter time (s): 122.828 samples/sec: 1.042

100%|██████████| 1/1 [02:03<00:00, 123.55s/it][A100%|██████████| 1/1 [02:03<00:00, 123.55s/it]
 14%|█▍        | 733/5198 [20:59:05<128:15:10, 103.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.52s/it][A100%|██████████| 1/1 [02:03<00:00, 123.52s/it]
 14%|█▍        | 733/5198 [20:59:05<128:15:18, 103.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.51s/it][A100%|██████████| 1/1 [02:03<00:00, 123.51s/it]
 14%|█▍        | 733/5198 [20:59:06<128:15:14, 103.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.56s/it][A100%|██████████| 1/1 [02:03<00:00, 123.56s/it]
 14%|█▍        | 733/5198 [20:59:06<128:15:11, 103.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.51s/it][A100%|██████████| 1/1 [02:03<00:00, 123.51s/it]
 14%|█▍        | 733/5198 [20:59:06<128:14:30, 103.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:03<00:00, 123.55s/it][A100%|██████████| 1/1 [02:03<00:00, 123.55s/it]
 14%|█▍        | 733/5198 [20:59:06<128:15:08, 103.41s/it]
100%|██████████| 1/1 [02:03<00:00, 123.55s/it][A100%|██████████| 1/1 [02:03<00:00, 123.55s/it]
 14%|█▍        | 733/5198 [20:59:08<128:14:54, 103.40s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_688
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:15<00:00, 135.73s/it][A100%|██████████| 1/1 [02:15<00:00, 135.73s/it]
 14%|█▍        | 734/5198 [21:01:20<140:07:24, 113.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 16:26:26,894] [INFO] [logging.py:96:log_dist] [Rank 0] step=726, skipped=0, lr=[1.9510939579796526e-05], mom=[(0.9, 0.999)]
steps: 726 loss: 0.6413 iter time (s): 135.195 samples/sec: 0.947

100%|██████████| 1/1 [02:15<00:00, 135.93s/it][A100%|██████████| 1/1 [02:15<00:00, 135.93s/it]
 14%|█▍        | 734/5198 [21:01:21<140:19:38, 113.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:15<00:00, 135.88s/it][A100%|██████████| 1/1 [02:15<00:00, 135.88s/it]
 14%|█▍        | 734/5198 [21:01:21<140:18:26, 113.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:15<00:00, 135.94s/it][A100%|██████████| 1/1 [02:15<00:00, 135.94s/it]
 14%|█▍        | 734/5198 [21:01:22<140:19:51, 113.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:15<00:00, 135.95s/it][A100%|██████████| 1/1 [02:15<00:00, 135.95s/it]
 14%|█▍        | 734/5198 [21:01:22<140:20:02, 113.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:15<00:00, 135.95s/it][A100%|██████████| 1/1 [02:15<00:00, 135.95s/it]
 14%|█▍        | 734/5198 [21:01:22<140:19:37, 113.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:16<00:00, 136.02s/it][A100%|██████████| 1/1 [02:16<00:00, 136.02s/it]
 14%|█▍        | 734/5198 [21:01:22<140:21:33, 113.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:16<00:00, 136.04s/it][A100%|██████████| 1/1 [02:16<00:00, 136.04s/it]
 14%|█▍        | 734/5198 [21:01:24<140:21:40, 113.19s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_689
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.72s/it][A100%|██████████| 1/1 [01:42<00:00, 102.72s/it]
 14%|█▍        | 735/5198 [21:03:03<136:19:27, 109.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 16:28:09,243] [INFO] [logging.py:96:log_dist] [Rank 0] step=727, skipped=0, lr=[1.9509188481338714e-05], mom=[(0.9, 0.999)]
steps: 727 loss: 0.5900 iter time (s): 101.479 samples/sec: 1.261

100%|██████████| 1/1 [01:42<00:00, 102.58s/it][A100%|██████████| 1/1 [01:42<00:00, 102.58s/it]
 14%|█▍        | 735/5198 [21:03:04<136:21:45, 109.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.60s/it][A100%|██████████| 1/1 [01:42<00:00, 102.60s/it]
 14%|█▍        | 735/5198 [21:03:04<136:21:24, 109.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.55s/it][A100%|██████████| 1/1 [01:42<00:00, 102.55s/it]
 14%|█▍        | 735/5198 [21:03:04<136:21:06, 109.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.55s/it][A100%|██████████| 1/1 [01:42<00:00, 102.55s/it]
 14%|█▍        | 735/5198 [21:03:04<136:20:53, 109.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.61s/it][A100%|██████████| 1/1 [01:42<00:00, 102.61s/it]
 14%|█▍        | 735/5198 [21:03:04<136:22:46, 110.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.87s/it][A100%|██████████| 1/1 [01:42<00:00, 102.87s/it]
 14%|█▍        | 735/5198 [21:03:07<136:29:38, 110.10s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_45
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.30s/it][A100%|██████████| 1/1 [01:43<00:00, 103.30s/it]
 14%|█▍        | 735/5198 [21:03:05<136:39:03, 110.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:04<00:00, 124.75s/it][A100%|██████████| 1/1 [02:04<00:00, 124.75s/it]
 14%|█▍        | 736/5198 [21:05:07<141:49:26, 114.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 16:30:14,399] [INFO] [logging.py:96:log_dist] [Rank 0] step=728, skipped=0, lr=[1.9507434332418014e-05], mom=[(0.9, 0.999)]
steps: 728 loss: 0.7601 iter time (s): 124.055 samples/sec: 1.032

100%|██████████| 1/1 [02:05<00:00, 125.15s/it][A100%|██████████| 1/1 [02:05<00:00, 125.15s/it]
 14%|█▍        | 736/5198 [21:05:09<141:58:19, 114.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:05<00:00, 125.18s/it][A100%|██████████| 1/1 [02:05<00:00, 125.18s/it]
 14%|█▍        | 736/5198 [21:05:09<141:58:53, 114.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:05<00:00, 125.16s/it][A100%|██████████| 1/1 [02:05<00:00, 125.16s/it]
 14%|█▍        | 736/5198 [21:05:09<141:58:06, 114.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:05<00:00, 125.04s/it][A100%|██████████| 1/1 [02:05<00:00, 125.04s/it]
 14%|█▍        | 736/5198 [21:05:09<141:56:29, 114.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:05<00:00, 125.15s/it][A100%|██████████| 1/1 [02:05<00:00, 125.15s/it]
 14%|█▍        | 736/5198 [21:05:09<141:58:00, 114.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:04<00:00, 124.74s/it][A100%|██████████| 1/1 [02:04<00:00, 124.74s/it]
 14%|█▍        | 736/5198 [21:05:12<141:54:31, 114.49s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_690
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:04<00:00, 124.33s/it][A100%|██████████| 1/1 [02:04<00:00, 124.33s/it]
 14%|█▍        | 736/5198 [21:05:09<141:52:05, 114.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.30s/it][A100%|██████████| 1/1 [01:22<00:00, 82.30s/it]
 14%|█▍        | 737/5198 [21:06:30<129:54:26, 104.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 16:31:35,983] [INFO] [logging.py:96:log_dist] [Rank 0] step=729, skipped=0, lr=[1.9505677133597203e-05], mom=[(0.9, 0.999)]
steps: 729 loss: 0.6047 iter time (s): 80.603 samples/sec: 1.588

100%|██████████| 1/1 [01:21<00:00, 81.30s/it][A100%|██████████| 1/1 [01:21<00:00, 81.30s/it]
 14%|█▍        | 737/5198 [21:06:30<129:35:06, 104.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.32s/it][A100%|██████████| 1/1 [01:21<00:00, 81.32s/it]
 14%|█▍        | 737/5198 [21:06:30<129:36:03, 104.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.35s/it][A100%|██████████| 1/1 [01:21<00:00, 81.35s/it]
 14%|█▍        | 737/5198 [21:06:31<129:36:05, 104.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.39s/it][A100%|██████████| 1/1 [01:21<00:00, 81.39s/it]
 14%|█▍        | 737/5198 [21:06:31<129:35:44, 104.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.32s/it][A100%|██████████| 1/1 [01:21<00:00, 81.32s/it]
 14%|█▍        | 737/5198 [21:06:31<129:35:13, 104.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.35s/it][A100%|██████████| 1/1 [01:21<00:00, 81.35s/it]
 14%|█▍        | 737/5198 [21:06:31<129:31:47, 104.53s/it]
100%|██████████| 1/1 [01:21<00:00, 81.36s/it][A100%|██████████| 1/1 [01:21<00:00, 81.36s/it]
 14%|█▍        | 737/5198 [21:06:33<129:33:45, 104.56s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_691

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.97s/it][A100%|██████████| 1/1 [01:28<00:00, 88.97s/it]
 14%|█▍        | 738/5198 [21:07:59<124:02:10, 100.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 16:33:05,248] [INFO] [logging.py:96:log_dist] [Rank 0] step=730, skipped=0, lr=[1.9503916885440035e-05], mom=[(0.9, 0.999)]
steps: 730 loss: 0.6218 iter time (s): 88.491 samples/sec: 1.446

100%|██████████| 1/1 [01:29<00:00, 89.26s/it][A100%|██████████| 1/1 [01:29<00:00, 89.26s/it]
 14%|█▍        | 738/5198 [21:07:59<123:52:02, 99.98s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.27s/it][A100%|██████████| 1/1 [01:29<00:00, 89.27s/it]
 14%|█▍        | 738/5198 [21:08:00<123:52:51, 99.99s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.28s/it][A100%|██████████| 1/1 [01:29<00:00, 89.28s/it]
 14%|█▍        | 738/5198 [21:08:00<123:53:20, 100.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.26s/it][A100%|██████████| 1/1 [01:29<00:00, 89.26s/it]
 14%|█▍        | 738/5198 [21:08:00<123:52:30, 99.99s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.29s/it][A100%|██████████| 1/1 [01:29<00:00, 89.29s/it]
 14%|█▍        | 738/5198 [21:08:00<123:52:56, 99.99s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.26s/it][A100%|██████████| 1/1 [01:29<00:00, 89.26s/it]
 14%|█▍        | 738/5198 [21:08:00<123:49:39, 99.95s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.26s/it][A100%|██████████| 1/1 [01:29<00:00, 89.26s/it]
 14%|█▍        | 738/5198 [21:08:02<123:51:06, 99.97s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_692
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.57s/it][A100%|██████████| 1/1 [01:35<00:00, 95.57s/it]
 14%|█▍        | 739/5198 [21:09:35<122:21:50, 98.79s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 16:34:41,151] [INFO] [logging.py:96:log_dist] [Rank 0] step=731, skipped=0, lr=[1.950215358851124e-05], mom=[(0.9, 0.999)]
steps: 731 loss: 0.6072 iter time (s): 95.125 samples/sec: 1.346

100%|██████████| 1/1 [01:35<00:00, 95.91s/it][A100%|██████████| 1/1 [01:35<00:00, 95.91s/it]
 14%|█▍        | 739/5198 [21:09:35<122:19:56, 98.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.94s/it][A100%|██████████| 1/1 [01:35<00:00, 95.94s/it]
 14%|█▍        | 739/5198 [21:09:35<122:21:06, 98.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.91s/it][A100%|██████████| 1/1 [01:35<00:00, 95.91s/it]
 14%|█▍        | 739/5198 [21:09:36<122:20:40, 98.78s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.97s/it][A100%|██████████| 1/1 [01:35<00:00, 95.97s/it]
 14%|█▍        | 739/5198 [21:09:36<122:21:31, 98.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.93s/it][A100%|██████████| 1/1 [01:35<00:00, 95.93s/it]
 14%|█▍        | 739/5198 [21:09:36<122:20:43, 98.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.95s/it][A100%|██████████| 1/1 [01:35<00:00, 95.95s/it]
 14%|█▍        | 739/5198 [21:09:36<122:18:58, 98.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.96s/it][A100%|██████████| 1/1 [01:35<00:00, 95.96s/it]
 14%|█▍        | 739/5198 [21:09:38<122:20:12, 98.77s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_693
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.47s/it][A100%|██████████| 1/1 [01:54<00:00, 114.47s/it]
 14%|█▍        | 740/5198 [21:11:29<128:12:33, 103.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 16:36:36,279] [INFO] [logging.py:96:log_dist] [Rank 0] step=732, skipped=0, lr=[1.9500387243376528e-05], mom=[(0.9, 0.999)]
steps: 732 loss: 0.5307 iter time (s): 114.293 samples/sec: 1.120

100%|██████████| 1/1 [01:55<00:00, 115.12s/it][A100%|██████████| 1/1 [01:55<00:00, 115.12s/it]
 14%|█▍        | 740/5198 [21:11:30<128:23:05, 103.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.08s/it][A100%|██████████| 1/1 [01:55<00:00, 115.08s/it]
 14%|█▍        | 740/5198 [21:11:31<128:23:06, 103.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.10s/it][A100%|██████████| 1/1 [01:55<00:00, 115.10s/it]
 14%|█▍        | 740/5198 [21:11:31<128:23:01, 103.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.10s/it][A100%|██████████| 1/1 [01:55<00:00, 115.10s/it]
 14%|█▍        | 740/5198 [21:11:31<128:23:34, 103.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.15s/it][A100%|██████████| 1/1 [01:55<00:00, 115.15s/it]
 14%|█▍        | 740/5198 [21:11:31<128:24:12, 103.69s/it]
100%|██████████| 1/1 [01:55<00:00, 115.08s/it][A100%|██████████| 1/1 [01:55<00:00, 115.09s/it]
 14%|█▍        | 740/5198 [21:11:31<128:21:32, 103.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.09s/it][A100%|██████████| 1/1 [01:55<00:00, 115.09s/it]
 14%|█▍        | 740/5198 [21:11:33<128:22:30, 103.67s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_694
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.93s/it][A100%|██████████| 1/1 [01:51<00:00, 111.93s/it]
 14%|█▍        | 741/5198 [21:13:21<131:21:52, 106.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 16:38:28,284] [INFO] [logging.py:96:log_dist] [Rank 0] step=733, skipped=0, lr=[1.9498617850602584e-05], mom=[(0.9, 0.999)]
steps: 733 loss: 0.5624 iter time (s): 111.177 samples/sec: 1.151

100%|██████████| 1/1 [01:51<00:00, 111.98s/it][A100%|██████████| 1/1 [01:51<00:00, 111.98s/it]
 14%|█▍        | 741/5198 [21:13:22<131:27:13, 106.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.98s/it][A100%|██████████| 1/1 [01:51<00:00, 111.98s/it]
 14%|█▍        | 741/5198 [21:13:23<131:26:52, 106.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 112.00s/it][A100%|██████████| 1/1 [01:51<00:00, 112.00s/it]
 14%|█▍        | 741/5198 [21:13:23<131:27:11, 106.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.01s/it][A100%|██████████| 1/1 [01:52<00:00, 112.01s/it]
 14%|█▍        | 741/5198 [21:13:23<131:27:53, 106.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 112.00s/it][A100%|██████████| 1/1 [01:51<00:00, 112.00s/it]
 14%|█▍        | 741/5198 [21:13:23<131:28:01, 106.19s/it]
100%|██████████| 1/1 [01:52<00:00, 112.02s/it][A100%|██████████| 1/1 [01:52<00:00, 112.02s/it]
 14%|█▍        | 741/5198 [21:13:23<131:26:37, 106.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.02s/it][A100%|██████████| 1/1 [01:52<00:00, 112.02s/it]
 14%|█▍        | 741/5198 [21:13:25<131:27:24, 106.18s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_695
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:06<00:00, 126.65s/it][A100%|██████████| 1/1 [02:06<00:00, 126.65s/it]
 14%|█▍        | 742/5198 [21:15:28<139:05:46, 112.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 16:40:35,707] [INFO] [logging.py:96:log_dist] [Rank 0] step=734, skipped=0, lr=[1.949684541075708e-05], mom=[(0.9, 0.999)]
steps: 734 loss: 0.5983 iter time (s): 126.563 samples/sec: 1.011

100%|██████████| 1/1 [02:07<00:00, 127.43s/it][A100%|██████████| 1/1 [02:07<00:00, 127.43s/it]
 14%|█▍        | 742/5198 [21:15:30<139:19:44, 112.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:07<00:00, 127.42s/it][A100%|██████████| 1/1 [02:07<00:00, 127.42s/it]
 14%|█▍        | 742/5198 [21:15:30<139:18:44, 112.55s/it]
100%|██████████| 1/1 [02:07<00:00, 127.31s/it][A100%|██████████| 1/1 [02:07<00:00, 127.31s/it]
 14%|█▍        | 742/5198 [21:15:30<139:16:35, 112.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:07<00:00, 127.33s/it][A100%|██████████| 1/1 [02:07<00:00, 127.33s/it]
 14%|█▍        | 742/5198 [21:15:30<139:17:48, 112.54s/it]
100%|██████████| 1/1 [02:07<00:00, 127.30s/it][A100%|██████████| 1/1 [02:07<00:00, 127.30s/it]
 14%|█▍        | 742/5198 [21:15:30<139:17:14, 112.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:07<00:00, 127.31s/it][A100%|██████████| 1/1 [02:07<00:00, 127.31s/it]
 14%|█▍        | 742/5198 [21:15:31<139:16:29, 112.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:07<00:00, 127.31s/it][A100%|██████████| 1/1 [02:07<00:00, 127.31s/it]
 14%|█▍        | 742/5198 [21:15:33<139:17:00, 112.53s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_696
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.15s/it][A100%|██████████| 1/1 [01:43<00:00, 103.15s/it]
 14%|█▍        | 743/5198 [21:17:12<135:42:54, 109.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 16:42:18,398] [INFO] [logging.py:96:log_dist] [Rank 0] step=735, skipped=0, lr=[1.9495069924408652e-05], mom=[(0.9, 0.999)]
steps: 735 loss: 0.5520 iter time (s): 101.916 samples/sec: 1.256

100%|██████████| 1/1 [01:42<00:00, 102.59s/it][A100%|██████████| 1/1 [01:42<00:00, 102.59s/it]
 14%|█▍        | 743/5198 [21:17:13<135:36:07, 109.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.67s/it][A100%|██████████| 1/1 [01:42<00:00, 102.67s/it]
 14%|█▍        | 743/5198 [21:17:13<135:37:20, 109.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.72s/it][A100%|██████████| 1/1 [01:42<00:00, 102.73s/it]
 14%|█▍        | 743/5198 [21:17:13<135:37:15, 109.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.62s/it][A100%|██████████| 1/1 [01:42<00:00, 102.62s/it]
 14%|█▍        | 743/5198 [21:17:13<135:35:34, 109.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.65s/it][A100%|██████████| 1/1 [01:42<00:00, 102.65s/it]
 14%|█▍        | 743/5198 [21:17:13<135:35:54, 109.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.69s/it][A100%|██████████| 1/1 [01:42<00:00, 102.69s/it]
 14%|█▍        | 743/5198 [21:17:13<135:36:02, 109.58s/it]
100%|██████████| 1/1 [01:42<00:00, 102.68s/it][A100%|██████████| 1/1 [01:42<00:00, 102.68s/it]
 14%|█▍        | 743/5198 [21:17:15<135:36:15, 109.58s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_697

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.55s/it][A100%|██████████| 1/1 [01:48<00:00, 108.55s/it]
 14%|█▍        | 744/5198 [21:19:01<135:21:05, 109.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 16:44:07,225] [INFO] [logging.py:96:log_dist] [Rank 0] step=736, skipped=0, lr=[1.949329139212692e-05], mom=[(0.9, 0.999)]
steps: 736 loss: 0.5841 iter time (s): 108.048 samples/sec: 1.185

100%|██████████| 1/1 [01:48<00:00, 108.83s/it][A100%|██████████| 1/1 [01:48<00:00, 108.83s/it]
 14%|█▍        | 744/5198 [21:19:01<135:18:11, 109.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.75s/it][A100%|██████████| 1/1 [01:48<00:00, 108.75s/it]
 14%|█▍        | 744/5198 [21:19:01<135:17:11, 109.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.81s/it][A100%|██████████| 1/1 [01:48<00:00, 108.81s/it]
 14%|█▍        | 744/5198 [21:19:02<135:18:23, 109.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.86s/it][A100%|██████████| 1/1 [01:48<00:00, 108.86s/it]
 14%|█▍        | 744/5198 [21:19:02<135:18:38, 109.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.84s/it][A100%|██████████| 1/1 [01:48<00:00, 108.84s/it]
 14%|█▍        | 744/5198 [21:19:02<135:18:15, 109.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.87s/it][A100%|██████████| 1/1 [01:48<00:00, 108.87s/it]
 14%|█▍        | 744/5198 [21:19:02<135:18:59, 109.37s/it]
100%|██████████| 1/1 [01:48<00:00, 108.86s/it][A100%|██████████| 1/1 [01:48<00:00, 108.86s/it]
 14%|█▍        | 744/5198 [21:19:04<135:18:46, 109.37s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_698
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.03s/it][A100%|██████████| 1/1 [01:26<00:00, 86.03s/it]
 14%|█▍        | 745/5198 [21:20:27<126:42:47, 102.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 16:45:32,896] [INFO] [logging.py:96:log_dist] [Rank 0] step=737, skipped=0, lr=[1.9491509814482483e-05], mom=[(0.9, 0.999)]
steps: 737 loss: 0.5771 iter time (s): 84.839 samples/sec: 1.509

100%|██████████| 1/1 [01:25<00:00, 85.65s/it][A100%|██████████| 1/1 [01:25<00:00, 85.66s/it]
 14%|█▍        | 745/5198 [21:20:27<126:29:14, 102.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.66s/it][A100%|██████████| 1/1 [01:25<00:00, 85.66s/it]
 14%|█▍        | 745/5198 [21:20:27<126:28:35, 102.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.63s/it][A100%|██████████| 1/1 [01:25<00:00, 85.63s/it]
 14%|█▍        | 745/5198 [21:20:27<126:28:33, 102.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.60s/it][A100%|██████████| 1/1 [01:25<00:00, 85.60s/it]
 14%|█▍        | 745/5198 [21:20:28<126:28:07, 102.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.66s/it][A100%|██████████| 1/1 [01:25<00:00, 85.66s/it]
 14%|█▍        | 745/5198 [21:20:28<126:29:17, 102.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.61s/it][A100%|██████████| 1/1 [01:25<00:00, 85.61s/it]
 14%|█▍        | 745/5198 [21:20:30<126:28:17, 102.25s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_699

100%|██████████| 1/1 [01:25<00:00, 85.61s/it][A100%|██████████| 1/1 [01:25<00:00, 85.61s/it]
 14%|█▍        | 745/5198 [21:20:28<126:28:32, 102.25s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.90s/it][A100%|██████████| 1/1 [01:42<00:00, 102.90s/it]
 14%|█▍        | 746/5198 [21:22:10<126:55:52, 102.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 16:47:16,502] [INFO] [logging.py:96:log_dist] [Rank 0] step=738, skipped=0, lr=[1.948972519204692e-05], mom=[(0.9, 0.999)]
steps: 738 loss: 0.5747 iter time (s): 102.820 samples/sec: 1.245

100%|██████████| 1/1 [01:43<00:00, 103.59s/it][A100%|██████████| 1/1 [01:43<00:00, 103.59s/it]
 14%|█▍        | 746/5198 [21:22:11<126:57:41, 102.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.62s/it][A100%|██████████| 1/1 [01:43<00:00, 103.62s/it]
 14%|█▍        | 746/5198 [21:22:11<126:58:01, 102.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.62s/it][A100%|██████████| 1/1 [01:43<00:00, 103.62s/it]
 14%|█▍        | 746/5198 [21:22:11<126:57:49, 102.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.62s/it][A100%|██████████| 1/1 [01:43<00:00, 103.62s/it]
 14%|█▍        | 746/5198 [21:22:11<126:57:38, 102.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.61s/it][A100%|██████████| 1/1 [01:43<00:00, 103.62s/it]
 14%|█▍        | 746/5198 [21:22:11<126:58:20, 102.67s/it]
100%|██████████| 1/1 [01:43<00:00, 103.61s/it][A100%|██████████| 1/1 [01:43<00:00, 103.61s/it]
 14%|█▍        | 746/5198 [21:22:14<126:57:24, 102.66s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_700

100%|██████████| 1/1 [01:43<00:00, 103.61s/it][A100%|██████████| 1/1 [01:43<00:00, 103.61s/it]
 14%|█▍        | 746/5198 [21:22:11<126:57:34, 102.66s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.87s/it][A100%|██████████| 1/1 [01:42<00:00, 102.87s/it]
 14%|█▍        | 747/5198 [21:23:53<127:05:35, 102.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 16:48:59,628] [INFO] [logging.py:96:log_dist] [Rank 0] step=739, skipped=0, lr=[1.9487937525392773e-05], mom=[(0.9, 0.999)]
steps: 739 loss: 0.5959 iter time (s): 102.407 samples/sec: 1.250

100%|██████████| 1/1 [01:43<00:00, 103.23s/it][A100%|██████████| 1/1 [01:43<00:00, 103.23s/it]
 14%|█▍        | 747/5198 [21:23:54<127:09:18, 102.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.20s/it][A100%|██████████| 1/1 [01:43<00:00, 103.20s/it]
 14%|█▍        | 747/5198 [21:23:54<127:08:41, 102.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.27s/it][A100%|██████████| 1/1 [01:43<00:00, 103.28s/it]
 14%|█▍        | 747/5198 [21:23:54<127:10:14, 102.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.21s/it][A100%|██████████| 1/1 [01:43<00:00, 103.21s/it]
 14%|█▍        | 747/5198 [21:23:55<127:09:23, 102.85s/it]
100%|██████████| 1/1 [01:43<00:00, 103.30s/it][A100%|██████████| 1/1 [01:43<00:00, 103.30s/it]
 14%|█▍        | 747/5198 [21:23:55<127:10:46, 102.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.27s/it][A100%|██████████| 1/1 [01:43<00:00, 103.27s/it]
 14%|█▍        | 747/5198 [21:23:55<127:09:43, 102.85s/it]
100%|██████████| 1/1 [01:43<00:00, 103.27s/it][A100%|██████████| 1/1 [01:43<00:00, 103.27s/it]
 14%|█▍        | 747/5198 [21:23:57<127:09:39, 102.85s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_701
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.22s/it][A100%|██████████| 1/1 [01:23<00:00, 83.22s/it]
 14%|█▍        | 748/5198 [21:25:17<119:54:47, 97.01s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 16:50:22,536] [INFO] [logging.py:96:log_dist] [Rank 0] step=740, skipped=0, lr=[1.9486146815093573e-05], mom=[(0.9, 0.999)]
steps: 740 loss: 0.6126 iter time (s): 81.937 samples/sec: 1.562

100%|██████████| 1/1 [01:22<00:00, 82.74s/it][A100%|██████████| 1/1 [01:22<00:00, 82.74s/it]
 14%|█▍        | 748/5198 [21:25:17<119:40:50, 96.82s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.78s/it][A100%|██████████| 1/1 [01:22<00:00, 82.78s/it]
 14%|█▍        | 748/5198 [21:25:17<119:41:10, 96.82s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.71s/it][A100%|██████████| 1/1 [01:22<00:00, 82.71s/it]
 14%|█▍        | 748/5198 [21:25:17<119:40:45, 96.82s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.69s/it][A100%|██████████| 1/1 [01:22<00:00, 82.69s/it]
 14%|█▍        | 748/5198 [21:25:17<119:39:38, 96.80s/it] 
100%|██████████| 1/1 [01:22<00:00, 82.71s/it][A100%|██████████| 1/1 [01:22<00:00, 82.71s/it]
 14%|█▍        | 748/5198 [21:25:17<119:41:00, 96.82s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.72s/it][A100%|██████████| 1/1 [01:22<00:00, 82.72s/it]
 14%|█▍        | 748/5198 [21:25:17<119:40:33, 96.82s/it] 
100%|██████████| 1/1 [01:22<00:00, 82.72s/it][A100%|██████████| 1/1 [01:22<00:00, 82.72s/it]
 14%|█▍        | 748/5198 [21:25:20<119:40:37, 96.82s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_702
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.08s/it][A100%|██████████| 1/1 [01:44<00:00, 104.08s/it]
 14%|█▍        | 749/5198 [21:27:01<122:34:43, 99.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 16:52:07,511] [INFO] [logging.py:96:log_dist] [Rank 0] step=741, skipped=0, lr=[1.948435306172383e-05], mom=[(0.9, 0.999)]
steps: 741 loss: 0.5983 iter time (s): 104.173 samples/sec: 1.229

100%|██████████| 1/1 [01:45<00:00, 105.02s/it][A100%|██████████| 1/1 [01:45<00:00, 105.02s/it]
 14%|█▍        | 749/5198 [21:27:02<122:42:04, 99.29s/it]
100%|██████████| 1/1 [01:44<00:00, 104.92s/it][A
100%|██████████| 1/1 [01:44<00:00, 104.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A 14%|█▍        | 749/5198 [21:27:02<122:40:03, 99.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.02s/it][A100%|██████████| 1/1 [01:45<00:00, 105.02s/it]
 14%|█▍        | 749/5198 [21:27:02<122:42:11, 99.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.03s/it][A100%|██████████| 1/1 [01:45<00:00, 105.03s/it]
 14%|█▍        | 749/5198 [21:27:02<122:41:34, 99.28s/it]
100%|██████████| 1/1 [01:45<00:00, 105.01s/it][A100%|██████████| 1/1 [01:45<00:00, 105.01s/it]
 14%|█▍        | 749/5198 [21:27:02<122:42:07, 99.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.99s/it][A100%|██████████| 1/1 [01:44<00:00, 104.99s/it]
 14%|█▍        | 749/5198 [21:27:05<122:41:17, 99.28s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_703

100%|██████████| 1/1 [01:45<00:00, 105.01s/it][A100%|██████████| 1/1 [01:45<00:00, 105.01s/it]
 14%|█▍        | 749/5198 [21:27:02<122:41:42, 99.28s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.34s/it][A100%|██████████| 1/1 [01:31<00:00, 91.34s/it]
 14%|█▍        | 750/5198 [21:28:32<119:43:03, 96.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 16:53:38,572] [INFO] [logging.py:96:log_dist] [Rank 0] step=742, skipped=0, lr=[1.948255626585902e-05], mom=[(0.9, 0.999)]
steps: 742 loss: 0.6110 iter time (s): 90.215 samples/sec: 1.419

100%|██████████| 1/1 [01:30<00:00, 90.92s/it][A100%|██████████| 1/1 [01:30<00:00, 90.92s/it]
 14%|█▍        | 750/5198 [21:28:33<119:35:01, 96.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.10s/it][A100%|██████████| 1/1 [01:31<00:00, 91.10s/it]
 14%|█▍        | 750/5198 [21:28:33<119:37:33, 96.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.94s/it][A100%|██████████| 1/1 [01:30<00:00, 90.94s/it]
 14%|█▍        | 750/5198 [21:28:33<119:35:30, 96.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.93s/it][A100%|██████████| 1/1 [01:30<00:00, 90.93s/it]
 14%|█▍        | 750/5198 [21:28:33<119:34:57, 96.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.01s/it][A100%|██████████| 1/1 [01:31<00:00, 91.01s/it]
 14%|█▍        | 750/5198 [21:28:33<119:36:28, 96.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.99s/it][A100%|██████████| 1/1 [01:30<00:00, 90.99s/it]
 14%|█▍        | 750/5198 [21:28:33<119:36:24, 96.80s/it]
100%|██████████| 1/1 [01:31<00:00, 91.02s/it][A100%|██████████| 1/1 [01:31<00:00, 91.02s/it]
 14%|█▍        | 750/5198 [21:28:36<119:36:29, 96.81s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_704
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.72s/it][A100%|██████████| 1/1 [01:18<00:00, 78.72s/it]
 14%|█▍        | 751/5198 [21:29:51<113:02:06, 91.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 16:54:57,203] [INFO] [logging.py:96:log_dist] [Rank 0] step=743, skipped=0, lr=[1.94807564280756e-05], mom=[(0.9, 0.999)]
steps: 743 loss: 0.5997 iter time (s): 77.809 samples/sec: 1.645

100%|██████████| 1/1 [01:18<00:00, 78.65s/it][A100%|██████████| 1/1 [01:18<00:00, 78.65s/it]
 14%|█▍        | 751/5198 [21:29:51<112:50:34, 91.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.53s/it][A100%|██████████| 1/1 [01:18<00:00, 78.53s/it]
 14%|█▍        | 751/5198 [21:29:51<112:49:50, 91.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.58s/it][A100%|██████████| 1/1 [01:18<00:00, 78.58s/it]
 14%|█▍        | 751/5198 [21:29:52<112:49:29, 91.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.56s/it][A100%|██████████| 1/1 [01:18<00:00, 78.56s/it]
 14%|█▍        | 751/5198 [21:29:52<112:48:41, 91.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.54s/it][A100%|██████████| 1/1 [01:18<00:00, 78.54s/it]
 14%|█▍        | 751/5198 [21:29:52<112:49:11, 91.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.51s/it][A100%|██████████| 1/1 [01:18<00:00, 78.51s/it]
 14%|█▍        | 751/5198 [21:29:52<112:48:30, 91.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:18<00:00, 78.54s/it][A100%|██████████| 1/1 [01:18<00:00, 78.54s/it]
 14%|█▍        | 751/5198 [21:29:54<112:49:12, 91.33s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_46
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:07<00:00, 127.43s/it][A100%|██████████| 1/1 [02:07<00:00, 127.43s/it]
 14%|█▍        | 752/5198 [21:31:59<126:24:16, 102.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 16:57:05,940] [INFO] [logging.py:96:log_dist] [Rank 0] step=744, skipped=0, lr=[1.9478953548951004e-05], mom=[(0.9, 0.999)]
steps: 744 loss: 0.7561 iter time (s): 128.261 samples/sec: 0.998

100%|██████████| 1/1 [02:09<00:00, 129.11s/it][A100%|██████████| 1/1 [02:09<00:00, 129.11s/it]
 14%|█▍        | 752/5198 [21:32:00<126:49:03, 102.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:09<00:00, 129.19s/it][A100%|██████████| 1/1 [02:09<00:00, 129.19s/it]
 14%|█▍        | 752/5198 [21:32:01<126:50:26, 102.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:09<00:00, 129.23s/it][A100%|██████████| 1/1 [02:09<00:00, 129.23s/it]
 14%|█▍        | 752/5198 [21:32:01<126:50:12, 102.70s/it]
100%|██████████| 1/1 [02:09<00:00, 129.30s/it][A100%|██████████| 1/1 [02:09<00:00, 129.30s/it]
 14%|█▍        | 752/5198 [21:32:01<126:52:11, 102.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:09<00:00, 129.22s/it][A100%|██████████| 1/1 [02:09<00:00, 129.22s/it]
 14%|█▍        | 752/5198 [21:32:01<126:50:17, 102.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:09<00:00, 129.18s/it][A100%|██████████| 1/1 [02:09<00:00, 129.18s/it]
 14%|█▍        | 752/5198 [21:32:03<126:49:26, 102.69s/it]Shard 752 in [76, 158, 182, 242, 293, 363, 418, 421, 752, 814, 842, 991, 1266, 1366, 1425, 1464, 1574, 1728, 2166, 2441, 2563, 2739, 2854, 2894, 3089, 3181, 3395, 3576, 3831, 4300, 4589, 4947, 4950]: file /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_705 skipped to avoid exceeding cuda memory
Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_706

100%|██████████| 1/1 [02:09<00:00, 129.22s/it][A100%|██████████| 1/1 [02:09<00:00, 129.22s/it]
 14%|█▍        | 752/5198 [21:32:01<126:49:47, 102.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.41s/it][A100%|██████████| 1/1 [01:51<00:00, 111.41s/it]
 15%|█▍        | 754/5198 [21:33:51<99:50:36, 80.88s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 16:58:57,427] [INFO] [logging.py:96:log_dist] [Rank 0] step=745, skipped=0, lr=[1.9477147629063637e-05], mom=[(0.9, 0.999)]
steps: 745 loss: 0.5901 iter time (s): 110.279 samples/sec: 1.161

100%|██████████| 1/1 [01:51<00:00, 111.11s/it][A100%|██████████| 1/1 [01:51<00:00, 111.11s/it]
 15%|█▍        | 754/5198 [21:33:52<99:54:51, 80.94s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.07s/it][A100%|██████████| 1/1 [01:51<00:00, 111.07s/it]
 15%|█▍        | 754/5198 [21:33:52<99:55:02, 80.94s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:50<00:00, 110.97s/it][A100%|██████████| 1/1 [01:50<00:00, 110.97s/it]
 15%|█▍        | 754/5198 [21:33:52<99:53:52, 80.93s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.02s/it][A100%|██████████| 1/1 [01:51<00:00, 111.02s/it]
 15%|█▍        | 754/5198 [21:33:52<99:53:58, 80.93s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.06s/it][A100%|██████████| 1/1 [01:51<00:00, 111.06s/it]
 15%|█▍        | 754/5198 [21:33:52<99:54:33, 80.93s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.08s/it][A100%|██████████| 1/1 [01:51<00:00, 111.08s/it]
 15%|█▍        | 754/5198 [21:33:52<99:54:36, 80.94s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.09s/it][A100%|██████████| 1/1 [01:51<00:00, 111.09s/it]
 15%|█▍        | 754/5198 [21:33:55<99:54:42, 80.94s/it]  Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_707
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.14s/it][A100%|██████████| 1/1 [01:31<00:00, 91.14s/it]
 15%|█▍        | 755/5198 [21:35:22<103:02:37, 83.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 17:00:28,110] [INFO] [logging.py:96:log_dist] [Rank 0] step=746, skipped=0, lr=[1.9475338668992883e-05], mom=[(0.9, 0.999)]
steps: 746 loss: 0.5351 iter time (s): 89.841 samples/sec: 1.425

100%|██████████| 1/1 [01:30<00:00, 90.63s/it][A100%|██████████| 1/1 [01:30<00:00, 90.63s/it]
 15%|█▍        | 755/5198 [21:35:22<102:52:29, 83.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.63s/it][A100%|██████████| 1/1 [01:30<00:00, 90.64s/it]
 15%|█▍        | 755/5198 [21:35:22<102:52:06, 83.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.66s/it][A100%|██████████| 1/1 [01:30<00:00, 90.66s/it]
 15%|█▍        | 755/5198 [21:35:23<102:51:32, 83.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.67s/it][A100%|██████████| 1/1 [01:30<00:00, 90.68s/it]
 15%|█▍        | 755/5198 [21:35:23<102:52:11, 83.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.61s/it][A100%|██████████| 1/1 [01:30<00:00, 90.61s/it]
 15%|█▍        | 755/5198 [21:35:23<102:51:39, 83.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.64s/it][A100%|██████████| 1/1 [01:30<00:00, 90.64s/it]
 15%|█▍        | 755/5198 [21:35:23<102:51:32, 83.34s/it]
100%|██████████| 1/1 [01:30<00:00, 90.64s/it][A100%|██████████| 1/1 [01:30<00:00, 90.64s/it]
 15%|█▍        | 755/5198 [21:35:25<102:51:47, 83.35s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_708

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.02s/it][A100%|██████████| 1/1 [01:27<00:00, 87.02s/it]
 15%|█▍        | 756/5198 [21:36:49<104:14:07, 84.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 17:01:55,390] [INFO] [logging.py:96:log_dist] [Rank 0] step=747, skipped=0, lr=[1.947352666931911e-05], mom=[(0.9, 0.999)]
steps: 747 loss: 0.5824 iter time (s): 86.466 samples/sec: 1.480

100%|██████████| 1/1 [01:27<00:00, 87.24s/it][A100%|██████████| 1/1 [01:27<00:00, 87.24s/it]
 15%|█▍        | 756/5198 [21:36:50<104:06:49, 84.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.21s/it][A100%|██████████| 1/1 [01:27<00:00, 87.21s/it]
 15%|█▍        | 756/5198 [21:36:50<104:05:51, 84.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.23s/it][A100%|██████████| 1/1 [01:27<00:00, 87.23s/it]
 15%|█▍        | 756/5198 [21:36:50<104:05:53, 84.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.25s/it][A100%|██████████| 1/1 [01:27<00:00, 87.25s/it]
 15%|█▍        | 756/5198 [21:36:50<104:06:36, 84.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.28s/it][A100%|██████████| 1/1 [01:27<00:00, 87.28s/it]
 15%|█▍        | 756/5198 [21:36:50<104:06:53, 84.38s/it]
100%|██████████| 1/1 [01:27<00:00, 87.25s/it][A100%|██████████| 1/1 [01:27<00:00, 87.25s/it]
 15%|█▍        | 756/5198 [21:36:50<104:06:12, 84.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.26s/it][A100%|██████████| 1/1 [01:27<00:00, 87.26s/it]
 15%|█▍        | 756/5198 [21:36:52<104:06:35, 84.38s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_709

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.19s/it][A100%|██████████| 1/1 [01:27<00:00, 87.19s/it]
 15%|█▍        | 757/5198 [21:38:17<105:10:42, 85.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 17:03:22,780] [INFO] [logging.py:96:log_dist] [Rank 0] step=748, skipped=0, lr=[1.947171163062364e-05], mom=[(0.9, 0.999)]
steps: 748 loss: 0.6625 iter time (s): 86.576 samples/sec: 1.478

100%|██████████| 1/1 [01:27<00:00, 87.28s/it][A100%|██████████| 1/1 [01:27<00:00, 87.29s/it]
 15%|█▍        | 757/5198 [21:38:17<105:04:31, 85.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.31s/it][A100%|██████████| 1/1 [01:27<00:00, 87.31s/it]
 15%|█▍        | 757/5198 [21:38:17<105:04:20, 85.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.37s/it][A100%|██████████| 1/1 [01:27<00:00, 87.37s/it]
 15%|█▍        | 757/5198 [21:38:17<105:05:26, 85.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.36s/it][A100%|██████████| 1/1 [01:27<00:00, 87.37s/it]
 15%|█▍        | 757/5198 [21:38:17<105:05:45, 85.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.32s/it][A100%|██████████| 1/1 [01:27<00:00, 87.32s/it]
 15%|█▍        | 757/5198 [21:38:18<105:05:15, 85.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.38s/it][A100%|██████████| 1/1 [01:27<00:00, 87.38s/it]
 15%|█▍        | 757/5198 [21:38:18<105:06:00, 85.20s/it]
100%|██████████| 1/1 [01:27<00:00, 87.37s/it][A100%|██████████| 1/1 [01:27<00:00, 87.37s/it]
 15%|█▍        | 757/5198 [21:38:20<105:05:51, 85.20s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_710
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.91s/it][A100%|██████████| 1/1 [01:39<00:00, 99.91s/it]
 15%|█▍        | 758/5198 [21:39:57<110:16:33, 89.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 17:05:03,264] [INFO] [logging.py:96:log_dist] [Rank 0] step=749, skipped=0, lr=[1.9469893553488793e-05], mom=[(0.9, 0.999)]
steps: 749 loss: 0.6106 iter time (s): 99.680 samples/sec: 1.284

100%|██████████| 1/1 [01:40<00:00, 100.45s/it][A100%|██████████| 1/1 [01:40<00:00, 100.45s/it]
 15%|█▍        | 758/5198 [21:39:57<110:19:57, 89.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.45s/it][A100%|██████████| 1/1 [01:40<00:00, 100.45s/it]
 15%|█▍        | 758/5198 [21:39:57<110:19:56, 89.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.39s/it][A100%|██████████| 1/1 [01:40<00:00, 100.39s/it]
 15%|█▍        | 758/5198 [21:39:58<110:19:17, 89.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.37s/it][A100%|██████████| 1/1 [01:40<00:00, 100.37s/it]
 15%|█▍        | 758/5198 [21:39:58<110:18:57, 89.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.40s/it][A100%|██████████| 1/1 [01:40<00:00, 100.40s/it]
 15%|█▍        | 758/5198 [21:39:58<110:19:21, 89.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.39s/it][A100%|██████████| 1/1 [01:40<00:00, 100.39s/it]
 15%|█▍        | 758/5198 [21:39:58<110:19:28, 89.45s/it]

  0%|          | 0/1 [00:00<?, ?it/s][A100%|██████████| 1/1 [01:40<00:00, 100.41s/it][A100%|██████████| 1/1 [01:40<00:00, 100.41s/it]
 15%|█▍        | 758/5198 [21:40:00<110:19:35, 89.45s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_711
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.92s/it][A100%|██████████| 1/1 [01:23<00:00, 83.92s/it]
 15%|█▍        | 759/5198 [21:41:21<108:22:58, 87.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 17:06:26,844] [INFO] [logging.py:96:log_dist] [Rank 0] step=750, skipped=0, lr=[1.946807243849784e-05], mom=[(0.9, 0.999)]
steps: 750 loss: 0.6181 iter time (s): 82.828 samples/sec: 1.545

100%|██████████| 1/1 [01:23<00:00, 83.59s/it][A100%|██████████| 1/1 [01:23<00:00, 83.59s/it]
 15%|█▍        | 759/5198 [21:41:21<108:14:46, 87.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.61s/it][A100%|██████████| 1/1 [01:23<00:00, 83.61s/it]
 15%|█▍        | 759/5198 [21:41:21<108:15:24, 87.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.61s/it][A100%|██████████| 1/1 [01:23<00:00, 83.61s/it]
 15%|█▍        | 759/5198 [21:41:21<108:14:56, 87.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.69s/it][A100%|██████████| 1/1 [01:23<00:00, 83.69s/it]
 15%|█▍        | 759/5198 [21:41:22<108:16:14, 87.81s/it]
100%|██████████| 1/1 [01:23<00:00, 83.64s/it][A100%|██████████| 1/1 [01:23<00:00, 83.64s/it]
 15%|█▍        | 759/5198 [21:41:22<108:15:35, 87.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.66s/it][A100%|██████████| 1/1 [01:23<00:00, 83.66s/it]
 15%|█▍        | 759/5198 [21:41:24<108:15:59, 87.80s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_712

100%|██████████| 1/1 [01:23<00:00, 83.68s/it][A100%|██████████| 1/1 [01:23<00:00, 83.68s/it]
 15%|█▍        | 759/5198 [21:41:22<108:16:22, 87.81s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.57s/it][A100%|██████████| 1/1 [01:40<00:00, 100.57s/it]
 15%|█▍        | 760/5198 [21:43:02<112:58:17, 91.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 17:08:08,223] [INFO] [logging.py:96:log_dist] [Rank 0] step=751, skipped=0, lr=[1.946624828623506e-05], mom=[(0.9, 0.999)]
steps: 751 loss: 0.5747 iter time (s): 100.534 samples/sec: 1.273

100%|██████████| 1/1 [01:41<00:00, 101.33s/it][A100%|██████████| 1/1 [01:41<00:00, 101.33s/it]
 15%|█▍        | 760/5198 [21:43:02<113:03:58, 91.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.36s/it][A100%|██████████| 1/1 [01:41<00:00, 101.36s/it]
 15%|█▍        | 760/5198 [21:43:02<113:05:20, 91.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.36s/it][A100%|██████████| 1/1 [01:41<00:00, 101.36s/it]
 15%|█▍        | 760/5198 [21:43:03<113:05:16, 91.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.37s/it][A100%|██████████| 1/1 [01:41<00:00, 101.37s/it]
 15%|█▍        | 760/5198 [21:43:03<113:05:53, 91.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.37s/it][A100%|██████████| 1/1 [01:41<00:00, 101.37s/it]
 15%|█▍        | 760/5198 [21:43:03<113:05:23, 91.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.35s/it][A100%|██████████| 1/1 [01:41<00:00, 101.36s/it]
 15%|█▍        | 760/5198 [21:43:03<113:05:34, 91.74s/it]
100%|██████████| 1/1 [01:41<00:00, 101.36s/it][A100%|██████████| 1/1 [01:41<00:00, 101.36s/it]
 15%|█▍        | 760/5198 [21:43:05<113:05:28, 91.74s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_713

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.33s/it][A100%|██████████| 1/1 [01:43<00:00, 103.33s/it]
 15%|█▍        | 761/5198 [21:44:45<117:14:18, 95.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 17:09:51,816] [INFO] [logging.py:96:log_dist] [Rank 0] step=752, skipped=0, lr=[1.9464421097285668e-05], mom=[(0.9, 0.999)]
steps: 752 loss: 0.5711 iter time (s): 102.763 samples/sec: 1.246

100%|██████████| 1/1 [01:43<00:00, 103.62s/it][A100%|██████████| 1/1 [01:43<00:00, 103.62s/it]
 15%|█▍        | 761/5198 [21:44:46<117:20:22, 95.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.51s/it][A100%|██████████| 1/1 [01:43<00:00, 103.51s/it]
 15%|█▍        | 761/5198 [21:44:46<117:18:55, 95.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.53s/it][A100%|██████████| 1/1 [01:43<00:00, 103.53s/it]
 15%|█▍        | 761/5198 [21:44:46<117:19:23, 95.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.51s/it][A100%|██████████| 1/1 [01:43<00:00, 103.51s/it]
 15%|█▍        | 761/5198 [21:44:46<117:19:21, 95.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.58s/it][A100%|██████████| 1/1 [01:43<00:00, 103.58s/it]
 15%|█▍        | 761/5198 [21:44:47<117:20:32, 95.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.53s/it][A100%|██████████| 1/1 [01:43<00:00, 103.53s/it]
 15%|█▍        | 761/5198 [21:44:47<117:19:35, 95.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.55s/it][A100%|██████████| 1/1 [01:43<00:00, 103.55s/it]
 15%|█▍        | 761/5198 [21:44:49<117:19:49, 95.20s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_714
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.92s/it][A100%|██████████| 1/1 [01:42<00:00, 102.92s/it]
 15%|█▍        | 762/5198 [21:46:28<120:06:25, 97.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 17:11:34,874] [INFO] [logging.py:96:log_dist] [Rank 0] step=753, skipped=0, lr=[1.946259087223588e-05], mom=[(0.9, 0.999)]
steps: 753 loss: 0.6062 iter time (s): 102.280 samples/sec: 1.251

100%|██████████| 1/1 [01:43<00:00, 103.06s/it][A100%|██████████| 1/1 [01:43<00:00, 103.06s/it]
 15%|█▍        | 762/5198 [21:46:29<120:10:18, 97.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.14s/it][A100%|██████████| 1/1 [01:43<00:00, 103.14s/it]
 15%|█▍        | 762/5198 [21:46:29<120:11:08, 97.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.16s/it][A100%|██████████| 1/1 [01:43<00:00, 103.16s/it]
 15%|█▍        | 762/5198 [21:46:30<120:11:47, 97.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.11s/it][A100%|██████████| 1/1 [01:43<00:00, 103.11s/it]
 15%|█▍        | 762/5198 [21:46:30<120:10:38, 97.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.08s/it][A100%|██████████| 1/1 [01:43<00:00, 103.08s/it]
 15%|█▍        | 762/5198 [21:46:30<120:10:51, 97.53s/it]
100%|██████████| 1/1 [01:43<00:00, 103.07s/it][A100%|██████████| 1/1 [01:43<00:00, 103.07s/it]
 15%|█▍        | 762/5198 [21:46:30<120:09:47, 97.52s/it]
100%|██████████| 1/1 [01:43<00:00, 103.06s/it][A100%|██████████| 1/1 [01:43<00:00, 103.06s/it]
 15%|█▍        | 762/5198 [21:46:32<120:09:50, 97.52s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_715
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.63s/it][A100%|██████████| 1/1 [01:33<00:00, 93.63s/it]
 15%|█▍        | 763/5198 [21:48:02<118:47:13, 96.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 17:13:08,510] [INFO] [logging.py:96:log_dist] [Rank 0] step=754, skipped=0, lr=[1.9460757611672877e-05], mom=[(0.9, 0.999)]
steps: 754 loss: 0.5793 iter time (s): 92.808 samples/sec: 1.379

100%|██████████| 1/1 [01:33<00:00, 93.60s/it][A100%|██████████| 1/1 [01:33<00:00, 93.60s/it]
 15%|█▍        | 763/5198 [21:48:03<118:42:59, 96.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.54s/it][A100%|██████████| 1/1 [01:33<00:00, 93.54s/it]
 15%|█▍        | 763/5198 [21:48:03<118:42:35, 96.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.55s/it][A100%|██████████| 1/1 [01:33<00:00, 93.55s/it]
 15%|█▍        | 763/5198 [21:48:03<118:43:38, 96.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.66s/it][A100%|██████████| 1/1 [01:33<00:00, 93.66s/it]
 15%|█▍        | 763/5198 [21:48:03<118:44:25, 96.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.60s/it][A100%|██████████| 1/1 [01:33<00:00, 93.60s/it]
 15%|█▍        | 763/5198 [21:48:03<118:44:10, 96.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.87s/it][A100%|██████████| 1/1 [01:33<00:00, 93.87s/it]
 15%|█▍        | 763/5198 [21:48:06<118:48:58, 96.45s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_716
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.12s/it][A100%|██████████| 1/1 [01:34<00:00, 94.12s/it]
 15%|█▍        | 763/5198 [21:48:04<118:54:52, 96.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.88s/it][A100%|██████████| 1/1 [01:48<00:00, 108.88s/it]
 15%|█▍        | 764/5198 [21:49:51<123:23:52, 100.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 17:14:58,063] [INFO] [logging.py:96:log_dist] [Rank 0] step=755, skipped=0, lr=[1.945892131618481e-05], mom=[(0.9, 0.999)]
steps: 755 loss: 0.5917 iter time (s): 108.471 samples/sec: 1.180

100%|██████████| 1/1 [01:49<00:00, 109.52s/it][A100%|██████████| 1/1 [01:49<00:00, 109.52s/it]
 15%|█▍        | 764/5198 [21:49:52<123:31:28, 100.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.60s/it][A100%|██████████| 1/1 [01:49<00:00, 109.60s/it]
 15%|█▍        | 764/5198 [21:49:52<123:33:03, 100.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.51s/it][A100%|██████████| 1/1 [01:49<00:00, 109.51s/it]
 15%|█▍        | 764/5198 [21:49:53<123:31:04, 100.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.49s/it][A100%|██████████| 1/1 [01:49<00:00, 109.49s/it]
 15%|█▍        | 764/5198 [21:49:53<123:31:09, 100.29s/it]
100%|██████████| 1/1 [01:49<00:00, 109.42s/it][A100%|██████████| 1/1 [01:49<00:00, 109.43s/it]
 15%|█▍        | 764/5198 [21:49:53<123:30:55, 100.28s/it]
100%|██████████| 1/1 [01:48<00:00, 108.96s/it][A100%|██████████| 1/1 [01:48<00:00, 108.96s/it]
 15%|█▍        | 764/5198 [21:49:53<123:27:04, 100.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.25s/it][A100%|██████████| 1/1 [01:49<00:00, 109.25s/it]
 15%|█▍        | 764/5198 [21:49:55<123:29:23, 100.26s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_717
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.05s/it][A100%|██████████| 1/1 [01:30<00:00, 90.06s/it]
 15%|█▍        | 765/5198 [21:51:22<119:47:01, 97.28s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 17:16:27,920] [INFO] [logging.py:96:log_dist] [Rank 0] step=756, skipped=0, lr=[1.9457081986360816e-05], mom=[(0.9, 0.999)]
steps: 756 loss: 0.5920 iter time (s): 89.076 samples/sec: 1.437

100%|██████████| 1/1 [01:29<00:00, 89.88s/it][A100%|██████████| 1/1 [01:29<00:00, 89.88s/it]
 15%|█▍        | 765/5198 [21:51:22<119:41:01, 97.19s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.87s/it][A100%|██████████| 1/1 [01:29<00:00, 89.87s/it]
 15%|█▍        | 765/5198 [21:51:22<119:41:35, 97.20s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.86s/it][A100%|██████████| 1/1 [01:29<00:00, 89.86s/it]
 15%|█▍        | 765/5198 [21:51:23<119:40:38, 97.19s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.89s/it][A100%|██████████| 1/1 [01:29<00:00, 89.89s/it]
 15%|█▍        | 765/5198 [21:51:23<119:41:29, 97.20s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.93s/it][A100%|██████████| 1/1 [01:29<00:00, 89.93s/it]
 15%|█▍        | 765/5198 [21:51:23<119:41:21, 97.20s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:29<00:00, 89.96s/it][A100%|██████████| 1/1 [01:29<00:00, 89.96s/it]
 15%|█▍        | 765/5198 [21:51:23<119:39:16, 97.17s/it] 
100%|██████████| 1/1 [01:29<00:00, 89.93s/it][A100%|██████████| 1/1 [01:29<00:00, 89.93s/it]
 15%|█▍        | 765/5198 [21:51:25<119:40:09, 97.18s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_718
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.66s/it][A100%|██████████| 1/1 [01:34<00:00, 94.66s/it]
 15%|█▍        | 766/5198 [21:52:57<118:54:11, 96.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 17:18:02,955] [INFO] [logging.py:96:log_dist] [Rank 0] step=757, skipped=0, lr=[1.945523962279099e-05], mom=[(0.9, 0.999)]
steps: 757 loss: 0.5864 iter time (s): 94.144 samples/sec: 1.360

100%|██████████| 1/1 [01:34<00:00, 94.93s/it][A100%|██████████| 1/1 [01:34<00:00, 94.93s/it]
 15%|█▍        | 766/5198 [21:52:57<118:50:15, 96.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.96s/it][A100%|██████████| 1/1 [01:34<00:00, 94.96s/it]
 15%|█▍        | 766/5198 [21:52:57<118:50:45, 96.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.02s/it][A100%|██████████| 1/1 [01:35<00:00, 95.02s/it]
 15%|█▍        | 766/5198 [21:52:58<118:51:17, 96.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.94s/it][A100%|██████████| 1/1 [01:34<00:00, 94.94s/it]
 15%|█▍        | 766/5198 [21:52:58<118:50:08, 96.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.99s/it][A100%|██████████| 1/1 [01:34<00:00, 94.99s/it]
 15%|█▍        | 766/5198 [21:52:58<118:51:23, 96.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.94s/it][A100%|██████████| 1/1 [01:34<00:00, 94.94s/it]
 15%|█▍        | 766/5198 [21:52:58<118:49:15, 96.52s/it]
100%|██████████| 1/1 [01:34<00:00, 94.97s/it][A100%|██████████| 1/1 [01:34<00:00, 94.97s/it]
 15%|█▍        | 766/5198 [21:53:00<118:50:24, 96.53s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_719
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.76s/it][A100%|██████████| 1/1 [01:32<00:00, 92.76s/it]
 15%|█▍        | 767/5198 [21:54:30<117:32:16, 95.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 17:19:35,906] [INFO] [logging.py:96:log_dist] [Rank 0] step=758, skipped=0, lr=[1.945339422606641e-05], mom=[(0.9, 0.999)]
steps: 758 loss: 0.6165 iter time (s): 92.107 samples/sec: 1.390

100%|██████████| 1/1 [01:32<00:00, 92.95s/it][A100%|██████████| 1/1 [01:32<00:00, 92.95s/it]
 15%|█▍        | 767/5198 [21:54:30<117:29:53, 95.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.83s/it][A100%|██████████| 1/1 [01:32<00:00, 92.83s/it]
 15%|█▍        | 767/5198 [21:54:30<117:27:28, 95.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.90s/it][A100%|██████████| 1/1 [01:32<00:00, 92.90s/it]
 15%|█▍        | 767/5198 [21:54:31<117:29:25, 95.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.87s/it][A100%|██████████| 1/1 [01:32<00:00, 92.87s/it]
 15%|█▍        | 767/5198 [21:54:31<117:28:48, 95.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.99s/it][A100%|██████████| 1/1 [01:32<00:00, 92.99s/it]
 15%|█▍        | 767/5198 [21:54:31<117:30:30, 95.47s/it]
100%|██████████| 1/1 [01:32<00:00, 92.89s/it][A100%|██████████| 1/1 [01:32<00:00, 92.89s/it]
 15%|█▍        | 767/5198 [21:54:31<117:28:39, 95.45s/it]
100%|██████████| 1/1 [01:32<00:00, 92.90s/it][A100%|██████████| 1/1 [01:32<00:00, 92.90s/it]
 15%|█▍        | 767/5198 [21:54:33<117:28:57, 95.45s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_47

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.77s/it][A100%|██████████| 1/1 [01:59<00:00, 119.77s/it]
 15%|█▍        | 768/5198 [21:56:30<126:31:08, 102.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 17:21:36,381] [INFO] [logging.py:96:log_dist] [Rank 0] step=759, skipped=0, lr=[1.9451545796779134e-05], mom=[(0.9, 0.999)]
steps: 759 loss: 0.8242 iter time (s): 119.934 samples/sec: 1.067

100%|██████████| 1/1 [02:00<00:00, 120.83s/it][A100%|██████████| 1/1 [02:00<00:00, 120.83s/it]
 15%|█▍        | 768/5198 [21:56:31<126:49:19, 103.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.89s/it][A100%|██████████| 1/1 [02:00<00:00, 120.89s/it]
 15%|█▍        | 768/5198 [21:56:31<126:49:32, 103.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.88s/it][A100%|██████████| 1/1 [02:00<00:00, 120.88s/it]
 15%|█▍        | 768/5198 [21:56:31<126:50:03, 103.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.81s/it][A100%|██████████| 1/1 [02:00<00:00, 120.81s/it]
 15%|█▍        | 768/5198 [21:56:31<126:48:41, 103.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.81s/it][A100%|██████████| 1/1 [02:00<00:00, 120.81s/it]
 15%|█▍        | 768/5198 [21:56:32<126:50:00, 103.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.84s/it][A100%|██████████| 1/1 [02:00<00:00, 120.84s/it]
 15%|█▍        | 768/5198 [21:56:34<126:49:38, 103.07s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_720

100%|██████████| 1/1 [02:00<00:00, 120.85s/it][A100%|██████████| 1/1 [02:00<00:00, 120.85s/it]
 15%|█▍        | 768/5198 [21:56:32<126:49:38, 103.07s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.34s/it][A100%|██████████| 1/1 [01:38<00:00, 98.34s/it]
 15%|█▍        | 769/5198 [21:58:08<124:53:43, 101.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 17:23:14,475] [INFO] [logging.py:96:log_dist] [Rank 0] step=760, skipped=0, lr=[1.9449694335522173e-05], mom=[(0.9, 0.999)]
steps: 760 loss: 0.5976 iter time (s): 96.864 samples/sec: 1.321

100%|██████████| 1/1 [01:37<00:00, 97.63s/it][A100%|██████████| 1/1 [01:37<00:00, 97.63s/it]
 15%|█▍        | 769/5198 [21:58:09<124:48:30, 101.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.69s/it][A100%|██████████| 1/1 [01:37<00:00, 97.69s/it]
 15%|█▍        | 769/5198 [21:58:09<124:49:49, 101.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.66s/it][A100%|██████████| 1/1 [01:37<00:00, 97.66s/it]
 15%|█▍        | 769/5198 [21:58:09<124:48:56, 101.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.74s/it][A100%|██████████| 1/1 [01:37<00:00, 97.74s/it]
 15%|█▍        | 769/5198 [21:58:09<124:49:40, 101.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.66s/it][A100%|██████████| 1/1 [01:37<00:00, 97.66s/it]
 15%|█▍        | 769/5198 [21:58:09<124:48:57, 101.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.63s/it][A100%|██████████| 1/1 [01:37<00:00, 97.63s/it]
 15%|█▍        | 769/5198 [21:58:09<124:48:38, 101.45s/it]
100%|██████████| 1/1 [01:37<00:00, 97.64s/it][A100%|██████████| 1/1 [01:37<00:00, 97.64s/it]
 15%|█▍        | 769/5198 [21:58:12<124:48:54, 101.45s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_721
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.44s/it][A100%|██████████| 1/1 [01:39<00:00, 99.44s/it]
 15%|█▍        | 770/5198 [21:59:48<124:11:27, 100.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 17:24:54,275] [INFO] [logging.py:96:log_dist] [Rank 0] step=761, skipped=0, lr=[1.9447839842889523e-05], mom=[(0.9, 0.999)]
steps: 761 loss: 0.5892 iter time (s): 98.964 samples/sec: 1.293

100%|██████████| 1/1 [01:39<00:00, 99.69s/it][A100%|██████████| 1/1 [01:39<00:00, 99.69s/it]
 15%|█▍        | 770/5198 [21:59:48<124:09:04, 100.94s/it]
100%|██████████| 1/1 [01:39<00:00, 99.83s/it][A100%|██████████| 1/1 [01:39<00:00, 99.83s/it]
 15%|█▍        | 770/5198 [21:59:48<124:12:28, 100.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.74s/it][A100%|██████████| 1/1 [01:39<00:00, 99.74s/it]
 15%|█▍        | 770/5198 [21:59:49<124:09:49, 100.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.74s/it][A100%|██████████| 1/1 [01:39<00:00, 99.74s/it]
 15%|█▍        | 770/5198 [21:59:49<124:09:36, 100.94s/it]
100%|██████████| 1/1 [01:39<00:00, 99.77s/it][A100%|██████████| 1/1 [01:39<00:00, 99.77s/it]
 15%|█▍        | 770/5198 [21:59:49<124:10:58, 100.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.71s/it][A100%|██████████| 1/1 [01:39<00:00, 99.71s/it]
 15%|█▍        | 770/5198 [21:59:49<124:09:40, 100.94s/it]
100%|██████████| 1/1 [01:39<00:00, 99.71s/it][A100%|██████████| 1/1 [01:39<00:00, 99.71s/it]
 15%|█▍        | 770/5198 [21:59:51<124:09:45, 100.95s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_722

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.55s/it][A100%|██████████| 1/1 [01:27<00:00, 87.55s/it]
 15%|█▍        | 771/5198 [22:01:15<119:17:52, 97.01s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 17:26:21,660] [INFO] [logging.py:96:log_dist] [Rank 0] step=762, skipped=0, lr=[1.9445982319476153e-05], mom=[(0.9, 0.999)]
steps: 762 loss: 0.6360 iter time (s): 86.603 samples/sec: 1.478

100%|██████████| 1/1 [01:27<00:00, 87.32s/it][A100%|██████████| 1/1 [01:27<00:00, 87.32s/it]
 15%|█▍        | 771/5198 [22:01:16<119:09:53, 96.90s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.45s/it][A100%|██████████| 1/1 [01:27<00:00, 87.45s/it]
 15%|█▍        | 771/5198 [22:01:16<119:10:09, 96.91s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.34s/it][A100%|██████████| 1/1 [01:27<00:00, 87.34s/it]
 15%|█▍        | 771/5198 [22:01:16<119:07:49, 96.88s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.37s/it][A100%|██████████| 1/1 [01:27<00:00, 87.37s/it]
 15%|█▍        | 771/5198 [22:01:16<119:08:50, 96.89s/it] 
100%|██████████| 1/1 [01:27<00:00, 87.37s/it][A100%|██████████| 1/1 [01:27<00:00, 87.37s/it]
 15%|█▍        | 771/5198 [22:01:16<119:08:01, 96.88s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.37s/it][A100%|██████████| 1/1 [01:27<00:00, 87.37s/it]
 15%|█▍        | 771/5198 [22:01:17<119:08:22, 96.88s/it] 
100%|██████████| 1/1 [01:27<00:00, 87.38s/it][A100%|██████████| 1/1 [01:27<00:00, 87.38s/it]
 15%|█▍        | 771/5198 [22:01:19<119:08:46, 96.89s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_723

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.10s/it][A100%|██████████| 1/1 [01:31<00:00, 91.10s/it]
 15%|█▍        | 772/5198 [22:02:47<117:10:48, 95.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 17:27:53,075] [INFO] [logging.py:96:log_dist] [Rank 0] step=763, skipped=0, lr=[1.9444121765878002e-05], mom=[(0.9, 0.999)]
steps: 763 loss: 0.5612 iter time (s): 90.610 samples/sec: 1.413

100%|██████████| 1/1 [01:31<00:00, 91.41s/it][A100%|██████████| 1/1 [01:31<00:00, 91.41s/it]
 15%|█▍        | 772/5198 [22:02:47<117:07:35, 95.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.50s/it][A100%|██████████| 1/1 [01:31<00:00, 91.50s/it]
 15%|█▍        | 772/5198 [22:02:47<117:09:18, 95.29s/it]
100%|██████████| 1/1 [01:31<00:00, 91.47s/it][A100%|██████████| 1/1 [01:31<00:00, 91.47s/it]
 15%|█▍        | 772/5198 [22:02:48<117:07:47, 95.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.51s/it][A100%|██████████| 1/1 [01:31<00:00, 91.51s/it]
 15%|█▍        | 772/5198 [22:02:48<117:08:31, 95.28s/it]
100%|██████████| 1/1 [01:31<00:00, 91.52s/it][A100%|██████████| 1/1 [01:31<00:00, 91.52s/it]
 15%|█▍        | 772/5198 [22:02:48<117:08:08, 95.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.47s/it][A100%|██████████| 1/1 [01:31<00:00, 91.47s/it]
 15%|█▍        | 772/5198 [22:02:48<117:07:23, 95.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.46s/it][A100%|██████████| 1/1 [01:31<00:00, 91.46s/it]
 15%|█▍        | 772/5198 [22:02:50<117:07:51, 95.27s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_724
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.48s/it][A100%|██████████| 1/1 [01:47<00:00, 107.48s/it]
 15%|█▍        | 773/5198 [22:04:35<121:43:41, 99.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 17:29:40,756] [INFO] [logging.py:96:log_dist] [Rank 0] step=764, skipped=0, lr=[1.944225818269199e-05], mom=[(0.9, 0.999)]
steps: 764 loss: 0.5562 iter time (s): 106.820 samples/sec: 1.198

100%|██████████| 1/1 [01:47<00:00, 107.63s/it][A100%|██████████| 1/1 [01:47<00:00, 107.63s/it]
 15%|█▍        | 773/5198 [22:04:35<121:39:56, 98.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.42s/it][A100%|██████████| 1/1 [01:47<00:00, 107.42s/it]
 15%|█▍        | 773/5198 [22:04:35<121:37:42, 98.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.50s/it][A100%|██████████| 1/1 [01:47<00:00, 107.50s/it]
 15%|█▍        | 773/5198 [22:04:35<121:37:38, 98.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.47s/it][A100%|██████████| 1/1 [01:47<00:00, 107.48s/it]
 15%|█▍        | 773/5198 [22:04:35<121:37:08, 98.94s/it]
100%|██████████| 1/1 [01:47<00:00, 107.49s/it][A100%|██████████| 1/1 [01:47<00:00, 107.49s/it]
 15%|█▍        | 773/5198 [22:04:35<121:36:54, 98.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:47<00:00, 107.55s/it][A100%|██████████| 1/1 [01:47<00:00, 107.55s/it]
 15%|█▍        | 773/5198 [22:04:36<121:37:45, 98.95s/it]
100%|██████████| 1/1 [01:47<00:00, 107.54s/it][A100%|██████████| 1/1 [01:47<00:00, 107.54s/it]
 15%|█▍        | 773/5198 [22:04:38<121:37:52, 98.95s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_725
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:58<00:00, 118.86s/it][A100%|██████████| 1/1 [01:58<00:00, 118.86s/it]
 15%|█▍        | 774/5198 [22:06:34<129:08:36, 105.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 17:31:40,833] [INFO] [logging.py:96:log_dist] [Rank 0] step=765, skipped=0, lr=[1.9440391570515985e-05], mom=[(0.9, 0.999)]
steps: 765 loss: 0.5821 iter time (s): 119.338 samples/sec: 1.073

100%|██████████| 1/1 [02:00<00:00, 120.07s/it][A100%|██████████| 1/1 [02:00<00:00, 120.07s/it]
 15%|█▍        | 774/5198 [22:06:35<129:25:00, 105.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.25s/it][A100%|██████████| 1/1 [02:00<00:00, 120.25s/it]
 15%|█▍        | 774/5198 [22:06:35<129:27:18, 105.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.24s/it][A100%|██████████| 1/1 [02:00<00:00, 120.24s/it]
 15%|█▍        | 774/5198 [22:06:36<129:27:17, 105.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.19s/it][A100%|██████████| 1/1 [02:00<00:00, 120.19s/it]
 15%|█▍        | 774/5198 [22:06:36<129:25:52, 105.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.27s/it][A100%|██████████| 1/1 [02:00<00:00, 120.27s/it]
 15%|█▍        | 774/5198 [22:06:36<129:27:27, 105.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][A100%|██████████| 1/1 [02:00<00:00, 120.17s/it][A100%|██████████| 1/1 [02:00<00:00, 120.17s/it]
 15%|█▍        | 774/5198 [22:06:36<129:26:16, 105.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.20s/it][A100%|██████████| 1/1 [02:00<00:00, 120.20s/it]
 15%|█▍        | 774/5198 [22:06:38<129:26:30, 105.33s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_726
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.63s/it][A100%|██████████| 1/1 [01:32<00:00, 92.63s/it]
 15%|█▍        | 775/5198 [22:08:07<124:36:05, 101.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 17:33:12,610] [INFO] [logging.py:96:log_dist] [Rank 0] step=766, skipped=0, lr=[1.9438521929948858e-05], mom=[(0.9, 0.999)]
steps: 766 loss: 0.6199 iter time (s): 90.872 samples/sec: 1.409

100%|██████████| 1/1 [01:31<00:00, 91.70s/it][A100%|██████████| 1/1 [01:31<00:00, 91.70s/it]
 15%|█▍        | 775/5198 [22:08:07<124:23:19, 101.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.72s/it][A100%|██████████| 1/1 [01:31<00:00, 91.72s/it]
 15%|█▍        | 775/5198 [22:08:07<124:24:36, 101.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.75s/it][A100%|██████████| 1/1 [01:31<00:00, 91.75s/it]
 15%|█▍        | 775/5198 [22:08:07<124:25:14, 101.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.69s/it][A100%|██████████| 1/1 [01:31<00:00, 91.69s/it]
 15%|█▍        | 775/5198 [22:08:07<124:24:02, 101.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.74s/it][A100%|██████████| 1/1 [01:31<00:00, 91.74s/it]
 15%|█▍        | 775/5198 [22:08:07<124:25:16, 101.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.72s/it][A100%|██████████| 1/1 [01:31<00:00, 91.72s/it]
 15%|█▍        | 775/5198 [22:08:07<124:23:42, 101.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.69s/it][A100%|██████████| 1/1 [01:31<00:00, 91.69s/it]
 15%|█▍        | 775/5198 [22:08:10<124:24:07, 101.25s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_727
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.38s/it][A100%|██████████| 1/1 [01:37<00:00, 97.38s/it]
 15%|█▍        | 776/5198 [22:09:44<123:10:10, 100.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 17:34:50,562] [INFO] [logging.py:96:log_dist] [Rank 0] step=767, skipped=0, lr=[1.9436649261590425e-05], mom=[(0.9, 0.999)]
steps: 767 loss: 0.5851 iter time (s): 97.082 samples/sec: 1.318

100%|██████████| 1/1 [01:37<00:00, 97.90s/it][A100%|██████████| 1/1 [01:37<00:00, 97.90s/it]
 15%|█▍        | 776/5198 [22:09:45<123:08:19, 100.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.82s/it][A100%|██████████| 1/1 [01:37<00:00, 97.82s/it]
 15%|█▍        | 776/5198 [22:09:45<123:07:14, 100.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.88s/it][A100%|██████████| 1/1 [01:37<00:00, 97.89s/it]
 15%|█▍        | 776/5198 [22:09:45<123:08:55, 100.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.83s/it][A100%|██████████| 1/1 [01:37<00:00, 97.83s/it]
 15%|█▍        | 776/5198 [22:09:45<123:07:39, 100.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.90s/it][A100%|██████████| 1/1 [01:37<00:00, 97.90s/it]
 15%|█▍        | 776/5198 [22:09:45<123:08:24, 100.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.91s/it][A100%|██████████| 1/1 [01:37<00:00, 97.91s/it]
 15%|█▍        | 776/5198 [22:09:45<123:08:18, 100.25s/it]
100%|██████████| 1/1 [01:37<00:00, 97.85s/it][A100%|██████████| 1/1 [01:37<00:00, 97.85s/it]
 15%|█▍        | 776/5198 [22:09:48<123:08:07, 100.25s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_728

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.56s/it][A100%|██████████| 1/1 [01:35<00:00, 95.56s/it]
 15%|█▍        | 777/5198 [22:11:20<121:29:51, 98.94s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 17:36:26,454] [INFO] [logging.py:96:log_dist] [Rank 0] step=768, skipped=0, lr=[1.9434773566041492e-05], mom=[(0.9, 0.999)]
steps: 768 loss: 0.5838 iter time (s): 95.111 samples/sec: 1.346

100%|██████████| 1/1 [01:35<00:00, 95.88s/it][A100%|██████████| 1/1 [01:35<00:00, 95.88s/it]
 15%|█▍        | 777/5198 [22:11:21<121:30:30, 98.94s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.93s/it][A100%|██████████| 1/1 [01:35<00:00, 95.93s/it]
 15%|█▍        | 777/5198 [22:11:21<121:31:10, 98.95s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.91s/it][A100%|██████████| 1/1 [01:35<00:00, 95.91s/it]
 15%|█▍        | 777/5198 [22:11:21<121:31:28, 98.96s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.86s/it][A100%|██████████| 1/1 [01:35<00:00, 95.86s/it]
 15%|█▍        | 777/5198 [22:11:21<121:30:24, 98.94s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.91s/it][A100%|██████████| 1/1 [01:35<00:00, 95.91s/it]
 15%|█▍        | 777/5198 [22:11:21<121:30:55, 98.95s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:35<00:00, 95.88s/it][A100%|██████████| 1/1 [01:35<00:00, 95.88s/it]
 15%|█▍        | 777/5198 [22:11:21<121:30:40, 98.95s/it] 
100%|██████████| 1/1 [01:35<00:00, 95.87s/it][A100%|██████████| 1/1 [01:35<00:00, 95.87s/it]
 15%|█▍        | 777/5198 [22:11:24<121:30:15, 98.94s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_729
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.29s/it][A100%|██████████| 1/1 [01:26<00:00, 86.29s/it]
 15%|█▍        | 778/5198 [22:12:47<116:54:18, 95.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 17:37:52,730] [INFO] [logging.py:96:log_dist] [Rank 0] step=769, skipped=0, lr=[1.9432894843903823e-05], mom=[(0.9, 0.999)]
steps: 769 loss: 0.6066 iter time (s): 85.507 samples/sec: 1.497

100%|██████████| 1/1 [01:26<00:00, 86.22s/it][A100%|██████████| 1/1 [01:26<00:00, 86.22s/it]
 15%|█▍        | 778/5198 [22:12:47<116:49:04, 95.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.23s/it][A100%|██████████| 1/1 [01:26<00:00, 86.23s/it]
 15%|█▍        | 778/5198 [22:12:47<116:48:54, 95.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.20s/it][A100%|██████████| 1/1 [01:26<00:00, 86.20s/it]
 15%|█▍        | 778/5198 [22:12:47<116:48:12, 95.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.25s/it][A100%|██████████| 1/1 [01:26<00:00, 86.25s/it]
 15%|█▍        | 778/5198 [22:12:48<116:49:04, 95.15s/it]
100%|██████████| 1/1 [01:26<00:00, 86.32s/it][A100%|██████████| 1/1 [01:26<00:00, 86.32s/it]
 15%|█▍        | 778/5198 [22:12:47<116:50:08, 95.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.28s/it][A100%|██████████| 1/1 [01:26<00:00, 86.28s/it]
 15%|█▍        | 778/5198 [22:12:48<116:49:14, 95.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.29s/it][A100%|██████████| 1/1 [01:26<00:00, 86.29s/it]
 15%|█▍        | 778/5198 [22:12:50<116:49:05, 95.15s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_730
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.28s/it][A100%|██████████| 1/1 [01:32<00:00, 92.28s/it]
 15%|█▍        | 779/5198 [22:14:19<115:51:14, 94.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 17:39:25,294] [INFO] [logging.py:96:log_dist] [Rank 0] step=770, skipped=0, lr=[1.943101309578016e-05], mom=[(0.9, 0.999)]
steps: 770 loss: 0.6160 iter time (s): 91.770 samples/sec: 1.395

100%|██████████| 1/1 [01:32<00:00, 92.52s/it][A100%|██████████| 1/1 [01:32<00:00, 92.52s/it]
 15%|█▍        | 779/5198 [22:14:19<115:50:02, 94.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.50s/it][A100%|██████████| 1/1 [01:32<00:00, 92.50s/it]
 15%|█▍        | 779/5198 [22:14:20<115:49:33, 94.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.56s/it][A100%|██████████| 1/1 [01:32<00:00, 92.56s/it]
 15%|█▍        | 779/5198 [22:14:20<115:50:39, 94.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.46s/it][A100%|██████████| 1/1 [01:32<00:00, 92.46s/it]
 15%|█▍        | 779/5198 [22:14:20<115:49:19, 94.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.57s/it][A100%|██████████| 1/1 [01:32<00:00, 92.57s/it]
 15%|█▍        | 779/5198 [22:14:20<115:51:03, 94.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.59s/it][A100%|██████████| 1/1 [01:32<00:00, 92.59s/it]
 15%|█▍        | 779/5198 [22:14:20<115:51:21, 94.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.63s/it][A100%|██████████| 1/1 [01:32<00:00, 92.63s/it]
 15%|█▍        | 779/5198 [22:14:22<115:51:57, 94.39s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_731
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.29s/it][A100%|██████████| 1/1 [01:59<00:00, 119.29s/it]
 15%|█▌        | 780/5198 [22:16:19<125:06:37, 101.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 17:41:25,678] [INFO] [logging.py:96:log_dist] [Rank 0] step=771, skipped=0, lr=[1.9429128322274217e-05], mom=[(0.9, 0.999)]
steps: 771 loss: 0.5740 iter time (s): 119.530 samples/sec: 1.071

100%|██████████| 1/1 [02:00<00:00, 120.35s/it][A100%|██████████| 1/1 [02:00<00:00, 120.35s/it]
 15%|█▌        | 780/5198 [22:16:20<125:22:44, 102.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.36s/it][A100%|██████████| 1/1 [02:00<00:00, 120.36s/it]
 15%|█▌        | 780/5198 [22:16:20<125:22:28, 102.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.34s/it][A100%|██████████| 1/1 [02:00<00:00, 120.34s/it]
 15%|█▌        | 780/5198 [22:16:20<125:22:51, 102.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.40s/it][A100%|██████████| 1/1 [02:00<00:00, 120.40s/it]
 15%|█▌        | 780/5198 [22:16:20<125:23:41, 102.18s/it]
100%|██████████| 1/1 [02:00<00:00, 120.30s/it][A100%|██████████| 1/1 [02:00<00:00, 120.30s/it]
 15%|█▌        | 780/5198 [22:16:20<125:22:41, 102.16s/it]
100%|██████████| 1/1 [02:00<00:00, 120.29s/it][A100%|██████████| 1/1 [02:00<00:00, 120.29s/it]
 15%|█▌        | 780/5198 [22:16:20<125:22:16, 102.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.28s/it][A100%|██████████| 1/1 [02:00<00:00, 120.28s/it]
 15%|█▌        | 780/5198 [22:16:23<125:22:21, 102.16s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_732
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:34<00:00, 94.03s/it][A100%|██████████| 1/1 [01:34<00:00, 94.03s/it]
 15%|█▌        | 781/5198 [22:17:53<122:13:58, 99.62s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 17:42:59,164] [INFO] [logging.py:96:log_dist] [Rank 0] step=772, skipped=0, lr=[1.9427240523990677e-05], mom=[(0.9, 0.999)]
steps: 772 loss: 0.5785 iter time (s): 92.722 samples/sec: 1.380

100%|██████████| 1/1 [01:33<00:00, 93.46s/it][A100%|██████████| 1/1 [01:33<00:00, 93.46s/it]
 15%|█▌        | 781/5198 [22:17:53<122:10:02, 99.57s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.57s/it][A100%|██████████| 1/1 [01:33<00:00, 93.57s/it]
 15%|█▌        | 781/5198 [22:17:54<122:12:16, 99.60s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.58s/it][A100%|██████████| 1/1 [01:33<00:00, 93.58s/it]
 15%|█▌        | 781/5198 [22:17:54<122:12:03, 99.60s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.49s/it][A100%|██████████| 1/1 [01:33<00:00, 93.49s/it]
 15%|█▌        | 781/5198 [22:17:54<122:10:43, 99.58s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.50s/it][A100%|██████████| 1/1 [01:33<00:00, 93.50s/it]
 15%|█▌        | 781/5198 [22:17:54<122:10:06, 99.57s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:33<00:00, 93.54s/it][A100%|██████████| 1/1 [01:33<00:00, 93.54s/it]
 15%|█▌        | 781/5198 [22:17:54<122:10:20, 99.57s/it] 
100%|██████████| 1/1 [01:33<00:00, 93.53s/it][A100%|██████████| 1/1 [01:33<00:00, 93.53s/it]
 15%|█▌        | 781/5198 [22:17:56<122:10:13, 99.57s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_733

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.74s/it][A100%|██████████| 1/1 [01:22<00:00, 82.74s/it]
 15%|█▌        | 782/5198 [22:19:16<116:03:32, 94.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 17:44:21,732] [INFO] [logging.py:96:log_dist] [Rank 0] step=773, skipped=0, lr=[1.9425349701535187e-05], mom=[(0.9, 0.999)]
steps: 773 loss: 0.6053 iter time (s): 81.711 samples/sec: 1.566

100%|██████████| 1/1 [01:22<00:00, 82.53s/it][A100%|██████████| 1/1 [01:22<00:00, 82.53s/it]
 15%|█▌        | 782/5198 [22:19:16<115:52:52, 94.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.41s/it][A100%|██████████| 1/1 [01:22<00:00, 82.41s/it]
 15%|█▌        | 782/5198 [22:19:16<115:51:52, 94.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.46s/it][A100%|██████████| 1/1 [01:22<00:00, 82.46s/it]
 15%|█▌        | 782/5198 [22:19:16<115:52:33, 94.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.50s/it][A100%|██████████| 1/1 [01:22<00:00, 82.50s/it]
 15%|█▌        | 782/5198 [22:19:16<115:52:08, 94.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.53s/it][A100%|██████████| 1/1 [01:22<00:00, 82.53s/it]
 15%|█▌        | 782/5198 [22:19:17<115:52:22, 94.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.49s/it][A100%|██████████| 1/1 [01:22<00:00, 82.49s/it]
 15%|█▌        | 782/5198 [22:19:17<115:52:22, 94.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.49s/it][A100%|██████████| 1/1 [01:22<00:00, 82.49s/it]
 15%|█▌        | 782/5198 [22:19:19<115:52:19, 94.46s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_734
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:41<00:00, 101.71s/it][A100%|██████████| 1/1 [01:41<00:00, 101.71s/it]
 15%|█▌        | 783/5198 [22:20:58<118:43:56, 96.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 17:46:04,223] [INFO] [logging.py:96:log_dist] [Rank 0] step=774, skipped=0, lr=[1.942345585551437e-05], mom=[(0.9, 0.999)]
steps: 774 loss: 0.5602 iter time (s): 101.738 samples/sec: 1.258

100%|██████████| 1/1 [01:42<00:00, 102.49s/it][A100%|██████████| 1/1 [01:42<00:00, 102.49s/it]
 15%|█▌        | 783/5198 [22:20:58<118:48:50, 96.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.50s/it][A100%|██████████| 1/1 [01:42<00:00, 102.50s/it]
 15%|█▌        | 783/5198 [22:20:59<118:48:37, 96.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.51s/it][A100%|██████████| 1/1 [01:42<00:00, 102.51s/it]
 15%|█▌        | 783/5198 [22:20:59<118:48:48, 96.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.50s/it][A100%|██████████| 1/1 [01:42<00:00, 102.50s/it]
 15%|█▌        | 783/5198 [22:20:59<118:48:36, 96.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.55s/it][A100%|██████████| 1/1 [01:42<00:00, 102.55s/it]
 15%|█▌        | 783/5198 [22:20:59<118:49:49, 96.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.54s/it][A100%|██████████| 1/1 [01:42<00:00, 102.54s/it]
 15%|█▌        | 783/5198 [22:20:59<118:49:21, 96.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.55s/it][A100%|██████████| 1/1 [01:42<00:00, 102.55s/it]
 15%|█▌        | 783/5198 [22:21:01<118:49:33, 96.89s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_48
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:59<00:00, 119.22s/it][A100%|██████████| 1/1 [01:59<00:00, 119.22s/it]
 15%|█▌        | 784/5198 [22:22:57<127:01:42, 103.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 17:48:03,957] [INFO] [logging.py:96:log_dist] [Rank 0] step=775, skipped=0, lr=[1.942155898653583e-05], mom=[(0.9, 0.999)]
steps: 775 loss: 0.7938 iter time (s): 119.100 samples/sec: 1.075

100%|██████████| 1/1 [02:00<00:00, 120.11s/it][A100%|██████████| 1/1 [02:00<00:00, 120.11s/it]
 15%|█▌        | 784/5198 [22:22:58<127:20:18, 103.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.08s/it][A100%|██████████| 1/1 [02:00<00:00, 120.08s/it]
 15%|█▌        | 784/5198 [22:22:59<127:19:34, 103.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.11s/it][A100%|██████████| 1/1 [02:00<00:00, 120.12s/it]
 15%|█▌        | 784/5198 [22:22:59<127:20:44, 103.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.17s/it][A100%|██████████| 1/1 [02:00<00:00, 120.17s/it]
 15%|█▌        | 784/5198 [22:22:59<127:21:13, 103.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.14s/it][A100%|██████████| 1/1 [02:00<00:00, 120.14s/it]
 15%|█▌        | 784/5198 [22:22:59<127:21:25, 103.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.16s/it][A100%|██████████| 1/1 [02:00<00:00, 120.16s/it]
 15%|█▌        | 784/5198 [22:22:59<127:21:34, 103.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:00<00:00, 120.10s/it][A100%|██████████| 1/1 [02:00<00:00, 120.10s/it]
 15%|█▌        | 784/5198 [22:23:02<127:21:34, 103.87s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_735
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:45<00:00, 105.13s/it][A100%|██████████| 1/1 [01:45<00:00, 105.13s/it]
 15%|█▌        | 785/5198 [22:24:42<127:37:45, 104.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 17:49:49,111] [INFO] [logging.py:96:log_dist] [Rank 0] step=776, skipped=0, lr=[1.9419659095208117e-05], mom=[(0.9, 0.999)]
steps: 776 loss: 0.6115 iter time (s): 103.881 samples/sec: 1.232

100%|██████████| 1/1 [01:44<00:00, 104.65s/it][A100%|██████████| 1/1 [01:44<00:00, 104.65s/it]
 15%|█▌        | 785/5198 [22:24:43<127:36:34, 104.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.66s/it][A100%|██████████| 1/1 [01:44<00:00, 104.66s/it]
 15%|█▌        | 785/5198 [22:24:43<127:36:31, 104.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.60s/it][A100%|██████████| 1/1 [01:44<00:00, 104.60s/it]
 15%|█▌        | 785/5198 [22:24:44<127:35:46, 104.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.62s/it][A100%|██████████| 1/1 [01:44<00:00, 104.62s/it]
 15%|█▌        | 785/5198 [22:24:44<127:36:15, 104.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.62s/it][A100%|██████████| 1/1 [01:44<00:00, 104.62s/it]
 15%|█▌        | 785/5198 [22:24:44<127:36:41, 104.10s/it]
100%|██████████| 1/1 [01:44<00:00, 104.61s/it][A100%|██████████| 1/1 [01:44<00:00, 104.61s/it]
 15%|█▌        | 785/5198 [22:24:44<127:36:14, 104.10s/it]
100%|██████████| 1/1 [01:44<00:00, 104.60s/it][A100%|██████████| 1/1 [01:44<00:00, 104.60s/it]
 15%|█▌        | 785/5198 [22:24:46<127:35:57, 104.09s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_736

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.96s/it][A100%|██████████| 1/1 [01:31<00:00, 91.96s/it]
 15%|█▌        | 786/5198 [22:26:15<123:13:08, 100.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 17:51:20,878] [INFO] [logging.py:96:log_dist] [Rank 0] step=777, skipped=0, lr=[1.941775618214077e-05], mom=[(0.9, 0.999)]
steps: 777 loss: 0.5565 iter time (s): 91.016 samples/sec: 1.406

100%|██████████| 1/1 [01:31<00:00, 91.85s/it][A100%|██████████| 1/1 [01:31<00:00, 91.85s/it]
 15%|█▌        | 786/5198 [22:26:15<123:05:28, 100.44s/it]
100%|██████████| 1/1 [01:31<00:00, 91.74s/it][A100%|██████████| 1/1 [01:31<00:00, 91.74s/it]
 15%|█▌        | 786/5198 [22:26:15<123:02:44, 100.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.84s/it][A100%|██████████| 1/1 [01:31<00:00, 91.84s/it]
 15%|█▌        | 786/5198 [22:26:16<123:04:19, 100.42s/it]
100%|██████████| 1/1 [01:31<00:00, 91.80s/it][A100%|██████████| 1/1 [01:31<00:00, 91.80s/it]
 15%|█▌        | 786/5198 [22:26:16<123:03:44, 100.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.74s/it][A100%|██████████| 1/1 [01:31<00:00, 91.74s/it]
 15%|█▌        | 786/5198 [22:26:16<123:03:18, 100.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.78s/it][A100%|██████████| 1/1 [01:31<00:00, 91.78s/it]
 15%|█▌        | 786/5198 [22:26:16<123:03:39, 100.41s/it]
100%|██████████| 1/1 [01:31<00:00, 91.79s/it][A100%|██████████| 1/1 [01:31<00:00, 91.79s/it]
 15%|█▌        | 786/5198 [22:26:18<123:03:29, 100.41s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_737
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.42s/it][A100%|██████████| 1/1 [01:26<00:00, 86.42s/it]
 15%|█▌        | 787/5198 [22:27:41<118:06:25, 96.39s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 17:52:47,527] [INFO] [logging.py:96:log_dist] [Rank 0] step=778, skipped=0, lr=[1.9415850247944285e-05], mom=[(0.9, 0.999)]
steps: 778 loss: 0.6290 iter time (s): 85.846 samples/sec: 1.491

100%|██████████| 1/1 [01:26<00:00, 86.56s/it][A100%|██████████| 1/1 [01:26<00:00, 86.56s/it]
 15%|█▌        | 787/5198 [22:27:42<117:58:42, 96.29s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.63s/it][A100%|██████████| 1/1 [01:26<00:00, 86.63s/it]
 15%|█▌        | 787/5198 [22:27:42<117:58:16, 96.28s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.54s/it][A100%|██████████| 1/1 [01:26<00:00, 86.54s/it]
 15%|█▌        | 787/5198 [22:27:42<117:57:52, 96.28s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.62s/it][A100%|██████████| 1/1 [01:26<00:00, 86.62s/it]
 15%|█▌        | 787/5198 [22:27:42<117:58:03, 96.28s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.65s/it][A100%|██████████| 1/1 [01:26<00:00, 86.65s/it]
 15%|█▌        | 787/5198 [22:27:42<117:58:22, 96.28s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.59s/it][A100%|██████████| 1/1 [01:26<00:00, 86.59s/it]
 15%|█▌        | 787/5198 [22:27:42<117:57:54, 96.28s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.61s/it][A100%|██████████| 1/1 [01:26<00:00, 86.61s/it]
 15%|█▌        | 787/5198 [22:27:45<117:58:01, 96.28s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_738
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.00s/it][A100%|██████████| 1/1 [01:28<00:00, 88.00s/it]
 15%|█▌        | 788/5198 [22:29:10<115:03:33, 93.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 17:54:15,714] [INFO] [logging.py:96:log_dist] [Rank 0] step=779, skipped=0, lr=[1.941394129323014e-05], mom=[(0.9, 0.999)]
steps: 779 loss: 0.5475 iter time (s): 87.431 samples/sec: 1.464

100%|██████████| 1/1 [01:28<00:00, 88.23s/it][A100%|██████████| 1/1 [01:28<00:00, 88.23s/it]
 15%|█▌        | 788/5198 [22:29:10<114:59:41, 93.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.25s/it][A100%|██████████| 1/1 [01:28<00:00, 88.25s/it]
 15%|█▌        | 788/5198 [22:29:10<115:00:09, 93.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.30s/it][A100%|██████████| 1/1 [01:28<00:00, 88.30s/it]
 15%|█▌        | 788/5198 [22:29:10<115:00:59, 93.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.24s/it][A100%|██████████| 1/1 [01:28<00:00, 88.24s/it]
 15%|█▌        | 788/5198 [22:29:10<115:00:18, 93.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.26s/it][A100%|██████████| 1/1 [01:28<00:00, 88.26s/it]
 15%|█▌        | 788/5198 [22:29:11<115:00:05, 93.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.31s/it][A100%|██████████| 1/1 [01:28<00:00, 88.31s/it]
 15%|█▌        | 788/5198 [22:29:11<115:00:48, 93.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:28<00:00, 88.32s/it][A100%|██████████| 1/1 [01:28<00:00, 88.32s/it]
 15%|█▌        | 788/5198 [22:29:13<115:01:07, 93.89s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_739
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.50s/it][A100%|██████████| 1/1 [01:37<00:00, 97.50s/it]
 15%|█▌        | 789/5198 [22:30:47<116:27:28, 95.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 17:55:53,772] [INFO] [logging.py:96:log_dist] [Rank 0] step=780, skipped=0, lr=[1.9412029318610768e-05], mom=[(0.9, 0.999)]
steps: 780 loss: 0.5833 iter time (s): 97.142 samples/sec: 1.318

100%|██████████| 1/1 [01:38<00:00, 98.04s/it][A100%|██████████| 1/1 [01:38<00:00, 98.04s/it]
 15%|█▌        | 789/5198 [22:30:48<116:31:11, 95.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.02s/it][A100%|██████████| 1/1 [01:38<00:00, 98.02s/it]
 15%|█▌        | 789/5198 [22:30:48<116:31:06, 95.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 98.00s/it][A100%|██████████| 1/1 [01:37<00:00, 98.00s/it]
 15%|█▌        | 789/5198 [22:30:48<116:30:07, 95.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.06s/it][A100%|██████████| 1/1 [01:38<00:00, 98.06s/it]
 15%|█▌        | 789/5198 [22:30:49<116:31:01, 95.14s/it]
100%|██████████| 1/1 [01:38<00:00, 98.03s/it][A100%|██████████| 1/1 [01:38<00:00, 98.03s/it]
 15%|█▌        | 789/5198 [22:30:49<116:30:35, 95.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.00s/it][A100%|██████████| 1/1 [01:38<00:00, 98.00s/it]
 15%|█▌        | 789/5198 [22:30:49<116:30:08, 95.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:37<00:00, 97.94s/it][A100%|██████████| 1/1 [01:37<00:00, 97.94s/it]
 15%|█▌        | 789/5198 [22:30:51<116:30:29, 95.13s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_740
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.45s/it][A100%|██████████| 1/1 [01:26<00:00, 86.45s/it]
 15%|█▌        | 790/5198 [22:32:14<113:20:46, 92.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 17:57:20,152] [INFO] [logging.py:96:log_dist] [Rank 0] step=781, skipped=0, lr=[1.9410114324699585e-05], mom=[(0.9, 0.999)]
steps: 781 loss: 0.5716 iter time (s): 85.526 samples/sec: 1.497

100%|██████████| 1/1 [01:26<00:00, 86.32s/it][A100%|██████████| 1/1 [01:26<00:00, 86.32s/it]
 15%|█▌        | 790/5198 [22:32:14<113:15:45, 92.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.34s/it][A100%|██████████| 1/1 [01:26<00:00, 86.34s/it]
 15%|█▌        | 790/5198 [22:32:14<113:17:10, 92.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.28s/it][A100%|██████████| 1/1 [01:26<00:00, 86.28s/it]
 15%|█▌        | 790/5198 [22:32:15<113:15:03, 92.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.28s/it][A100%|██████████| 1/1 [01:26<00:00, 86.28s/it]
 15%|█▌        | 790/5198 [22:32:15<113:15:13, 92.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.34s/it][A100%|██████████| 1/1 [01:26<00:00, 86.34s/it]
 15%|█▌        | 790/5198 [22:32:15<113:15:45, 92.50s/it]
100%|██████████| 1/1 [01:26<00:00, 86.34s/it][A100%|██████████| 1/1 [01:26<00:00, 86.34s/it]
 15%|█▌        | 790/5198 [22:32:15<113:15:34, 92.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.37s/it][A100%|██████████| 1/1 [01:26<00:00, 86.37s/it]
 15%|█▌        | 790/5198 [22:32:17<113:16:01, 92.50s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_741
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:43<00:00, 103.47s/it][A100%|██████████| 1/1 [01:43<00:00, 103.47s/it]
 15%|█▌        | 791/5198 [22:33:58<117:24:45, 95.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 17:59:04,383] [INFO] [logging.py:96:log_dist] [Rank 0] step=782, skipped=0, lr=[1.9408196312110964e-05], mom=[(0.9, 0.999)]
steps: 782 loss: 0.5795 iter time (s): 103.372 samples/sec: 1.238

100%|██████████| 1/1 [01:44<00:00, 104.13s/it][A100%|██████████| 1/1 [01:44<00:00, 104.13s/it]
 15%|█▌        | 791/5198 [22:33:59<117:31:18, 96.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.13s/it][A100%|██████████| 1/1 [01:44<00:00, 104.13s/it]
 15%|█▌        | 791/5198 [22:33:59<117:32:05, 96.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.19s/it][A100%|██████████| 1/1 [01:44<00:00, 104.19s/it]
 15%|█▌        | 791/5198 [22:33:59<117:31:40, 96.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.20s/it][A100%|██████████| 1/1 [01:44<00:00, 104.20s/it]
 15%|█▌        | 791/5198 [22:33:59<117:31:43, 96.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.15s/it][A100%|██████████| 1/1 [01:44<00:00, 104.15s/it]
 15%|█▌        | 791/5198 [22:33:59<117:31:43, 96.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.19s/it][A100%|██████████| 1/1 [01:44<00:00, 104.20s/it]
 15%|█▌        | 791/5198 [22:33:59<117:32:14, 96.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:44<00:00, 104.17s/it][A100%|██████████| 1/1 [01:44<00:00, 104.17s/it]
 15%|█▌        | 791/5198 [22:34:02<117:31:45, 96.01s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_742
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:05<00:00, 125.64s/it][A100%|██████████| 1/1 [02:05<00:00, 125.64s/it]
 15%|█▌        | 792/5198 [22:36:04<128:25:18, 104.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 18:01:10,955] [INFO] [logging.py:96:log_dist] [Rank 0] step=783, skipped=0, lr=[1.9406275281460255e-05], mom=[(0.9, 0.999)]
steps: 783 loss: 0.5865 iter time (s): 125.748 samples/sec: 1.018

100%|██████████| 1/1 [02:06<00:00, 126.59s/it][A100%|██████████| 1/1 [02:06<00:00, 126.59s/it]
 15%|█▌        | 792/5198 [22:36:05<128:44:37, 105.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:06<00:00, 126.67s/it][A100%|██████████| 1/1 [02:06<00:00, 126.67s/it]
 15%|█▌        | 792/5198 [22:36:05<128:46:23, 105.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:06<00:00, 126.80s/it][A100%|██████████| 1/1 [02:06<00:00, 126.80s/it]
 15%|█▌        | 792/5198 [22:36:06<128:49:05, 105.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:06<00:00, 126.71s/it][A100%|██████████| 1/1 [02:06<00:00, 126.71s/it]
 15%|█▌        | 792/5198 [22:36:06<128:47:29, 105.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:06<00:00, 126.70s/it][A100%|██████████| 1/1 [02:06<00:00, 126.70s/it]
 15%|█▌        | 792/5198 [22:36:06<128:46:38, 105.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:06<00:00, 126.70s/it][A100%|██████████| 1/1 [02:06<00:00, 126.70s/it]
 15%|█▌        | 792/5198 [22:36:08<128:46:56, 105.22s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_743
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:06<00:00, 126.75s/it][A100%|██████████| 1/1 [02:06<00:00, 126.75s/it]
 15%|█▌        | 792/5198 [22:36:06<128:47:51, 105.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.66s/it][A100%|██████████| 1/1 [01:40<00:00, 100.66s/it]
 15%|█▌        | 793/5198 [22:37:45<126:53:58, 103.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 18:02:51,106] [INFO] [logging.py:96:log_dist] [Rank 0] step=784, skipped=0, lr=[1.9404351233363766e-05], mom=[(0.9, 0.999)]
steps: 784 loss: 0.5524 iter time (s): 99.178 samples/sec: 1.291

100%|██████████| 1/1 [01:39<00:00, 99.99s/it][A100%|██████████| 1/1 [01:39<00:00, 99.99s/it]
 15%|█▌        | 793/5198 [22:37:45<126:49:37, 103.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.97s/it][A100%|██████████| 1/1 [01:39<00:00, 99.97s/it]
 15%|█▌        | 793/5198 [22:37:45<126:49:17, 103.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.93s/it][A100%|██████████| 1/1 [01:39<00:00, 99.93s/it]
 15%|█▌        | 793/5198 [22:37:46<126:50:14, 103.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.04s/it][A100%|██████████| 1/1 [01:40<00:00, 100.04s/it]
 15%|█▌        | 793/5198 [22:37:46<126:51:30, 103.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:40<00:00, 100.05s/it][A100%|██████████| 1/1 [01:40<00:00, 100.05s/it]
 15%|█▌        | 793/5198 [22:37:46<126:51:20, 103.67s/it]
100%|██████████| 1/1 [01:39<00:00, 100.00s/it][A100%|██████████| 1/1 [01:40<00:00, 100.00s/it]
 15%|█▌        | 793/5198 [22:37:46<126:50:55, 103.67s/it]
100%|██████████| 1/1 [01:40<00:00, 100.03s/it][A100%|██████████| 1/1 [01:40<00:00, 100.03s/it]
 15%|█▌        | 793/5198 [22:37:48<126:51:00, 103.67s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_744
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:16<00:00, 136.41s/it][A100%|██████████| 1/1 [02:16<00:00, 136.41s/it]
 15%|█▌        | 794/5198 [22:40:01<138:59:25, 113.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 18:05:08,850] [INFO] [logging.py:96:log_dist] [Rank 0] step=785, skipped=0, lr=[1.940242416843878e-05], mom=[(0.9, 0.999)]
steps: 785 loss: 0.5508 iter time (s): 136.903 samples/sec: 0.935

100%|██████████| 1/1 [02:17<00:00, 137.96s/it][A100%|██████████| 1/1 [02:17<00:00, 137.96s/it]
 15%|█▌        | 794/5198 [22:40:03<139:24:47, 113.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:18<00:00, 138.10s/it][A100%|██████████| 1/1 [02:18<00:00, 138.10s/it]
 15%|█▌        | 794/5198 [22:40:03<139:27:38, 114.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:18<00:00, 138.02s/it][A100%|██████████| 1/1 [02:18<00:00, 138.02s/it]
 15%|█▌        | 794/5198 [22:40:04<139:25:49, 113.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:17<00:00, 137.95s/it][A100%|██████████| 1/1 [02:17<00:00, 137.95s/it]
 15%|█▌        | 794/5198 [22:40:04<139:24:40, 113.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:17<00:00, 137.99s/it][A100%|██████████| 1/1 [02:17<00:00, 137.99s/it]
 15%|█▌        | 794/5198 [22:40:04<139:26:53, 113.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:18<00:00, 138.03s/it][A100%|██████████| 1/1 [02:18<00:00, 138.03s/it]
 15%|█▌        | 794/5198 [22:40:06<139:26:22, 113.98s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_745
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:18<00:00, 138.32s/it][A100%|██████████| 1/1 [02:18<00:00, 138.32s/it]
 15%|█▌        | 794/5198 [22:40:04<139:33:09, 114.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:32<00:00, 92.40s/it][A100%|██████████| 1/1 [01:32<00:00, 92.40s/it]
 15%|█▌        | 795/5198 [22:41:34<131:16:19, 107.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 18:06:40,217] [INFO] [logging.py:96:log_dist] [Rank 0] step=786, skipped=0, lr=[1.9400494087303556e-05], mom=[(0.9, 0.999)]
steps: 786 loss: 0.5983 iter time (s): 90.199 samples/sec: 1.419

100%|██████████| 1/1 [01:31<00:00, 91.13s/it][A100%|██████████| 1/1 [01:31<00:00, 91.13s/it]
 15%|█▌        | 795/5198 [22:41:34<131:01:35, 107.13s/it]
100%|██████████| 1/1 [01:30<00:00, 90.89s/it][A100%|██████████| 1/1 [01:30<00:00, 90.89s/it]
 15%|█▌        | 795/5198 [22:41:34<130:57:52, 107.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.97s/it][A100%|██████████| 1/1 [01:30<00:00, 90.97s/it]
 15%|█▌        | 795/5198 [22:41:35<130:58:01, 107.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.06s/it][A100%|██████████| 1/1 [01:31<00:00, 91.06s/it]
 15%|█▌        | 795/5198 [22:41:35<130:59:18, 107.10s/it]
100%|██████████| 1/1 [01:30<00:00, 90.92s/it][A100%|██████████| 1/1 [01:30<00:00, 90.92s/it]
 15%|█▌        | 795/5198 [22:41:35<130:57:52, 107.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.66s/it][A100%|██████████| 1/1 [01:30<00:00, 90.66s/it]
 15%|█▌        | 795/5198 [22:41:35<130:56:01, 107.05s/it]
100%|██████████| 1/1 [01:30<00:00, 90.97s/it][A100%|██████████| 1/1 [01:30<00:00, 90.97s/it]
 15%|█▌        | 795/5198 [22:41:37<130:57:57, 107.08s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_746

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.39s/it][A100%|██████████| 1/1 [01:36<00:00, 96.39s/it]
 15%|█▌        | 796/5198 [22:43:11<127:17:44, 104.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 18:08:16,874] [INFO] [logging.py:96:log_dist] [Rank 0] step=787, skipped=0, lr=[1.9398560990577305e-05], mom=[(0.9, 0.999)]
steps: 787 loss: 0.5960 iter time (s): 95.827 samples/sec: 1.336

100%|██████████| 1/1 [01:36<00:00, 96.55s/it][A100%|██████████| 1/1 [01:36<00:00, 96.55s/it]
 15%|█▌        | 796/5198 [22:43:11<127:07:56, 103.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.58s/it][A100%|██████████| 1/1 [01:36<00:00, 96.58s/it]
 15%|█▌        | 796/5198 [22:43:11<127:05:31, 103.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.58s/it][A100%|██████████| 1/1 [01:36<00:00, 96.59s/it]
 15%|█▌        | 796/5198 [22:43:11<127:05:33, 103.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.59s/it][A100%|██████████| 1/1 [01:36<00:00, 96.59s/it]
 15%|█▌        | 796/5198 [22:43:12<127:06:23, 103.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.64s/it][A100%|██████████| 1/1 [01:36<00:00, 96.64s/it]
 15%|█▌        | 796/5198 [22:43:12<127:06:37, 103.95s/it]
100%|██████████| 1/1 [01:36<00:00, 96.55s/it][A100%|██████████| 1/1 [01:36<00:00, 96.55s/it]
 15%|█▌        | 796/5198 [22:43:12<127:04:35, 103.92s/it]
100%|██████████| 1/1 [01:36<00:00, 96.56s/it][A100%|██████████| 1/1 [01:36<00:00, 96.56s/it]
 15%|█▌        | 796/5198 [22:43:14<127:06:04, 103.94s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_747

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.11s/it][A100%|██████████| 1/1 [01:51<00:00, 111.11s/it]
 15%|█▌        | 797/5198 [22:45:02<129:54:09, 106.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 18:10:08,633] [INFO] [logging.py:96:log_dist] [Rank 0] step=788, skipped=0, lr=[1.939662487888021e-05], mom=[(0.9, 0.999)]
steps: 788 loss: 0.5516 iter time (s): 111.009 samples/sec: 1.153

100%|██████████| 1/1 [01:51<00:00, 111.77s/it][A100%|██████████| 1/1 [01:51<00:00, 111.77s/it]
 15%|█▌        | 797/5198 [22:45:03<129:58:08, 106.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.84s/it][A100%|██████████| 1/1 [01:51<00:00, 111.84s/it]
 15%|█▌        | 797/5198 [22:45:03<129:57:47, 106.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.83s/it][A100%|██████████| 1/1 [01:51<00:00, 111.83s/it]
 15%|█▌        | 797/5198 [22:45:03<129:58:18, 106.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.95s/it][A100%|██████████| 1/1 [01:51<00:00, 111.95s/it]
 15%|█▌        | 797/5198 [22:45:03<130:01:05, 106.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.86s/it][A100%|██████████| 1/1 [01:51<00:00, 111.86s/it]
 15%|█▌        | 797/5198 [22:45:04<129:59:39, 106.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.11s/it][A100%|██████████| 1/1 [01:52<00:00, 112.11s/it]
 15%|█▌        | 797/5198 [22:45:06<130:04:08, 106.40s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_748
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.35s/it][A100%|██████████| 1/1 [01:52<00:00, 112.35s/it]
 15%|█▌        | 797/5198 [22:45:04<130:08:41, 106.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.24s/it][A100%|██████████| 1/1 [01:49<00:00, 109.24s/it]
 15%|█▌        | 798/5198 [22:46:51<131:03:10, 107.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 18:11:58,070] [INFO] [logging.py:96:log_dist] [Rank 0] step=789, skipped=0, lr=[1.939468575283343e-05], mom=[(0.9, 0.999)]
steps: 789 loss: 0.5920 iter time (s): 108.358 samples/sec: 1.181

100%|██████████| 1/1 [01:49<00:00, 109.45s/it][A100%|██████████| 1/1 [01:49<00:00, 109.45s/it]
 15%|█▌        | 798/5198 [22:46:52<131:05:35, 107.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.36s/it][A100%|██████████| 1/1 [01:49<00:00, 109.36s/it]
 15%|█▌        | 798/5198 [22:46:52<131:04:20, 107.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.34s/it][A100%|██████████| 1/1 [01:49<00:00, 109.34s/it]
 15%|█▌        | 798/5198 [22:46:53<131:05:17, 107.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.47s/it][A100%|██████████| 1/1 [01:49<00:00, 109.47s/it]
 15%|█▌        | 798/5198 [22:46:53<131:06:19, 107.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:48<00:00, 108.85s/it][A100%|██████████| 1/1 [01:48<00:00, 108.85s/it]
 15%|█▌        | 798/5198 [22:46:53<131:00:49, 107.19s/it]
100%|██████████| 1/1 [01:49<00:00, 109.38s/it][A100%|██████████| 1/1 [01:49<00:00, 109.38s/it]
 15%|█▌        | 798/5198 [22:46:53<131:05:31, 107.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:49<00:00, 109.18s/it][A100%|██████████| 1/1 [01:49<00:00, 109.18s/it]
 15%|█▌        | 798/5198 [22:46:55<131:04:05, 107.24s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_749
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.77s/it][A100%|██████████| 1/1 [01:42<00:00, 102.77s/it]
 15%|█▌        | 799/5198 [22:48:34<129:31:07, 105.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 18:13:40,986] [INFO] [logging.py:96:log_dist] [Rank 0] step=790, skipped=0, lr=[1.9392743613059082e-05], mom=[(0.9, 0.999)]
steps: 790 loss: 0.6185 iter time (s): 102.059 samples/sec: 1.254

100%|██████████| 1/1 [01:42<00:00, 102.78s/it][A100%|██████████| 1/1 [01:42<00:00, 102.78s/it]
 15%|█▌        | 799/5198 [22:48:35<129:25:49, 105.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.91s/it][A100%|██████████| 1/1 [01:42<00:00, 102.91s/it]
 15%|█▌        | 799/5198 [22:48:35<129:27:38, 105.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.83s/it][A100%|██████████| 1/1 [01:42<00:00, 102.83s/it]
 15%|█▌        | 799/5198 [22:48:36<129:26:32, 105.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.83s/it][A100%|██████████| 1/1 [01:42<00:00, 102.83s/it]
 15%|█▌        | 799/5198 [22:48:36<129:27:16, 105.94s/it]
100%|██████████| 1/1 [01:42<00:00, 102.80s/it][A100%|██████████| 1/1 [01:42<00:00, 102.80s/it]
 15%|█▌        | 799/5198 [22:48:36<129:25:58, 105.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.84s/it][A100%|██████████| 1/1 [01:42<00:00, 102.84s/it]
 15%|█▌        | 799/5198 [22:48:36<129:23:47, 105.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:42<00:00, 102.81s/it][A100%|██████████| 1/1 [01:42<00:00, 102.81s/it]
 15%|█▌        | 799/5198 [22:48:38<129:25:15, 105.91s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_plain_texts/shard_49
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:01<00:00, 121.23s/it][A100%|██████████| 1/1 [02:01<00:00, 121.23s/it]
[2024-06-30 18:15:42,778] [INFO] [logging.py:96:log_dist] [Rank 0] step=791, skipped=0, lr=[1.939079846018025e-05], mom=[(0.9, 0.999)]
steps: 791 loss: 0.8190 iter time (s): 121.242 samples/sec: 1.056

100%|██████████| 1/1 [02:02<00:00, 122.25s/it][A100%|██████████| 1/1 [02:02<00:00, 122.25s/it]

100%|██████████| 1/1 [02:02<00:00, 122.42s/it][A100%|██████████| 1/1 [02:02<00:00, 122.42s/it]

100%|██████████| 1/1 [02:02<00:00, 122.25s/it][A100%|██████████| 1/1 [02:02<00:00, 122.25s/it]

100%|██████████| 1/1 [02:02<00:00, 122.28s/it][A100%|██████████| 1/1 [02:02<00:00, 122.28s/it]

100%|██████████| 1/1 [02:02<00:00, 122.19s/it][A100%|██████████| 1/1 [02:02<00:00, 122.19s/it]
Checkpointing at shard 799

100%|██████████| 1/1 [02:02<00:00, 122.35s/it][A100%|██████████| 1/1 [02:02<00:00, 122.35s/it]

100%|██████████| 1/1 [02:02<00:00, 122.32s/it][A100%|██████████| 1/1 [02:02<00:00, 122.32s/it]
[2024-06-30 18:15:44,062] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step791 is about to be saved!
[2024-06-30 18:15:45,258] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step791/layer_00-model_states.pt...
[2024-06-30 18:15:47,931] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step791/layer_02-model_states.pt...
[2024-06-30 18:15:49,516] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step791/layer_08-model_states.pt...
[2024-06-30 18:15:49,703] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step791/layer_07-model_states.pt...
[2024-06-30 18:15:50,963] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step791/layer_05-model_states.pt...
[2024-06-30 18:15:53,998] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step791/layer_00-model_states.pt.
[2024-06-30 18:15:54,487] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step791/layer_06-model_states.pt...
[2024-06-30 18:15:59,985] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step791/layer_04-model_states.pt...
[2024-06-30 18:16:00,942] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step791/layer_03-model_states.pt...
[2024-06-30 18:16:01,429] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step791/layer_01-model_states.pt...
[2024-06-30 18:21:09,502] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step791/layer_03-model_states.pt.
[2024-06-30 18:21:09,832] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step791/layer_02-model_states.pt.
[2024-06-30 18:21:09,889] [INFO] [logging.py:96:log_dist] [Rank 1] Saving model checkpoint: /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step791/mp_rank_01_model_states.pt
[2024-06-30 18:21:09,889] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step791/mp_rank_01_model_states.pt...
[2024-06-30 18:21:09,928] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step791/layer_01-model_states.pt.
[2024-06-30 18:21:10,119] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step791/mp_rank_01_model_states.pt.
[2024-06-30 18:21:10,119] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step791 is ready now!
[2024-06-30 18:21:10,134] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step791/mp_rank_02_model_states.pt...
[2024-06-30 18:21:10,187] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step791/layer_07-model_states.pt.
[2024-06-30 18:21:10,233] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step791/mp_rank_06_model_states.pt...
[2024-06-30 18:21:10,593] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step791/mp_rank_02_model_states.pt.
[2024-06-30 18:21:10,593] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step791 is ready now!
[2024-06-30 18:21:10,614] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step791/mp_rank_06_model_states.pt.
[2024-06-30 18:21:10,614] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step791 is ready now!
[2024-06-30 18:21:10,712] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step791/mp_rank_00_model_states.pt
[2024-06-30 18:21:10,712] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step791/mp_rank_00_model_states.pt...
[2024-06-30 18:21:11,459] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step791/mp_rank_00_model_states.pt.
[2024-06-30 18:21:11,459] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step791 is ready now!
[2024-06-30 18:21:12,580] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step791/layer_04-model_states.pt.
[2024-06-30 18:21:13,215] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step791/mp_rank_03_model_states.pt...
[2024-06-30 18:21:13,356] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step791/mp_rank_03_model_states.pt.
[2024-06-30 18:21:13,356] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step791 is ready now!
[2024-06-30 18:21:37,208] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step791/layer_06-model_states.pt.
[2024-06-30 18:21:38,409] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step791/mp_rank_05_model_states.pt...
[2024-06-30 18:21:38,559] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step791/mp_rank_05_model_states.pt.
[2024-06-30 18:21:38,559] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step791 is ready now!
[2024-06-30 18:21:54,277] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step791/layer_05-model_states.pt.
[2024-06-30 18:21:54,578] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step791/mp_rank_04_model_states.pt...
[2024-06-30 18:21:54,794] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step791/mp_rank_04_model_states.pt.
[2024-06-30 18:21:54,795] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step791 is ready now!
[2024-06-30 18:21:54,983] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step791/layer_08-model_states.pt.
[2024-06-30 18:21:55,113] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step791/layer_09-model_states.pt...
[2024-06-30 18:21:56,144] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step791/layer_09-model_states.pt.
[2024-06-30 18:21:56,146] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step791/mp_rank_07_model_states.pt...
[2024-06-30 18:21:56,211] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/atuin/b207dd/b207dd11/LLaVA-PEFT_adapter_32_64_4_checkpoint/global_step791/mp_rank_07_model_states.pt.
[2024-06-30 18:21:56,211] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step791 is ready now!
 15%|█▌        | 800/5198 [22:56:52<273:00:59, 223.48s/it] 15%|█▌        | 800/5198 [22:56:50<271:52:08, 222.54s/it]Checkpoint saved using --- 372.18946862220764 seconds ---
 15%|█▌        | 800/5198 [22:56:50<271:50:24, 222.52s/it] 15%|█▌        | 800/5198 [22:56:50<271:47:01, 222.47s/it] 15%|█▌        | 800/5198 [22:56:50<271:49:24, 222.50s/it] 15%|█▌        | 800/5198 [22:56:50<271:58:44, 222.63s/it] 15%|█▌        | 800/5198 [22:56:53<271:47:39, 222.48s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_750
 15%|█▌        | 800/5198 [22:56:50<271:56:28, 222.60s/it]Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A

  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:00<?, ?it/s][A[A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.76s/it][A100%|██████████| 1/1 [01:23<00:00, 83.76s/it]
 15%|█▌        | 801/5198 [22:58:16<221:54:54, 181.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 18:23:22,362] [INFO] [logging.py:96:log_dist] [Rank 0] step=792, skipped=0, lr=[1.9388850294820995e-05], mom=[(0.9, 0.999)]
steps: 792 loss: 0.6037 iter time (s): 85.729 samples/sec: 1.493

100%|██████████| 1/1 [01:26<00:00, 86.04s/it][A100%|██████████| 1/1 [01:26<00:00, 86.04s/it]
 15%|█▌        | 801/5198 [22:58:16<222:01:43, 181.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.24s/it][A100%|██████████| 1/1 [01:26<00:00, 86.24s/it]
 15%|█▌        | 801/5198 [22:58:17<222:04:19, 181.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.38s/it][A100%|██████████| 1/1 [01:26<00:00, 86.38s/it]
 15%|█▌        | 801/5198 [22:58:17<222:04:32, 181.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.44s/it][A100%|██████████| 1/1 [01:26<00:00, 86.44s/it]
 15%|█▌        | 801/5198 [22:58:17<222:04:39, 181.82s/it]
100%|██████████| 1/1 [01:26<00:00, 86.48s/it][A100%|██████████| 1/1 [01:26<00:00, 86.48s/it]
 15%|█▌        | 801/5198 [22:58:17<222:04:54, 181.83s/it]
100%|██████████| 1/1 [01:26<00:00, 86.50s/it][A100%|██████████| 1/1 [01:26<00:00, 86.50s/it]
 15%|█▌        | 801/5198 [22:58:17<222:03:34, 181.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.52s/it][A100%|██████████| 1/1 [01:26<00:00, 86.52s/it]
 15%|█▌        | 801/5198 [22:58:19<222:04:38, 181.82s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_751
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:54<00:00, 114.75s/it][A100%|██████████| 1/1 [01:54<00:00, 114.75s/it]
 15%|█▌        | 802/5198 [23:00:11<197:27:17, 161.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 18:25:18,206] [INFO] [logging.py:96:log_dist] [Rank 0] step=793, skipped=0, lr=[1.9386899117606326e-05], mom=[(0.9, 0.999)]
steps: 793 loss: 0.5667 iter time (s): 115.013 samples/sec: 1.113

100%|██████████| 1/1 [01:55<00:00, 115.82s/it][A100%|██████████| 1/1 [01:55<00:00, 115.83s/it]
 15%|█▌        | 802/5198 [23:00:12<197:49:46, 162.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.75s/it][A100%|██████████| 1/1 [01:55<00:00, 115.75s/it]
 15%|█▌        | 802/5198 [23:00:12<197:49:34, 162.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.79s/it][A100%|██████████| 1/1 [01:55<00:00, 115.79s/it]
 15%|█▌        | 802/5198 [23:00:13<197:50:23, 162.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:55<00:00, 115.77s/it][A100%|██████████| 1/1 [01:55<00:00, 115.77s/it]
 15%|█▌        | 802/5198 [23:00:13<197:51:08, 162.03s/it]
100%|██████████| 1/1 [01:55<00:00, 115.79s/it][A100%|██████████| 1/1 [01:55<00:00, 115.79s/it]
 15%|█▌        | 802/5198 [23:00:13<197:49:48, 162.01s/it]
100%|██████████| 1/1 [01:55<00:00, 115.79s/it][A100%|██████████| 1/1 [01:55<00:00, 115.79s/it]
 15%|█▌        | 802/5198 [23:00:13<197:51:07, 162.03s/it]
100%|██████████| 1/1 [01:55<00:00, 115.79s/it][A100%|██████████| 1/1 [01:55<00:00, 115.79s/it]
 15%|█▌        | 802/5198 [23:00:15<197:50:25, 162.02s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_752

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.74s/it][A100%|██████████| 1/1 [01:36<00:00, 96.74s/it]
 15%|█▌        | 803/5198 [23:01:48<173:43:15, 142.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 18:26:54,676] [INFO] [logging.py:96:log_dist] [Rank 0] step=794, skipped=0, lr=[1.9384944929162236e-05], mom=[(0.9, 0.999)]
steps: 794 loss: 0.5621 iter time (s): 95.658 samples/sec: 1.338

100%|██████████| 1/1 [01:36<00:00, 96.42s/it][A100%|██████████| 1/1 [01:36<00:00, 96.42s/it]
 15%|█▌        | 803/5198 [23:01:49<173:46:23, 142.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.42s/it][A100%|██████████| 1/1 [01:36<00:00, 96.42s/it]
 15%|█▌        | 803/5198 [23:01:49<173:47:13, 142.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.40s/it][A100%|██████████| 1/1 [01:36<00:00, 96.41s/it]
 15%|█▌        | 803/5198 [23:01:49<173:46:32, 142.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.39s/it][A100%|██████████| 1/1 [01:36<00:00, 96.39s/it]
 15%|█▌        | 803/5198 [23:01:49<173:47:40, 142.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.40s/it][A100%|██████████| 1/1 [01:36<00:00, 96.40s/it]
 15%|█▌        | 803/5198 [23:01:50<173:47:26, 142.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:36<00:00, 96.48s/it][A100%|██████████| 1/1 [01:36<00:00, 96.48s/it]
 15%|█▌        | 803/5198 [23:01:50<173:47:46, 142.36s/it]
100%|██████████| 1/1 [01:36<00:00, 96.48s/it][A100%|██████████| 1/1 [01:36<00:00, 96.48s/it]
 15%|█▌        | 803/5198 [23:01:52<173:48:08, 142.36s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_753

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.14s/it][A100%|██████████| 1/1 [01:22<00:00, 82.14s/it]
 15%|█▌        | 804/5198 [23:03:11<151:43:40, 124.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 18:28:16,593] [INFO] [logging.py:96:log_dist] [Rank 0] step=795, skipped=0, lr=[1.938298773011568e-05], mom=[(0.9, 0.999)]
steps: 795 loss: 0.5581 iter time (s): 81.092 samples/sec: 1.578

100%|██████████| 1/1 [01:21<00:00, 81.89s/it][A100%|██████████| 1/1 [01:21<00:00, 81.89s/it]
 15%|█▌        | 804/5198 [23:03:11<151:37:33, 124.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.93s/it][A100%|██████████| 1/1 [01:21<00:00, 81.93s/it]
 15%|█▌        | 804/5198 [23:03:11<151:38:12, 124.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.91s/it][A100%|██████████| 1/1 [01:21<00:00, 81.91s/it]
 15%|█▌        | 804/5198 [23:03:11<151:36:41, 124.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.90s/it][A100%|██████████| 1/1 [01:21<00:00, 81.90s/it]
 15%|█▌        | 804/5198 [23:03:11<151:37:13, 124.22s/it]
100%|██████████| 1/1 [01:21<00:00, 81.88s/it][A100%|██████████| 1/1 [01:21<00:00, 81.88s/it]
 15%|█▌        | 804/5198 [23:03:11<151:37:00, 124.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.86s/it][A100%|██████████| 1/1 [01:21<00:00, 81.86s/it]
 15%|█▌        | 804/5198 [23:03:11<151:36:48, 124.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:21<00:00, 81.87s/it][A100%|██████████| 1/1 [01:21<00:00, 81.87s/it]
 15%|█▌        | 804/5198 [23:03:14<151:37:10, 124.22s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_754
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:38<00:00, 98.83s/it][A100%|██████████| 1/1 [01:38<00:00, 98.83s/it]
 15%|█▌        | 805/5198 [23:04:50<142:28:18, 116.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 18:29:56,277] [INFO] [logging.py:96:log_dist] [Rank 0] step=796, skipped=0, lr=[1.938102752109457e-05], mom=[(0.9, 0.999)]
steps: 796 loss: 0.5710 iter time (s): 98.862 samples/sec: 1.295

100%|██████████| 1/1 [01:39<00:00, 99.65s/it][A100%|██████████| 1/1 [01:39<00:00, 99.65s/it]
 15%|█▌        | 805/5198 [23:04:50<142:37:04, 116.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.73s/it][A100%|██████████| 1/1 [01:39<00:00, 99.73s/it]
 15%|█▌        | 805/5198 [23:04:51<142:38:43, 116.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.80s/it][A100%|██████████| 1/1 [01:39<00:00, 99.80s/it]
 15%|█▌        | 805/5198 [23:04:51<142:38:30, 116.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:39<00:00, 99.82s/it][A100%|██████████| 1/1 [01:39<00:00, 99.82s/it]
 15%|█▌        | 805/5198 [23:04:51<142:39:47, 116.91s/it]
100%|██████████| 1/1 [01:39<00:00, 99.82s/it][A
100%|██████████| 1/1 [01:39<00:00, 99.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A 15%|█▌        | 805/5198 [23:04:51<142:38:56, 116.90s/it]
100%|██████████| 1/1 [01:39<00:00, 99.86s/it][A100%|██████████| 1/1 [01:39<00:00, 99.86s/it]
 15%|█▌        | 805/5198 [23:04:51<142:39:59, 116.91s/it]
100%|██████████| 1/1 [01:39<00:00, 99.75s/it][A100%|██████████| 1/1 [01:39<00:00, 99.75s/it]
 15%|█▌        | 805/5198 [23:04:54<142:39:13, 116.90s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_755

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:23<00:00, 83.12s/it][A100%|██████████| 1/1 [01:23<00:00, 83.12s/it]
 16%|█▌        | 806/5198 [23:06:13<130:16:51, 106.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 18:31:19,291] [INFO] [logging.py:96:log_dist] [Rank 0] step=797, skipped=0, lr=[1.9379064302727794e-05], mom=[(0.9, 0.999)]
steps: 797 loss: 0.6244 iter time (s): 82.072 samples/sec: 1.560

100%|██████████| 1/1 [01:23<00:00, 83.01s/it][A100%|██████████| 1/1 [01:23<00:00, 83.01s/it]
 16%|█▌        | 806/5198 [23:06:13<130:11:46, 106.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.89s/it][A100%|██████████| 1/1 [01:22<00:00, 82.89s/it]
 16%|█▌        | 806/5198 [23:06:14<130:10:50, 106.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.89s/it][A100%|██████████| 1/1 [01:22<00:00, 82.89s/it]
 16%|█▌        | 806/5198 [23:06:14<130:11:12, 106.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.83s/it][A100%|██████████| 1/1 [01:22<00:00, 82.83s/it]
 16%|█▌        | 806/5198 [23:06:14<130:10:07, 106.70s/it]
100%|██████████| 1/1 [01:22<00:00, 82.87s/it][A100%|██████████| 1/1 [01:22<00:00, 82.87s/it]
 16%|█▌        | 806/5198 [23:06:14<130:10:58, 106.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:22<00:00, 82.89s/it][A100%|██████████| 1/1 [01:22<00:00, 82.89s/it]
 16%|█▌        | 806/5198 [23:06:14<130:10:44, 106.70s/it]
100%|██████████| 1/1 [01:22<00:00, 82.89s/it][A100%|██████████| 1/1 [01:22<00:00, 82.89s/it]
 16%|█▌        | 806/5198 [23:06:16<130:10:50, 106.71s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_756

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:30<00:00, 90.66s/it][A100%|██████████| 1/1 [01:30<00:00, 90.66s/it]
 16%|█▌        | 807/5198 [23:07:44<124:31:38, 102.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 18:32:50,686] [INFO] [logging.py:96:log_dist] [Rank 0] step=798, skipped=0, lr=[1.9377098075645195e-05], mom=[(0.9, 0.999)]
steps: 798 loss: 0.5242 iter time (s): 90.521 samples/sec: 1.414

100%|██████████| 1/1 [01:31<00:00, 91.29s/it][A100%|██████████| 1/1 [01:31<00:00, 91.29s/it]
 16%|█▌        | 807/5198 [23:07:45<124:31:44, 102.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.25s/it][A100%|██████████| 1/1 [01:31<00:00, 91.25s/it]
 16%|█▌        | 807/5198 [23:07:45<124:31:04, 102.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.22s/it][A100%|██████████| 1/1 [01:31<00:00, 91.22s/it]
 16%|█▌        | 807/5198 [23:07:45<124:31:01, 102.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.27s/it][A100%|██████████| 1/1 [01:31<00:00, 91.27s/it]
 16%|█▌        | 807/5198 [23:07:45<124:30:19, 102.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.34s/it][A100%|██████████| 1/1 [01:31<00:00, 91.34s/it]
 16%|█▌        | 807/5198 [23:07:45<124:31:26, 102.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:31<00:00, 91.29s/it][A100%|██████████| 1/1 [01:31<00:00, 91.29s/it]
 16%|█▌        | 807/5198 [23:07:46<124:31:37, 102.09s/it]
100%|██████████| 1/1 [01:31<00:00, 91.30s/it][A100%|██████████| 1/1 [01:31<00:00, 91.30s/it]
 16%|█▌        | 807/5198 [23:07:48<124:31:47, 102.10s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_757
Training on 128 of 128 sentences.


  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.72s/it][A100%|██████████| 1/1 [01:24<00:00, 84.72s/it]
 16%|█▌        | 808/5198 [23:09:09<118:12:53, 96.94s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 18:34:15,412] [INFO] [logging.py:96:log_dist] [Rank 0] step=799, skipped=0, lr=[1.9375128840477593e-05], mom=[(0.9, 0.999)]
steps: 799 loss: 0.5553 iter time (s): 83.986 samples/sec: 1.524

100%|██████████| 1/1 [01:24<00:00, 84.78s/it][A100%|██████████| 1/1 [01:24<00:00, 84.78s/it]
 16%|█▌        | 808/5198 [23:09:10<118:10:45, 96.91s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.81s/it][A100%|██████████| 1/1 [01:24<00:00, 84.81s/it]
 16%|█▌        | 808/5198 [23:09:10<118:10:21, 96.91s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.76s/it][A100%|██████████| 1/1 [01:24<00:00, 84.76s/it]
 16%|█▌        | 808/5198 [23:09:10<118:09:12, 96.89s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.75s/it][A100%|██████████| 1/1 [01:24<00:00, 84.75s/it]
 16%|█▌        | 808/5198 [23:09:10<118:09:26, 96.89s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.78s/it][A100%|██████████| 1/1 [01:24<00:00, 84.78s/it]
 16%|█▌        | 808/5198 [23:09:10<118:09:49, 96.90s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:24<00:00, 84.73s/it][A100%|██████████| 1/1 [01:24<00:00, 84.73s/it]
 16%|█▌        | 808/5198 [23:09:10<118:10:13, 96.91s/it] 
100%|██████████| 1/1 [01:24<00:00, 84.73s/it][A100%|██████████| 1/1 [01:24<00:00, 84.73s/it]
 16%|█▌        | 808/5198 [23:09:13<118:09:52, 96.90s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_758
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:51<00:00, 111.42s/it][A100%|██████████| 1/1 [01:51<00:00, 111.42s/it]
 16%|█▌        | 809/5198 [23:11:01<123:38:08, 101.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 18:36:07,774] [INFO] [logging.py:96:log_dist] [Rank 0] step=800, skipped=0, lr=[1.9373156597856765e-05], mom=[(0.9, 0.999)]
steps: 800 loss: 0.5488 iter time (s): 111.513 samples/sec: 1.148

100%|██████████| 1/1 [01:52<00:00, 112.46s/it][A100%|██████████| 1/1 [01:52<00:00, 112.46s/it]
 16%|█▌        | 809/5198 [23:11:02<123:50:47, 101.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.50s/it][A100%|██████████| 1/1 [01:52<00:00, 112.50s/it]
 16%|█▌        | 809/5198 [23:11:03<123:50:44, 101.58s/it]
100%|██████████| 1/1 [01:52<00:00, 112.58s/it][A100%|██████████| 1/1 [01:52<00:00, 112.58s/it]
 16%|█▌        | 809/5198 [23:11:02<123:53:11, 101.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.51s/it][A100%|██████████| 1/1 [01:52<00:00, 112.51s/it]
 16%|█▌        | 809/5198 [23:11:03<123:50:58, 101.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.52s/it][A100%|██████████| 1/1 [01:52<00:00, 112.52s/it]
 16%|█▌        | 809/5198 [23:11:03<123:51:31, 101.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:52<00:00, 112.49s/it][A100%|██████████| 1/1 [01:52<00:00, 112.49s/it]
 16%|█▌        | 809/5198 [23:11:03<123:51:00, 101.59s/it]
100%|██████████| 1/1 [01:52<00:00, 112.50s/it][A100%|██████████| 1/1 [01:52<00:00, 112.50s/it]
 16%|█▌        | 809/5198 [23:11:05<123:50:53, 101.58s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_759

  0%|          | 0/1 [00:00<?, ?it/s][ATraining on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.39s/it][A100%|██████████| 1/1 [01:26<00:00, 86.39s/it]
 16%|█▌        | 810/5198 [23:12:28<118:13:26, 96.99s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 18:37:33,932] [INFO] [logging.py:96:log_dist] [Rank 0] step=801, skipped=0, lr=[1.9371181348415456e-05], mom=[(0.9, 0.999)]
steps: 801 loss: 0.5923 iter time (s): 85.139 samples/sec: 1.503

100%|██████████| 1/1 [01:25<00:00, 85.96s/it][A100%|██████████| 1/1 [01:25<00:00, 85.96s/it]
 16%|█▌        | 810/5198 [23:12:28<118:06:25, 96.90s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.87s/it][A100%|██████████| 1/1 [01:25<00:00, 85.87s/it]
 16%|█▌        | 810/5198 [23:12:28<118:06:12, 96.89s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.00s/it][A100%|██████████| 1/1 [01:26<00:00, 86.00s/it]
 16%|█▌        | 810/5198 [23:12:29<118:07:23, 96.91s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.96s/it][A100%|██████████| 1/1 [01:25<00:00, 85.96s/it]
 16%|█▌        | 810/5198 [23:12:29<118:07:08, 96.91s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.99s/it][A100%|██████████| 1/1 [01:25<00:00, 85.99s/it]
 16%|█▌        | 810/5198 [23:12:29<118:07:36, 96.91s/it] 
100%|██████████| 1/1 [01:25<00:00, 85.96s/it][A100%|██████████| 1/1 [01:25<00:00, 85.96s/it]
 16%|█▌        | 810/5198 [23:12:29<118:07:15, 96.91s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:25<00:00, 85.96s/it][A100%|██████████| 1/1 [01:25<00:00, 85.96s/it]
 16%|█▌        | 810/5198 [23:12:31<118:07:32, 96.91s/it] Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_760
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.51s/it][A100%|██████████| 1/1 [01:26<00:00, 86.51s/it]
 16%|█▌        | 811/5198 [23:13:55<114:30:51, 93.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 18:39:00,934] [INFO] [logging.py:96:log_dist] [Rank 0] step=802, skipped=0, lr=[1.9369203092787376e-05], mom=[(0.9, 0.999)]
steps: 802 loss: 0.6067 iter time (s): 86.198 samples/sec: 1.485

100%|██████████| 1/1 [01:26<00:00, 86.95s/it][A100%|██████████| 1/1 [01:26<00:00, 86.95s/it]
 16%|█▌        | 811/5198 [23:13:55<114:28:00, 93.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.94s/it][A100%|██████████| 1/1 [01:26<00:00, 86.94s/it]
 16%|█▌        | 811/5198 [23:13:55<114:27:46, 93.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.98s/it][A100%|██████████| 1/1 [01:26<00:00, 86.98s/it]
 16%|█▌        | 811/5198 [23:13:56<114:29:20, 93.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:27<00:00, 87.00s/it][A100%|██████████| 1/1 [01:27<00:00, 87.00s/it]
 16%|█▌        | 811/5198 [23:13:56<114:28:24, 93.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 86.98s/it][A100%|██████████| 1/1 [01:26<00:00, 86.98s/it]
 16%|█▌        | 811/5198 [23:13:56<114:28:13, 93.94s/it]
100%|██████████| 1/1 [01:27<00:00, 87.00s/it][A100%|██████████| 1/1 [01:27<00:00, 87.00s/it]
 16%|█▌        | 811/5198 [23:13:56<114:29:22, 93.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [01:26<00:00, 87.00s/it][A100%|██████████| 1/1 [01:27<00:00, 87.00s/it]
 16%|█▌        | 811/5198 [23:13:58<114:28:37, 93.94s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_761
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:12<00:00, 132.21s/it][A100%|██████████| 1/1 [02:12<00:00, 132.21s/it]
 16%|█▌        | 812/5198 [23:16:07<128:33:15, 105.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A[2024-06-30 18:41:14,709] [INFO] [logging.py:96:log_dist] [Rank 0] step=803, skipped=0, lr=[1.9367221831607197e-05], mom=[(0.9, 0.999)]
steps: 803 loss: 0.5787 iter time (s): 132.922 samples/sec: 0.963

100%|██████████| 1/1 [02:13<00:00, 133.78s/it][A100%|██████████| 1/1 [02:13<00:00, 133.78s/it]
 16%|█▌        | 812/5198 [23:16:09<129:00:35, 105.89s/it]
100%|██████████| 1/1 [02:13<00:00, 133.64s/it][A100%|██████████| 1/1 [02:13<00:00, 133.64s/it]
 16%|█▌        | 812/5198 [23:16:09<128:57:46, 105.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:13<00:00, 133.62s/it][A100%|██████████| 1/1 [02:13<00:00, 133.62s/it]
 16%|█▌        | 812/5198 [23:16:09<128:58:45, 105.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:13<00:00, 133.71s/it][A100%|██████████| 1/1 [02:13<00:00, 133.71s/it]
 16%|█▌        | 812/5198 [23:16:09<128:59:22, 105.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:13<00:00, 133.63s/it][A100%|██████████| 1/1 [02:13<00:00, 133.63s/it]
 16%|█▌        | 812/5198 [23:16:09<128:58:38, 105.86s/it]
100%|██████████| 1/1 [02:13<00:00, 133.71s/it][A100%|██████████| 1/1 [02:13<00:00, 133.71s/it]
 16%|█▌        | 812/5198 [23:16:10<128:59:29, 105.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [02:13<00:00, 133.70s/it][A100%|██████████| 1/1 [02:13<00:00, 133.70s/it]
 16%|█▌        | 812/5198 [23:16:12<128:59:11, 105.87s/it]Loading dataset from /home/atuin/b207dd/b207dd11/LLaVA-PEFT_processed_dataset_with_images/shard_762
Training on 128 of 128 sentences.

  0%|          | 0/1 [00:00<?, ?it/s][A
  0%|          | 0/1 [00:00<?, ?it/s][A